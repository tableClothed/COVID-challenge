title,abstract,text,similarity
Internet-based surveillance systems for monitoring emerging infectious diseases,"Emerging infectious diseases present a complex challenge to public health offi cials and governments; these challenges have been compounded by rapidly shifting patterns of human behaviour and globalisation. The increase in emerging infectious diseases has led to calls for new technologies and approaches for detection, tracking, reporting, and response. Internet-based surveillance systems off er a novel and developing means of monitoring conditions of public health concern, including emerging infectious diseases. We review studies that have exploited internet use and search trends to monitor two such diseases: infl uenza and dengue. Internet-based surveillance systems have good congruence with traditional surveillance approaches. Additionally, internet-based approaches are logistically and economically appealing. However, they do not have the capacity to replace traditional surveillance systems; they should not be viewed as an alternative, but rather an extension. Future research should focus on using data generated through internet-based surveillance and response systems to bolster the capacity of traditional surveillance systems for emerging infectious diseases.","Emerging infectious diseases are of particular concern to public health. Emergence is driven by sociocultural, environmental, and ecological factors. 1 The vulnerability of people to emerging infectious diseases has been shown by the emergence of AIDS in the late 1970s, severe acute respiratory syndrome (SARS) in 2003, pandemic infl uenza H1N1 in 2009, and multidrug-resistant nosocomial pathogens, as well as the re-emergence of dengue, chikungunya, and malaria. Traditionally, eff ective disease surveillance is expensive and needs a formal public health network. 2 Such systems are maintained by most countries, to varying degrees. Data sources, surveillance methods, analytical approaches, and factors aff ecting these systems are varied and have been reviewed in detail elsewhere. 3, 4 Traditional, passive surveillance systems typically rely on data submitted to the relevant public health authority by physicians, laboratories, and other health-care providers; they provide information crucial to the eff ective functioning of health systems. 5 These systems can be com plex and expensive. Time and resource constraints, as well as a lack of operational knowledge of reporting systems, adversely aff ect the completeness of reporting, 6 resulting in an incomplete account of disease emergence. Furthermore, substantial lags between an event and its notifi cation are common; a result of late or failed reporting and the hierarchical structure of these systems. 7 The average delay from receipt to dissemination of data by traditional sentinel surveillance networks is roughly 2 weeks. 8 Internet availability and use has increased greatly in the past 10 years (fi gure 1). 9, 10 The availability of healthrelated information on the internet (of varying quality and legitimacy) has also changed how people seek information about health. 10, 11 These changes provide a new means to detect and monitor infectious diseases. The nature of emerging infectious diseases often limits the eff ectiveness of traditional surveillance systems. 12 Digital surveillance could improve both the sensitivity and timeliness of detection of health events. 13 We review recent studies that have exploited internet use and search trends to monitor two acute-onset viral illnesses of worldwide importance that have substantial seasonal and geographic variation: infl uenza and dengue. We critically analyse the eff ectiveness of monitoring internet data to track these diseases and discuss the advantages and limitations of this approach. Finally, we make recommendations for future research into these systems.

Digital surveillance attempts to provide knowledge of public health issues by analysis of health information stored digitally, as well as the distribution and patterns governing access to these data. Approaches to digital surveillance vary according to the media targeted. However, all exploit changes in behaviour related to information seeking, collection, storage, and communication pathways that have occurred with the development and increased availability of the internet and associated technologies.

Several surveillance systems use non-structured, eventbased, digital data. 14 The Global Public Health Intelligence Network (GPHIN)-developed by the Public Health Agency of Canada-automatically retrieves information about potential public health emergencies from news feed aggregators and distributes this information to public health agencies, including the WHO Global Outbreak Alert and Response Network. 2, 15 The eff ectiveness of this system was shown during the SARS outbreak; GPHIN detected SARS more than 2 months before the fi rst publications by the WHO. 2 Other systems-eg, HealthMap 16 and ProMED-mail 17, 18 -provide information about emerging public health problems by aggregating information about emerging diseases from various structured and non-structured data sources. These and other similar systems are reviewed elsewhere. 13, 14, 19 Internet use has increased consistently in almost every country. 20 Internet users in the USA alone generate 8 million queries for health-related information every day. 21 The increase in worldwide internet availability and use over the past 10 years, combined with these changes in health-seeking behaviour, has created new possibilities for the development of innovative surveillance systems. 9, 10, 22, 23 Although still very much in its infancy, analysis of digital data has been used to monitor communicable 2,24-33 and non-communicable diseases, 34, 35 as well as mental health, 36, 37 illegal drug use, 38 health policy impact, 39 and behaviours with potential health implications. 40 Numerous studies have sought to exploit online healthseeking behaviour to monitor disease incidence. Although these studies use diff erent data sources, they all rely on the premise that people who contract a disease will seek information about their condition from the internet and that incidence can be estimated by tracking changes in frequencies of searches for key terms. By monitoring search queries submitted to the search engine Yahoo!, Polgreen and colleagues 41 predicted increases in positive infl uenza cultures 1-3 weeks before their occurrence. Similarly, Hulth and co-workers 42 developed a model for estimating intensity and peak incidence of infl uenza in Sweden by monitoring queries submitted to the medical web site Vårdguiden. This model correlated closely with both data for infl uenza-like illness (R²=0·89) and laboratory-confi rmed cases of infl uenza (R²=0·90). A subsequent study showed this model to have good congruence with sentinel data over the course of the 2009 infl uenza H1N1 pandemic (r=0·88-0·90). 43 More recently, infl uenza incidence in China was estimated by assessment of searches submitted to Baidu (the most commonly used search engine in China). 44 This study reported a correlation of R²=0·96 between a composite search index (eight terms) and monthly Ministry of Health infl uenza reports. Furthermore, using a combination of Ministry of Health and Baidu data, the researchers produced accurate estimates (R²=0·95) of incidence 1-2 weeks before of Ministry of Health reports.

Google search queries also correlate highly with disease incidence. Historical logs of aggregated Google search queries-presented as normalised time seriesare publically available through Google Trends from Jan 1, 2004. These data are available by country, state, and city in the USA, but only at country-level for many other regions (especially low-income countries). Previously, Google off ered two user interfaces to access search reports: Google Trends and Google Insights for Search, which were merged in September, 2012. 45 Carneiro and Mylonakis 24 used Google Trends to analyse worldwide search frequency for the term ""bird fl u"". They reported an increase in search frequency between 2005, and 2006, coinciding with the spread of avian infl uenza from China to Turkey. Other studies reported the use of Google search data to monitor the frequency of searches for manually selected terms related to infl uenza in Chinese, 46 Spanish, 31 and French. 28 These studies reported high degrees of correlation, which shows the potential application of this technology in languages other than English. Ginsberg and colleagues 47 used an automated approach to select search terms from Google search logs with the greatest correlation with the US Infl uenza Sentinel Provider Surveillance Network of the US Centers for Disease Control and Prevention (CDC). The terms were then used to develop a model for monitoring infl uenza activity. Estimates from the model correlated highly with regional Centers for Disease Control and Prevention data (r=0·80-0·96, nine regions) and accurately estimate incidence of infl uenza-like illness 1-2 weeks before surveillance reports. 47 An online infl uenza surveillance tool-Google Flu Trends-is based on the model of Ginsberg and coworkers and now includes 29 countries.

To date, two publications have reported the use of internet search data to estimate incidence of dengue. Chan and colleagues 48 used a similar method to Ginsberg and coworkers 47 to create models of dengue transmission for Bolivia, Brazil, India, Indonesia, and Singapore. Correlations between model estimates and holdout surveillance data (data excluded from the model, used for validation) were high for all countries (r=0·83-0·99). These models have been used to develop a free, publically available online resource for dengue surveillance: Google Dengue Trends. Althouse and colleagues 49 used Google Insights for Search to monitor searches for dengue-related terms and applied these results to step-down linear regression models for Bangkok (Thailand) and Singapore. Both models showed a high degree of correlation with surveillance data (R²=0·95 for Bangkok and 0·94 for Singapore). Additionally, this study developed support vector machine 50 and logistic regression models to predict periods of high dengue incidence. Area-under-the-receiveroperating-characteristic-curve, using the 75th percentile, was 0·960 for Bangkok and 0·906 for Singapore according 

to the support vector machine model compared with 0·960 and 0·896 respectively for the logistic regression model.

Several studies have compared the performance of Google Flu Trends with national data for infl uenza-like illness. Google Flu Trends was visually compared with surveillance data for Australia 51 53 These fi ndings accord with the results of Hulth and colleagues 43 and Valdivia and colleagues 54 who showed that Google Flu Trends correlated strongly with estimates of infl uenza incidence and peak incidences produced from data collected by sentinel physician networks throughout Europe. Finally, Google Flu Trends correlated highly with the Electronic Surveillance System for the Early Notifi cation of Community-Based Epidemics (ESSENCE; a syndromic surveillance system run by the US Department of Defence; r=0·88) 55 and with infl uenzalike illness estimates produced for Flanders, Belgium, by the Great Infl uenza Survey (a weekly, online infl uenza survey; r=0·62-0·94). 56 Traditional infl uenza surveillance systems commonly monitor incidence with virological data, rather than infl uenza-like illness. Data from Google Flu Trends was highly correlated with data from the US Infl uenza Virologic Surveillance System (r=0·72); 57 however, this correlation was lower than that reported for Google Flu Trends and CDC infl uenza-like illness data (r=0·94). Google Flu Trends estimates have been reported to correlate highly with laboratory-confi rmed infl uenza at a provincial and city level. Malik and colleagues 12 reported the correlation between weekly counts of laboratoryconfi rmed H1N1 infl uenza cases in Manitoba, Canada, and Google Flu Trends data during the 2009 infl uenza pandemic (R²=0·69; 2 week lag). Similarly, Google Flu Trends had a high level of congruence with virology data from a Baltimore hospital (adult r=0·88; paediatric r=0·72). 58 Dugas and coworkers 58 noted that Google Flu Trends correlated well with paediatric emergency department crowding measures, leading them to suggest that Google Flu Trends could be used for strategic management of emergency department resources. The potential applications of Google Flu Trends data to strategic allocation of resources and priority setting is further shown by Patwardhan and Bilkovski, 59 who compared sales of four drugs commonly prescribed for treatment of infl uenza with Google Flu Trends and CDC ILINet data; aggregate correlation between Google Flu Trends and prescription sales was r=0·92 .

Any changes to the status quo of internet search behaviour could alter how well Google Flu Trends models actual infl uenza incidence. Loss of resolution might occur as a result of media-driven interest or through other events that change search behaviour. 43, 49, 57, 58, 60, 61 Google Flu Trends accounts for changing search behaviour by updating the model each year to best represent reference surveillance data. 62 Despite this precaution, a loss of resolution was reported to have occurred during the 2009 H1N1 infl uenza pandemic. 53 

Studies have predominantly focused on retrospective assessment of the performance of Google Flu Trends. However, almost real-time disease tracking can be done by application of Google Flu Trends data to a seasonspecifi c compartmental mathematical model. 63 Google Flu Trends data can also be used for early detection of epidemics. 64 Pervaiz and colleagues applied various algorithms to Google Flu Trends data to develop early epidemic detection systems capable of generating actionable alerts. Although this study did not identify a single best method, it showed the potential use of Google Flu Trends data in this manner. Zhou and coworkers 65 have developed a system to predict epidemic alert levels from daily Google Trends data. Hidden Markov modelbased methods predicted infl uenza alert levels in realtime with 97·7% accuracy and provided an indication of infl uenza activity up to 4 weeks ahead of the release of CDC reports. In another recent study, ensemble adjustment was used to assimilate Google Flu Trends data into a humidity-driven compartmental mathematical model, enabling real-time predictions of peaks to be made more than 7 weeks in advance of their occurrence. 66 Finally, using a negative binomial generalised autoregressive moving average model-which included Google Flu Trends data as a secondary variable-Dugas and colleagues 67 predicted weekly infl uenza cases at a medical centre with a high degree of accuracy (83% of estimates were within seven cases).

These models are promising and, overall, Google Flu Trends seems to provide timely and accurate estimates of infl uenza-like illness and laboratory-confi rmed infl uenza. However, methods to integrate this information into existing surveillance systems need to be developed. 55 Scarpino and colleagues 68 postulated that the predictive power of the Texas ILINet could be improved by use of a smaller set of carefully chosen sentinel providers. Additionally, they investigated the potential of incorporating Google Flu Trends data into the network as a virtual provider. Google Flu Trends was reported to have a high degree of correlation with the ILINet in Texas (R²=0·77 at a 0 week lag). It was the most informative provider, matching the predictive performance of an optimised network of 44 sentinel providers.

The power of social media as both a source of information and as a means of disseminating information is increasingly recognised in public health. 69, 70 Corley and colleagues 71 have proposed that infl uenza incidence could be estimated by tracking use of key terms in web and social media. They analysed the frequency of English language blog posts that contained the terms ""infl uenza"" or ""fl u"" and compared these with CDC ILINet data. Correlation was r=0·63 for this study and r=0·55 in a subsequent study with an extended dataset. 72 Microblogs (such as Twitter) were not included in these studies. Collier and coworkers 73 used supervised learning to categorise expressions from Twitter messages into fi ve infl uenza-related categories and correlated these expressions with CDC data for positive infl uenza A H1N1 tests. Correlations in this study (r=0·58-0·67) were similar to those for Corley and colleagues. 71, 72 Chew and Eysenbach 74 sorted Twitter posts containing terms related to infl uenza A H1N1 into groups describing ""personal experiences"" or ""concern"" and compared these with H1N1 incidence rates in the USA. Correlations were r=0·77 for ""personal experiences"" and r=0·66 for ""concern"". These correlations are not as high as those reported for approaches based on internet search queries. However, Lampos and Cristianini 75 reported correlations of up to r=0·933 for their analysis of infl uenza created with a supervised learning framework compared with infl uenza-like illnesses reported by the UK Health Protection Agency. They concluded that a supervised learning framework is a suitable method for selection of features for use in digital surveillance systems. Culotta 76 reported that the accuracy of estimates could be improved by use of a document classifi cation component; they reported correlations of up to r=0·97.

Google Flu Trends usually showed an increase of infl uenza incidence 0-2 weeks before traditional systems. Internet-based surveillance systems circumvent the bureaucratic structure of traditional systems. Furthermore, they target a diff erent section of the community to traditional surveillance systems. Zeng and Wagner's 77 model of patient behaviour during epidemics identifi es four phases in health-care seeking: recognition of symptoms, interpretation of symptoms, representation of illness, and seeking treatment. Traditional surveillance systems only source data from people seeking treatment. Internet-based surveillance systems access people from not just the fi nal phase, but also the earlier interpretation of symptoms and representation of illness phases. 48 However, internet-based surveillance systems are limited to people who seek health-related information on the internet (or proxies, such as parents or carers of sick children). Despite this limitation, they can capture many cases. Attrition during disease pathogenesis or healthseeking pathways is both high and cumulative-results of a study done in rural Cambodia showed that 67% of cases of haemorrhagic fever were treated at home, rather than in a health facility; thus, a health-care-based surveillance system would miss 67% of information before it even becomes accessible. 78 Systems that target points earlier in surveillance will produce more timely information. For an infl uenza epidemic with a 20% infection rate, 10% clinical attack rate, 2% case hospital admission rate, and 0·1% symptomatic case fatality rate, 79 the fraction of the population assessable by an internet-based surveillance system (7488 people per 100 000 patients) would be nearly ten-times that of a traditional system (750 people per 100 000 patients), for a population with the internet use of an average highincome country (76·8%; fi gure 2). 9 Internet-based surveillance systems work best for large populations 24 and their use can be limited by national infrastructure (fi gure 3). Although the fraction of people assessable with an internet-based system in the average low-income country (30·7% internet access) is only 2993 people per 100 000 patients (fi gure 2), this fraction still exceeds that of a traditional surveillance system (750 people per 100 000 patients). The number of people who have access to the internet is not the only relevant factor. Internet use and health-seeking behaviour vary between diff erent sectors of the community. 23, 80 The accuracy of national Google Flu Trends estimates is positively correlated with the proportion of the population who use the internet to obtain health-related information. 54 However, large discrepancies exist between availability and uptake of the internet, and seeking health-care information as a proxy for disease has biases stemming from unequal use and access. 20 The spatial resolution of Google Flu Trends (and Google Trends) is improving. At present, Google Flu Trends off ers some city-level estimates of infl uenza incidence in the USA but probably has neither the sensitivity nor spatial resolution necessary to detect small, localised outbreaks. 12 Spatial resolution is limited by the level of data aggregation and search volume; Review resolution should improve over time as overall internet access increases and the internet becomes more widely accepted as a source of health-based information. 54 Results of these systems should also be interpreted carefully. Although internet-based surveillance systems seem to have high correlation with traditional surveillance systems, overall correlations could hide short-term periods of high variance. 62 Translation of internet-based data into an accurate, meaningful, and useful format is a challenge. Bias introduced by self-reporting and media-driven interest might be the biggest confounder of internet-based surveillance systems. Targeting microblogs has the potential to track, not just disease activity, but also related community concerns and perceptions. 73 However, the frequency of posts on social media is generally accepted to be a function of personal experience and perception of what an individual believes the ir friends and followers would fi nd interesting, rather than a true refl ection of the occurrence of an event. 81 Similarly, the media drive search frequency. An increase in searches for ""bird fl u"" occurred in the USA between 2005 and 2006, despite no avian infl uenza being detected; this trend was attributed to media-driven interest about the infl uenza outbreak aff ecting Asia at the time. 24 A similar occurence was reported for dengue-related searches in India in 2006; an unusually large spike in searches was attributed to news that a member of the prime minister's family had been admitted to hosptial for dengue. 48 To reduce the eff ect of media-driven searches, the Google Dengue Trends model replaces spikes that exceed the mean of the previous 4 weeks by fi ve SDs with an imputed value. 48 Mediadriven behaviour does not exclusively aff ect internetbased surveillance systems. On April 26, 2009, the US CDC declared a national public-health emergency in response to the emerging H1N1 pandemic; the following week was termed fear week. 61 Despite state-wide viral surveillance data showing little infl uenza activity, emergency department patient volumes increased substantially. A similar trend occurred in a Baltimore paediatric emergency department. 58 Because changes in Google Flu Trends over this period correlated with the increase in emergency department patient volumes, the investigators suggested that Google Flu Trends could have a role in planning emergency department surge capacity; 58 rather than representing infl uenza incidence, Google Flu Trends identifi ed public perceptions of the threat of infl uenza and predicted the associated increase in health-care demand.

Unlike systems that rely on input from health-care practitioners or laboratories, internet-based surveillance instruments are unlikely to become overwhelmed during a pandemic and, because they are automated, are available year-round (contingent on suffi cient search volume), whereas traditional networks might only operate seasonally. 82 These internet-based systems could be of particular use in countries with poorly developed traditional surveillance systems. 52 However, implementation of such systems in these countries is fraught with diffi culties. Internet-based surveillance systems work on the premise that disease incidence correlates with frequency of information-seeking using specifi c terms. Textual information can be diffi cult to classify and interpret 83 and accuracy might be heavily aff ected by cultural nuances, language shifts, and use of colloquialisms or even memes. The model of Collier and coworkers 73 needed a fi lter to reduce the eff ect of terms such as ""Bieber fever"" (which refers to infatuation with Canadian pop musician Justin Bieber) on the keyword of interest, ""fever"". Changes to search behaviours and information-seeking practices will aff ect the performance of these models; 62 furthermore, such changes are unlikely to occur uniformly. The re-emergence of infectious diseases with similar clinical presentations-eg, chikungunya in dengue-endemic areas-also presents a diffi culty. 48 Models should be designed for a specifi c system (country or region) and be validated against reference data before they are used to guide health policy or action. As such, they cannot replace traditional surveillance. 42 The problem of privacy has been raised by several researchers. 2, 48, 83 For ethical reasons, data are de-identifi ed or-in the case of data from Google-aggregated before public release, precluding identifi cation of the source of specifi c posts or searches. Although not a problem in itself, this process could make interpretation diffi cult. Content cannot be connected with individuals and care should be taken not to commit an ecological fallacy-to make inferences about the characteristics of individuals based on aggregate data. 36 Finally, the security of health information is an imperative. 84 Google Flu Trends and Google Dengue Trends are operated by the philanthropic arm of Google, which is a publicly listed company. Although these services are freely available, Google does not release the search terms used in the algorithms; caution is urged in relying too heavily on closed-source data that are under the control of a multinational company.

Few studies have explored how to translate internetbased surveillance systems into a public health response. Search queries submitted to Vårdguiden have been used to develop an automated system for generation of reports about epidemiological trends. 85 GET WELL (Generating Epidemiological Trends from WEb Logs, Like) extracts search queries from Vårdguiden logs, aggregates the data (weekly), and produces time-series graphs. Additionally, the system enables custom statistical analyses to be integrated; this function is routinely used for norovirus and infl uenza. GET WELL is used by Swedish Institute for Infectious Disease Control in conjunction with traditional surveillance networks to identify emerging concerns and to focus epidemiological investigations.

The potential for internet-based surveillance systems to revolutionise emerging infectious disease surveillance was shown by Scarpino and colleagues. 68 They presented a method for optimisation of sentinel surveillance networks that enabled integration of Google Flu Trends into the network as a virtual provider (enabling it to function as a sentinal provider reporting infl uenza-like illness within the community). Google Flu Trends alone explained roughly 60% of infl uenza-associated hospital admissions in Texas; which is equivalent to the performance of an optimised sentinel network with 44 providers (R²=0·63). Furthermore, Google Flu Trends outperformed the 2008 Texas ILINet which drew information from 82 providers (R²=0·57). An optimised network of 82 providers outperformed Google Flu Trends (R²=0·77); however, the best predictive performance was achieved by optimised hybrid networks, which allowed use of Google Flu Trends as a virtual provider. Allowing Google Flu Trends as a virtual provider in a network of 82 providers increased predictive performance by a further 12·5% (R²=0·90). 68 These studies show potential applications of internet-based surveillance systems in bolstering traditional surveillance system capacity and guiding public health action. However, the routine integration of non-traditional, unstructured, internetbased data into existing surveillance systems will necessitate a change in the structure and rhetoric of units responsible for surveillance if it is to be eff ectively translated into public health action. 86

To date, most studies of internet-based surveillance systems are retrospective analyses of performance; the prospective performance of these systems needs to be assessed. Future studies should not only focus on development of new detection methods nor on application of these methods to new diseases, but they should also explore ways to integrate these approaches into existing systems. 55 In doing so, care must be taken to ensure that new systems add to the capacity of old ones. The potential application of internet-based surveillance systems is not restricted to surveillance. They can also be strategic instruments for resource management and allocation, 58, 59 which warrants further investigation. Finally, despite the potential of internet-based surveillance systems, they No data available <20% 20-40% 40-60% 60-80% >80%

have not been applied with a global focus. Strategies for surveillance of infectious diseases have been criticised for focusing too heavily on high-income countries. 87 New infectious diseases emerge all over the world and their emergence is aff ected by many sociocultural, economic, environmental, and ecological factors. 1 The international nature of emerging infectious diseases, combined with the globalisation of travel and trade, have increased the interconnectedness of all countries. Strategies to detect, monitor, and control emerging infectious diseases should recognise this change-these diseases are a global concern. The potential to develop global surveillance systems for emerging infectious diseases that use internet-based data should be explored.

Assessment of internet queries for surveillance of emerging infectious diseases is a new concept that has been applied with promising results. These systems are appealing from a logistical, economical, and epidemiological standpoint. Internet-based systems are intuitive, adaptable, operate in almost real-time and, once established, are cheap to operate and maintain. 12 Furthermore, these systems do not rely on the healthcare system to provide and analyse data, or a government to disseminate information and advise the international community of emerging concerns-all limitations of traditional surveillance systems. However, internet-based surveillance does not provide an alternative to traditional surveillance systems. Rather, these systems are an extension of traditional systems. The societal eff ect and extent of spread of infectious diseases within a community cannot be measured by any one surveillance system. 43 Surveillance systems should be fl exible, built with models that incorporate several means of collecting information, and integrate information from other sources to create a comprehensive understanding of and approach to addressing emerging problems. 86 Further more, addressing emerging infectious diseases is con tingent on their recognition as global, rather than regional, issues. A global response requires concerted international approaches to strengthen the capacity of emerging infectious diseases surveillance systems worldwide. Future research needs to focus on how to use internet-based surveillance systems to complement existing systems.

WH developed the original idea for this Review. The structure of the Review was developed by WH and GJM. GJM did the literature search, wrote the fi rst draft, and created tables and fi gures. WH produced the map. WH, ACAC, and GMW provided editorial advice on the report and the fi nal version was approved by all authors.

We declare that we have no confl icts of interest.

We searched Medline (via PubMed) and Web of Science with the following search terms: ""digital disease detection"" ""Google Flu Trends"", ""Google Insights"", ""Google Trends"", ""infodemiology"", ""infoveillance"", ""real-time disease surveillance"", and ""syndromic surveillance"". We also did searches with the terms ""dengue"", ""infectious"", OR ""infl uenza"" AND ""early warning"", ""Google"", ""internet"", ""search engine"", ""social media"", ""Twitter"", ""Facebook"", OR ""web"". Finally, we did searches for the terms ""internet"" OR ""web"" AND ""disease surveillance"" OR ""disease detection"". To be eligible for inclusion, studies needed to be peer reviewed, describe the use of internet-search metrics or social media data for surveillance of infl uenza or dengue, and assess performance of this surveillance approach by comparing it with data from traditional surveillance approaches. Results were restricted to those published in English between Jan 1, 2008, and June 30, 2013. The appendix shows the publications that fi t the inclusion criteria.

See Online for appendix

",0.8078308232755516
ScienceDirect Development of the electronic surveillance monitoring system on web applications,"This paper presents the electronic surveillance monitoring system (ESMS) via the web based application used especially for the health sector. The system is created for three purposes, the alert function for the surveillance and rapid response team (SRRT), the monitoring for inspection and evaluation, and the back-office report. With the import and export functions that are capable to retrieve electronic health record and edit the R506 and R507 data, the SRRT and local team can easily set up and manage their resources. The GPS function helps care takers to identify the geographical data for any countermeasure and action. The program is designed to submit reports automatically to the Ministry of Public Health (MOPH). The SRRT module can operate in both online and off-line conditions.","To achieve the goal for the total health care, World Health Organization (WHO) suggests four health services: the continuum of care, the health promotion, the disease prevention, and the palliative care service. These services are the main key success factor for the concept of health for all and all for health. The concept of health for all basically covers the primary health care and universal health coverage 1 . The ideas for responsiveness, efficiency, accessibility and availability are included. On the other hand, the concept of all for health is focused on health literacy, social and financial risk. WHO experts also recommended the care takers to concentrate their additional efforts on surveillance reports and epidemiological surveys in the community level, before moving to the hospital process 2,3 . Both health promotion and the disease prevention require the multidisciplinary team, which combines staffs such as physicians, epidemiologists, nurses, and village head. Stakeholders from hospital levels and community levels must operate together to overcome the diseases under surveillance 4 .

In additional to take a countermeasure from the cause of outbreak, the Ministry of Public Health (MOPH) regulates the protocols and establishes the surveillance and rapid response team (SRRT). SRRT consists of local staffs from MOPH, health volunteer, and community head. When the disease is found either in a hospital or a community, a SRRT team will go to investigate and report back to the hospital and the department of disease control (DDC) at MOPH. All activities, processes and evidences including the outcome must be measured and responded back to headquarter in the sub-region within 72 hours. Moreover according to the guideline, several reports from SRRT and teams must be submitted within 1-3 days to avoid the repeated cycle 5 .

Depending on the situation and disease, some surveillance reports are required to daily process from the SRRT to DDC, where some are weekly. For example the case report for diseases under surveillance 506 and 507 (R506 and R507) is daily requested. Serious epidemiology are required to monitor and response immediately such as Middle East respiratory syndrome coronavirus (MERS-CoV) and swine flu. All infected states must be presented to the centers disease control and prevention (CDC), WHO as agreement in MOU. However, these protocols and reports contains many different sub-system parts in which paper-based documents are basically used, and thus it becomes very difficult and complicated to process and share the data. Many have been informally done and handled carelessly, and thus no evidence could be found or confirmed.

As reports have to send to different departments and organizations, this is a difficult task for the SRRT and epidemiologist teams to catch up with their routine. Many times they fail to process due to the short of mandate. Therefore, for better prevalence and prevention for the surveillance team, this research aims to design the system that can monitor, track, and alert the SRRT team along with other necessary functions such as submitting reports in order to fill the gap and solve the above problems.

The ESMS is an electronic surveillance program designed by using web-based application to connect a SRRT, care providers and epidemiologist teams, and to process all protocols and documents with electronic forms. The concept of the program is to present four modules, the monitoring system, the alert and warning function, the job task system, and the report section. The existing processes and flows have been analyzed. The documents and files used for each process and the types of information are evaluated. The flow starts when the case is found either by a patient visit or a report. Warning and surveillance requests are issued from the epidemiologist team to three local organizations, SRRT, DCC, and municipality from Ministry of Interior (MOI). The case reports from sub-district and the field team are used to identify the priority of problem areas. If outbreak is contaminated, the final report will be sent to the provincial public health office and National Health Society Organization (NHSO). GIS and the webbased programming are added in order to determine the event location and abilities to retrieve the information.

As the design aims to replace the paper-based forms, new electronic record forms were designed for the SRRT and community health care team. All ESMS dataset of patients in the epidemic and surveillance services were simplified based on the process and data flow of R506 and R507 standard formats. All details were collected and analyzed in order to verify the problems and gaps between each informal process, and also to determine the informal documents such as Facebook, Line or Whatsapp. Moreover the connections between the data recorded in their processes were reorganized to minimize the under-coverage problems from the case report. Other problems such as when pandemic was subsided, OPD and IPD nurses only make a direct call to social medicine section for the patient that were sent for PCR were carefully considerate. The new dataset regarding to the new flow and stakeholder were listed as shown in Fig. 1 . Qualitative attributes such as simplicity, flexibility, and stability of the new system were verified and compared. In addition the stage, in which sample was send for the laboratory test, was modified to match the requirement from the MOPH headquarter. Instead of having only two laboratory stages, result positive and result negative, the result waiting was added as the third stage. This third stage simply put an ease to the care taker team as it took time for the department of medical science to analyze the simple being sent. Authority for each monitoring process were required as security. This program was designed to be able to import and export electronic health record (EHR) database module from hospital information system (HIS) and the surveillance documents R506 and R507. The new system flow was aimed to improve the completeness and quality of the report and information in the database.

The experiment results showed that the ESMS has abilities to help SRRT and the community team in the 8th health region. It successfully demonstrated four potentials for a better process as it reduces time and improves an overall performance by taking out the duplicated and informal documents. Many informal processes and documents such as using the social network were reduced. The results from SRRT and surveillance team indicated that with this system the contamination is easier to achieve. As the program allowed the team to manage and operate their work. With the data entry function that could select staff tasks along with their area of responsibility that matched the available resources, provincial public health staffs easily determine and set up the active field team according to the outbreak level. With the HIS-import function, the ESMS is able to fill out the patient forms in a shorter time and thus reduce the mandate and workload for the SRRT and back office.

Moreover, it showed the system effectiveness by warning the local team for data completion of the requested area, and reminding the DDC to analyze the laboratory test. The alert massage also set to pop-up when information was missing such as the number identification. This function helped a local team and care provider not to miss typing patient information. The GPS pointed out the demographical data in the event case. The program sent a report back to DDC and region health office in the csv format. Fig. 2 displays the items and functions in the ESMS report module as the dashboard style. All reports from each hospital using this program can successfully sent directly to the provincial public health office, but fail to deliver to National Health Society Organization (NHSO) due to the new data format. 

This ESMS can basically improve an overall performance by enhancing the electronic data into their protocol. The system reduced the human error and usage time from requiring and filling reports from different subsystems. The web application also provided a convenient way to access, edit, and modify data. This system checked null and error in the form before submitting a file which contains the surveillance reports from all hospitals in the 8 th health region to MOPH and other health organization. The reports generated from this program were mostly the csv format as agreement from the DDC. This saved the back-office team from the troubles as filling documents from the paperbased system was one of the toughest issues due to differences in types and formats. The simplified forms for SRRT and GPS helped the district health officer to manager their team and verify their performance.

",0.794128486283745
BMC Public Health Beyond traditional surveillance: applying syndromic surveillance to developing settings -opportunities and challenges,"Background: All countries need effective disease surveillance systems for early detection of outbreaks. The revised International Health Regulations [IHR], which entered into force for all 194 World Health Organization member states in 2007, have expanded traditional infectious disease notification to include surveillance for public health events of potential international importance, even if the causative agent is not yet known. However, there are no clearly established guidelines for how countries should conduct this surveillance, which types of emerging disease syndromes should be reported, nor any means for enforcement.","In this paper, we review examples of these novel applications in the detection of vector-borne diseases, foodborne illness, and sexually transmitted infections. We hope to demonstrate that syndromic surveillance in its basic version is a feasible and effective tool for surveillance in developing countries and may facilitate compliance with the new IHR guidelines.

All countries, whether high or low resourced, need sensitive disease surveillance systems for the early detection and monitoring of outbreaks. Syndromic surveillance, or the use of near ""real-time"" data and automated tools to detect and characterize unusual activity for further public health investigation, has been used in the United States and many other countries to augment traditional surveillance. For the purposes of this debate, we propose an expanded definition of syndromic surveillance to include the use of data on pre-diagnostic clinical syndromes rather than confirmed cases of specific diseases. The use of pre-diagnostic data and statistical algorithms aims to detect epidemics earlier than traditional surveillance based on reporting from laboratories and healthcare facilities, including atypical presentations of severe disease [1] . In 2003, over 100 different US health jurisdictions used syndromic surveillance to augment their public health surveillance [2] . In addition, several countries have used syndromic surveillance for the early detection and response to diseases of public health importance.

Despite this widespread use, syndromic surveillance is meant to enhance rather than replace traditional surveillance. An Institute of Medicine study concluded that a balance is needed between strengthening the proven approach of traditional surveillance and innovative surveillance systems [3] .

In many developing countries, surveillance is limited due to the lack of a robust public health or laboratory infrastructure; however, the revised International Health Regulations [IHR] , which entered into force for 194 World Health Organization [WHO] member states in 2007, require the reporting of public health emergencies of potential international concern even if the disease agent is unknown, such as for a previously unknown disease or a known disease presenting in more severe form [1, 4] . Syndromic surveillance, just as in the developed world, can augment traditional surveillance in developing countries [1] .

Syndromic surveillance often involves automated electronic reporting and statistical algorithms that sometimes require a complex information technology infrastructure. However, syndromic surveillance does not need to be highly computerized or technical; its tools can be simple, using few technological or human resources, and can complement existing surveillance programs [5] .

An early example of ""low technology"" syndromic surveillance is the use of acute flaccid paralysis (AFP) as the syndromic flag for poliomyelitis. The syndrome is infrequent and may detect an excess of cases of poliomyelitis in a timely fashion by comparing observed rates of AFP to expected rates [6, 7] . Nonetheless, syndromic surveillance can detect outbreaks of disease that do not fall into current WHO case classifications, which is particularly important for emerging diseases, or diseases with severe clinical presentations with undetermined diagnoses, such as the Severe Acute Respiratory Syndrome [SARS] outbreak of 2002-2003.

Since resources for surveillance are scarce in many countries, compounded by high rates of staff turnover and difficulties with Internet access and other communication tools, syndromic surveillance systems in low resourced countries need to be simple and build on prior work. The WHO open-source systems for surveillance are accessible to countries and technological assistance can be provided [5] . This paper will review the background for the IHRs and their application to syndromic surveillance, and review examples of syndromic surveillance programs that are currently being used in developing countries.

Given the recent concern for pandemics such as SARS and highly pathogenic avian influenza [H5N1], global and regional surveillance should be built on the concept of integrated surveillance. Prior to their revision, the IHR mandated reporting of only three diseases to the WHO: cholera, plague, and yellow fever. A revision of the IHR undertaken in 1995 was finalized in 2005 [4] . The revised IHR address the need for strengthening of disease surveillance by modifying disease lists to include syndromes for diseases of epidemic potential, and recommend the establishment of mechanisms for reporting outbreaks of major public health importance and the development of early warning surveillance systems. The IHR now include reporting by all countries for poliomyelitis, smallpox, human influenza caused by a new subtype, SARS, cholera, plague, yellow fever, viral hemorrhagic fevers, West Nile virus [WNV] , and other diseases of regional concern such as meningococcal disease and dengue [4, 8] .

Annex I, part A.4 (a) of the revised IHR states that ""state parties are to develop the capacity to detect events involving disease or death above expected levels for the particular time and place in all areas within the territory of the State Party,"" providing impetus for countries to improve their broad based public health surveillance infrastructure. IHR 2005 expands upon the previous IHR by broadening the scope of public health reporting, demanding improved surveillance and response at the country level, and strengthening core surveillance and outbreak response capacity [9] . Refer to Figure 1 Recommended syndromes for surveillance include hemorrhagic fever, acute respiratory syndrome, acute gastrointestinal syndrome, neurological syndrome, and a provision for severe infectious illness [10] . Although these syndromes are not officially part of the decision instrument, implementation of the syndromic approach complements the disease-specific approach with a precise definition for each syndrome, and was pilot-tested in 21 countries [8, 11] . Development and field testing of syndromic reporting initially identified 5 syndromes of potential public health importance. After the interim review, WHO concluded that syndromic reporting could be useful at the country level but was not feasible for the purposes of glo-bal public health reporting due to the challenges of field reporting of syndromes and inability to standardize rules for outbreak control for these syndromes [8, 11] . Baker and Fidler raised concerns that syndromic surveillance may not be effective in the timely detection of emerging diseases [9] . Although these critiques raised valid concerns, in some areas syndromic surveillance systems have detected outbreaks in a timely fashion, complementing traditional surveillance. The WHO also supported the use of syndromic surveillance at the national level during its interim review as part of strengthening core surveillance capacity. Many countries have already implemented surveillance systems to comply with the revised IHR, including surveillance for severe diarrhea, dengue fever [DF] and dengue hemorrhagic fever [DHF] , and acute flaccid paralysis [e.g., refs. [7, 8, 12] ].

A meeting of the Pan American Health Organization on the Surveillance Network for Emerging Infectious Diseases in Amazon countries in 2005 recommended the development of early warning systems, adopting the syndromic approach to surveillance to heighten the sensitiv- ity of disease detection and improve clinical management of cases, such as the febrile icteric syndrome for yellow fever. Although in 2005 there were few guidelines for syndromic surveillance in the region, a recommendation to disseminate protocols was made [13] , and new applications have since been developed, as we discuss below.

General Surveillance for Infectious Diseases Many syndromic surveillance systems detect general febrile illnesses such as malaria, dengue fever, other vector-borne diseases, and foodborne illness. Collaboration between countries with experience in syndromic surveillance and low resource nations has resulted in the introduction of syndromic surveillance to those countries.

[EWORS] is a collaboration between the Indonesian Ministry of Health and the US Naval Medical Research Unit-2 [NAMRU-2], in Jakarta, and was adopted by the Government of Indonesia as a national surveillance system in 2007 [1, 5, 14] . EWORS includes patients presenting to public hospitals and suspected of having an acute infection. Participating hospitals, clinics and emergency departments use a short, standardized questionnaire to collect demographic and clinical information. The questionnaire is filled out on a computer terminal with EWORS software and the data files are sent by email to the EWORS hub in the Ministry of Health for analysis daily. Counts of sign and symptom combinations that may reflect infectious diseases of national importance are compared to baseline counts by automated algorithms and monitored at reporting hospitals and Ministry of Health offices. If an outbreak is suspected, Ministry of Health staff may initiate investigation or control efforts. The EWORS hub also sends a monthly report to each participating site summarizing their surveillance data. System advantages include rapid data acquisition and interpretation by hospital operators, which may allow for earlier case finding. One limitation of EWORS has been the challenges with linking suspected outbreaks to response actions, which requires coordination of local bureaucracies. A second limitation is challenges with standardization of procedures at hubs, which can create alert uncertainty [15] . EWORS has now expanded to include other Southeast Asian nations, including Laos. In Peru, the Ministry of Health and US Naval Medical Research Center Detachment [NMRCD], in Lima, have collaborated to develop a similar system for early warning of dengue epidemics [15] . A second Peruvian system, Alerta, developed by Voxiva, the Peruvian Navy, and NMRCD, allows real time transmission via mobile telephone, text message, or Internet of health information from sailors and their families [1] . The system monitors all nationally notifiable diseases and syndromes, as well as other diseases of particular importance to the Peruvian Navy. [15] . Demographic and clinical data for suspected or confirmed cases of disease and syndromes is collected by the medical officer at each site, who spends ten to thirty minutes daily in medical record review for reporting. The data is then transmitted to the Alerta Disamar central hub by Internet, toll free telephone, or radio. Reporting frequency varies by disease and ranges from daily or twice weekly in batches for common syndromes such as diarrhea or respiratory illness. The hub uses Voxiva software to convert data reported by different communication methods to a common format. Staff review graphs of weekly counts automatically generated in Excel. Alerta has identified over 31 disease outbreaks [15, 16] and has facilitated investigation of diarrheal disease, malaria, and influenza as well as detected an outbreak of cyclosporiasis at a naval base in Lima, Peru. Alerta has been especially useful in helping the Peruvian Navy identify and respond to outbreaks at remote bases, which previously may have gone unreported or identified long after they began because usual reporting channels were slow [15, 17] .

Syndromic surveillance may provide a relatively inexpensive tool for early detection of malaria outbreaks in low resource countries. In Ethiopia, weekly malaria cases collected from health centers in 10 districts from 1990 to 2000 were reviewed [18] . Four types of alert threshold algorithms were compared by plotting a curve for each type of alert. The curve demonstrated potentially prevented disease cases versus the number of alerts over a decade. This study found that simple weekly percentile cutoffs were as good as the more complex algorithms for detection of malaria outbreaks [18] , exemplifying that syndromic surveillance can be basic while still providing useful information. WHO has advocated alerts when weekly cases exceed 75% of baseline [19] ; syndromic surveillance may be able to provide early alerts of this type that will allow timely spraying and mass drug administration. The use of these types of comparative statistics in surveillance is a novel method for evaluation of the performance of malaria early warning systems [18] .

In 2002, the Uganda Ministry of Health piloted a new district level monitoring system in the southwestern highlands. Incoming clinical data from health centers are collated and entered onto a district level computer and compared with a baseline of historical illness data. An anomaly measure is used to provide the index of deviation, followed by electronic reporting. This simple system detected two malaria outbreaks in Kabale, in 2005 and 2006, more than two weeks before case numbers began to peak [20] .

Some surveillance systems monitor climatic and environmental data to forecast infectious disease outbreaks. In some areas, climate variables monitored by satellite can provide a two to three month lead-time for malaria epidemics [21] . In Eritrea, monthly outpatient cases of malaria in 242 districts and NDVI and rainfall datasets showed strong correlation, but coverage of clinical data stations was considered too poor to be of use in epidemic control [21] . In Tanzania, analysis of two malaria seasons in the highlands showed an association between regional rainfall and malaria cases. An early warning system based on rainfall observations may thus be useful for malaria epidemic prediction in some areas [21, 22] . An example of such a system is the USAID Africa Data Dissemination website FEWS-NET, which uses rainfall-based indicators to predict change in malaria risk [23] . Similar dissemination websites could be employed in low to medium resource countries for malaria and other vector-borne diseases where remote Internet access is available.

Syndromic surveillance for malaria may enhance public health response. Since a locally transmitted case of malaria occurred in 2006 in Jamaica, active fever surveillance has been implemented for early detection at sentinel healthcare sites, airports and seaports [24] . Analysis occurs at the local level and then is transmitted centrally on a daily basis. The information is then used to conduct active door to door surveillance of fever cases if warranted.

Dengue surveillance is typically conducted by the passive notification of suspected or confirmed Dengue Fever (DF) or Dengue Hemorrhagic Fever (DHF) cases and deaths. These passive systems have low specificity due to infrequent laboratory confirmation but are still useful due to their simplicity and low use of resources. Unfortunately, waiting for reporting by clinicians may lead to delays in public health action and decrease efficacy of control measures. Active surveillance may include clinician sentinel networks, active fever surveillance by community health workers, and sentinel hospital systems. The first two monitor for nonspecific viral syndrome, which may also be useful for detecting outbreaks of other diseases such as influenza or malaria. A web-based reporting system may improve reporting completeness [25] . Hospital sentinel systems monitor for severe disease and death, with immediate investigation of all hemorrhagic fever. Such systems must be complemented by laboratory-based surveillance for trends and serotypes [26] .

Despite concerns with its specificity, surveillance of the fever syndrome may be useful given that fever is likely caused by dengue in endemic regions [27] . In addition to serologic surveillance, there has been great interest in syndromic surveillance for detection and control of dengue [28] .

As an example, in 2004 an early warning system, 2 SE FAG, was established in French Guiana with the goal of detecting outbreaks of febrile illness in French soldiers, including dengue [29] . In 2006 the system was expanded to include 25 civilian health centers that provide surveillance on sanitary conditions. Before 2006, the only data available for dengue surveillance in French Guiana was laboratory confirmed cases. They compared the frequency and timing of detected febrile cases with the traditional surveillance system for dengue, and the sensitivity was found to be high, but specificity was low [30] [31] [32] . For this system, data on all cases of fever, suspected and confirmed cases of dengue fever, and confirmed cases of malaria by syndromic surveillance syndrome definitions (fever plus headache, myalgia, arthralgia, or retro-orbital pain) are employed. Data is collected in real-time by a medical provider seeing a patient, and information is recorded on the available platform (PDA or a computer). Data is then reported to French health authorities in Cayenne. Syndromic surveillance data is converted to a weekly format and reported to the health authorities weekly in cases of normal operation, or immediately in the case of an alarm. Automated alarms are issued from the syndromic surveillance system based on current past experience graph (CPEG). Under ideal circumstances, there is a 60-minute delay between case presentation and detection by the system [30, 31, 33] . To evaluate the effectiveness of the system, during an outbreak of DEN-2 DF beginning in November 2006, data on confirmed dengue fever cases from a reference laboratory and data from 2SE FAG for the occurrence of undiagnosed fever associated with headaches, arthralgias, myalgias, or retro-orbital pain were compared. Levels of alarm and public health actions taken were also recorded. The syndromic surveillance pre-alarm activated 6 weeks prior to the full alarm in week 2 of 2006 and provided early warning for military personnel in comparison to the laboratory-based program [33] .

The system was able to detect 6900 suspected dengue cases compared to 800 laboratory-confirmed cases in 2006. Although the sensitivity was high, specificity was low. Other limitations included incomplete report forms and dengue fever reporting being 67% higher than with traditional reports, most likely because traditional surveillance is limited to confirmed cases [30] [31] [32] . Despite its sensitivity, there has been some concern with using a febrile syndrome for dengue surveillance, given that of 7195 febrile cases, only 8% were confirmed to be dengue [13] . As in other applications of syndromic surveillance, other methods of surveillance must also be in place. A lab-oratory-based system for dengue may be more useful; yet given limited laboratory capabilities in dengue endemic areas, syndromic surveillance may provide valuable information on population epidemiology prior to laboratory confirmation [13] . Vector surveillance and control provides the earliest opportunity to avert or contain dengue epidemics, but many dengue-endemic countries lack resources for launching these programs.

The IHR call for reporting of other vector borne diseases such as West Nile virus and Rift Valley fever. A surveillance system developed in the Netherlands for early detection of WNV focuses on cases presenting with neurologic diseases and includes the monitoring of hospital discharge data, trends in laboratory testing, and monitoring neurological diseases in horses [34] . Such a system could be applied to medium resource developing countries by monitoring the neurologic syndrome and neurologic disease in animals.

Similar to early warning systems for malaria, comparison of different prediction models for cutaneous leishmaniasis [CL] show a strong relationship with climatic variables and thus may be amenable to the development of an early warning system [35] . Models for CL incidence in Costa Rica may outperform models with no climatic indicators [36] . For vector-borne diseases with a clear relationship with the El Nino Southern Oscillation phenomenon [ENSO], models that use climate indicators to forecast disease risks are being developed [37] . In Australia, climate modeling has shown a sensitivity of up to 90% when combined with mosquito surveillance data to predict epidemics of Ross River virus disease [38] . However, many climate-based systems are not widely used due to the lack of published models outside testing areas. Disease modeling is often limited to discrete data sets for small areas [39] . Nonetheless, modeling of these data sets may be useful for selected syndromes in low resource regions. Monitoring of both climate triggers and vector-borne disease indicators together may increase sensitivity and specificity and also provide validation of data sources and backup for potential system failure.

Several recent emerging infectious disease outbreaks, such as SARS and highly pathogenic avian influenza [H5N1], arose in Asia. Surveillance for new respiratory illnesses is therefore crucial in this region. In many regions, electronic data exist that can assist with an automated system. In Taiwan, an emergency department based syndromic surveillance system for 189 hospitals automatically transmits electronic patient data to the Taiwan Centers for Disease Control. This system was built on existing work done in the United States in collaboration with the Realtime Outbreak and Disease Surveillance [RODS] Laboratory [40] . The goal of this system, among the first nationwide real time surveillance systems in Asia, is to detect winter and summer spikes in influenza-like illness, respiratory syndrome, and gastrointestinal illness [41] . Should another epidemic like SARS arise, this system may be able to provide early warning and notification, thus improving global surveillance of emerging infectious diseases. Such automated systems could be used in other medium resource regions for the detection of emerging viral illnesses.

Syndromic surveillance for foodborne illness is important given the globalization of the food supply and the morbidity caused by diarrhea in the developing world. Systems can monitor for gastrointestinal illnesses through the tracking of diarrhea and vomiting symptoms. In the United States, the RUSick 2 disease forum is a web-based forum that allows residents to report information on nausea, vomiting and diarrhea syndromes, including foods consumed, with the goal of identifying common food vehicles in gastrointestinal outbreaks. The goal of this system is to decrease the time delay with routine laboratory surveillance for food borne outbreaks. Completeness of the syndromic surveillance reports collected via the webbased forum has been found to be as effective as similar reports from phone calls to the health department [42, 43] . Poison Control Center data has also been used to detect foodborne outbreaks, and found to be useful in early detection where there is no confirmatory diagnostic information available [44] . Establishment of these types of networks may be useful in areas with medium resources and good communications infrastructure.

These types of surveillance can also be applied to the developing world. In the Pacific region, there are four distinct levels of foodborne disease surveillance: no formal surveillance, syndromic surveillance, laboratory or pathogen-specific methods, and integrated food chain surveillance [45] . Vanuatu and Solomon Islands primarily use syndromic surveillance. Few countries have specialized laboratory surveillance, and thus information on specific pathogens is limited. A regional approach under the Pacific Public Health Surveillance Network would include development of uniform case definitions for reporting as the basis for syndromic surveillance and facilitate centralized data collection and sharing [45] .

Incidence estimates of typhoid fever in Egypt have been derived recently from hospital-based syndromic surveillance along with lab-based surveillance. Although assisted by the syndromic surveillance system, the majority of patients were evaluated in the primary care system and would not have been detected by the hospital based syndromic surveillance. This situation emphasizes the ability of syndromic surveillance to augment but not replace traditional surveillance. Syndromic surveillance must be broad in scope in order to catch mild disease and expand surveillance beyond hospital data, which tends to capture more severe cases [46] . This type of surveillance may be difficult to enact in low resource regions with limited access to laboratory facilities.

As for vector-borne diseases, environmental parameters may be useful for early detection of food or waterborne disease outbreaks. One study found strong correlation between cases of Vibrio cholera O1 in children in Bangladesh and temperature and rainfall two to four months prior. This type of model could be a good model for a climate-based early warning system for cholera in this region [47] and could be implemented in low resource countries.

Syndromic surveillance systems have also been useful in detection of diarrheal outbreaks. EWORS facilitated the detection of a large cholera outbreak in Indonesia [48] .

The WHO recommends a global health sector strategy as part of a multisectoral approach to responding to epidemics of STIs, including a syndromic approach for the detection and management of abnormal vaginal discharge [49] . The WHO strategy aims to decrease the cost of testing and to improve treatment practices, with a certain minimum data required for surveillance. This plan mandates knowledge of the prevalence of specific agents and their susceptibilities, which necessitates at least periodic laboratory surveillance [50] . Vaginal discharge and urethritis are the most common syndromes [51] . Syndrome case reports may include genital ulcers, urethral discharge, and vaginal discharge [52] . Monitoring of these syndromes may allow improved public health response for countries with low resources, for which automated reporting is not easily implemented. Since the introduction of syndromic surveillance in 1996 in Burkino Faso, the prevalence of STIs such as gonorrhea, syphilis, and chlamydia has decreased [53] , providing an impetus to continue this surveillance. In Cote d'Ivoire, the national health information system collects data in all community-based public health clinics, which are located in 29 districts and 10 regions [54] .

In the United States, the Philadelphia Department of Public Health monitors chief complaint and discharge data from emergency departments containing reportable disease information to detect cases of syphilis and manage them according to CDC guidelines [55] . These types of systems could be implemented in the developing world where electronic data or computerized systems are available.

Syndromic surveillance is thought by many to be a high technology tool. But surveillance of syndromes is not a new phenomenon, with one of the earliest examples being acute flaccid paralysis for detection of poliomyelitis outbreaks [6] . Surveillance of influenza like illness worldwide is another example of syndrome rather than disease specific surveillance [56] . While syndromic surveillance is augmenting traditional surveillance in the developed world, it also has the potential to improve timely detection of infectious disease outbreaks in developing countries, most of which lack access to a strong public health infrastructure and specialized laboratories. The burden of public health surveillance in under-resourced and understaffed settings is a challenge. Despite this, there are several examples of low cost syndromic surveillance programs that may enhance global public health. For example, community based programs that employ volunteers may lessen the burden on hospital workers [15] . Increased use of automated reporting may decrease the burden on health care and public health workers and allow for more complete reporting of potential cases of public health importance.

Syndromic surveillance may be especially useful for early epidemic control of certain vector borne diseases as well as for diseases of public health importance that have the potential to cross international boundaries. Examples of current applications of syndromic surveillance in developing countries are summarized in Table 1 . The IHR mandated the reporting of diseases of international importance; surveillance for syndromes may facilitate compliance with this IHR requirement. There is currently no infrastructure in place to enforce these guidelines, and each country must design a national surveillance system that can allow for timely detection and notification of these disease outbreaks. Although WHO is required to assist countries in developing capacity to meet these requirements, no funding is allocated from WHO for this purpose. Thus, improving countries' national public health infrastructure and reporting capabilities will require large financial and technical support, likely from countries with existing automated reporting [9] . Improvements in the communication infrastructure, including Internet access, will need to occur to allow electronic communication and enhance the timeliness of reporting. Furthermore, investment in training in epidemiology, field investigation, and information technology are vital to the future success of broader surveillance activities.

Although syndromic surveillance can provide useful early warning of diseases such as malaria, there are no guidelines for what to do with the information provided. It is still necessary to have a robust public health infrastructure for investigation of cases and implementation of an effec- [54] tive control program as with any surveillance system. Simple monitoring tools can facilitate effective epidemic control, but require the translation of this early warning information into timely public health action.

Syndromic surveillance systems should build on existing public health surveillance infrastructure, as well as work that has been done in other regions. The collaboration between the Taiwan Centers for Disease Control and the RODS Laboratory is one such example [40, 41] . With increasing access to the Internet, and decreased cost and improved user friendliness of information technology in developing countries [1] , novel applications for syndromic surveillance are enhancing traditional surveillance and will hopefully continue to improve the detection of outbreaks worldwide, fulfilling the goals of the IHR. We hope this review demonstrates both the effectiveness and feasibility of ""low-tech"" syndromic surveillance in low resources countries, and can be the starting point for further development of guidelines for how to conduct syndromic surveillance in developing countries. 

",0.7933796202429038
Advanced Querying Features for Disease Surveillance Systems Advanced Querying Features for Disease Surveillance Systems,"Most automated disease surveillance systems notify users of increases in the prevalence of reports in syndrome categories and allow users to view patient level data related to those increases. Occasionally, a more dynamic level of control is required to properly detect an emerging disease in a community. Dynamic querying features are invaluable when using existing surveillance systems to investigate outbreaks of newly emergent diseases or to identify cases of reportable diseases within data being captured for surveillance. The objective of the Advance Querying Tool (AQT) is to build a more flexible query interface for most web-based disease surveillance systems. This interface allows users to define and build their query as if they were writing a logical expression for a mathematical computation. The AQT allows users to develop, investigate, save, and share complex case definitions. It provides a flexible interface that accommodates both advanced and novice users, checks the validity of the expression as it is built, and marks errors for users.","In its 2007 annual report, the World Health Organization warned of the increased rate at which diseases spread in a world where 2 billion people travel by air [1] . The early detection of known and emerging illnesses is becoming more important. Automated disease surveillance systems have been in existence for over 10 years [2] [3] [4] . Most of these systems analyze data by syndrome and search for disease outbreaks. A syndrome in this context is defined as a group of diseases related in some fashion, such as respiratory diseases. This level of investigation is often sufficient, but a more dynamic level of control may be required to understand an emerging illness in a community.

For example, during the 2002-2003 Severe Acute Respiratory Syndrome (SARS) disease epidemic [5] , the respiratory syndrome definition used by most automated disease surveillance systems was too broad to track SARS [6] . In this case, the users needed to create queries that looked for specific keywords in the patient chief complaint or specific combinations of ICD-9 codes [7] . A chief complaint is text entered by a triage professional in an emergency room or a clinic, based on a patient's description of their primary symptoms. Today's public health departments must deal with a multitude of data coming from a variety of sources. For example, Electronic Medical Record (EMR) data include sources such as radiology, laboratory, and pharmacy data. A more sophisticated querying tool is needed to assist investigators with creating inquiries across multiple data sources [8] [9] [10] .

Currently, there are surveillance systems, such as the Electronic Surveillance System for the Early Notification of Community-based Epidemics (ESSENCE) [11] , which provide limited dynamic querying capability. However, we wanted to design a flexible and simple graphical user interface (GUI) for this and other types of surveillance systems. Our prototype system, the Advanced Querying Tool (AQT), allows the investigators to handle complex cases where one can incorporate any data elements available in a disease surveillance system, then mix and match these data elements in order to define valid queries. Hence, this system removes the need for database administrators and application developers to define pre-packaged database queries and user interfaces every time a new and innovative query is written.

As an example, investigating a potential influenza outbreak in an adult population may require respiratory syndrome queries only, while investigating a similar outbreak in children under 4 years old may involve queries in both gastrointestinal and respiratory syndromes ( Figure  1 ). Table 1 provides examples of how a dynamic query tool exploits combinations of data elements available to disease surveillance systems. Most automated disease surveillance systems have a fixed number of predefined syndromes. These applications severely limit the surveillance system value for diseases that fall outside of its broad syndrome categories. The background noise level rises when all the chief complaints that potentially fall into a syndrome category are included, which in turn requires many more positive cases to identify an abnormal condition. Merely adding sub-syndrome categories, that are more granular than syndromes and cover a broader range of conditions than typical syndromic surveillance like injures and chronic disease [12] , provides the users with a more comprehensive means to filter the analysis window. If a disease surveillance system has 400 sub-syndromes, then taken singly the user has 400 additional choices; by combining two or three sub-syndromes, the analysis options are magnified to over ten million choices. Of course not all of these options are sensible, so the actual number of options is somewhat less. Even greater analytic flexibility is provided through the use of data elements contained within electronic medical records. The capability to select a combination of a microbiology laboratory result, radiology result, and ICD-9 code provides for a powerful tool that enables the public health community to rapidly identify specific high risk patients. 

The following objectives summarize the design features of the AQT: The tool's interface will help generate queries that can process any kind of data regardless of its source (e.g., emergency room visit, office visit, pharmacy, and laboratory). Unlike fixed-form query interfaces, AQT will not restrict users in what they can query. Instead, the user will be able to formulate ad-hoc queries across assorted data sources without the need to understand the underlying data models and the query languages associated with different systems. In addition, using this tool should save investigators' valuable time in obtaining the query results. Currently, if the surveillance system cannot generate the desired queries, the application developers and/or database administrators may have to create new interfaces or functionalities. The AQT, however, empowers the users to move forward with their research without waiting for developer or administrator modifications to the surveillance systems.

The interface will accommodate users with different levels of experience in creating complex and valid queries. The process will be natural and follow the same patterns that one uses to express a mathematical equation. At the same time, it will give the more experienced users, who are familiar with the data elements, the freedom to define complex queries by sidestepping the guiding tools. The advanced users will have the ability to type in their queries and the tool will validate them and provide feedback on possible syntax errors.

The interface will allow users to save and share queries with other public health professionals, even in different jurisdictions. After defining a complex query the user has the ability to store the query for future investigations. One should be able to execute the stored query repeatedly in the future, include it as a segment of a bigger query, or customize and execute it. These saved queries can then be shared as part of collaborative efforts among users in different departments and jurisdictions. AQT will provide an interface for disease surveillance systems to store, retrieve, and share queries. These capabilities are especially valuable for users employing a case definition for following a disease outbreak. A case definition is a set of symptoms, signs, etc., by which public health professionals define those patients considered to be directly a part of the disease outbreak.

Finally, the tool should be self-contained and generic. This allows most web-based disease surveillance systems to incorporate the AQT into their systems.

The entire functionality of the tool is placed within a single web page ( Figure 2 ).

The screen in Figure 2 is divided into 5 major sections. Starting at the top, the user can filter the data by picking the data source from a dropdown list, start and end date. The surveillance system should supply this list of data sources to the AQT. The next area below is the Message Area where the GUI communicates with the user. Any information, warnings, or error messages are displayed in this section. The next area, the query section, contains the query expression. The users can either directly type the query expression or use the tool to generate the query expression and paste it in this area. Alternatively, they can use a combination of the two methods by typing part of the expression and pasting the rest using the query builder. The query section is followed by the query builder section where the tool provides list boxes, buttons, etc., to direct the user through the process of generating the query expression. The bottom section is where an action on the query is performed. Users can validate the expression's syntax, save the query for their own future use, save it to be shared with others in the user community, clear the query expression and start over, or simply execute the query and get the results.

As mentioned earlier, the capability to generate queries on data from a variety of sources is one of the objectives of the AQT. Each data source has its own distinctive set of data elements. The interface has to provide a list of data elements pertaining to the chosen data source. For example, the data might represent different geographic regions from one data source to the other. That is, one source might have data identified by zip codes while another source uses some other type of defined region such as hospitals, pharmacies, and schools. Another area where data sources can be different is in medical groupings. For example, office visits often use ICD-9 codes [7] , while emergency departments use patient chief complaints. The interface is designed to distinguish valid data elements for each data source and populate the data element list box accordingly.

After selecting a data source the tool populates a list box with a set of associated data elements for the data source. The list box is divided into three major areas:

• The geography system • The medical grouping system • Others such as age, sex, saved and shared queries. Figure 3 shows how the medical grouping systems differ for Emergency Room (right) and over the counter (left) data sources. As mentioned earlier, a main objective of the AQT is to provide an interface that caters to both novice and experienced users. The experienced users simply type the query, while beginners and those who are more comfortable with a guided interface can use list boxes and buttons to generate the queries. In fact, one can type part of the query and use the tool to generate the rest of the query (Figure 4) . When a user types a query directly, it is assumed that the user knows the syntax and valid data elements pertaining to the data source, though the tool does check the syntax and provide feedback. Because we want the users to define and build their query as if they were writing a logical expression for a mathematical computation, the syntax is simple and close to the ""where"" clause of a Structure Query Language (SQL) statement. However, one does not need to know SQL to write the expressions. A query consists of one or more simple expressions joined by ""AND"" and/or ""OR,"" negated by ""NOT,"" and grouped by parentheses. A simple expression is enclosed within square brackets ([]) and defined by a variable, a logical operator, and a value. For example, if an investigator is searching for reported fever cases within a specified zip code, the query then consists of two simple expressions; one which searches for the specified zip code and the other which checks the fever syndrome. The final query may look like the expression below:

If the investigators want to narrow the search into a certain age group they can type or use the tool to add AND [AGE = ""0-4""] to the above expression. Hence, the users can add more conditions without worrying about the underlying data model.

The most complex part of the syntax occurs when searching for values that contain, start with, or end with a set of characters ( Figure 5 ). In this case, the syntax uses ""*"" as the wildcard character. For example, a user would type [chief-complaints = ""*head*""] in the query box if he/she is looking for all the records of chief-complaints that include the word ""head."" Similarly, if a user types [chief-complaints = ""head*""] or generates it using the tool (selects the Starts With from the operator list box and types head in the text field), the resulting query would search for all the records where the chief-complaints field begins with the word ""head."" The procedure for generating expressions follows the same pattern a person would use to create a logical expression. The interface will provide a natural flow to help the users to create an expression as if they are typing it. They may start with selecting a data element or variable such as 'SEX', then a logical operator like '=', and finally a value like 'MALE' or 'FEMALE'. The user can add 'AND' or 'OR' and create the next expression using this same process.

The user can interject expressions in the middle of a query, remove parts of the query, or undo the last change made to the query. As changes are being made, the tool validates the entire query in the background and provides instant feedback. This method of constructing queries is more intuitive to the users than that of creating all the individual expressions first and then joining them together.

Once the data source is selected, a list of core data elements is provided in a list box. From the list box the user can select a data element. Based on the type of the data element, a list of valid logical operators for that data element is placed in another list box. Figure 6 shows the list of valid operators for text fields.

In cases such as zip code and syndrome, '=' and '<>' operators are also valid. For age the operators '>', '<', '<=', and '>=' are added to the list. Once the user selects a data element, a list of valid values pertaining to the data element is listed in yet another list box. The user can select one or more of these values, and if more than one value is selected the user can choose to group these values using 'AND' or 'OR'. Note that the AQT generates the expression in a left to right progression in the same manner as one typing the expression (Figure 7 ).

The next step is to add this expression to the query. By clicking on the ""Add Expression"" button, the expression is pasted at the cursor location in the query area. One can add more expressions to this query by clicking AND or OR buttons and following the same process ( Figure 8 ).

The AQT helps users quickly identify limits for variables with large sets of values. Because data elements such as zip codes and ICD-9 codes have a lot of values for dropdown lists, finding a particular value in these list boxes is very cumbersome. The tool provides an intermediate step for filtering these options into a more manageable list (Figure 9 ). For example, if the investigators are interested in data from certain zip codes in a state, they can reduce the options by typing the first two digits of the zip code and thereby filtering the list. The tool will generate valid expressions and provide a mechanism to check the query expressions when a user types parts or all of them. Every time an expression is generated by the tool and the Add Expression button is clicked, the tool examines the entire query expression, checking it against the syntax rules. Before saving or executing the expression the AQT automatically checks the syntax and if it detects any syntax errors it will provide meaningful error messages in the message area ( Figure 10) . Additionally, at any point the user can click on the validate button and check the syntax. Frequently, investigators want to execute a query over time, run the same query with different values, or use the query inside more complex queries. Similarly as all the other data elements (zip code, syndrome, region, etc.), the permanent storage and retrieval of queries (File system, database, or any other mechanism) are the responsibility of the disease surveillance system. The AQT is merely an interface to assist the investigators with their research by hiding the complexity and inner workings of the underlying data model.

Once the users define the desired query they can click on [Save Public Expression] or [Save Private Expression] buttons. If the query is valid, the screen provides an area to enter a unique name for the query (Figure 11 ).

If the query is successfully validated the AQT passes the name and query expression to the surveillance system. It is the surveillance system's responsibility to confirm that the query's name is unique and provide feedback to the AQT the success or failure of the save operation. Based on the feedback received the AQT provides an appropriate message in the message area.

In a collaborative environment users would like to share their findings and queries with others. Providing the capability to save and share the queries for collaborative use enables others in the user community to run these queries as they are or to make the modifications necessary to help with their own investigations. The AQT facilitates saving public queries by providing an interface similar to saving private queries ( Figure 11 ). The surveillance system should implement the inner workings of the permanent storage and retrieval of public queries. The next step is retrieving these saved queries. There are two options in the data element list box in the query builder section of the AQT: one option is for retrieving the private saved queries, and the other option is for retrieving public saved queries ( Figure 12 ). Upon selection of either one, a list of corresponding queries will be presented to the users. This list includes the text of the query and the unique name given to that query. By clicking on the query name the saved query will be added to the expression in the Query area.

At this point users can add more conditions to the same query, such as specifying a zip code, changing the value for age, etc.

The final objective of this project is for the AQT to have the capability to be used with most web-based surveillance systems. One can think of the AQT as a widget, or an add-on with some defined interfaces. The back end can be implemented in a variety of popular technologies such as .NET, Java Servlet, or any other server technology as long as it can communicate via an http protocol. The surveillance system has to provide the interfaces that supply values for the different parts of the screen, and the functionality to parse the final query text and run it against the underlying database.

Making the tool adaptable to many web-based systems requires the AQT to contain all the processing dynamically, including validating the query syntax and changing the contents of the list boxes. In a web-based environment, this means using browser components such as HTML, Cascading Style Sheets (CSS) [13] , JavaScript, and the Document Object Model (DOM) [14] to implement application logic. In developing AQT, we utilized HTML, JavaScript, and AJAX (Asynchronous JavaScript and XML) and placed all the processing on the local machine to avoid any server dependency.

We used JavaScript to apply validation, data handling, and screen processing on the browser side, and AJAX for communicating with server applications. AJAX is used for creating interactive web applications and is a cross-platform technique usable on many different operating systems, computer architectures, and web browsers, because it is based on open standards such as JavaScript and XML. The intent of this technique is to make web pages more responsive by exchanging small amounts of data with the server behind the scenes, so that the entire web page does not have to be reloaded each time the user requests a change. This feature increases the web page's interactivity, speed, functionality, and usability. AJAX is asynchronous in that loading does not interfere with normal page loading.

The AQT uses AJAX calls to obtain required data for populating the different list boxes on the screen. For example, when the user selects a data source the tool calls the surveillance system, passes the selected data source, gets a list of data elements from the server (the surveillance system), and then populates the data element list box. The communication to the server is done by an AJAX call, and the JavaScript processes the returned data and populates the list.

ESSENCE has been one of the early adaptors of AQT. Although the capability to create efficient custom queries for emergency room chief complaints data existed prior to the AQT, the query building process was cumbersome and not user-friendly. It was easy to make syntax errors while typing a query, and there was no mechanism to validate the logic of the query statement. Furthermore, while ""AND"" and ""OR"" and ""ANDNOT"" expressions were possible, there was no method to construct complex Boolean operations with parentheses to clarify the order of operations. The previous capability allowed the user to base the custom query on Data Source, Geography System, or Medical Grouping System, however, since the selections were not part of the query statement they could not be modified without returning to the pre-selection screens and re-starting the query process. Additionally, the original capability did not allow for querying of data beyond the fundamental chief complaints-level. The following screen shot shows the query options that were available with the original feature. A sample chief complaints query designed to capture Influenza-Like-Illness is shown in Figure13.

The AQT not only contains several capabilities that were not previously available, but also provides an intuitive user-friendly interface that allows the user to build simple or highly ^cough^,and,^fever, or,^sorethroat^,and, fever^,andNot, ^Asthma^ complex queries more easily. Two new features in the AQT are parentheses, which allow the user to clarify the order of operations, and the ability to select variables such as Region, Zipcode, Hospital, Syndrome, Sub-syndrome, Chief Complaint, Age, and Sex, as part of the query statement. This allows for easy query modifications. Additionally, the AQT lets the user query data beyond the fundamental chief complaints level into a more sensitive Sub-syndrome or Syndrome level. It also allows users to develop queries that contain combinations of chief complaints, syndromes, and sub-syndromes into one query. The query can also contain combinations of different geographies such as zipcodes and regions. This capability is not available without AQT.

During the query building process the AQT automatically validates the logic of query expression as it is created, and the user has the option to conduct a final validation prior to executing the query. This feature allows the user to quickly identify syntax errors and correct them before adding further complexity or executing the query. The following screen shot ( Figure  14) shows the query options available within the AQT feature. A sample chief complaints query designed to capture Influenza-Like-Illness in Region_A is shown. 

",0.7901909392466197
Smart home technology for telemedicine and emergency management,"With the ageing population, mobility is an important issue and it deters the elderlies to visit health clinics on a regular basis. Individuals with disabilities also face the same obstacles for their out-of-home medical visits. In addition, people living in remote areas often do not get the needed health care attention unless they are willing to spend the time, effort and cost to travel. Advances in information and telecommunication technologies have made telemedicine possible. Using the latest sensor technologies, a person's vital data can be collected in a smart home environment. The bio-information can then be transferred wirelessly or via the Internet to medical databases and the healthcare professionals. Using the appropriate sensing apparatus at a smart home setting, patients, elderlies and people with disabilities can have their health signals and information examined on a realtime and archival basis. Recovery process can be charted on a regular basis. Remote emergency alerts can be intercepted and responded quickly. Health deterioration can be monitored closely enabling corrective actions. Medical practitioners can therefore provide the necessary healthrelated services to more people. This paper surveys and compiles the state-of-the-art smart home technologies and telemedicine systems.","In the past decade, one of the fastest growing multidisciplinary research areas is telemedicine. Many definitions of this term exist depending on the specific context. Other terms that often used interchangeably, in conjunction with, or under the umbrella of telemedicine, include telehealthcare, telemonitoring, e-health, e-care, ambient assisted living, smart homecare etc. All these terminologies, though, have the same objectives of delivering remote healthcare to an individual's home and enabling continuous health monitoring and emergency management.

The increasing attention given to telemedicine is due to many factors. With unaccommodating transportation, and crowed hospitals and clinics in most cities, it is difficult for the elderlies and physically challenged to venture out of their homes to meet with health professionals for the needed treatment or for their routine clinical check-ups. Similarly, healthcare delivery in remote rural areas is a demanding endeavour. Having the capability of delivering healthcare services at the patients' home not only saves a great deal in monetary and human resources, but it also reduces response time in emergency situations. This is especially beneficial in the case where a large number of patients can be dealt with via communication technologies quickly from a centralized location without sending medical personnel to their individual homes.

Telemedicine has drawn worldwide attention in the 2000s as modern technologies have made remote healthcare delivery a reality. Within the European Community, there were the HHH (home or hospital in heart failure) trials of a low-cost, self-managed home monitoring system for patients with chronic heart failures (Pinna et al. 2003) . It was found that monthly home telemonitoring of cardiorespiratory signals being sent to a centralized interactive voice responding system is feasible and patients' compliance is high. The SM4All (Smart hoMes for ALL) project initiated by the European commission aims to provide a middleware platform for pervasive embedded service in a smart environment (Baldoni 2009 ). The objectives of SM4All are to provide dependability, scalability, privacy and security to users with disabilities.

The Brazilian family health program was initiated for preventive medicine delivered to the lower income population living in remote regions (Correia et al. 2008) . The associated Borboleta system enables healthcare professionals to use PDAs (personal digital assistants) and mobile communication technologies for providing on-site home healthcare and improving the quality of public health services.

In the USA, healthcare is a big financial burden for government, employers, and citizens. White et al. (2006) discussed major challenges to improve healthcare quality and concluded that a distributed diagnosis and home healthcare paradigm is the best approach for affordability and quality.

Germany has an initiative to provide encrypted health data for patients during emergency using electronic health card (Dunnebeil et al. 2011) , though there is resistance by some medical professionals mainly due to privacy issues.

Telemedicine is a multidisciplinary research and application area using advanced technologies in information processing, telecommunication, bio-sensing, and artificial intelligence. Specifically, smart environment and technologies play important roles in making home telemedicine feasible. One can view sensors being the foundation and communication networks as the pillars of a building, supporting various telemedicine applications under the roof to facilitate and provide a smart home environment to individuals, as shown in Fig. 1 .

This work presents a survey of the latest advances in smart environment and home telemedicine. It is an extensively updated version of an earlier work on home telemedicine review (Li and Li 2011) . In addition, the current focus is on smart environment and emergency management. There exist numerous works in the literature and therefore only representative, technologically innovative, and interesting systems and approaches are presented. To properly introduce smart environment in telemedicine and emergency management, the fundamental technologies, potential applications, their evaluations, and future directions are presented in a sequential coherent perspective. Section 2 introduces smart environment enabling technologies including communication, sensor and sensor network. Applications of smart telemedicine technologies for specific diseases, emergency management, and the elderly and physically challenged, are presented in Sect. 3. Target user groups' concerns and healthcare professionals' evaluation of telemedicine and smart homecare systems are discussed in Sect. 4. In the concluding Sect. 5, challenges, concerns and issues related to smart homecare are considered, and future trends of smart homecare environment are identified.

In order to provide telemedicine effectively, various techniques and methodologies from different areas have to be integrated seamlessly into a smart system. This section examines the primary state-of-the-art enabling technologies for smart environment within a homecare setting for telemedicine: communication and associated telehealth standards, sensors, and sensor networks.

Many telemedicine systems leverage the latest mobile and wireless communication technologies as well as the widely available internet infrastructure to deliver quality services to home patients (Castro et al. 2001; Bonacina and Masseroli 2006; Li et al. 2008) . A home patient monitoring system proposed by Figueredo and Dias (2004) uses a simple RS232 serial interface to connect a mobile phone to patient monitoring devices, and transmits vital signs over the internet to the hospital. vNurse is a system developed by Rehunathan et al. (2011) that uses the smart phone platform to provide secure and remote patient monitoring. Bio-data in vNurse are collected from a wireless body network and transmitted using mobile networks with IP (internet protocol) connection. Multi-agent systems are commonly found in smart telehealth applications. One of the earliest telemedicine projects, the independent lifestyle assistant, incorporates techniques in sensing model, distress situation detection, network response planning and machine learning (Haigh et al. 2002) . The Assistant is implemented as a multi-agent oriented assistive living architecture. Liao et al. (2009) presented a telemonitoring architecture based on mobile agents and they also addressed the issues of reliability, security, and manageability of this platform. Bramanti et al. (2010) employed GIS (geographical information system) technology to identify the optimal locations of clinics that could provide neurological telemedicine services to patients. A remote-client, servicecenter architecture was proposed that uses 3G/CDMA network and the internet to transfer vital sign information and medical analysis reports (Zhang et al. 2010) .

The web is a common and well-developed medium for communicating monitored and emergency data. Raad and Yang (2009) used the web for reporting real-time status and actions of a home bound elderly. Voice over IP (VoIP) is another family of technologies and communication protocols that can be used effectively in smart environment and telehealthcare. Menkens and Kurschl (2010) investigated and evaluated VoIP enabled communication platforms and proposed a system for regular monitoring as well as providing responsive actions in emergency situations.

Citing decision and notification delays in typical telemedicine homecare settings, as a result of the large volume of information occupying the limited communication resources and consuming valuable computation resources on the remote server, Chen (2010) team designed a smart gateway bridging a home-based wireless senor network and a public communication network. Implemented as a standalone embedded system, the gateway is also capable of tracking a patient's health state and providing fast response in emergencies.

Communication is the foundation of providing telehealthcare in the smart home environment. There are many existing and emerging standards such as the IHE (integrating the healthcare enterprise) recommendations for information exchange (IHE 2012) , and the very popular Zigbee (Zigbee Alliance 2012) that have been used in many smart environment projects (Lin and Sheng 2008; Fraile et al. 2010) .

de Toledo et al. (2006a, b) argued that in order for e-health to progress, the use of standards in providing plugand-play devices and interoperable modules is necessary. ISO/IEC 29341 universal plug and play (UPnP) device architecture (ISO 2012a) is a standard for plug-and-play. Lin and Sheng (2008) carried out a study of using UPnP network protocols to facilitate services in a residential network. Park et al. (2011) examined the ISO/IEEE 11073 point-of-care medical device communication (ISO 2012b) and its compatibility to legacy devices.

One of the important works related to standards is Anagnostaki et al. (2002) development of a codification scheme for vital signs in health information interchange. They also discussed the practical aspect of integrating the proposed scheme into medical devices. Jang et al. (2007) provided a noteworthy comparison of the key features, including power, complexity, number of nodes, latency, range, expandability, data rate, security, and audio connection, among the short-range communication protocols: Wi-Fi IEEE 802.11b standard (IEEE 2012), ZigBee (ZigBee Alliance 2012), and Bluetooth (Bluetooth 2012). Ultra-wideband radio has also been proven to be effective in a smart home environment (Bonato 2010).

Many research projects have drafted an exhaustive list of sensors to be used in their prototype work such as the TAFETA (technology assisted friendly environment for the third age) group's implementation (Arcelus et al. 2007 ). TAFETA has shown how various sensors can be used effectively for different purposes in a smart home: magnetic switches on doors to monitor entry and exit, thermistor to track temperature, accelerometers on chairs and flooring to measure impact which is indicative of a falling condition, RFID (radio-frequency identification) to assist people with Alzheimer or dementia, infrared motion sensor to detect mobility and presence, microphone array to detect abnormal noises and cries for help, smart grab bars with pressure sensors embedded to measure strength and balance trend, and pressure sensitive mats under bed to monitor deviated entry and exit patterns.

In a typical smart home telemedicine system, there are two major types of data that need to be collected. The occupant's health state and the environmental information are important parameters to monitor and track. Different types of sensors can be used to detect vital signs such as ECG (electrocardiogram) for heart rate, EMG (electromyogram) for muscle activities, and blood pressure monitor for hypertension, while accelerometer, microphone, light sensor, air pressure recorder, and humidity indicator can be used to detect motion and location (Fraile et al. 2010 ). In addition to signals obtained from sensors that are attached to the body or physical measurement devices in the home, there are other media that could be monitored such as video and sound. Though, sound is the preferred medium due to privacy concerns. Smart home technology 537 Istrate et al. (2006) team developed a sound analysis system to detect and classify alarming sounds in a noisy environment. Using wavelet technology to process sound signals, their system achieves good performance comparable to other systems using different monitoring technologies. Laydrus et al. (2007) investigated the use of frequency domain features in an automated sound analysis system and was able to achieve over 90 % accuracy in classifying 19 real-world sounds. Vacher et al. (2009) presented a sound classification and speech recognition system with microphones placed in the home to detect short sentences or words that may indicate a distress situation. Though, Fleury et al. (2008) found that screams and distress sentences are difficult to differentiate due to distress sentences are similar to short words. Hollosi et al.

(2010) devised an acoustic event detection and classification system for ambient assistive living environment and interpreted coughing as an indicator of upcoming illness.

Pressure sensors have been used extensively in various parts of a smart home. Arcelus et al. (2009) installed pressure sensors under the bed and on the floor next to the bed. Their collected data include sitting pressure, standing pressure, and the time from sit to stand, which provide valuable information on a patient's mobility and other health-related data. Leusmann et al. (2011) used arrays of Piezo sensors to implement a sensor floor to track the whereabouts of the home occupants. Moreover, data collected can be used to analyze impact patterns in case of fall or other emergency situations. Similarly, Miao et al. (2009) proposed a fall detection approach based on head tracking using two video cameras. They constructed three-dimensional head position models with unimportant objects and background filtered out.

Location tracking is an important aspect of providing a smart home environment. Global positioning system (GPS) has limitation operating indoor. Various techniques have been used for indoor position location including the use of cascade correlation network and neural network modeling (Chen et al. 2011 ). Helal et al. (2003 at the University of Florida has been working on the house of Matilda project for the past several years. Matilda is an in-laboratory mock up house to experiment various innovative ideas for smart home. One of their focuses is location tracking of the elderly by the use of ultrasonic sensor technology.

Wearable devices have been research extensively in the past decade. With the advances in device miniaturization and communication techniques, wearable devices can serve many different roles in telehealthcare, for instance, as a standalone monitoring device or as a node in a sensor network (Hung et al. 2004; Axisa et al. 2005; Kang et al. 2006) . Chaczko et al. (2008) developed a small wearable device that incorporates data storage, display screen, speaker, microphone, GPS, RFID and accelerometers. The ability to monitor and locate makes this an ideal device to be installed in various places in the home and on the patient. Wang et al. (2007) presented a body piconet based on smart sensor nodes for ECG. Their work uses Bluetooth technology for in-home data transfer and the internet for network data transfer to a hospital. Nag and Sharma (2006) presented their work on a wireless smart clothing system that is capable of acquiring ECG, pulse oximetry, body motion/tilt and skin temperature data. Bonato (2010) gave an extensive survey and review of the major approaches to implement wearable systems. Enabling technologies discussed in that work include miniaturization, lower-power radio, and dedicated operating system, which make body sensor network a reality.

Instead of focusing on specific or a few signals, multimodal systems are gaining popularity. Medjahed et al. (2009) presented a fuzzy logic system utilising a wide range of sensors to recognize activities in a home environment. These sensors include physiological types (cardiac frequency, activity, agitation, posture and fall detection), microphones, infrared, water debit and statechange in appliances.

Many innovative and non-intrusive approaches have been developed in the past several years. Ichihashi and Sankai (2007) developed a small 'smart telecom' unit that integrates sensing circuit, digital signal processor, and wireless communication into a device of size 25 by 37 mm. Such small devices can monitor one's vital signs without being invasive. Kim et al. (2007) developed an integrated home health monitor using a chair as a non-invasive platform. This all-in-one monitor can record ECG, estimate blood pressure, measure blood glucose level and ear temperature. These sampled signals are then transmitted to a home server using Zigbee technology, which in turn are transmitted to a healthcare center via the internet.

Ho et al. (2009) presented a very interesting initiative in an attempt to harvest body temperature and vibrations in the house to power implantable glucose sensors within a wireless home network. Ping et al. (2009) home healthcare research project places heavy emphasis on recognizing a patient's emotional state in addition to physical state. Facial, vocal, eye-movement, and physiological signals are tracked and analyzed to provide the psychological aspects of a patient's health.

Hussain and colleagues (2009) explored the integration of RFID and wireless sensor network in a smart home environment. Their idea is to use the wireless sensor network for tracking the movement and location of individuals while the identification of a person can be accomplished by the wearing of RFID tags. The separation of these events allows for quick decision-making and responses to various situations.

This section presents the major application areas that smart telemedicine plays a dominant role.

Unlike face-to-face medical consultation, useful information must be derived from the raw data in telemedicine. It is almost impossible for humans to examine this large volume of data manually and to detect any changes. Therefore, techniques have to be developed in order to automate the diagnostics and abnormality detection process. This section introduces smart telehealth systems developed for specific illnesses.

Back in 2000, Finkelstein and Friedman (2000) presented a home asthma telemonitoring system that has the capability of assisting asthma patients in self-care plans as well as alerting healthcare personnel when distress situation is detected. Lau et al. (2002) implemented a multimedia system that employs bio-sensor data, messages and video transmission to allow physicians and patients with shoulder replacement surgery to communicate and monitor the progress. Chun et al. (2003) developed a home telemedicine system for cardiac and respiratory disease, diabetes, and hypertension. Using artificial intelligence techniques, this system is capable of providing automated diagnostic and consultation. Performance evaluation has shown that the implemented system is a viable alternative to personal monitoring and consultation. Rudi and Celler (2006) presented an expert telemedicine system that is capable of storing various data and measurement related to diabetes management. In addition to present to medical professionals records associated with individual patients, the system is also capable of recommending insulin dose adjustment to patients. Jiang and Xie (2009) proposed a telehealth monitoring system that uses data mining techniques to deal with the large volume of biological data. They also utilized association rules to recommend actions to be taken for hypertension. Zhang et al. (2009) developed a chronic disease management system using a real-time knowledge base and the case based reasoning approach, together with a web patient monitoring system, to improve the diagnostic of diabetes and hypertension.

Fergus et al. (2009) developed a body area sensor network intended for physiotherapist's use. This system collects and stores motion data of the home patient, and provides some quantitative assessments of the patient's progress. Gobbi et al. (2009) designed a system that addresses issues related to real-time data processing, network architecture, and web-based data management and services. As an automated home monitoring system for lung obstruction, that system was shown to be reliable and efficient. Silva et al. (2010) developed an internet-based system for home monitoring of patients with respiratory muscle disorders. They concluded that their system would be a useful tool for the evaluation of inspiratory muscle in telemedicine services, thus reducing the costs of handling these patients.

A smart home with technologies to enhance the quality of life of quadriplegia patient was proposed by Uzunay and Bicakci (2007) . They placed heavy emphasis on the security aspect of their voice activated smart home facilities. To monitor blood flow velocity in a wireless home environment, Wu et al. (2011) presented a self-monitoring device to measure blood flow velocity that is integrated in a LabVIEW (LabView 2012) mobile environment. Smart home telemedicine technology is ideal for patient selfmonitoring and quality of life improvement, which are the subjects in the next section.

The segments of our population that need quality healthcare the most are the elderly and physically impaired. Home telemedicine and telehealthcare systems are the solution to deliver low-cost yet quality services for these individuals.

In 2006, the United Nation estimated that at least 650 million people have disabilities worldwide (United Nation 2006) . There are various types and degrees of disabilities. According to the Massachusetts Department of Elementary and Secondary Education, the impairments can be classified into communication, emotional, health, intellectual, neurological, physical, and sensory (MDESE 2000) . Andrich et al. (2006) presented their smart home project with case studies involving people with disabilities in different categories: hemiplegia, paraplegia, quadriplegia, motor impairment, and cognitive impairment. Disabled person with the specific type of impairment would require specialised care and tailored smart home technologies.

Many telehealth and assistive systems have been proposed and are in place for the elderlies. Meng et al. (2000) has been working on teleoperated mobile robots via the internet to provide quality healthcare to the elderly. They have also designed robotic pets that are capable of physiological data collection and transmission, as well as simple healthcare tasks (Ling et al. 2005) . Briere and colleagues (2009) presented a teleoperated mobile robot with videoconferencing capability for in-home telerehabilitation services. Vergados et al. (2008 Vergados et al. ( , 2010 discussed their INHOME project which goal is to provide intelligent ambient assistive living services to elderly people at home for independent living. Lim et al. (2010) presented a home healthcare set-top box specially designed for the elderlies. Their work focused on standard compatibility and Smart home technology 539 adherence to the ISO/IEEE 11073 personal health data standard. Vinjumur et al. (2010) implemented a web-based medicine management system that uses RFID tags to monitor medication intake for the elderly at home. With multimodal signal sampling, it is imperative to incorporate data fusion techniques in telehealth monitoring and decision-making. Virone et al. (2003) investigated data fusion of collected video and sound signals in the monitoring of elderly patients at home. Medjahed's group focused on data fusion of multi-senor inputs to provide medical recommendation using a rule based approach (Medjahed et al. 2011) .

Artificial intelligence techniques play a major role in smart home systems. Papamatthaiakis and colleagues (2010) presented an indoor activity recognition system for the elderlies. Using association rules and Allen's temporal relations, they claimed a 100 % recognition rate in identifying everyday activity such as bathing, preparing meals, doing laundry, etc. The MavHome project aims to provide a smart and adaptive environment for inhabitants (Jakkula et al. 2007) . In order to meet the goals of comfort and efficiency in MavHome, health trend monitoring and prediction are made using support vector machine and forecasting tools based on time series data collected in a sensor network. Huo et al. (2009) presented a healthcare environment for the elderlies using a home sensor network and a body sensor network. The interesting aspects of this work lie in the functionalities provided, including outdoor monitoring, and emergency decision and alarms. Various communication techniques, such as automated telephone call, SMS and email, are integrated into the system, transmitting emergency signals to caregivers and family members. Smart decision-making using hidden Markov model is proposed to speed up the decision process, increase the accuracy of event detection, minimise measurement errors, and correct transmission errors. Franco et al. (2010) proposed the use of passive infrared sensors placed in the living quarters of an elderly person to detect abnormal changes in behavior. This system would allow early admission of dependent care for those who show a shift in daily routine, for example, individuals with Alzheimer disease. The monitoring of behavioural changes is an area of interest in telehealth since the onset of certain alarming situations could be detected and healthcare professionals could then be notified. The next section focuses on using smart healthcare system to handle emergency.

Emergency planning and management with respect to inhome healthcare has been a vigorously research topic. Rosen et al. (2002) proposed the Cybercare system to handle national scale disasters. Taking a military approach to map strategy, operations and technology to the healthcare realm of policy, functionality and network infrastructure technologies, they argued the necessity of a nation-wide support information infrastructure to cope with disaster, and of incorporating surge-capacity into a national disaster response system.

Citing the fact that the patients who receive critical emergency services often are not the actual victims of the disaster or outbreak such as SARS (severe acute respiratory syndrome), Joseph et al. (2005) developed a home healthcare disaster planning, recovery, and management system to facilitate treatment of the actual victims. By integrating in-home intelligent devices to provide timely measured information to public offices such as Red Cross, local police etc., they reasoned that the medical personnel can provide homecare remotely and deal with a mass-scale epidemic and natural disasters appropriately.

Smart environment not only can be used in a home environment but can also be used outdoor. Smalls et al. (2009) devised a health monitoring system for use in mass causality emergency situations. By placing a health monitoring device on the body of a victim and integrating this node to a wireless ad-hoc network, vital signs of the victim can be transmitted to regional and national emergency response institutions. This is particular useful in cases where infrastructures are non-operational due to catastrophic disaster or when communication channels are overwhelmed by emergency requests. Advances in wireless technology have driven down the cost of ad-hoc networks, and with fewer attending field personnel, Smalls et al.'s approach may prove to be cost effective in the very near future. Wouhaybi et al. (2010) also proposed a system with similar objectives but they focused on the reduction of false alarm using a rule-based decision system. A disaster management framework proposed by Bessis et al. (2010) integrates various technologies including web services, grid and cloud computing, ad-hoc mobile networks, and wearable and body sensors. Their aim is to provide coherent and collective resource utilization and decisionmaking for multiple parties in emergency situations. Jang et al. (2007) proposed a system using multiple sensor technologies including bio-sensors to monitor an elderly's daily physiological status. Many services are provided to the patient including early warning due to a change of health status, advice for health improvement, and appointment with specific medical practitioners. In addition to sensors, an active robot that provides services to human is part of a smart assistive environment proposed by Lin et al. (2009) . Using multimodal observations to recognize voice and other events, their project shows that health predictions, evaluations, and decisions become more reasonable in the evaluation of emergency level and the assistance required in critical events.

In one of the early studies, de Lunsignan et al. (2000) examined the effectiveness of a home cardiopulmonary monitoring system. This system collects various vital measures via sensors attached to the body and transmits the data wirelessly to a nearby unit at the patient's home. The data are then transferred to a centralised monitoring station. They found the system is acceptable to patients, functionally satisfactory in the home environment, and very reliable in the collection of objective data. Capomolla et al. (2004) monitored patients with CHF (chronic heart failure) either under usual care or telemonitoring care. Their study showed that home telemonitoring is more effective than usual care in reducing healthcare requirements and can improve outcome in CHF patients. Raju et al. (2004) presented their study on the cost effectiveness of mobile telemedicine applications, and the quality of care and medical error reduction. They reported on their extensive literature search and felt that the findings are inconclusive and well-designed protocols are necessary to conduct further large-scale investigations. Zhang and Bai (2005) used a queueing model to evaluate the performance of a home ECG and blood pressure monitoring system based on trial data over a 4-month period. Their objective was to study the traffic load, response time, and scalability of the system. The results are more than satisfactory and show great potential of the examined monitoring system. de Toledo et al. (2006a) reported their experience in using a telemedicine homecare system for patients with chronic obstructive pulmonary disease. Their results suggest that home telemedicine services provide good support to the healthcare professionals, improve patients' condition, and incur low costs.

Jasemian (2008) argued that a successful telemedicine application depends on the patient's compliance, trust and comfort in such home-based systems. An experiment was carried out in 2008 with the patients using ECG monitoring device with a real-time wireless system continuously for a long period of time. Over half of the participants found the system user friendly, reliable, and usable with acceptable performance. Though they found the ECG device heavy and not user-friendly.

Some have argued that the evaluation of home telehealth information systems should not be assessed simply on grounds of technical innovation but should use a holistic interpretive approach. In 2008, Kaldoudi and colleagues (2008) proposed a framework for evaluating home telehealth intervention, together with its application for peritoneal dialysis at home. Ojasalo et al. (2010) conducted a study on smart home technologies and services for intellectually disabled. They found that safety technologies are very well received, and the balance of safety and privacy can be addressed by the appropriate technologies. A 2011 study conducted by Ziefle et al. (2011) on the acceptance of video monitoring in smart home environment for elderly and disabled reveals that acceptance and users' needs and wants are the main issues in a successful deployment of such home medical monitoring technology. The study also shows that there are serious concerns that data may be altered, illegally accessed, and deleted intentionally or due to system failure or virus attack.

Beer and Takayama (2011) performed a study on elderlies who used a mobile remote presence (MRP) system. This study reveals many interesting issues. Benefits of MRP identified by the elderlies include being able to see and be seen with a MRP system, reduction in travel costs and hassles, and a decrease in isolation in a social context. However, concerns raised include MRP usage etiquette, personal privacy, possible overuse, and reliance on the system. Though the elderlies in the study are not technologically inclined, they prefer to operate the MRP system by themselves.

Smart home healthcare and telemedicine systems are here to stay, but there are still many challenges and issues to be resolved. Innovation is important to improve the efficiency and effectiveness, and hence acceptance, of these systems.

Security is major concern in the acceptance of homecare with modern technologies. Many research groups have focused on one of the most important issue in telemedicine, that of the integrity and security of transmitted data. Simpson et al. (2006) posed several challenging issues regarding continuous home monitoring: who should receive information as the patient, family members, caregivers and medical professionals all have interest; what information should each person receive without violating any data privacy and security concerns; how should information be presented since each party may prefer different mode of communication such as telephone, computer, etc. Proposed solutions to the security issue include cryptography (Mantas et al. 2009 ) and context-aware access control rules (Guennoun and El-Khatib 2009).

Due to the sensitive nature of health information, privacy is an important issue in data transmission and storage in telehealth systems. Without proper and established protocols and regulations in place, telemedicine would not be used widely as many people are concerned with the Smart home technology 541 privacy of their health information. Kotz and colleagues (2009) compared existing privacy frameworks, identified a set of desirable privacy properties in mobile healthcare systems, and used their findings to propose a privacy framework. They also raised several privacy issues and questions that need to be addressed by technical people, governmental agencies and regulatory organisations. Reliability is another critical factor in the implementation of smart homecare. Wireless technologies make telehealth care possible, however, such networks that operate in hostile outdoor environment have many reliability issues. Using rural China as a case study, Fong and Pecht (2010) identified and reviewed the factors that can impact on the reliability of telehealth care networks: physical obstacles, atmospheric absorption, inadequate fade margin and system failure. Gaddam et al. (2008) studied extensively the various issues related to the implementation of sensor networks for home healthcare and emergency. They have identified potential challenges including interoperability and interference, real-time data acquisition and processing, reliability and robustness, energy conservation, data management, data privacy and security, and comfort and unobtrusive operation. In addition, design issues for wireless networks considered are deployment of sensor nodes, mobility of wireless sensor, cost and size of the wireless node, infrastructure of the network, network coverage, network size, power management, life-time of the sensor networks, and quality of service requirements in such networks.

Since the second-half of the 2000s, there have been numerous reported work and innovation in smart healthcare systems. Taylor and Dajani (2008) gave a sound argument that the future home healthcare systems should take into consideration a well-balanced implementation infrastructure based on the web, mobile, and broadband technologies. Moritz et al. (2009) emphasized the importance of various fundamental issues in using interoperable devices in home healthcare. These issues include energy consumption, power supply, memory, computing power, and bandwidth.

Koufi and colleagues (2010) implemented a grid portal that provides services to people who need medical advice at their homes. The portal is an integrated system of wireless personal digital assistants (PDAs) and grid technology, with heavy design emphasis placed on security access and storage of data.

For telehealth, the monitoring of an individual creates a continuous stream of data that must be stored either locally at home or at a centralised database. Lasierra et al. (2010 Lasierra et al. ( , 2011 used an ontology approach to arrange patient data and records in a formal structure so as to support health information interoperability.

Invasive devices are being recognised as one of the prime reasons at-home patients are hesitant to use telehealth care monitoring systems. Motoi et al. (2010) demonstrated the possibility of using non-invasive technologies for home healthcare. Devices are installed on toilets, bathtubs, and beds to measure various vital signals. They deployed this prototyping system for subjects with cardiovascular disease or sleep disorder successfully.

Modifying and conditioning patient's behaviour is another innovative trend that is gaining attention these days. Evers and Krose (2010) developed a monitoring system tracking the physical and emotional condition via a sensor network. Patients are provided with feedback to promote activities and behaviour with positive health impact. Also, the integration of wearable technology and robots is a promising avenue to facilitate therapeutic intervention for chronic conditions, which potentially can reap benefits from these combined technologies (Bonato 2010).

Point-of-care testing is another developing trend in enhancing home healthcare. Many innovative devices are being investigated that potentially shorten the time between testing and diagnostic, and are especially useful in rural settings. Beyette et al. (2011) provided a comprehensive survey and a special volume on these innovative handheld and home-based devices. These devices include sensors for multispectral imaging, tomography, cardiac, EEG, Chlamydia trachomatis, bladder pressure, respiratory impairment, as well as for detection and analysis of macula swelling, pathogen detection, metabolic syndrome prediction, energy metabolism, Chagas disease, vascular tree identification, Parkinson's disease, etc.

Back in 2005, Stankovic et al. (2005) at the University of Virginia identified three critical development issues in wireless sensor networks for in-home healthcare. The first issue is the enabling technologies for future medical devices: interoperability, real-time data acquisition and analysis, reliability and robustness, and new node architectures. Embedded, real-time, networked system infrastructure is the other critical development area which includes patient and object tracking, communication, interference, multimodal collaboration, energy conservation, and multi-tiered data management. The third issue concerns medical practice-driven models and requirements including role-base access control and delegation in realtime, unobtrusive operation, and records and data privacy and security.

The critical development areas of concern, as suggested by Stankovic's team, have not yet been fully addressed with today's technology. There are ample opportunities for research and development in improving telemedicine systems as they are still at an infancy stage. Some of the challenges and issues in building a smart home environment are shown in Fig. 2 . Without a doubt, smart home telemedicine systems will be deployed in an increasingly rapid pace in the years to come.

Anagnostaki A et al (2002) 

",0.7843679437754867
Evaluating Hospital-Based Surveillance for Outbreak Detection in Bangladesh: Analysis of Healthcare Utilization Data,The International Health Regulations outline core requirements to ensure the detection of public health threats of international concern. Assessing the capacity of surveillance systems to detect these threats is crucial for evaluating a country's ability to meet these requirements.,"We propose a framework to evaluate the sensitivity and representativeness of hospital-based surveillance and apply it to severe neurological infectious diseases and fatal respiratory infectious diseases in Bangladesh. We identified cases in selected communities within surveillance hospital catchment areas using key informant and house-to-house surveys and ascertained where cases had sought care. We estimated the probability of surveillance detecting different sized outbreaks by distance from the surveillance hospital and compared characteristics of cases identified in the community and cases attending surveillance hospitals.

We estimated that surveillance detected 26% (95% CI 18%-33%) of severe neurological disease cases and 18% (95% CI 16%-21%) of fatal respiratory disease cases residing at 10 km distance from a surveillance hospital. Detection probabilities decreased markedly with a1111111111 a1111111111 a1111111111 a1111111111 a1111111111

distance. The probability of detecting small outbreaks (three cases) dropped below 50% at distances greater than 26 km for severe neurological disease and at distances greater than 7 km for fatal respiratory disease. Characteristics of cases attending surveillance hospitals were largely representative of all cases; however, neurological disease cases aged <5 y or from the lowest socioeconomic group and fatal respiratory disease cases aged !60 y were underrepresented.

Our estimates of outbreak detection rely on suspected cases that attend a surveillance hospital receiving laboratory confirmation of disease and being reported to the surveillance system. The extent to which this occurs will depend on disease characteristics (e.g., severity and symptom specificity) and surveillance resources.

We present a new approach to evaluating the sensitivity and representativeness of hospitalbased surveillance, making it possible to predict its ability to detect emerging threats.

• Many countries rely on hospital-based surveillance for the detection of infectious diseases of national and global public health relevance.

• It is often difficult to access suitable external reference data to assess the capacity of a surveillance system to detect cases and outbreaks or to characterize cases.

• We demonstrate a novel approach using healthcare utilization data to evaluate the sensitivity and representativeness of severe infectious disease surveillance in Bangladesh.

• The capacity to detect cases and outbreaks decreased with distance from surveillance hospitals.

• Cases captured by surveillance differed from cases in communities by age and socioeconomic status.

• Geographic coverage of surveillance could be improved by including other hospitals in the surveillance system.

• The presented approach is applicable for a wide range of infectious diseases in different settings, taking some practical considerations into account.

• Hospital-based surveillance may have low sensitivity in rural areas at greater distances from surveillance hospitals, suggesting a risk of unrecognized transmission of emerging infectious diseases.

A well-functioning disease surveillance system is crucial for the identification and control of outbreaks, and hence the prevention of national and global health emergencies [1] . The World Health Organization (WHO) highlighted the value of national surveillance systems in the International Health Regulations (2005) , an agreement among all member states to develop and maintain sufficient capacity for the detection, reporting, and control of public health threats of international concern [2] . Infectious disease surveillance should enable (i) the timely detection of outbreaks, (ii) the quantification of health problems, (iii) the identification of subpopulations at risk, and (iv) the assessment of temporal trends including the impact of control strategies [3, 4] . National surveillance systems typically collect data from patients seeking care at sentinel hospitals or other healthcare facilities and can provide useful information for public health purposes. However, hospital-based surveillance generally underestimates disease burden since only a proportion of cases visit a hospital for care [5] . Low case detection may also undermine the value of hospital-based surveillance for outbreak detection. Moreover, if patients captured by the surveillance system are not representative of all cases in the community, surveillance statistics could lead to erroneous interpretations of disease patterns and misallocation of prevention resources. In particular, sex, socioeconomic status, or distance can affect healthcare seeking at hospitals, especially where access to care is limited [6] [7] [8] [9] . Surveillance evaluation guidelines, such as those established by the US Centers of Disease Control and Prevention, list sensitivity and representativeness among the attributes that a public health surveillance system should possess and that require assessment [10, 11] . In order to follow these guidelines, we need external reference data that are often unavailable in resource-poor settings [12] .

Here, we present a new approach to evaluating the capacity of a surveillance system to detect and characterize disease cases, with emphasis on outbreaks of emerging infections that often occur as small case clusters in remote areas. We apply our methodology to assess hospital-based surveillance of severe neurological infectious disease and fatal respiratory infectious disease in Bangladesh.

The field teams obtained written informed consent from participants or their guardians (if <18 y of age) during community surveys. Healthcare utilization survey protocols were reviewed and approved by the Ethical Review Committee of the International Centre for Diarrhoeal Disease Research, Bangladesh.

how epidemiological studies can be used to identify cases with severe symptoms in communities and capture their personal and healthcare utilization characteristics (data collection stage) (Fig 1) . In addition to detailing how we collected the data in this study, we provide information about how the approach could be varied in other settings. We subsequently demonstrate how such data can be used to evaluate the sensitivity and representativeness of surveillance systems (evaluation stage). We then apply our approach to the detection of severe neurological infectious diseases and fatal respiratory infectious diseases in Bangladesh as a case study.

Selecting study locations. The first step was to randomly select communities at differing distances from the surveillance hospitals. We specified catchment areas of selected hospitals based on hospital records and subsequently randomly selected small administrative units from which all communities were surveyed. Selection of communities could also be done through census data or using detailed population maps of the area.

Identifying people with diseases in the selected community. Study teams visited the selected communities and identified cases that had had the disease of interest. The retrospective identification of severe disease cases in the community was based on syndromic criteria, used as a proxy for clinical case definitions that would be applied in healthcare facilities. The In the Bangladesh example, the catchment areas of surveillance hospitals were first defined based on hospital records (e.g., areas where >50% or >75% of cases reside) [13, 14] . Subsequently, small administrative units were chosen at random from within the catchment area, and all communities in the selected areas were surveyed. Cases in the community were identified based on lists of deaths in addition to community networking strategies (rural settings) or house-to-house surveys (urban settings). Information on symptoms (to establish case definitions), healthcare seeking behavior, and characteristics of cases was collected. In other settings, the exact survey procedures may vary according to the context. identification of such cases in the community is often the most problematic step, and the optimum strategy will depend on the local context, the severity of the disease, and the specificity of disease symptoms.

Collecting information on healthcare seeking and personal case characteristics. To estimate case detection probabilities, identify biases in case statistics, and characterize the healthcare utilization behavior in the population, we needed information about the healthcare seeking and personal characteristics of cases. In particular, we needed to identify whether the cases attended a surveillance hospital. Such information was obtained during household visits of identified cases. To understand the impact of distance from the hospital, we approximated the locations of households by the central positions of the small administrative units. Alternatively, household locations could be recorded precisely using GPS devices.

Quantifying the probability of detecting a case. We estimated the case detection probability as the proportion of cases who reportedly attended a surveillance hospital among all cases identified in the community. We further assessed how this probability changed with distance from the surveillance hospital.

Quantifying the probability of detecting outbreaks. We subsequently used the estimated case detection probabilities to quantify the capacity of the surveillance system to identify disease outbreaks. We estimated outbreak detection probabilities for varying outbreak sizes and for outbreaks occurring at different distances from surveillance hospitals.

Assessing the representativeness of detected cases. We evaluated the representativeness of detected cases by estimating the difference between case statistics (proportions of specific case characteristics) based on all cases in the community and based on identified cases who attended the surveillance hospital. The investigated characteristics included sex, age, and socioeconomic status.

Assessing alternative surveillance strategies. To investigate how sensitivity and representativeness of the surveillance system could be improved by integrating other healthcare providers, we applied the evaluation procedures as described above to other healthcare provider types.

We demonstrate the application of the proposed evaluation strategy by using it to assess the capacity of hospital-based surveillance for severe infectious diseases in Bangladesh, which is based on tertiary care hospitals located throughout the country. We used data from two surveys carried out in catchment areas of some of these hospitals that investigated the healthcare utilization behavior of individuals with severe neurological infectious disease or fatal respiratory infectious disease (Fig 2A) [14, 15] . These disease types are of great public health relevance in Bangladesh (e.g., Japanese encephalitis and influenza) but also represent symptoms typical of other emerging infectious diseases (e.g., Nipah and severe acute respiratory syndrome). A first survey collected data between 10 June 2008 and 30 March 2009 about cases with symptoms of severe neurological infection that occurred within the previous 12 mo in 60 small administrative units (mean population size of 28,000 people) in the catchment areas of three surveillance hospitals [14] . A second survey collected data between 3 April 2012 and 22 February 2013 about acute respiratory infection (ARI)-related deaths that occurred within the previous 24 mo in 22 administrative units in the catchment areas of 11 surveillance hospitals [15] . We considered ARI-related deaths as a proxy for respiratory disease of sufficient severity to require medical attention. The surveillance hospital in Dhaka City was excluded from the original studies because of the difficulty of defining the catchment area (a step necessary for the original study purpose), as people nationwide seek medical care in Dhaka. The surveys followed procedures as previously described and summarized below [13, 14] . Characteristics of the study population are described in Fig. A in S1 Text. [16] . Sixty-eight percent of the population in Bangladesh lives >30 km from a surveillance hospital (including the Dhaka surveillance hospital), a distance at which case and outbreak detection probabilities are low. (C) Probability of surveillance case detection by distance. The observed probability was calculated as a moving average over a 25 km distance window. Case detection probabilities were estimated using logbinomial regression models including distance as an explanatory variable. Evaluating Hospital-Based Surveillance

The catchment areas of selected hospitals were first specified based on hospital records (S1 Text). Small administrative units (mean population of 28,000 people) were subsequently selected randomly within the catchment areas, and all communities in the selected areas surveyed. The identification of cases in selected communities was based on social structures, i.e., cases were identified by visiting public meeting points, such as mosques, markets, or tea-stalls, where health problems in the community are often publicly discussed. Cases were subsequently confirmed by household visits. In urban areas, house-to-house surveys were conducted to compensate for less pronounced community structures. Additional fatal respiratory infectious disease cases were identified through lists of deaths provided by administrative officers. For both disease types, the identification of cases was based on syndromic criteria. We defined severe neurological infectious disease as fever with altered mental status for >6 h or with unconsciousness for !1 h, or fever with altered mental status, unconsciousness, or a new onset seizure that resulted in death. Fatal respiratory infectious disease (ARI-related death) was defined as having any two of the following symptoms in the 30 d prior to death: sudden onset of fever, cough, breathing difficulty, feeding difficulty, or runny nose. Deaths in children aged <5 y were also classified as ARI-related deaths if there was a sudden onset of breathing difficulty in the 30 d prior to death.

During surveys, information was collected on healthcare utilization behavior and personal characteristics of identified severe neurological and fatal respiratory disease cases. Cases or their household members were asked whether the case visited the surveillance hospital or any other healthcare provider, including other nonlocal hospitals, during his/her illness. Further, information on sex, age, socioeconomic status, and geographic location of households of cases was collected.

We defined ""community cases"" as all severe neurological or fatal respiratory disease cases identified during community surveys (whether they attended a surveillance hospital or not) and ""surveillance cases"" as the subset of community cases who reportedly attended a surveillance hospital. For each case identified in community surveys, we identified whether they attended their nearest surveillance hospital. We then estimated the distance to that surveillance hospital as the distance between the residence administrative unit centroid and that specific surveillance hospital using QGIS [17] . Age was categorized as <5, 5-14, 15-59, and !60 y. A socioeconomic status index was generated by principal component analysis based on household assets (electricity, working television, bicycle, motorcycle, sewing machine, mobile phone) and categorized into tertiles (lowest, middle, and highest) [18] . In sensitivity analyses, we explored the use of continuous age and socioeconomic status classified into quintiles (S1 Text). Socioeconomic status was missing for 45 of 1,633 fatal respiratory disease cases, who were excluded from the analysis where this information was required. Three fatal respiratory disease cases were excluded from all analyses due to missing healthcare seeking information.

We estimated the disease-specific case detection probability as the proportion of cases who reportedly sought care at a surveillance hospital among all cases identified during community surveys (number of surveillance cases/number of community cases) and computed 95% confidence intervals (95% CIs) based on the Clopper-Pearson exact method [19] . We quantified case detection probabilities by distance from a surveillance hospital using log-binomial regression analysis separately for severe neurological and fatal respiratory disease cases. We further investigated more complex functional forms of distance in log-binomial regression models. We fitted models with polynomial terms up to the fifth degree and models with basic splines with knots at various positions (between 20 and 50 km distance). Model fit was compared based on the Akaike information criterion (AIC), and the models with lowest AIC were selected. The fit of selected models was compared to the observed proportion of cases who attended surveillance hospitals at different distances (moving average over a distance window of 25 km). We estimated the proportion of the population living >30 km and >50 km from a surveillance hospital using gridded population density estimates of 100 × 100 m resolution [16] .

To quantify the capacity of the surveillance system to detect outbreaks of varying sizes, we calculated the probability that at least one case was detected:

Pr outbreak1 is the outbreak detection probability based on a one-case threshold, Pr is the case detection probability, and s is the outbreak size. This calculation assumes that the probability of detecting a sentinel case is independent of other cases. We used distance-specific case detection probabilities estimated by log-binomial regression and obtained confidence intervals of outbreak detection probabilities based on the 95% CI limits of case detection probabilities. We further estimated the size of the smallest outbreak that would be detected with !90% probability by distance from the surveillance hospital. For emerging infectious diseases of global health importance, such as Nipah, severe acute respiratory syndrome, or avian influenza, a single detected case may be considered an outbreak. For other disease systems (e.g., endemic diseases or diseases for which differential diagnosis is difficult), an outbreak may be declared only after more than a single case is detected over a specified period of time and within specified geographic boundaries [20] . We can extend the framework to estimate the probability of identifying an outbreak with different outbreak thresholds applied, and we provide examples for outbreaks defined as detection of at least two cases or at least five cases. We calculated the probability of detecting at least two cases (Pr outbreak2 ) as one minus the probability of detecting no cases (Pr 0 ) and exactly one case (Pr 1 ):

Likewise, we estimated the probability of detecting at least five cases (Pr outbreak5 ) as one minus the probability of detecting no cases (Pr 0 ) and exactly one (Pr 1 ), two (Pr 2 ), three (Pr 3 ), and four cases (Pr 4 ):

We investigated the representativeness of surveillance cases (sex, age, and socioeconomic group) by comparing the proportion of cases with a specific characteristic (and exact binomial confidence intervals) among community cases to the proportion of cases with that characteristic among surveillance cases. We quantified the absolute difference in proportions (proportion of cases with characteristic among surveillance cases minus proportion among community cases) with 95% CIs and p-values using bootstrapping (2,000 bootstrap iterations) [21] .

Based on the collected healthcare utilization data, we evaluated how the sensitivity and representativeness of a surveillance system may be improved by integrating other healthcare providers. We classified healthcare providers as (i) surveillance hospitals, (ii) other hospitals (government and private clinics), (iii) qualified private practitioners, and (iv) the informal sector (unqualified practitioners such as traditional healers, village doctors, homeopaths, and pharmacies). We estimated the proportion of cases attending each healthcare provider class, with exact binomial confidence intervals, and estimated outbreak detection probabilities based on proportions attending the surveillance hospital plus (i) other hospitals, (ii) qualified private practitioners, or (iii) informal healthcare providers. Furthermore, we compared the proportion of cases with each characteristic (sex, age, and socioeconomic group) among community cases to the proportion among those attending each healthcare provider class and quantified absolute differences in proportions with 95% CIs and p-values using bootstrapping (2,000 bootstrap iterations).

All statistical analyses and graphics were implemented in the R computing environment; maps were created using QGIS software [17, 22] .

The studied communities were located within 95 km (severe neurological infectious disease) and 62 km (fatal respiratory infectious disease) of a surveillance hospital. In these communities, 76 of 426 severe neurological disease cases (18%, 95% CI 14%-22%) and 234 of 1,630 fatal respiratory disease cases (14%, 95% CI 13%-16%) attended a surveillance hospital. Adjusting for distance, the case detection probability was nearly twice as high among severe neurological disease cases than among fatal respiratory disease cases (risk ratio 1.8, 95% CI 1.4-2.3; p < 0.001). At 10 km distance, an estimated 26% (95% CI 18%-33%) of severe neurological disease cases and 18% (95% CI 16%-21%) of fatal respiratory disease cases were detected by the hospital-based surveillance. The detection probability decreased with distance from the surveillance hospital, and the decline was faster for fatal respiratory disease than for severe neurological disease. A 10 km distance increase resulted in a 12% (95% CI 4%-19%; p = 0.003) relative reduction in case detection probability for severe neurological disease but a 36% (95% CI 29%-43%; p < 0.001) relative reduction for fatal respiratory disease (Fig 2C) . Including more complex functional forms of distance in the log-binomial regression models did not improve model fit based on AIC (Table A and Figs . B and C in S1 Text).

The probability of detecting an outbreak of exactly three cases (if a single detected case was considered an outbreak) dropped below 50% at distances greater than 26 km for severe neurological disease and at distances greater than 7 km for fatal respiratory disease (Fig 3A) . Fig 3B  and 3C show the minimum number of cases required for surveillance to detect outbreaks with a probability of !90% if different outbreak thresholds are applied. For outbreaks defined as detection of at least one case, we found that an outbreak of fatal respiratory disease required 12 cases (95% CI 11-13) to be detected with 90% probability at 10 km from a surveillance hospital, but 30 cases (95% CI 24-39) to be detected at 30 km. In contrast, the impact of distance on the outbreak size requirement was much more limited for severe neurological disease: eight cases (95% CI 6-12) at 10 km and 11 cases (95% CI 9-14) at 30 km. For outbreaks defined as detection of at least two cases, 14 severe neurological disease cases (95% CI 11-20) and 20 fatal respiratory disease cases (95% CI 18-23) would be necessary for an outbreak to be detected at 10 km distance, and 19 severe neurological disease cases (95% CI 15-24) and 51 fatal respiratory disease cases (95% CI 41-66) at 30 km. The necessary outbreak sizes increased further when a five-case threshold was applied, so that 28 severe neurological disease cases (95% CI [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] and 39 fatal respiratory disease cases (95% CI 35-44) would need to occur for an outbreak to be detected at 10 km distance, and 36 (95% CI 30-46) and 97 (95% CI 79-128), respectively, cases at 30 km.

Surveillance hospital attendance among community cases varied by case characteristics, leading sometimes to biased disease statistics among surveillance cases (Table B in S1 Text). For severe neurological disease, individuals aged <5 y represented 48% of community cases but only 29% of surveillance cases (p < 0.001). Additionally, the proportion of cases in the lowest socioeconomic group was lower among surveillance cases than among community cases (43% versus 57%; p = 0.012), while the proportion of individuals aged 15-59 y was higher (43% versus 29%; p = 0.005) (Fig 4A) . For fatal respiratory disease, the proportion of individuals aged !60 y (47% versus 62%; p < 0.001) was lower among surveillance cases than among community cases, while the proportion of individuals aged <5 y (24% versus 18%; p = 0.020), individuals aged 15-59 y (27% versus 18%; p < 0.001), and cases in the highest socioeconomic group (43% versus 37%; p = 0.022) was higher (Fig 4B) . We observed a slight difference in the proportion of females for fatal respiratory disease (34% among surveillance cases versus 38% among community cases; p = 0.108), but not for severe neurological disease (39% versus 40%; p = 0.861). Results were consistent in sensitivity analyses with age as a continuous variable and socioeconomic status classified into quintiles (Figs. D and E in S1 Text).

A substantial proportion of cases (severe neurological disease 42% [95% CI 38%-47%]; fatal respiratory disease 26% [95% CI 24%-28%]) visited multiple healthcare providers during their illness. Forty-eight percent (95% CI 44%-53%) of severe neurological disease cases and 31% (95% CI 29%-34%) of fatal respiratory disease cases attended any hospital, including surveillance hospitals (Fig 5) . Including other hospitals that were attended by cases in the surveillance system could have increased the overall case detection probability by 31% (absolute increase) for severe neurological disease cases and 17% for fatal respiratory disease cases. The capacity to detect outbreaks would have increased, so that outbreaks containing four severe neurological or eight fatal respiratory disease cases would have been detected with !90% probability for any distance in the range 0-40 km from the original surveillance hospital, compared to 13 and 47 cases, respectively, with the current system ( Fig. F in S1 Text) . However, since individuals who attended any hospital had similar characteristics in terms of sex, age, and socioeconomic status as those attending surveillance hospitals (Fig. G in S1 Text), this expansion would not have increased disease detection in key groups such as the lowest socioeconomic group. Only with the informal sector incorporated in the surveillance system would cases in such groups be detected.

We described an analytic approach for evaluating the sensitivity and representativeness of hospital-based surveillance systems and applied it to surveillance for severe neurological diseases and fatal respiratory infectious diseases in Bangladesh. We quantified the proportion of cases detected and the probability that the surveillance system would detect different sized outbreaks by distance from the surveillance hospital. Finally, we characterized biases in surveillance statistics and identified potential improvements to the surveillance platform.

We estimated that approximately one-quarter of severe neurological disease cases and onefifth of fatal respiratory disease cases occurring 10 km from a surveillance hospital would be detected with current surveillance. The proportion of cases attending a surveillance hospital declined significantly with increasing distance between individuals' residence and the surveillance hospital, substantially faster for fatal respiratory disease than for severe neurological disease. These low detection probabilities mean that hospital-based surveillance in Bangladesh (like in most other resource-poor countries presumably) would likely miss a high proportion of single-case public health events. Of greater relevance is that surveillance system capacity to detect outbreaks and detection probabilities increased substantially with the number of cases. The required number of cases to detect outbreaks with high probability varied with disease type and distance from the surveillance hospital. It could be as low as about ten cases if the outbreak occurred <10 km from the surveillance hospital but increased quickly with distance for Evaluating Hospital-Based Surveillance fatal respiratory disease. For outbreaks defined as a single detected case, we found that more than half of outbreaks with ten cases of fatal respiratory disease would be missed if the outbreak occurred >32 km from the hospital. Such detailed quantification of outbreak detection probability is essential to ascertain the likelihood that an emerging threat can be detected early enough to be contained [23] .

In some circumstances, authorities may have to wait until more than a single case is detected to recognize that an outbreak is occurring. In particular, difficult differential diagnoses and lack of appropriate diagnostic tests mean that only when a number of cases are detected from the same area and over a short time frame will an outbreak be identified and further investigations conducted. In addition, where a low background level of transmission is expected (such as with endemic diseases), public health authorities may wait until a particular threshold is exceeded before declaring an outbreak. In both of these scenarios, where multiple cases need to be detected by the hospital before an outbreak is recognized, the optimal number of detected cases and their spatial and temporal separation will depend on the disease system. We can incorporate this information into our flexible framework and provide examples where we calculate the size an outbreak needs to be for scenarios where at least two or five cases need to be detected (Fig 3B and 3C ). In particular, this demonstrates that if an outbreak is identified only once five cases are detected at the surveillance hospital, the size of the outbreak would have to be substantially larger (e.g., nearly 100 total cases of a fatal respiratory disease at 30 km from a surveillance hospital) for there to be a 90% chance of an outbreak being identified. This highlights the possibility that, by the time an outbreak reaches sufficient size to be detected by the system, outbreak control measures may be much less effective at controlling spread. Thresholds for case counts that trigger an outbreak response should be crafted taking this possibility into account.

Low detection probabilities for outbreaks that occur far from surveillance hospitals are an important concern because pathogens with high case fatality such as Japanese encephalitis and Nipah virus are nearly exclusively found in rural communities in Bangladesh [24, 25] , and Evaluating Hospital-Based Surveillance these communities are usually located far from surveillance hospitals. Rural environments are also considered to be at highest risk for the emergence of novel pathogens [26, 27] . Population distribution maps suggest that 68% of the population in Bangladesh live in communities >30 km from a surveillance hospital (representing 108 million individuals) and 40% live >50 km from a surveillance hospital (representing 63 million people) (Fig 2B) . Strengthening healthcare-based surveillance in these areas should be a priority, and cost-effective approaches to achieving surveillance targets need to be identified. There is increasing recognition of the value of novel data sources to improve the sensitivity of infectious disease surveillance, some of which can provide crucial information in remote areas [20] . Novel approaches include surveillance for media reports of disease clusters, as used for various infectious diseases in Bangladesh [12, 28] , and training of local drug sellers to recognize and report disease symptoms, as rolled out nationally to enhance tuberculosis surveillance in Ghana [29] . Other surveillance data streams, such as monitoring over-the-counter medication sales, telephone triage, and webbased queries, have been successfully integrated in surveillance systems in resource-rich settings [30] .

We found that cases attending surveillance hospitals were not necessarily representative of all cases in the community. In particular, the youngest severe neurological disease cases and the oldest fatal respiratory disease cases were less likely to attend surveillance hospitals, and attendance was also lower among cases in the lowest socioeconomic group. Similar variation in hospital attendance has been reported in other resource-poor settings [6, 8, 9] , indicating that hospital-based surveillance in these countries may have comparable limitations. Disease statistics obtained through hospital-based surveillance have to be interpreted in the light of detected biases, and correction factors may need to be applied. For example, underestimating severe neurological disease among young children may mislead any future Japanese encephalitis vaccination strategy [31, 32] . Differential surveillance hospital attendance may also influence the capacity to detect emerging infections, such as the avian influenza A (H7N9) virus that emerged in 2013 in China with observed cases mainly among elderly men [33] .

Overall, access to appropriate care was poor-over 30% of community cases with severe disease or who died in our study never saw a qualified provider. Such low access is a common problem in low-income settings and means that a large proportion of the population, and particularly subgroups that are potentially at highest need, do not receive the required medical attention [6] [7] [8] [9] . For example, difficulties accessing qualified healthcare providers for elderly people, who are often at greatest risk of respiratory disease, can have severe consequences for the outcome of disease. Previous studies have demonstrated that accessibility to healthcare is a significant predictor of morbidity and mortality among elderly individuals with respiratory disease [34] .

The study showed that healthcare utilization behavior varied by disease type, which may be due to different characteristics of cases such as their age, socioeconomic status, and geographic location (Fig. A in S1 Text) . The majority of fatal respiratory disease cases were !60 y old and may have faced limitations in mobility; moreover, rapid progression of disease to death may have prevented cases in this age group from seeking appropriate care. Cases and their family members in general may have also perceived neurological symptoms as more severe, resulting in higher motivation to attend a qualified healthcare provider [7] .

We evaluated potential improvements of surveillance by analyzing healthcare seeking behavior among cases identified in communities. While the majority of individuals did seek care, much of this was in the informal sector, which cannot easily be incorporated into surveillance activity. Nevertheless, including other hospitals attended by cases in the surveillance system (the exact location and number of these hospitals was unfortunately not identified during surveys) would double case detection probabilities and allow detection of medium-sized outbreaks (<10 cases) in a wider geographic area. However, in the case of Bangladesh, such extension is likely to be prohibitively expensive. Mapping other hospitals in Bangladesh that may serve as surveillance sites would allow testing of various surveillance scenarios to identify the optimal location of surveillance sites while keeping the same total number or to quantify the number of sites needed to achieve a target surveillance coverage [35] . Many emerging infectious diseases originate as spillover infections of zoonotic diseases into the human population [36] . Therefore, mapping the occurrence of relevant zoonotic diseases (e.g., avian influenza) and combining such maps with the estimated outbreak detection probabilities would allow highlighting of surveillance gaps for particular types of emerging infectious diseases.

The capacity of surveillance systems to detect outbreaks will depend not only on the probability that a case attends a surveillance hospital, but also on whether the case undergoes confirmatory laboratory testing and is subsequently reported through the surveillance system by the hospital. Here we assumed a ""best-case scenario"" with a fully functional surveillance system at the hospital level, where each case who attends the surveillance hospital is ultimately recognized and confirmed as a case. Case detection at the hospital may however be incomplete, since case definitions at hospitals may differ from syndromic definitions, a surveillance sampling frame may be applied, or resources and trained personnel for the diagnosis and reporting of cases may be limited [37] . The calculation of case and outbreak detection probabilities may be adjusted for misdiagnosis and underreporting at hospitals if such information is available. We further assumed complete detection of cases in communities during surveys. Although a few cases may have been missed, this assumption is justified as we investigated severe disease conditions that are easily remembered by family and community members. Moreover, survey procedures combining interviews of key informants and house-to-house visits were specifically designed to capture near-complete case information. Further, any missed cases are unlikely to impact our estimates, as such impacts would occur only if there was differential healthcare seeking between those detected and those missed. We investigated spatial differences in hospital attendance based on the straight-line distance of communities from the surveillance hospital. If available, other distance measures such as travel distance or travel time may provide a more accurate indicator of distance from the surveillance hospital. In some cases, these measures may strongly vary with the season, and it would be interesting to explore how that may impact the probability of detecting an outbreak. We assumed that cases did not visit other surveillance hospitals than the catchment hospital. Given the poor road infrastructure in the country, it would be very unusual to travel to a tertiary care hospital that was not the closest one. It is possible that some individuals traveled to Dhaka; however, these are likely to be wealthier individuals who would visit small private healthcare facilities that are not part of the surveillance network. The surveillance hospital in Dhaka was not included in our study. This is unlikely to have biased our assessment of the performance of the surveillance system outside the capital. Indeed, this would introduce a bias only under the unlikely scenario that many cases in our study who did not attend the nearest surveillance hospital (and were therefore not captured there) instead attended the surveillance hospital in Dhaka (and were captured there). Surveillance system performance in the capital city may however differ from elsewhere, and a comprehensive assessment of the national surveillance system would therefore have to include Dhaka. Moreover, hospital-based surveillance is only one surveillance type in Bangladesh, and other data sources need to be considered to assess the country's overall capacity to detect public health events.

The described methodology is applicable to assessing surveillance for other severe diseases in resource-poor settings, keeping in mind practical constraints. Conducting community surveys may be labor intensive, time consuming, and expensive depending on the setting and may be particularly challenging in densely populated areas such as Dhaka. Nonetheless, such surveys are valuable tools for obtaining external reference data and simultaneously assess heterogeneities in healthcare access. The effectiveness of community networking may depend on the social structures in the study area; where social links are weaker (e.g., in urban areas), house-to-house surveys, even though more labor intensive, may be more suitable for the identification of cases in the community. The proposed strategy is valid for diseases of sufficient severity to require medical attention and to be remembered by cases and family members. The approach is syndromic (i.e., disease types are classified based on a set of symptoms), and the classification specificity may vary by disease.

In conclusion, this study allowed us to quantify the sensitivity and representativeness of hospital-based surveillance and to identify weaknesses, particularly in detecting small-to medium-sized outbreaks in remote areas. These findings highlight difficulties that low-middle-income countries may have in meeting International Health Regulations requirements, despite considerable investment in hospital-based surveillance platforms. 

",0.7725496565463779
Integrated Sensor Systems and Data Fusion for Homeland Protection,"As stated by John Naisbitt in his bestseller ""Megatrends"" [1] , published in 1982, about the new trends and directions transforming our lives: ""We are drowning in information but starved for knowledge. This level of information is clearly impossible to be handled by present means. Uncontrolled and unorganized information is no longer a resource in an information society, instead it becomes the enemy."" This successful sentence can be taken as a statement of the problem of information fusion: how can knowledge, awareness and decision making capability be achieved starting from the available information?","and data links. After conceiving also algorithms to track targets on the basis of the angle and identification measurements provided by ESM on a moving platform, data fusion of active and passive tracks was provided [14] [15] [16] [17] .

Nowadays concepts have been developed and spread to be applied to very complex systems with the aim to achieve the highest level of intelligence as possible and hopefully to support decision. Data fusion is aimed to enhance situation awareness and decision making through the combination of information/data obtained by networks of homogeneous and/or heterogeneous sensors. A sensor network presents advantages over a single sensor under different points of views, as it supplies both redundant and complementary information. Redundant information is exploited to make the system robust to the failure in order that a malfunction of an entity of the system means only a degradation of the performances, rather than the complete failure of the system, since information about the same environment can be obtained from different sources. More robustness can be achieved also with respect to interferences, both intentional and unintentional, due to frequency and spatial diversity of the sensors. Complementary information build up a more complete picture of the observed system; for example sensors are dislocated over large regions providing diverse viewing angles of observed phenomenon and different technologies can be employed in the same application to provide improved system performance.

A large number of different applications, algorithms and architectures have been developed exploiting these advantages. Several examples can be found in robotics, military applications, Homeland Protection and management of large and complex critical infrastructures. Although the specific nature of each problem is different, the final goal, from the point of view of the sensed information, is always the same: using all the available data to better understand the investigated phenomena. The aim of this chapter is to give an overview of the several approaches that can be followed to design and analyze systems for Homeland Protection. Different fusion architectures can be drawn on the basis of the employed algorithms; according to this approach, three general categories can be identified in the literature [18, 19] : centralized, hierarchical, and decentralized/netcentric.

The traditional architecture is centralized: in this framework several sensing devices are connected to a central component, the fusion node. For example, in the case of a sensor network employed for the surveillance of an area, usually the information traffic goes from the sensor nodes to a single sink node called information fusion center. According to the information received from the sensors, the fusion center monitors the area where the sensors are deployed and decides the actions to take. Conceptually, the algorithms employed in this case are relatively simple and the resource allocation is straightforward because the central component has an overall view of the whole system. This kind of architecture presents several drawbacks: high computational load, the possibility of catastrophic failure when the fusion node goes down and the lack of flexibility to changes of the system and sensor entities. Therefore this approach is still valid if the number of sensors, whose information is fused, independently of the width of the area to be monitored, is limited and also the relationship and interconnections among sensors are limited too.

In hierarchical architectures, there are several fusion nodes, where intermediate fusion processes are performed, and an ending central fusion node. The principle of a hierarchy is to reduce the communications and computational loads of centralized systems by distributing data fusion tasks among a hierarchy of sensor entities. However in a hierarchy there is still a central component acting as a fusion center. Entities constituting local fusion center, locally process information and send it to the central fusion node. This approach is commonly used in robotics and surveillance applications. Although this architecture reduces the computational and communication loads, there are still some drawbacks

The diagram of Figure 22 .2 provides a decomposition of the Homeland Protection domain: the two main sub-domains are Homeland Defense (HD) and Homeland Security (HS) [21] .

HD includes the typical duties and support systems of military joint forces and single armed forces. Usually HD systems are strictly military, are employed by military personnel only, satisfy specific technical requirements, operational needs and environmental scenarios, and in most cases are designed to face only military threats. The new trend aims to employ military surveillance systems in combined military and civil operations, especially to face terrorism [22] . The military domain has also been swept in recent years by the NCO paradigm; NCO predicates a tighter coupling among forces, especially in the cognitive domain, to achieve synchronization, agility and decision superiority and it is a strong driver in the transformation from a platform-centric force to a network-centric force [20] .

HS is a very broad and complex domain that requires coordinated action among national and local governments, private sector and concerned citizens across a country; it covers issues such as crisis management, border control, critical infrastructure protection and transportation security [23, 24] . Crisis management is the ability of identifying and assessing a crisis, planning a response, and acting to resolve the crisis situation. Border control aims to build a smart protection belt all around a country to counter terrorism and illegal activities; yet it is not resolutive due to the difficulty of controlling the country boundaries along their full and variegated extension, the non necessarily physical nature of attacks in the current information age, and the threats which often arise internally to the country itself. HS includes also land security that is particularly critical because of its complexity and strategic importance; the security of critical assets, such as electric power plants, communication infrastructures, strategic areas and railway networks, must be ensured continuously in space and time [25] [26] [27] . The most recent terrorist attacks have shown the vulnerability of national critical infrastructures [28] and have made the world aware of the possibility of large-scale terrorist offensive actions against civil society: the September 11th, 2001 attack on the World Trade center in New York City is the most dramatic example of this new terrorism. The main emphasis has been put on the terrorist threat, but what emerges is the fragility and vulnerability of modern society to both deliberate threats and natural disasters. The HP domain includes also the protection from deliberate attacks against the commercial activities of a Country led also out of the national territory, comprehensive also of the territorial waters and Exclusive Economic Zone (EEZ). Seaborne piracy against transport vessels remains a significant issue (with estimated worldwide losses of US$13-16 billion per year), particularly in the waters between the Red Sea and Indian Ocean, off the Somali coast, and also in the Strait of Malacca and Singapore, which are navigated by over 50,000 commercial ships a year [29, 30] .

The globalization, the pervasiveness of information technologies and the transformation of the industrial sector and civil society have created new vulnerabilities in the system as a whole, but all this has happened without a corresponding effort to increase its robustness and security. As an example, single infrastructure networks have grown over the years independently, creating autonomous ""vertical"" systems with limited points of contact; around year 2000, as a consequence of the change of trend in the socio-techno scenario, the infrastructures have begun to share services and thus to create interconnected and interdependent systems. Nowadays infrastructures are interconnected and mutually dependent in a complex way: a phenomenon that affects one infrastructure can have a direct or indirect impact on other infrastructures, spreading on a wide geographical area and affecting several sectors of the citizen life. This is schematically represented in Figure 22 .4 [31, 32] .

Beside the physical protection of territory, citizens, critical assets and activities, the security of information and computer systems is one the greatest challenges for a Country. Information and communication technologies have enhanced the efficiency and the comfort of the civil society on one hand, but added complexity and vulnerability on the other hand. The cyber security consists in ensuring the protection of information and property from hackers, corruption, or natural disaster, maintaining however the information and property accessible and productive to its intended users. This problem is pervasive in nearly all the systems supporting a nation: financial, energy, healthcare and transportation. The new trend toward the mobile communications is revealing a new cyber vulnerability, for instance the sheer mass of mobile endpoints gives more protection to hackers leading a cyber attack starting from a mobile. Therefore, the mobile infrastructure is becoming a critical infrastructure as well [33] .

Nowadays the challenge is to understand this new scenario and to address the use of new and efficient algorithms for the information fusion in the domain of large integrated systems [34] . To integrate such heterogeneous information the necessity emerges to develop new algorithms of data fusion and information fusion to achieve an operational picture. In such scenario, where the attack can be lead with unconventional manners, information of heterogeneous sources, despite appearing uncorrelated, Interdependencies between present infrastructures. (From [31] , reprinted with permission.)

can be related and hence exploited by its fusion. Therefore particular attention is due to the information sources; Section 2.22.4 is devoted to this aspect of the problem, giving an overview of the sensors and the systems that traditionally provide information.

Before addressing in more detail the topic of data fusion applied to the domain of Homeland Protection, it is useful to briefly review the evolution of data fusion and, more recently, the definition of the new paradigms and the introduction to high-level data fusion and information fusion.

A definition of data fusion is provided in [35] : ""Data fusion is a process that combines data and knowledge from different sources with the aim of maximizing the useful information content, for improved reliability or discriminant capability, while minimizing the quantity of data ultimately retained."" Another definition is provided by the Joint Directors of Laboratories (JDL) Data Fusion Subpanel (DFS) which, in its latest revision of its data fusion model, Steinberg and Bowman [36] settle with the following short definition: ""Data fusion is the process of combining data or information to estimate or predict entity states."" Due to its generality, the definition of JDL encompasses the previous one. One aspect of the data fusion process, which is not included in the first definition and is implicit in the second, is process refinement, i.e., the improving of data fusion process and data acquisition. Many authors, recognize process refinement and data fusion to be so closely coupled that process refinement should be considered to be a part of the data fusion process. This is not a new technique in itself, rather a framework for incorporating reasoning and learning with perceived information into systems, utilizing both traditional and new areas of research. These areas include decision theory, management of uncertainty, digital signal processing, and computer science. The data fusion process comprises techniques for data reduction, data association, resource management, and fusion of uncertain, incomplete, and contradictory information.

In 1986, an effort to standardize the terminology related to data fusion began and the JDL data fusion working group was established. The result of that effort was the conception of a process model for data fusion and a data fusion lexicon. The so-called JDL fusion model [37] is a functional model, developed to overcome potential confusion in the community and to improve communications among military researchers and system developers. The model provides a common frame of reference for fusion discussions and to facilitate understanding and recognizing the problems where data fusion is applicable. The first issue of the model, dated 1988, provided four fusion levels:

• level 1: Object refinement, • level 2: Situation refinement, • level 3: Threat refinement, • level 4: Process refinement.

In 1998 Steinberg et al. [38] revised and expanded the JDL model to broaden the functional model and related taxonomy beyond the original military focus. They introduced a level 0 to the model for estimation and prediction of signal/object observable states on the basis of pixel/signal-level data association and characterization. They also suggested renaming and re-interpretation of level 2 and level 3 to focus on understanding the external world beyond military situation and threat focus. Figure 22 .5 reports a block diagram representing this functional model. Although originally developed for military applications, the model is generally applicable. Furthermore, the model does not assume its functions to be automated, they could equally well be maintained by human labor. Hence, the model is both general and flexible. The revised JDL model levels specify logical separations in the data fusion process and divide information into different levels of abstraction depending on the kind of information they produce, where the lower levels yield more specific, and the higher more general, information. The model is divided into the following five levels [18] :

• Level 0-sub-object assessment: the pre-detection activities such as pixel or signal processing, spatial or temporal registration is present. Level 0 deals with the estimation and prediction of signal/object observable states on the basis of pixel/signal level data association and characterization. • Level 1-object assessment: is concerned with estimation and prediction of target locations, behavior or identity. In this level, which is sometimes referred to as multi-sensor data fusion or multisensor integration, data is combined to assign dynamic features (e.g., velocity) as well as static (e.g., identity) to objects, hence adding semantic labels to data. This level includes techniques for data association and management of objects (including creation and deletion of hypothesized objects, and state updates of the same). Level 1 addresses the following functions: data alignment, data/object correlation, object positional/kinematic/attribute estimation, object identity estimation. • Level 2-situation assessment: investigates the relations among entities such as force structure and communication roles. This level involves aggregation of level 1 entities into high-level, more abstract entities, and relations between entities. An entity in this level might be a pattern of connected objects of level 1 entities. Input data are assessed with respect to the environment, relationship among level 1 entities, and entity patterns in space and time. Level 2 addresses the following functions: object aggregation, contextual interpretation/fusion, event/activity aggregation, multi-perspective assessment. • Level 3-impact assessment: outlines sets of possible courses of action and the effect on the current situation. The impact assessment, which is sometimes called significance estimation or threat refinement, estimates and predicts the combined effects of system control plans and the entities of level 2 (possibly including estimated or predicted plans of other environment agents) on system objectives. Level 3 addresses the following functions: estimate/aggregate force capabilities, predict enemy intent, identify threat opportunities, estimate implications, multi perspective assessment. • Level 4-process refinement: is an element of Resource Management used to close the loop by re-tasking resources to support the objectives of the mission. Process refinement evaluates the performance of the data fusion process during its operation and encompasses everything that refines it, e.g., acquisition of more relevant data, selection of more suitable fusion algorithms, optimization of resource usage with respect to, for instance, electrical power consumption. Process refinement is sometimes called process adaption to emphasize that it is dynamic and should be able to evolve with respect both its internal properties and the surrounding environment. The function of this level is in some literature handled by a so called meta-manager or meta-controller. It is also rewarding to compare level 4 fusion to the concept of covert attention in biological vision which involves, e.g., sifting through an abundance of visual information and selecting properties to extract. Level 4 addresses the following functions: evaluation (real-time control/long term improvement), fusion control, source requirements, mission management.

The 1998 revised JDL fusion model recognized the original Process Refinement level 4 function as a Resource Management function. In 2002, a level 5 was added [39, 40] , named User Refinement, into the JDL model to support a user's trust, workload, attention, and situation awareness. Mainly the level 5 was added to distinguish between machine-process refinement and user refinement of either human control action or the user's cognitive model. In many cases the data fusion process is focused on the machine point of view, however a full advantage can be taken by considering also the human factor, not only as a qualified expert to refine the fusion process, but also as a costumer for whom the fusion system is designed. Figure 22 .6, taken from [40] , shows the JDL fusion model including also the level 5.

Later in [41] also a level 6, Mission Management, was added; this level tackles the adaptive determination of spatial-temporal control of assets (e.g., airspace operations) and route planning and goal determination to support team decision making and actions (e.g., theater operations) over social, economic, and political constraints. Figure 22 .7 shows a multi-sensor data fusion architecture with a representation of the levels involved into each process of data fusion. Level 0 and level 1 concern the combination of data from different Data fusion architecture. sensors, level 2 and level 3 are often referred to as information fusion. Under the proposed partitioning scheme, the same entity can simultaneously be the subject of level 0, 1, 2, and 3 fusion processes. Entity features can be estimated from one or more entity signal observations (e.g., pixel intensities, emitter pulse streams) via a level 0 data preparation/association/estimation process. The identity, location, track and activity state of an entity (whether it be a man, a vehicle, or a military formation) can be estimated on the basis of attributes inferred from one or more observations; i.e., via a level 1 data preparation/association/estimation process. The same entity's compositional or relational state (e.g., its role within a larger structure and its relations with other elements of that structure) can be inferred via level 2 processes. Thus, a single entity-anything with internal structure, whether man, machine, or mechanized infantry brigade-can be treated either as an individual, subject to level 1 observation and state estimation-or as a ""situation,"" subject to compositional analysis via level 2 entity/entity association and aggregate state estimation. The impact of a signal, entity, or situation on the user goal or mission can then be predicted based upon an association of these to alternative courses of action for each entity via a level 3 process.

There are also other fusion models developed on the basis of different perspectives, including a purely computational and a human information processing. In the following an overview of different models [42] .

The DIKW (Data Information Knowledge and Wisdom) [43] hierarchy organizes data, information, knowledge, and wisdom in layers with an increasing level of abstraction and addition of knowledge, starting from the bottommost data layer. The hierarchy can be considered alike the JDL data fusion model because both start from raw transactional data to yield knowledge at an increasing level of abstraction.

The JDL model and many other computational models do not simulate the complex human cognitive process that leads to ""become aware,"" because they do not model the fusion process from a human perspective. In 1988, Endsley defined the situation awareness as ""the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their state in the near future"" [44] . In [45, 46] he identified three levels of situation awareness, namely perception, comprehension, and projection, parallel to the corresponding levels in the JDL model. Therefore the levels in the JDL model can be considered as processes producing results to help a human operator became aware of the situation. In [47] in addition to this three different aspects identified by Endsley, the model included also ""intention"" (i.e., the understanding of own options and courses of action relative to own goals) and ""metacognition"" (i.e., accounting for how reliable own situation awareness is likely to be). These levels summarize the fact that situation awareness requires the understanding of information, events, and the impact of own actions on own goals and objectives. This process involves several capabilities as learning, detection of anomalies, prediction of future behaviors, managing uncertainty, and analysis of heterogeneous sources.

The OODA (Observe-Orient-Decide-Act) loop, developed by Boyd in 1987 [48] , is one of the first C4I (Command, Control, Communications, Computers, and Intelligence) architectures and it represents the classic decision-support mechanism in military information operations. Because decision-support systems for situational awareness are tightly coupled with fusion systems, the OODA loop has also been used for sensor fusion [49] . Observations in OODA refer to scanning the environment and gathering information from it; orientation is the use of the information to form a mental image of the circumstances; decision is considering options and selecting a subsequent course of action; and action refers to carrying out the conceived decision. Bedworth and O'Brien [50] report a comparison of the OODA loop to the levels of the JDL model.

The human information processing can be modeled by the Rasmussen model [51, 52] . It is composed of three layers, namely skill-based, rule-based, and knowledge-based processing. The input of the process is a perception (e.g., the detection of a target by a sensor) and the output is an action. An example of result at the first level may be represented by the automatic identification of a tank by processing of row sensors data; at the next level an enemy unit composition can be indentified on the basis of its number and relative locations. Knowledge-based behavior represents the most complex cognitive processing used to handle novel, complex, situations where no routine or rule is available to manage situations. An example of this type of processing may be the interpretation of unusual behavior, and the consequent generation of a course of actions based on enemy unit size and behavior.

The Generic Error modeling System (GEMS) [53] is an extension of Rasmussen's approach, which describes the competencies needed by workers to perform their roles in complex systems. GEMS describes three major categories of errors: skill-based slips and lapses, rule-based mistakes, and knowledge-based mistakes. Table 22 .1, from [42] , shows a correspondence, and not a comparison, among levels and layers of various models presented before. This table is intended as a guide to identify the components of a data fusion architecture, where the separation between the columns is not so sharp. Notice that the JDL model does not explicitly model into a level the action consequent to the threat assessment. The action Rule/knowledgebased processing n/a n/a level, with the sense of a reaction is only in part included in the process refinement level 4, for this reason the column ""action"" has been inserted in the table, to allow a more clear correspondence with the other models that explicitly account for the reaction. The JDL model is the one that allows the most global view of the data fusion process from an operative perspective: there is not any correspondence of the other models with JDL level 4.

This section gives a broad and very general description of the basic categories of intelligence that are the source of data/information employed to perform the fusion process. The USAF (United States Air Force) in 1998 first and the ODNA (Office of Directors of National Intelligence) later in 2008 described in their studies that there are six basic intelligence categories [54, 55] : In addition, there is also Scientific and Technical (S&T) Intelligence resulting from the analysis of foreign scientific and technical information. In the following is an overview of the categories.

SIGINT is achieved by the interception/detection of electromagnetic (em) emissions. SIGINT includes Electronic Intelligence (ELINT) and Communications Intelligence (COMINT). The former derives from the processing and analysis of em radiation emitted from emitters, in most of cases radars, not employed for communications, other than nuclear detonations or radioactive sources. An emitter may be related closely to a specific threat. The information that can be achieved by a typical ESM (Electronic Support Measures) device consists of an estimate of the emitter category, location, with a certain accuracy, and various electronic attributes, such as frequency and pulse duration. This information can be employed in a high-level fusion process. COMINT derives from the processing and analysis of intercepted communications from emitters. The communications may be encrypted and they may be of several forms such as voice, e-mail, fax and the like.

IMINT is obtained by sensors working in several bandwidths which are able to produce a view of the scenario or of the specific target: electro/optical sensors, infrared, radar (e.g., Synthetic Aperture Radar (SAR) and Inverse SAR (ISAR), and Moving Target Indicator (MTI)), laser, laser radar (LADAR), and multi-spectral sensors. Each sensor has a unique capability. Some work in all weather conditions, some may work also in night conditions, and some produce high-quality images with detectable signatures.

MASINT is obtained by the collection and the analysis of several and heterogeneous sensors and instruments usually working in different regions or domains of the em spectrum, such as infrared or magnetic fields. MASINT includes Radar Intelligence (RADINT), Nuclear Intelligence (NUCINT), Laser Intelligence (LASINT), and Chemical and Biological Intelligence (CBINT). RADINT, for example, is a specialized form of ELINT, which categorizes and locates as active or passive collection of energy reflected from a target.

HUMINT is the collection of information derived by the human contact. Information of interest might include target name, size, location, time, movement, and intent. HUMINT typically includes structured text (e.g., tables, lists), annotated imagery, and free text (e.g., sentences, paragraphs). HUMINT provides comprehension of adversary actions, capability and capacity, plans and intentions, decisions, research goals and strategies.

OSINT is publicly available information appearing either in print or in electronic form including radio, television, newspapers, journals, the Internet, commercial databases, videos, graphics, and drawings. OSINT can be considered as a complement to the other intelligence categories and can be used to fill gaps and improve accuracy and confidence in classified information. A special mentioning is for the Internet, that, with its blogs, e-mails, videos, messages and mobile systems, favors an ever greater interaction between users. Moreover notice that there is a little overall planning in the development of the World Wide Web, but rather a myriad of initiatives by individuals of small groups. Government have always tried to use telephone tapping, surveillance, files, i.e., intelligence. Now this is possible on a different scale given the technical possibilities offered by satellites, mobile, phones, credit cards management systems, information storage, etc. From the topological point of view, Internet is a scale-free complex network with a power-law of the distribution of the nodes [56] ; this technical remark should be considered in the data exploitation analysis.

GEOINT is the analysis and the visual representation of the activities on the earth related to the security achieved by the sensors (radar, optical, IR, multispectral) deployed in the space. The information related to GEOINT is obtained through an integration of imagery, imagery intelligence, and geospatial information.

Stand-alone sensors usually provide a fragmentary view of a complex situation of interest. A significant enhancement of performance can therefore be accomplished by a combination of networked sensors in the close vicinity to the region of interest. Using efficient methods of centralized or decentralized multiple sensor fusion, the quality of the produced situation picture can significantly be improved. In practice, improvements with respect to the following aspects are of interest:

• production of accurate and continuous tracks (e.g., objects, persons, single vehicles, group objects), • system reaction rates (e.g., track extraction, detection of target maneuvers, track monitoring), • sustainment of reconnaissance capabilities in case of either system or network failures (e.g., graceful degradation), • system robustness against jamming and deception, • compensation of degradation effects (e.g., sensor misalignment, limited sensor resolution), • robustness against sub-optimal real-time realizations of sensor data fusion algorithms, • processing of eventually delayed sensor data (e.g., out-of sequence measurements).

In the following, several sections tackle different aspects related to homogeneous sensor networks.

Sensor fusion networks can be categorized according to the type of sensor configuration. Durrant-Whyte distinguishes three types of sensor configuration as schematized in Figure 22 .8 [57, 58] . Sensors configuration (from [57] , reprinted with permission).

Competitive sensor data fusion: Sensors are configured competitive if each sensor delivers independent measurements of the same property. Sensor data represent the same attribute, and the fusion is to reduce uncertainty and resolve conflicts. Competitive sensor configuration is also called a redundant configuration. Sensors S1 and S2 in Figure 22 .8 represent a competitive configuration, where both sensors redundantly observe the same property of an object in the environment space. Complementary sensor data fusion: A sensor configuration is called complementary if the sensors do not directly depend on each other, but can be combined to give a more complete image of the phenomenon under observation. Fusion of the sensor data provides an overall and complete model. Examples for a complementary configuration is the employment of multiple cameras each observing disjoint parts of a room, or using multiple spectrum signatures to identify a land cover type, or using different waveform to identify an aircraft type. Sensor S2 and S3 in Figure 22 .8 represent a complementary configuration, since each sensor observes a different part of the environment space.

In both competitive and complementary sensor configurations, there is an improvement of the accuracy of the target characteristics estimation consequent to the data fusion. In their seminal work H. Cramer and C.R. Rao found how to compute the best theoretical accuracy that can be achieved by an estimator. The lower bound of accuracy, i.e., the mean square error of any unbiased estimator, is given by the inverse of the so-called Fisher Information Matrix (FIM). The computation of the CRLB (Cramer-Rao Lower Bound) applies to problems involving the maximum likelihood estimation of unknown constant parameters from noisy measurements [59] . The best achievable improvement of target location and track accuracy can be quantified by the reduction of the CRLB consequent to the track fusion. In [60] this computation is reported in case of fusion of data from two sensors with an ideal unitary detection probability. In [61, 62] the same computation has been proposed in case of detection probability less than one and false alarm probability higher than zero. Cooperative sensor data fusion: A cooperative sensor network uses the information provided by two independent sensors to derive information that would not be available from the single sensors. An example for a cooperative sensor configuration is stereoscopic vision: by combining two-dimensional images from two cameras at slightly different viewpoints a three-dimensional image of the observed scene is derived. Cooperative sensor fusion is the most difficult to design, because the resulting data are sensitive to inaccuracies in all individual participating sensors. Thus, in contrast to competitive fusion, cooperative sensor fusion generally decreases accuracy and reliability. Sensor S4 and S5 in Figure 22 .8 represent a cooperative configuration. Both sensors observe the same object, but the measurements are used to form an emerging view on object C that could not have been derived from the measurements of S4 or S5 alone.

These three categories of sensor configuration are not mutually exclusive. Many applications implement aspects of more than one of the three types. An example for such a hybrid architecture is the application of multiple cameras that monitor a given area. In regions covered by two or more cameras the sensor configuration can be competitive or cooperative. For regions observed by only one camera the sensor configuration is complementary.

Sensor networks have countless applications, for example, we mention the sensor networks used in computer science and telecommunications, in biology, where they can be used to monitor the behavior of animal species such as birds or fishes, and in habitat monitoring, where they can be used to provide real-time rainfall and water level information used to evaluate the possibility of flooding. In the field of Homeland Protection one of the main task to be assigned to a sensor network is the surveillance with its most general significance. Automatic surveillance is a process of monitoring the behavior of selected objects (targets and/or anomalies) inside a specific area by means of sensors. A target generally consists of an object (e.g., a tank close to a land border or a rubber approaching to the coast) whose presence and characteristics can be detected and estimated by the sensor; an anomaly consists in a non usual behavior (e.g., a jeep moving off-road, the increasing of the radioactivity level within an area) that can be revealed by the sensor. Sensors typically provide the following functions:

• detection of a targets or anomalies inside the surveillance area, • estimation of target position or the anomaly localization and extension, • monitoring of the target kinematic (tracking) or of the anomaly behaviors, • classification and/or recognition of the targets.

To perform the previous functions, the sensors can be organized on the bases of several approaches. The classical approach to surveillance of wide areas is based on the use of a single or few sensors with long range capabilities. The signal received by the single sensor is processed by means of suitable digital signal processing subsystems. In this case the sensors are costly, with adequate computation and communication capabilities. Sensors are normally located in properly selected sites, to mitigate terrain masking problems; nevertheless, they provide different performance depending on the location of target inside the surveillance area. Typical sensors are radars (ground-based, air-borne, ship-borne or space-based), infrared or TV cameras, seismic, acoustical, radioactive sensors. Usually in this kind of networks, as represented in Figure 22 .9, the information traffic goes from the sensor nodes to a single Block-diagram for optimal system resource management in a sensor network. sink node called information fusion center that performs the target localization and tracking. According to the information received from the sensors the fusion center monitors the area where the sensors are deployed and decides, on the basis of the state estimates and their accuracy (e.g., a covariance matrix for a Kalman filter or a particle cloud for a particle filter) the actions to take.

In [63] an example of high-performance radar netted for Homeland Security application with a centralized data fusion process is described. The same classical approach is presented in [64] where this kind of sensor network is employed for natural resource management and bird air strike hazard (BASH) applications.

However if an intruder reaches and neutralizes the fusion center, the communication between the network nodes are interrupted and the whole network is exposed to the risk of becoming useless as a network even if the individual sensors may still be all working.

Nowadays, a novel approach to the automatic surveillance has been adopted; it is based on the use of many sensors with short range capabilities, low costs, and limited computation and communication capabilities. In case of a huge number of sensors, the use of information fusion centers is unpractical and their functioning is based on the information exchange between ""near-by"" sensors. The sensors can be distributed in fixed positions of the territory, but they could also be deployed adaptively to the change of the scenario. There are several approaches: they can be randomly distributed inside the surveillance area and if the number of sensors is high, the performance of the surveillance system can be considered independent of the location of the targets; then the signal received by each sensor is processed using the computational capabilities of a sub-portion of the sensor system and employed to re-organize dynamically the network. Sensors may be agile in a variety of ways, e.g., the ability to reposition, point an antenna, choose sensing mode, or waveform. Notice that the number of potential tasking of the network grows exponentially with the number of sensors. The goal of sensor management in a large network is to choose actions for individual sensors dynamically so as to maximize overall network utility. This process is called Collaborative Signal and Information Processing (CSIP) [65] . One of the central issues for CSIP to address is energy-constrained dynamic sensor collaboration: how to dynamically determine who should sense, what needs to be sensed, and who the information must be passed onto. This kind of processing system allows a limitation in the consumption of power. Applying a surveillance strategy which accounts for the target tracking accuracy and the sensor random location, only a limited number of sensors are awake and follow/anticipate the target movement; thus, the network self-organizes to detect and track the target, allowing an efficient performance from the energetic point of view with limited sensor prime power and with a reduced number of sensors working in the whole network. For example in [66] , instead of requesting data from all the sensors, the fusion center iteratively selects sensors for the target localization: first a small number of anchor sensors send their data to the fusion center to obtain a coarse location estimate, then, at each step a few non-anchor sensors are activated to send their data to the fusion center to refine the location estimate iteratively. Moreover the possibility to actively probe certain nodes allows to disambiguate multiple interpretations of an event.

In [67] the techniques of information-driven dynamic sensor collaboration is introduced. In this case an information utility measurement is defined as the statistical entropy and it is exploited to evaluate the benefits in employing part of the network that consequently is re-organized. Other cost/utility functions can be employed as criteria to dynamically re-organize the sensor network as described in [68, 69] .

Several analytical efforts have been done to evaluate the performance of such networks in terms of tracking accuracy. As usual the CRLB has been taken as reference of the best achievable accuracy; in particular a new concept of conditional PCRLB (Posterior Cramer Rao Lower Bound) is proposed and derived in [70] . This quantity is dependent on the actual observation data up to the current time, and is implicitly dependent on the underlying system state. Therefore, it is adaptive to the particular realization of the underlying system state and provides a more accurate and effective online indication of the estimation performance than the unconditional PCRLB. In [71, 72] the PCRLB is proposed as a criterion to dynamically select a subset of sensors over time within the network to optimize the tracking performance in terms of mean square error. In [73] the same criterion is proposed as a framework for the systematic management of multiple sensors in presence of clutter.

Self-organization can be defined as the spontaneous set-up of a globally coherent pattern out of local interactions among initially independent components. Sensors are randomly spread out over a two dimensional surveillance area. In a self-organized system, its elements affect only close elements; distant parts of the system are basically unaffected. The control is distributed, i.e., all the elements contribute to the fulfillment of the task. The system is relatively insensitive to perturbations or errors, and have a strong capacity to restore itself. Initially independent components form a coherent whole able to efficiently fulfill a particular function [74] . Flocks of birds, shoals of fish, swarms of bees are examples of self-organizing systems; they move together in an elegantly synchronized manner without a leader which coordinates them and decides their movement. It has been shown that flocks of birds selforganize into V-formations when they need to travel long distances to save energy, by taking advantage of the upwash generated by the neighboring birds. Cattivelli and Sayed [75] propose a model for the upwash generated by a flying bird, and shows that a flock of birds is able to self-organize into a Vformation as if every bird processes spatial and network information by means of an adaptive diffusive process. This result has interesting implications. First, a simple diffusion algorithm is able to account for self-organization of birds. Second, according to the model, that birds can self-organize on the basis of the upwash generated by the other birds. Third, some information is necessarily shared among birds to reach the optimal flight formation. The paper also proposes a modification to the algorithm that allows birds to organize, starting from a V-formation, into a U-formation, leading to an equalization effect, where every bird in the flock observes approximately the same upwash. The same algorithm based on birds flight is extended in [76] to the problem of distributed detection, where a set of sensors/nodes is required to decide between two hypotheses on the basis of the collected measurements. Each node makes individual real-time decisions and communicates only with its immediate neighbors, in order that any fusion center is not necessary. The proposed distributed detection algorithms are based on diffusion strategies described in [77] [78] [79] and their performance is evaluated by means of classical probabilities of detection and false alarms.

These diffusion detection schemes are attractive in the context of wireless and sensor networks thanks to their intrinsic adaptability, scalability, improved robustness to node and link failure as compared to centralized schemes, and their potential to save energy and communication resources.

Several studies have shown how a simple self-synchronization mechanism, borrowed from biological systems, can form the basic tool for achieving globally optimal distribution decisions in a wireless sensor network with no need for a fusion center. Self-synchronization is a phenomenon first observed between pendulum clocks (hooked to the same wooden beam) by Christian Huygens in 1658. Since then, self-synchronization has been observed in a myriad of natural phenomena, from flashing fireflies in South East Asia to singing crickets, from cardiac peacemaker or neuron cells to menstrual cycles of women living in strict contact with each other [80] . The goal of these studies is to find a strategy of interaction among the sensors/nodes that could allow them to reach globally optimal decisions in terms of a ""consensus"" value in a totally decentralized manner. Distributed consensus algorithms are indeed techniques largely studied in distributed computing [81, 82] . The approaches suggested in [83, 84] give a form of consensus achieved through self-synchronization that may result critical in wide-area networks, where propagation delays might induce an ambiguity problem. This problem is overcome in [85] [86] [87] where also a model of the network and of the sensors is proposed. Each of the N nodes composing the network is equipped with four basic components: (1) a transducer that senses the physical parameter of interest y i (e.g., temperature, concentration of contaminants, radiation, etc.); (2) a local processing unit that provides a function g i (y i ) of the measurements; (3) a dynamical system, initialized with the local measurements, whose state x i (t) evolves as a function of its own measurement g i (y i ) and of the state of nearby sensors; (4) a radio interface that makes possible the interactions among the sensors. The criterion to reach a consensus value is the asymptotical convergence toward a common value of all the derivatives of the state, for any set of initial conditions and for any set of bounded. This condition makes the convergence to the final consensus independent of the network graph topology. However the topology has an impact on several aspects: the overall energy necessary to achieve the consensus and the convergence time. In general there exists a trade-off between the local power transmitted by a each sensor and the converge time depending on the algebraic connectivity of the network graph, as shown in [88] . In the practical applications these aspects cannot be neglected; for instance, the design of a network should account for the precision to achieve, and the time to get the consensus value at the given precision, versus such constraints as the energy limitations of the sensors. A global overview of the problem is given in [89] .

Moving from the functional model to a working implementation in a real environment involves a number of design considerations: including what information sources to use and what fusion architecture to employ, communication protocols, etc.

Admittedly, the fusion of data is decoupled from the actual number of information sources and, hence, does not require necessarily multiple sensors: the fusion, in fact, may be performed also on a temporal sequence of data that was generated by a single information source (e.g., a fusion algorithm may be applied to a sequence of images produced by a single camera sensor). However, employing a number of sensors provides many advantages as well explained in the previous Sections. Unsurprisingly, there are also difficulties associated with the use of multiple sensors.

A missed sensor registration may cause a failure in the correct association between signals or features of different measurements. This problem and the similar data association problem are very important and apply also to single sensor data processing. To perform data registration, the relative locations of the sensors, the relationship between their coordinate systems, and any timing errors need to be known, or estimated, and accounted for otherwise a mismatch between the compiled picture and the truth may result. An overstated confidence in the accuracy of the fused output, and inconsistencies between track databases, such as multiple tracks that correspond to a single target may appear. A missed registration can result from location and orientation errors of the sensor relative to the supporting platform, or of the platform relative to the Earth, such as a bearing measurement with an incorrect North alignment. Errors may be present in data time stamping, and numerical errors may occur in transforming data from one coordinate system to another. Automatic sensor registration can correct for these problems by estimating the bias in the measurements along with the kinematics of the target. However, the errors in sensor registration need to be known and accounted for [90] . In [91] a maximum likelihood (EML) algorithm for registration is presented using a recursive two-step optimization that involves a modified Gauss-Newton procedure to ensure fast convergence. In [92] a novel joint sensor association, registration, and fusion is performed exploiting the expectation-maximization algorithm incorporated with the linear Kalman filter (KF) to give simultaneous state and parameter estimates. The same approach can be followed also with non linear filtering techniques as the Extended KF (EKF) and the Unscented KF (UKF) as proposed in [93] , where also the performance is evaluated by means of the PCRLB.

Next to the spatial sensor registration also the temporal alignment cannot be neglected. For instance, a critical aspect of a sensor network is its vulnerability to temporary node sleeping, due to duty-cycling for battery recharge, permanent failures, or even intentional attacks.

Other realistic problems, such as conflicting information and noise model assumptions, may enable the use of some fusion techniques. Noisy input data sometimes yield conflicting observations, a problem that has to be addressed and which does not arise in single sensor data processing. The administration of multiple sensors have to be coordinated and information must be shared between them.

Most of the optimization algorithms have been developed in a centralized framework, i.e., they have been conceived to perform centralized data fusion process. In the last years the trend is to employ network centric approaches, and the mathematical optimization algorithms must be able to support this approach. In the following an example of the adaptation of a ""centralized-conceived"" algorithm to the new trend is presented.

Consider the following minimization problem to solve:

where α, β, γ , δ, ε, η are real positive values and the function f x, y, z = w ≥ 0 represents an ellipsoid function, whose axes do not coincide with the reference frame axes if δ = 0, ε = 0, η = 0. The problem of Eq. (22.1) can be solved by the steepest descent method in a centralized fusion process frame, hence it will be named ""centralized steepest descent."" The centralized steepest descent method when used to solve minimization problems is an iterative procedure that, beginning from an initial guess, updates at every iteration the current approximation of the solution of the function to minimize with a step in the direction of the gradient of the own function. In a network centric approach it may Data Fusion centralnode be solved by the application of the Jacobi method 2 usually employed for the iterative solution of linear system equation.

Consider three agents (namely agent 1, 2, and 3) controlling the three variables x, y, and z. In the centralized data fusion process, represented in Figure 22 .10a, the communication between the three agents is completely performed at the same instant of time; in the network centric case this does not happen. Consider the model of Figure 22 .10b with the following communication scheme:

agent 1 communicates to agent 2, agent 2 communicates agent 3, agent 3 communicates to agent 1; moreover the communications among agents is not instantaneous, but they succeeds in time.

The method of the centralized steepest descent applied to the function f (x, y, z), given a starting point (x 0 , y 0 , z 0 ), is based on the following iterations:

where k = 0, 1, . . ., and h ≥ 0 represents the step employed in the steepest descent method. 2 The Jacobi method is an algorithm for determining the solutions of a system of linear equations with largest absolute values in each row and column dominated by the diagonal element. Each diagonal element is solved for, and an approximate value plugged in. The process is then iterated until it converges. This algorithm is a stripped-down version of the Jacobi transformation method of matrix diagonalization. The method is named after German mathematician Carl Gustav Jakob Jacobi [96] .

A network centric steepest descent method can be derived by the communication scheme represented in Figure 22 .10b and described below. Given the starting point (x 0 , y 0 , z 0 ), the following iterations can be done:

where k = 0, 3, 6, . . . and h ≥ 0 represents the step employed in the steepest descent method. Figure 22 .11 shows the comparison of the two methods for the previous model. Note that the three agents in the net-centric approach are those looking at the function to be minimized along the x, y, and z axes respectively. The black square and the red diamond in the curves represent respectively the starting point of the iteration and the final position. The black solid line shows the trajectory described by the variables (x, y, z) obtained by the application of the centralized steepest descent method; the red solid line shows the behavior of the variables obtained by the net-centric steepest descent method. Note that the red line approaches the minimum by moving along the x, y, and z axes separately. The ellipsoids of Figure 22 .11 represent the iso-level surfaces of the objective function. Notice that the telecommunication network modeled for the net-centric steepest descent determines the usual Jacobi iteration employed for the solution of linear systems associated to minimization problems [94] [95] [96] . In the following Section 2.22.6.1 this approach is applied to reach the optimal deployment of a sensor network.

This section proposes several study cases of sensor networks employing novel approaches. Section 2.22.6.1 proposes an optimization method, projected in the network centric frame, to obtain the optimal deployment of a cooperative sensor network; Section 2.22.6.2 describes how to employ the so-called bio-inspired models of dynamic sensor collaboration in a chemical sensor network to detect a chemical pollutant; finally Section 2.22.6.3 gives a description of the typical problem of detection of radioactive sources.

This section presents a mathematical model for the deployment of a sensor network, for the creation of consensus values from the noisy data measured and a statistical methodology to detect local anomalies Starting point Convergence point Centralized steepest descent Net-centric steepest descent

Comparison between the trajectories computed by the centralized and the network centric steepest descent.

in these data. A local anomaly in the data is associated to the presence of an intruder. The model of sensor network presented here is characterized by the absence of a fusion center. In other words the deployment, the construction of the consensus values, and the detection of local anomalies in the data are the result of local interactions between sensors. Nevertheless the local interactions will lead to global solution of the considered problem. This is an example of model of a network centric sensor network. The sensors are assumed to be identical and they measure a quantity pertinent to the properties of the area to survey able to reveal the presence of an intruder. In the proposed study case the sensors are able to measure the temperature of the territory in the position or in the ""area"" where they are located; in absence of anomalies there is a uniform temperature on the territory where the sensors are deployed. The sensor measures are noisy and can be considered synchronous. This measurement process is repeated periodically in time with a given frequency. From these measures a ""consensus"" temperature is deduced, pertinently to the territory where the sensors are deployed and an estimate of the magnitude of the noise contained in the data. Finally using these consensus values as reference values local anomalies are Territory of the city of Urbino (Italy) selected for the study case.

detected by the individual sensors. In the following we give some analytical details of the consensus method [97] . Let be a bounded connected polygonal domain in two dimensional real Euclidean space R 2 . The domain represents the territory where the sensor network must be deployed; in our case the downtown part of the Italian city of Urbino, shown in Figure 22 .12. Let · denote the Euclidean norm of in R 2 . Consider N sensors s 1 , s 2 , . . . , s N , located respectively, in the points ξ 1 , ξ 2 , . . . , ξ N ∈ , assumed to be distinct. To the sensor network deployed in the points ξ 1 , ξ 2 , . . . , ξ N corresponds a graph whose nodes are the sensors location and whose edges join the sensors able to communicate between themselves. This graph is assumed to be connected and can be imagined as laid on the territory. The assumption that the graph is connected is equivalent to assuming that the sensors constitute a network. For i = 1, 2, . . . , N , a polygonal region i ⊂ is associated to each sensor s i ; this region is defined by the condition that the points belonging to i are closest to the sensor s i , that is they are closest to ξ i , than to any other of the remaining sensors s j located in ξ j , j = i, j = 1, 2, . . . , N . It follows:

When for a given x ∈ the minimizer of the function f ( j) = x − ξ j , j = 1, 2, . . . , N is not unique we attribute x to i , where i is the smallest index between the indices that are minimizers of the function f.

The collection of subsets { 1 , 2 , . . . , N } defined in Eq. (22.4) and further specified by the condition above is a partition of and it is a Voronoi partition of associated to the Voronoi centers ξ 1 , ξ 2 , . . . , ξ N , as represented in Figure 22 .13 [98] , where the sets 1 , 2 , . . . , N are the Voronoi cells. The sensor s i is located in ξ i , with ξ i ∈ i , i = 1, 2, . . . , N , and monitors the sub-region i of . Note that there is a Voronoi partition of associated to each choice of the Voronoi centers After the definition of a Voronoi partition of , we want to determine the optimal one with respect to a pre-specified criterion, that in this study case is the fact that the Voronoi centers ξ 1 , ξ 2 , . . . , ξ N should coincide (as much as possible) with the centers of mass of the corresponding Voronoi cells 1 , 2 , . . . , N . This property translates in mathematical terms the request that the sensors are well distributed on the territory. That is what is called optimal Voronoi partition, i.e., the Voronoi partition associated to the Voronoi centers whose coordinates ξ * 1 , ξ * 2 , . . . , ξ * N are the solution of the following problem: (22.5) subject to the constraints:

where B j is the center of mass of the Voronoi cell j , j = 1, 2, . . . , N . Moreover we require:

That is the Voronoi centers and the centers of mass of the Voronoi cells coincide. Note that in general B j depends on ξ 1 , ξ 2 , . . . , ξ N and that the function .7) is not unique and it can be solved by the application of the steepest descent concept, revised in a network centric frame as shown conceptually in Section 2.22.5.7 [94] . This method can be used to solve the problem of Eq. (22.5) with an iterative procedure, that beginning from an initial guess, updates at every iteration the current approximation of the solution with a step in the direction of the gradient of the .7) and to the requirement that its implementation must lead to a network centric solution of the deployment problem. For sake of brevity, how to impose Eq. (22.6) will not be discussed here, however a treatment of constraints in the continuous analog of the steepest descent algorithm can be found in [99] . Note also that the solutions of Eqs. (22.5) and (22.6) that are of interest are usually interior points of the constraints (6) . That is the constraint issue usually is not relevant in the solution of Eqs. (22.5) and (22.6) . Similarly we will not pay attention to condition of Eq. (22.7). In fact with respect to Eq. (22.7), we will simply verify if the solution of the optimization problem determined by the steepest descent method satisfies Eq. (22.7). Let us concentrate our attention on the issue of building a network centric implementation of the continuous analog of the steepest descent method to solve Eq. (22.5) . Assume that the sensor s i knows only the position of its neighbor sensors, that is of the sensors that belong to a disk with center ξ i and radius r > 0, i = 1, 2, . . . , N . Later we will show how to choose r. The solution of the optimization problem of Eq. (22.5) is found approximating the solution of the system of differential equations:

where λ 1 denotes a real parameter, with the solution of the ""network centric"" system differential equations:ξ

where

andB i, j being the center of mass of the Voronoi cell˜ i, j obtained computing the Voronoi partition of associated to the Voronoi centers ξ j , j ∈ L i , i = 1, 2, . . . , N . Assume that r > 0 is large enough to guarantee that ξ j is neighbor of ξ i when the distance between j and i is zero, i, j = 1, 2, . . . , N .

Note that with this assumption we haveB i,i = B i , i = 1, 2, . . . , N . In Eqs. (22.8) and (22.9 ) the dot denotes the differentiation with respect to λ 1 . We observe that Eq. Remind that we have assumed that the graph G associated to the optimal deployment is connected (see Figures 22.14 and 22.13b) . Moreover we remind that, since there is not a fusion center, each node of the graph G does not know the positions of all the remaining nodes of the graph, in fact it knows only the positions of its neighbor nodes. Let L be the Laplacian matrix associated to G [100] . The matrix L is a symmetric positive semi-definite N × N matrix. Let x(λ 2 ) = (x 1 (λ 2 ), x 2 (λ 2 ), . . . , x N (λ 2 )) T , λ 2 > 0, be a real N dimensional vector depending on the real parameter λ 2 . The superscript (·) T means transposed. We consider the system of ordinary differential equations:

x(λ 2 ) = −Lx(λ 2 ), λ 2 > 0 (22.12) equipped with the initial conditions:

where Lx denotes the usual matrix vector multiplication, α = (α 1 , α 2 , . . . , α N ) T is a known initial condition and the dot denotes differentiation with respect to λ 2 . Since G is connected we have:

where x(λ 2 ), λ 2 > 0, is the solution of Eqs. (22.12) and (22.13) . This result follows easily from the spectral properties of L [100] . Note also that the right hand side of Eq. (22.14) is the ""average"" of the initial condition α. Note that Eq. (22.12) can be interpreted as the ""heat equation"" on the graph G, that the problem of Eqs. (22.12) and (22.13) can be seen as an initial value problem for the heat equation on G and that Eq. (22.14) can be understood as the approach to an asymptotic equilibrium ""temperature"" in an ""heat transfer"" problem. We assume that during the monitoring phase the sensor measures a physical quantity, such as, for example, the temperature, of the region i where it is located. The sensors are identical, the measures made by the sensors are synchronous, repeated periodically in time and of course they are noisy. Moreover they are assumed to be independent. A first set of measures is taken by the sensors at time t = t 0 and is collected in the vector β 0 = (β 0,1 , β 0,2 , . . . , β 0,N ,) T , where β 0,i is the measure done by the sensor s i . The set of measure β 0 will be used to obtain the ""consensus"" value β 0 of the quantity monitored in at time t = t 0 . We choose:

Remind that the sensor s i located in ξ i knows β 0,i and communicates with the sensors s j located in ξ j , j ∈ L i , i = 1, 2, . . . , N . In order to provide to the sensor s i , the consensus value β 0 in a network centric manner we proceed as follow: we choose α = β 0 in Eq. (22.13) and we integrate numerically the initial value problem of Eqs. (22.12) and (22.13) using the explicit Euler method to obtain a numerical approximation of lim λ 2 →+∞ x(λ 2 ). Note that the ith differential equation of Eq. (22.12) is integrated in the location ξ i , and that using the explicit Euler method this can be done using only information available in the location ξ i . Note that the analytic solution of Eqs. (22.12) and (22.13) is not ""network centric"" but its approximation with the explicit Euler method is ""network centric."" In the former case to achieve the solution each node should know the whole graph, i.e., all the nodes. The ith node is not able to achieve the solution exploiting only the information in its posses: in this sense the solution is not ""network centric."" Otherwise, exploiting the Euler approximation of the exponential of a matrix, the whole knowledge of the graph is not necessary: in this sense a ""network centric"" solution is achieved.

Once obtained β 0 we consider the following vector:

Then we choose α = γ 0 in Eq. (22.13) and we integrate Eqs. (22.12) and (22.13) with the explicit Euler method as done above. In this way we obtain asymptotically a numerical approximation of γ 0 where:

This approximation of γ 0 is provided to each sensor in a network centric manner. Note that γ 0 is an estimate of the magnitude of the noise contained in the data; in fact γ 0 is the ""sample"" variance of the measures β 0,i made by the sensor at time t = t 0 . The approximation of β 0 and γ 0 obtained integrating numerically Eqs. (22.12) and (22.13) are the consensus values. These values are ""global"" values (that is they depend on all the measures made by the sensor network at time t = t 0 ) and have been provided to each sensor in a network centric manner (that is using only ""local"" interactions between sensors).

The sensor s i repeats periodically in time the measure of the quantity of interest and after a given time interval has as its disposal a set of measures that can be compared with the consensus values β 0 and γ 0 to detect (local) anomalies. Let us assume that the set of measures made by the sensor s i is a sample taken from a set of independent identically distributed Gaussian random variables of mean μ i and variance σ 2 i . In these hypotheses the Student t-test and the Chi-square test [101] are the elementary statistical tools that must be used to compare μ i and σ 2 i (that are unknown) to β 0 and γ 0 . The result of this comparison is the detection of local anomalies. A (statistical) significance is associated to the detected anomalies. The statistical tests used are based on the assumption that the measures come from a set of independent identically distributed Gaussian random variables. Note that the estimators β 0 and γ 0 can be used in more general circumstances.

Typically the challenge in the deployment of an operational wireless sensor network (WSN) resides in establishing the balance between its operational requirements (e.g., minimal detection threshold, the size of surveillance region, detection time, the rate of false negatives, etc.) and the available resources (e.g., energy supply, number of sensors, communication range, fixed detection threshold of individual sensors, limited budget for the cost of hardware, maintenance, etc.) [102] . The issue of resource constraints is particularly important for a network of chemical sensors, because modern chemical sensors are equipped with air-sampling units (fans), which turn on when the sensor is active. Operating a fan requires a significant amount of energy as well as a frequent replacement of some consumable items (i.e., cartridges, filters). This leads to the critical requirement in the design of a WSN to reduce the active (air-sampling) time of its individual sensors.

One attractive way to achieve the described balance between the requirements and the constraints of WSN is to exploit the idea of dynamic sensor collaboration (DSC) [103, 104] . The DSC implies that a sensor in the network should be invoked (or activated) only when the network will gain information by its activation [104] . For each individual sensor this information gain can be evaluated against other performance criteria of the sensor system, such as the detection delay or the detection threshold, to find an optimal solution in given circumstances. However, the DSC-based algorithms involve continuous estimation of the state of each sensor in the network and usually require extensive computer simulations [103, 104] . These simulations may become unpractical as the number of sensors in the network increases. Furthermore, the simulations can provide the numerical values for optimal network parameters only for a specific scenario.

This motivates the development of another simple and analytic approach to the problem of network analysis and design. The main idea is to phenomenologically employ the so-called bio-inspired (epidemiology, population dynamics) or physics inspired (percolation and graph theory) models of DSC in the sensor network in order to describe the dynamics of collaboration as a single entity [105] [106] [107] [108] [109] [110] . From a formal point of view, the equations of bio inspired models of DSC are the ones of the ""meanfield"" theory, meaning that instead of working with dynamic equations for each individual sensor we use only a small number of equations for the ""averaged"" sensor state (i.e., passive, active, faulty, etc.), regardless of the actual number of sensors in the system.

The analytic approach can lead to the valuable insights into the performance of the proposed sensor network system by providing simple analytical expressions to calculate the vital network parameters, such as the detection threshold, robustness, responsiveness and stability and their functional relationships.

The fluctuations in concentration C of the pollutant are modeled by the probability density function (pdf) with the mean C 0 as a parameter [111] :

Here the value γ = 26/3 can be chosen to make it compliant with the theory of tracer dispersion in Kolmogorov turbulence [111] , but it may vary with meteorological conditions. The parameter ω, which models the tracer intermittency in the turbulent flow, can be in the range We adopt a binary model of a chemical sensor, with reading V specified as:

where C * is the threshold (an internal characteristic of the sensor). It can be shown [112] that the probability of detection of an individual sensor embedded in the environmental model described by Eq. (22.18) is given by:

where

is the cumulative distribution function corresponding to pdf of Eq. (22.18), see [113] .

Examples of WSN network operating in the tracer filed with different correlation structure [117] . (reprinted with permission.)

Suppose that N chemical sensors are uniformly distributed over the surveillance domain of area S and adopt the following network protocol for dynamic collaboration. Each sensor can be only in one of the two states: active and passive. The sensor can be activated only by a message it receives from another sensor. Once activated, the sensor remains in the active state during an interval of time τ * ; then it ""dies out"" (becomes passive). While being in the active state, the sensor senses the environment and if the chemical tracer is detected, it broadcasts a (single) message. The broadcast capability of the sensor is characterized by its communication range r * . This network with the described dynamic collaboration can be modeled using the epidemic SIS model (susceptible-infected-susceptible) [114] : (22.22) where N + , N − denote the number of active and passive sensors, respectively. The nonlinear terms on the right hand side of Eq. (22.22) are responsible for the interaction between the sensors; parameter α is a measure of this interaction. The number of sensor is assumed constant, hence we have an additional equation: N + + N − = N . Since the parameter alpha describes the intensity of social interaction in a community [114] we can propose that:

where m is the number of contacts made by the activated (""infected"") sensor during its infectious period τ * (i.e., the number of sensors that received the wake-up message from an alerting sensor). In our case m = π · r 2 * · N /S. Then we have:

where G is a calibration constant. In order to simplify notation we will further assume that G is absorbed in the definition of r * . Equation (22.22) combined with N + + N − = N can be reduced to one equation for y = N + :

where b = α N − 1/τ * . By simple change of variables z = α y/b, this equation can be reduced to the standard logistic equation [115, 116] :

The solution of the logistic equation is well-known:

where z 0 = z(0). Observe that the WSN will be able to detect the presence of a pollutant only if b > 0, because then z → 1 as t → ∞ independent of z 0 . In this case, after a certain transition interval, the WSN will reach a new steady state with:

From (22.27) and using the expression for b stated above, the activation time (transition interval) is given by:

From Eq. (22.29) it follows that the key requirement for the network to be operational b > 0 is that ατ * N > 1, that is:

where R 0 is a well-known parameter in epidemiology, referred to as the basic reproductive number [114] . Observe that R 0 is independent of τ * ; however, according to Eq. (22.29) the response time of the WSN is strongly dependent on τ * . It remains to specify q, the number of sensors that should initially be active for the described WSN with dynamic collaboration to be effective. The initial condition is simply q · p > 1, that is on average q > 1/ p. Eqs. (22.28)-(22.30) are important analytic results. For a given level of mean pollutant concentration C 0 and meteorological conditions (γ, ω), these expressions provide a simple yet rigorous way to estimate how a change in network and sensor parameters (i.e., N , C * , τ * ) will affect the network performance (i. e., N + , τ ) .

The examples of agent-based simulation of ""information epidemic"" in WSN, which satisfies the threshold condition of Eq. (22.30) is presented in Figure 22 .16. We can observe that by change of the configuration parameters of WSN we can vary the activation time and the saturation limit of the detection system. Further development of the theoretical framework presented in this section can be found in [117] [118] [119] [120] . 

Recently there has been an increased interest in detection and localization of radioactive material [121] [122] [123] [124] [125] . Radioactive waste material is relatively easy to obtain with numerous accidents involving its loss or theft reported. The danger is that a terrorist group may acquire some radiological material and use it to build a dirty-bomb. The dirty bomb would consist of waste by products from nuclear reactors wrapped in conventional explosives, which upon detonation would expel deadly radioactive particles into the environment. The ability to rapidly detect and localize radioactive sources is important in order to disable and isolate the potential threat in emergency situations. This section is concerned with radiological materials that emit gamma rays. The probability that a gamma radiation detector registers z ∈ N counts (N being the set of natural numbers including zero) in τ seconds, from a source that emits on average μ counts per second is [126] :

where λ = μτ is the mean and variance of the Poisson distribution. The measurements of radiation field are assumed to be made using a network of low-cost Geiger-Müller (GM) counters as sensors.

In general, the problem of detection and localization of point sources or radioactive sources can be solved using either controllable or uncontrollable sensors. Controllable sensors can move and vary the radiation exposure time [127, 128] . In this Section we will focus on uncontrollable sensors, placed at known locations with constant and known exposure times.

Assume that r ≥ 0 sources (r is unknown) are present in the area of interest. Furthermore, the assumption is that the area is flat without obstacles (""open field""). Each source i = 1, 2, . . . , r is parameterized by its 2D location (x i , y i ) and its equivalent strength α i (a single parameter which takes into account the activity of the source, the value of gamma energy per integration and scaling factors involved, see [129] ). Thus the parameter vector of source i is ϑ i = x i y i α i T , while the total parameter vector is a stacked vector: ϑ = ϑ T 1 · · · ϑ T r T . Suppose a network of GM counters is deployed in the field of interest. Let GM counter j = 1, . . . , m, located at ξ j ζ j , reports its count z j every τ seconds. Assuming that each GM counter has a uniform directional response and that attenuation of gamma radiation due to air can be neglected, the joint density of the measurement vector z = z 1 · · · z m T , conditional on the parameter vector ϑ and the knowledge that r sources are present, can be modeled as [129] :

Here λ j (ϑ) is the mean radiation count at sensor j:

being the distance between the source i and sensor j, and λ b the average count due to the background radiation (assumed known). The problem for the network of GM counters is to estimate the number of sources r and the parameter vector for each source ϑ i , i = 1, . . . , r . In this section we will present the experimental results obtained using real data and a Bayesian estimation algorithm combined with the minimum description length (MDL) for source number estimation. A radiological field trial was conducted on a large, flat, and open area without any obstacles at the Puckapunyal airfield site in Victoria, Australia. The measurements were collected using the DSTOs 3 Low Cost Advanced Airborne Radiological Survey (LCAARS) survey system which consists of an AN/PDR-77 radiation survey meter equipped with an RS232 interface module, a gamma probe and software written in Visual Basic running on a laptop computer. The gamma probe contains two GM tubes to cover both low and high ranges of dose rates. It was capable of measuring gamma radiation dose rates from background to 9.99 Sv/h 4 without saturating [130] with a fairly flat response [131] . Three radiation sources were used in the field trial: source 1 was a cesium sources ( 137 Cs) with ϑ 1 = 11 m 10 m 9105 µSv/h T , source 2 was also a cesium source with ϑ 2 = 3 m 50 m 1868 µSv/h T , and source 3 was a cobalt source ( 60 Co) with ϑ 3 = 41m 5m 467 µSv/h T . The aerial image of the experimental site with the location of sources and the local Cartesian coordinate system is shown in Figure 22 .17. Four data sets were collected during the field trails in the presence of r sources, with respectively r = 0, 1, 2, 3 [132] . Data sets with r > 0 sources contains 50 count measurements in each measurement point. Estimation of parameter vector ϑ, under the assumption that r is known, was carried out using the Bayesian importance sampling technique known as the progressive correction [125, 133] . This technique assumes that prior distribution of ϑ, denoted p 0 (ϑ), is available. The information contained in the measurement vector z is combined with the prior to give the posterior pdf: p(ϑ|z) ∝ l(z|ϑ) · p 0 (ϑ). The minimum mean squared error estimate of ϑ is then the posterior expectation:

The problem is that the posterior pdf and hence the posterior expectation of Eq. (22.35) cannot be found analytically for the described problem. Instead, an approximation of Eq. (22.35) is computed via the importance sampling: it involves drawing N p samples of the parameter vector from an importance density and approximating the integral by a weighted sum of the samples. This is carried out in a few stages, each stage drawing samples from a ""target distribution"" which is gradually approaching the true posterior. The ""target distribution"" at stage s = 1, . . . , S is constructed as: p s (ϑ|z) ∝ l(z|ϑ) G s · p 0 (ϑ), (22.36) where G s = s l=1 γ l with γ ∈ [0, 1) and G S = S l=1 γ l = 1. An adaptive scheme for the computation of S and factors γ 1 , γ 2 , . . . , γ S is given in [125, 133] . Assume that a random sample ϑ n s−1 N p n=1 from p s−1 (ϑ|z) is available and one wants to generate the samples or particles from p s (ϑ|z). The progressive correction algorithm steps are then as follows [125] :

compute not-normalized weight of each sample as: w n s = l(z|ϑ) γ s , for n = 1, . . . , N p ; 3. normalize weights; 4. perform re-sampling of particles [134] ; 5. carry out Markov chain Monte Carlo (MCMC) move step for each particle [134] .

The procedure is repeated for every stage s < S until G s < 1. The initial set of particles is drawn from the prior density p 0 (ϑ). The final estimate in Eq. (22.35) is approximated aŝ

The number of sources was estimated using the MDL algorithm [59] , which will choose r ∈ {1, 2, . . . , r max } that will maximize the following quantity: β r = log l(z|θ(r )) − 1 2 log J(θ(r )) , (22.38) whereθ(r ) is the estimate obtained under the assumption that r sources are present and

is the Fisher Information Matrix. It can be shown that The inverse of the FIM gives us the CRLB, which represents the theoretical lower bound for estimation error covariance [135] . Figure 22 .18 shows the output of the progressive correction algorithm for data set 3 (with three sources present) after (a) s = 2 and (b) s = 11 stages of processing. The red stars indicate the locations of three sources. The green line shows the initial polygon A for the location of sources. The prior density for sampling the initial set of particles for source i = 1, . . . , r is: (22.42) where U A (x i , y i ) stands for uniform distribution over the polygon A and κ.ν (α i ) is the gamma distribution with parameters κ = 1.5 and ν = 8000. From Figure 22 .18 we observe how the progressive correction algorithm localiszs the three sources fairly accurately. As we mentioned earlier, 50 count measurements have been collected by each sensor. This allows us to find the root mean square (rms) estimation error using each snapshot of measurement data from all sensors. Table 22 .2 shows the resulting rms errors versus the theoretical CRLB.

The theoretical CRLB was computed using the idealized measurement model as stated by Eqs. (22.32)- (22.34) . Considering that this measurement model was very crude with a number of factors neglected (e.g., uniform directional response, neglected air attenuation, perfect knowledge of sensor locations, known and constant average background radiation, etc.), the agreement between the theoretical bound and the RMS estimation errors in Table 22 .2 is remarkable. The experimental results in this table effectively verify the measurement model as well as the estimation algorithm. Results for estimation of r are shown in Table 22 .3. The table lists the number of runs (out of 50) that resulted in r ∈ {0, 1, 2, 3}. It can be observed that the number of sources is estimated correctly in the majority of cases.

More results of experimental data processing can be found in [131, 132] . In a recent study [136] it was found that by using all 50 snapshots of measurement data for estimation by progressive correction, results in a posterior pdf which is very narrow but does not include the true source positions. This indicates that the measurement model is not perfect, which is not surprising considering that it is based on many approximations. In situations where the measurement likelihood is not exact, it is necessary to introduce a degree of caution to make the estimation more robust. In the framework of progressive correction this can be achieved by G S = S l=1 γ l < 1. In this way the measurement likelihood is effectively approximated by a fuzzy membership function which has a theoretical justification in random set theory [137, Chapter 7] .

If one wants to relax the assumption that radioactive sources are point sources, the problem becomes the one of radiation field estimation. This is an inverse problem, difficult to solve in general. By modeling the radiation field by a Gaussian mixture, however, the problem becomes tractable and some recent results are reported in [138] .

Multi-sensor management concerns with the control of environment perception activities by managing or coordinating the usage of multiple heterogeneous sensor resources. Multi-sensor systems are becoming increasingly important in a variety of military and civilian applications. Since a single sensor generally can only perceive limited partial information about the environment, multiple similar and/or dissimilar sensors are required to provide sufficient local pictures with different focus and from different viewpoints in an integrated manner. As viewed, information from heterogeneous sensors can be combined using data fusion algorithms to obtain synergistic observation effects. Thus the benefit of multi-sensors system are to broaden perception and enhance awareness of the state of the world compared to what could be acquired by a single sensor system. The increased sophistication of sensor assets along with the large amounts of data to be processed has pushed the information acquisition problem far beyond what can be handled by human operator. This motivates the emerging interest in research into automatic and semi-automatic management of sensor resources for improving overall perception performance beyond basic fusion of data.

Multi-sensor management is formally described as a system or process that seeks to manage or coordinate the usage of a suite of sensors or measurement devices in a dynamic, uncertain environment, to improve the performance of data fusion and ultimately that of perception.

The basic objective of sensor management is to select the right sensors to do the right service on the right object at the right time. Sensor management, aiming at improving data fusion performance by controlling sensor behavior, plays the role of level 4 functions in JDL model presented in Section 2.22.3. Mainly the same considerations made for homogeneous sensor networks are still valid: the criteria followed to manage the network remains the same, however there is an increasing of complexity due to the diversity of the sensors. In the following Sections the problems related to multi-sensor management are divided into three main categories i.e., sensor deployment, sensor behavior assignment, and sensor coordination.

Sensor deployment is a critical issue for intelligence collection in an uncertain dynamic environment. It concerns with making decisions about when, where, and how many sensing resources need to be deployed in reaction to the state of the environment and its changes.

Sensor placement needs special attention in sensor deployment. It consists of positioning multiple sensors simultaneously in optimal or near optimal locations to support surveillance tasks when necessary. Typically it is desired to locate sensors within a particular region determined by tactical situations to optimize a certain criterion usually expressed in terms of global detection probability, quality of tracks, etc. This problem can be formulated as one of constrained optimization of a set of parameters. It is subject to constraints due to the following factors:

• sensors are usually restricted to specified regions due to tactical considerations; • critical restrictions may be imposed on relative positions of adjacent sensors to enable their mutual communication when sensors are arranged as distributed assets in a decentralized network (e.g., net-centric approach);

• the amount of sensing resources that can be positioned in a given period is limited due to logistical restrictions.

In simple cases, decisions on sensor placement are to be made with respect to a well-prescribed and stationary environment. An example of a stationary problem is the placing of radars to minimize the terrain screening effect in detection of an aircraft approaching a fixed site. Another example is the arrangement of a network of intelligence gathering assets in a specified region to target another well-defined area. In the above scenarios, mathematical or physical models such as terrain models, propagation models, etc. are commonly available and they are used as the basis for evaluation of sensor placement decisions. Paper [139] presents a study for finding a solution to the placement of territorial resources for multi-purpose telecommunication services considering also the restrictions imposed by the orography of the territory itself. To solve this problem genetic algorithms 5 are used to identify sites to place the resources for the optimal coverage of a given area. The used algorithm has demonstrated to be able to find optimal solutions in a variety of considered situations.

More challenging are those situations in which the environment is dynamic and sensors must repeatedly be repositioned to be able to refine and update the state estimation of moving targets in real time. Typical situations where reactive sensor placement is required are, for instance, submarine tracking by means of passive sonobuoys in an anti-submarine warfare scenario; locating moving transmitters using ESM (Electronic Support Measures) receivers; tracking of tanks on land by dropping passive acoustic sensors.

The basic purpose of sensor management is to adapt sensor behavior to dynamic environments. By sensor behavior assignment is meant efficient determination and planning of sensor functions and usage according to changing situation awareness or mission requirements. Two crucial points are involved. Firstly the decisions about the set of observation tasks (referred to as system-level tasks) that the sensor system is supposed to accomplish currently or in the near future, on the basis of the current/predicted situation as well as the given mission goal. Secondly the planning and scheduling of actions of the deployed sensors to best accomplish the proposed observation tasks and their objectives.

Owing to limited sensing resources, it is prevalent in real applications that available sensors are not able to serve all desired tasks and achieve all their associated objectives simultaneously. Therefore a reasonable compromise between conflicting demands is sought. Intuitively, more urgent or important tasks should be given higher priority in their competition for resources. Thus a scheme is required to prioritize observation tasks. Information about task priority can be very useful in scheduling of sensor actions and for negotiation between sensors in a decentralized paradigm.

To focus on this class of problems, let us consider a scenario including a number of targets as well as multiple sensors, which are capable of focusing on different objects with different modes for target tracking and/or classification. The first step for the sensor management system should be to utilize evidences gathered to decide objects of interest and to prioritize which objects to look at in the time 5 Genetic algorithm (GA) is a search heuristic that mimics the process of natural evolution. This heuristic is routinely used to generate useful solutions to optimization and search problems. GA belongs to the larger class of evolutionary algorithms (EA), which generate solutions to optimization problems using techniques inspired by natural evolution, such as inheritance, mutation, selection, and crossover [140] .

following. Subsequently, in the second step, different sensors together with their modes are allocated across the interesting objects to achieve best situation awareness. In fact, owing to the constraints on sensors and computational resources, it is in general not possible to measure all targets of interest with all sensors in a single time interval. Also, improvement of the accuracy on one object may lead to degradation of performance on another object. What is required is a suitable compromise among different targets.

As stated in the previous Sections, there are two general ways to integrate a set of sensors into a sensor network. One is the centra1ized paradigm, where all actions of all sensors are decided by a central mechanism. The other alternative is to treat sensors in the network as distributed intelligent agents with some degree of autonomy. In such a decentralized architecture, bi-directional communication between sensors is enabled, so that communication bottlenecks possibly existing in a centralized network can be avoided. A major research objective of decentralized sensor management is to establish cooperative behavior between sensors with no or little external supervision. In a decentralized sensor network scenario a local view perceived from a sensor can be shared by some members of the sensor community. Intuitively, a local picture from one sensor can be used to direct the attention of other sensors or transfer tasks such as target tracking from one sensor to another. An interesting question is how participating sensors can autonomously coordinate their movements and sensing actions, on grounds of shared information, to develop an optimal global awareness of the environment with parsimonious consumption of time and resources.

As for homogeneous sensor network, the CSIP approach can be exploited [141, 142] : the network consists of different kinds of sensors, randomly distributed inside the surveillance area and if the number of sensors is high, the performance of the surveillance system can be considered independent of the location of the targets. Each sensor has a different functioning level. A first level sensor, with small sensing and communication capabilities may provide only detection information; a second level sensor may provide detection and localization information, with medium sensing and communication capabilities. Finally a third level sensor may provide tracking information and may be able to perform target recognition and classification. Usually the number of low level sensors exceeds the number of higher level sensors and only close sensors exchange data.

In [143] the network consists of two types of sensors: simple and complex as represented in Figure 22 .19a. The simple ones have only the capability of sensing their coverage area with a reduced computation capabilities and they transmit data to complex sensors. The information they provide may be encoded, for example, by a ""1"" if sensor detects something crossing its coverage area and by a ""0"" otherwise. Complex sensors, instead, have computation capabilities; they are able to locate the target by applying sophisticated algorithms (e.g., in [143] the maximum likelihood estimation algorithm is applied). The topology simulated in [143] , constituted by 80 simple sensors and 20 complex sensors, is represented in Figure 22 .19b: the sensors are indicated by circles; the complex sensors are connected by the solid lines, simple and complex sensor by dashed lines. Figure 22 .20 shows the number of active sensors during the target tracking: the theoretical value and the simulated value are compared. It is evident that in a self-organizing configuration the number of active sensors is optimized with the consequent advantage of saving of power. An adaptive self-configuring system consists of a collection of independent randomly located sensors that, carrying ahead local interactions, estimate the position of the target without a centralized control unit that coordinates their communication. It is fault tolerant and adapts to changing conditions. Furthermore, it is able to self-configuring, i.e., there is not an external entity that configures the network. Finally, the task is performed efficiently, i.e., it guarantees both a reasonably long network life and good target tracking performances. From local interactions, sensors form an efficient system that follows the target, i.e., local communication leads to a self-organizing network that exploits the features of the theories of random graphs and of self-organizing systems. The most natural way to approach random network topology is by means of the theory of random graphs [144, 145] . The theory of random graphs allows, for instance, to compute an upper bound to the estimated number of active sensors at each time step.

When the fusion of heterogeneous signals is performed, there is a formal problem to solve. The signal received by the different sensors may be statistically dependent because of the complex intermodal interactions; usually the statistical dependence is either ignored or not adequately considered. Usually the multiple hypotheses testing theory is based on the statistical independence of the received signals, in our case this condition is not maintained, therefore techniques as the ""copula probability theory"" may be useful.

In probability theory and statistics, a copula can be used to describe the dependence between random variables [146] . The cumulative distribution function of a random vector can be written in terms of marginal distribution functions and a copula. The marginal distribution functions describe the marginal distribution of each component of the random vector and the copula describes the dependence structure between the components. Copulas are popular in statistical applications as they allow one to easily model and estimate the distribution of random vectors by estimating marginal distributions and copula separately. The Sklar's theorem ensures that the joint cumulative distribution function (cdf) F Z (z 1 , z 2 , . . . , z N ) of random variables Z 1 , Z 2 , . . . , Z N are joined by a copula function C(·) to the respective marginal distributions F Z 1 (z 1 ), F Z 2 (z 2 ), . . . , F Z N (z N ) as [147] : F Z N (z N ) ). (22.43) Further, if the marginals are continuous, C(·) is unique. By the differentiation of the joint cdf, the joint pdf is obtained:

The copula density c(·), function of the N marginals from the N sensors, represents a correction term of the independent product of densities of Eq. (22.44) .

Processing heterogeneous data set is not straightforward as they may not be commensurate. In addition, the signals may also exhibit statistical dependence due to overlapping fields of view. In [148] the authors propose a copula-based solution to incorporate statistical dependence between disparate sources of information. The important problem of identifying the best copula for binary classification problems is also addressed and a copula based test-statistic, able to decouples marginals and dependency information, is developed.

This section tackles the problem of the surveillance of the borders of a nation. The region of interest, in general, may be very wide consisting even of thousands of kilometers of coastline and land border line, and millions of square kilometers. Such a system must face threats such as drug trafficking, intrusions (man, vehicles and airplanes), illegal immigration, smuggling, human trafficking, arms smuggling, unauthorized deforestation, terrorist activities over the military defense of the borders in order to ensure the territorial defense and the national sovereignty in the areas close to the border line. In the following Sections an overview of the range of possibilities and solutions in the design of the surveillance asset and data fusion process of such systems devoted to border control is given.

The size of the region, the nature of the border and the complexity of the scenario require the provision of different pictures of the region with different field of view at different resolution and time scales, suggesting a multi-sensor/multi-scale approach integrated in a hierarchical architecture of the whole system. Typically a global field of view of the whole region is necessary at the higher Command and Control (C2) level to capture the overall situation. A higher level of resolution and refresh rate is necessary at the lower and local level to analyze and control in depth each single zone of a region. Therefore the surveillance segment may be structured according to a multilayer architecture where layers realize different trade-offs in terms of field of view and granularity and refresh time. The surveillance segment comprises several types of sensors, each one characterized by different achievable resolution, field of view, and revisiting time. A pictorial sketch of the surveillance architecture is depicted in Figure 22 .21 for a notional country: sensors on board of satellites are expected to provide a global coverage of the monitored area at medium resolution with a low refresh rate, typically in the order of several hours or days; a higher resolution data and a higher refresh rate, in the order of seconds or tens of seconds, is provided by ground sensors on limited areas; airborne sensors (e.g., Unmanned Air Vehicle, UAV) will provide data on remote areas with good resolution data and short deployment time.

All data collected by the sensors are exploited by the fusion engine, highlighted in the figure. It is responsible to track and classify relevant entities present in the scenario and to provide a high quality representation of the situation. Also the data fusion process supports this multi-scale approach performing a distributed and network-centric processing at the various levels of the architecture, in accordance with available communication bandwidth and latency.

Pictorial of the surveillance architecture.

The surveillance of critical perimeters is one of the most important issues in Homeland defense and Homeland Protection systems. The ground surveillance needs are relevant to border protection applications, but include also local area protection, such as critical infrastructure, military/civilian posts.

During the last 10 years special attention has been focused on the realization of so-called ""electronic fence"" for perimeter/border control and several developments have been carried out to demonstrate the efficiency of such systems. However several problems occurred when the electronic fences became operational, showing lacks in the practical use by the operators (i.e., high number of false alarms, loss of/slow communication links) together with the problem of the high funding required for the whole system. One example is described in [149] , that requires now a total different approach for the surveillance of a wide national border (>500 km).

In the following an overview of the problems and solutions related to the implementation of an electronic fence is presented. The major components are:

• Sensors: they may be either active or passive, radar networks or heterogeneous sensor networks, (e.g., passive IR-infrared, seismic, acoustic, electro-optic-E/O, etc.). • Communication network: necessary to data exchange, may be subdivided into sub-networks if necessary. • Fusion engines: they perform data collection, data fusion and classification; this capability can be spread across the layers that compose the electronic fence (i.e., in the master stations, but also in the C2 centers).

Depending on the geographical deployment of the protection system, the data are then exchanged with C2 centers, both at local level and wide area (i.e., national) level. In Figure 22 .22 an example of an electronic fence architecture is depicted. In this case a wide area to be controlled, such as a border of a nation, has been considered; the subnets are geographically distributed along the boundaries. The architecture has the advantage to be modular and scalable and it can be organized with different level C2 centers (local, regional, national), depending also on the size of the considered boundaries. Each subnet is able to ensure the data exchange among the sensors. An overview of the sensors that can be employed in an electronic fence is presented.

Example of electronic fence architecture.

Microwave (X, Ku, Ka band) ground based radars are widely used to perform the monitoring of open wide areas. The monitoring of walking people and vehicles for ground applications, and of small sized boat for sea and river applications are relevant. The detection ranges varies from 2 km to 10 km for people, and from 5 km to 20 km for vehicles. Aerial targets (e.g., helicopters, low level aircraft) are also detected. Depending on the technology used these radars can be subdivided into the following two categories:

• Incoherent: they are low cost devices, FMCW (Frequency Modulated Continuous Wave) or pulsed (often a magnetron is used as most of the navigational radars), where the detection of the moving targets is based on inter-clutter visibility. Resolutions are typically of few meters or tenths of meters both in range and cross-range. • Coherent: they are solid state transmitter based, FMCW or pulse compressed, where the detection of the moving targets is based on sub-clutter visibility. The MTD (Moving Target Detection) filtering, even if the radar is working at X-band, requires low scan rates (in the order of 1-3 RPM-Round Per Minute) to allow high Doppler frequency resolution (0.2-0.5 m/s) to resolve slow moving target also in presence of strong clutter [150] .

The attention is for sensors able to operate in critical environments and many studies have been performed, in this direction, mainly using aerial platforms equipped with SAR. The aircraft equipped with sensors are used for wide areas where ground based sensors are not suitable or cannot be installed, such as in forest or jungle. However the use of airborne platforms to perform surveillance, are limited to missions ""on spot"" because it is not practical or cost/effective for continuous surveillance. The radar sensor can be mounted on manned or unmanned aircraft, usually equipped with electro-optic devices, and they can be used to monitor areas of several tenths of kilometer length. Other solutions take into account the installation of the radar either on a tethered aerostat or on a hovering helicopter. GMTI (Ground Moving Target Indication) from a stationary platform has been demonstrated.

Fixed radars for border control are usually in X and Ku band, but, because of the attenuation they suffer from foliage, they cannot be used for FOPEN applications. The ability of traditional microwave radars in operating in an environment with dense foliage is severely limited by foliage backscatter and attenuation of microwave frequencies through foliage [151] . As attenuation falls with increasing wavelength, lower frequencies such as those in the VHF and UHF bands (30-1000 MHz) may be suitable for FOPEN radar applications [152] [153] [154] [155] . FOPEN SAR (Synthetic Aperture Radar) systems started to be used in the early 1990s. They are usually mounted on manned or unmanned aircraft and mainly address illegal activity control and search-and-rescue operations. The focus is now for ground based systems and/or sensors with capabilities to detect walking personnel and moving vehicles [156] . Logistic constraints drive the technology to very low power devices, that are able to operate for several months or years, without maintenance. Another important issue is, together with a good probability of detection, the low false alarm probability, that is requested to be lowered up to 1 false alarm per day, or lower, even in presence of specific weather conditions (rain, wind) and/or local seasonal fauna. A special attention is due to the effect of environment. In dense foliage environments the main clutter effects are the backscatter and the attenuation. Backscatter: The fixed clutter returns can have a zero Doppler component raising up to 60-70 dB above the noise level with spectra amplitude and shape without large variations with frequency, but depending mainly on the wind strength [150] . Considering the measurements reported in [150] of the backscatter Doppler spectra, in order to perform efficient clutter rejection, two values of thresholds can be used: i.e., 1 m/s in case of light air, 2 m/s in case of windy/gale. Attenuation: The attenuation depends mainly on the frequency used and the radar beam grazing angle, even if small variations are reported with different polarizations [153] . Many studies have been carried out for SAR application and several studies report data for attenuation measured directly at ground level [151, 153, 154, 157] . The total attenuation, taking in account the major effects of the environment for a ground radar, can be summarized as follows: (22.45) where: 4 is the attenuation due to the ground reflection at the heights of the antenna (h r ) and the target (h t ), for the wavelength λ, • L f is the attenuation due to the foliage: it depends on the distance, the polarization and the forest type. It depends also on the distribution of the trees and the diameter of the masts, that can limit the line of sight, together with the height and density of lower canopy level.

The main requirements/constraints addressed are the range of the detections, which is reduced by the attenuation due to foliage and the low antenna height, that is usually limited to 1-2 m for logistic purposes. Also the power consumption must be kept at minimum level, also considering that photovoltaic cells are not suitable for installation on the ground in the forest. As a consequence the emitted power must be kept at a level of several mW. Camouflage and anti-tamper are often required. Very low cost is a mandatory requirement. Low Probability of Intercept (LPI) capabilities are necessary. Walking personnel and moving vehicles should be detected.

Even if the FOPEN radars are referred to the forest environment, the sensor described above is suitable to operate also in different installations, considering, for example, riverside or sea harbor protection applications. In these cases the different environmental conditions allow to achieve better radar performances. In addition, several other constraints (for example the management of transmitted power) can be mitigated by the use of photovoltaic cells and/or different antenna installations.

In Figures 22.23 and 22 .24 some outputs of the target detected by the UHF radar are shown. The information are displayed on range-Doppler maps, that are suitable to be read by a trained operator, giving information on the radial speed and, with a medium-high resolution in range, it helps the operator in the targets discrimination and alarm recognition. 

In this section we consider the Unattended Ground Passive Sensors (UGPS) and Electro-Optic (EO) to detect moving people or vehicles.

UGPS. They are used in case of small areas or critical infrastructure perimeter surveillance. They give alarms in presence of target in the operational range and, in some cases, can give a pre-classification of the target detected. The range of each sensor is usually limited to 10 m, but the latest technologies promise to reach detection ranges up to 50 m. They have very small dimension (less than 1 l volume) and low weight (less than 1 kg); they can be rapidly installed on rough ground or roads. Figure 22 .25 gives an example of positioning of UGPS in an operative field. They are of following basic types:

• seismic: to detect seismic movement produced by vehicles wheels or people walking, • acoustic: to detect vehicle engine noise, • infrared: to detect differences in thermal data from the environment due to the infrared signature of people and vehicles, • magnetic: to detect magnetic filed variation produced by vehicles.

Electro-Optic: They are widely used for surveillance, and many signal processing techniques assist the operator for target detection alerts.

They can be fixed or rotating covering up to 360 • in azimuth. For the night vision infrared EO are used, either passive or active, and they can reach a visibility of several kilometers in range. The EO are normally used stand alone or connected with radar sensor to help the operator for classification and identification of the detected targets. For example, with active infrared the operator can read (up to 2 km far from the camera) the license plate of a vehicle previously detected and tracked by the radar.

The sensors operate in cluster, and they are connected via a low power RF link, operating at UHF or L/S bands. The data of the unmanned radars can be combined with the data of other UGPS sensors C2 and operator console

Unattended ground radar network.

(infrared, acoustic, seismic), or connected to an existing network, to perform a more reliable detection system.

In Figure 22 .26 an example of sensor network is reported. As shown, adjacent sensor nodes are connected together and the information are sent, to the master station, via the short range radio link; the master station performs data fusion and medium range connection with the other master stations, or the C2 center. In case of long range connection the master stations are connected via radio link repeaters or satellite connections.

Special care must be taken to avoid interactions among the sensors, where two or more sensors share the same visibility area. Mutual interferences can be avoided using different frequencies and/or different timing for the transmitted waveform and also orthogonally coded waveforms.

The data transfer among the nodes is performed using the radio link between adjacent nodes. In case of linear geometric distribution the data grow up linearly with the number of nodes in the subnet; as a consequence the number of nodes in the subnet is limited by the maximum data rate of the single connection link.

The linear electronic fence can be composed of two or more parallel sections to allow redundancy in case of failure or loss of visibility of one or more sensors.

An example of electronic fence is shown in Figure 22 .27. In this case different environment conditions have been considered (riverside, forest, manmade buildings, and obstacles) and a network of FOPEN unattended ground radar sensors is used.

The fusion engine allows to fuse heterogeneous sensor data at multiple levels to perform tracking and classification of relevant entities present in the scenario and to provide a high quality representation of the situation together with cartographic layers and sensed images of the terrain. Figure 22 .28 provides an example of architecture for the fusion engine.

Border surveillance: a notional case.

Fusion engine architecture.

The tracking function processes the raw data provided by sensors and generates a set of tracks, representative of the real entities present in the scenario. A track typically carries the following information: a timestamp, position coordinates, velocity components, uncertainty on the kinematic components as expressed through the covariance matrix and additional attributes such as class/type and identity. In consideration of the potentially huge geographic extension of the system and of the importance to optimize the deployment of sensors as well as communication and processing power resources, a distributed tracking architecture is necessary. At the first level of the tracking architecture each sensor produces its own ""local"" tracks, in order to make available to the fusion engine a filtered information. Then a second level tracking combines local tracks originating from different sources into system tracks. This solution distributes the computational load on the peripheral nodes and reduces considerably the communication traffic which must be transmitted from the local level to the higher echelons; this is extremely important in consideration of the reduced bandwidth generally available between the peripheral elements and the center of the system.

In this step of the process, information of different nature can be fused producing a unique high quality information. Radar tracks can be fused with multiple images acquired by SAR and optical sensors, even if acquired at different resolutions, to achieve an improved representation of the scene with respect to the one achievable by processing data sets separately, in particular in terms of detection and false alarm probabilities when dealing with small targets (i.e., targets that occupy only few pixels of the image) [158] [159] [160] [161] [162] . The cartographic layers, superimposed with SAR or optical images, allow to put into context all the available information and support the fusion process (e.g., target tracking for ground vehicles especially during maneuvers).

Another output of the fusion engine is the classification of the tracked targets and entities of the scenario, i.e., the attribution of a class to the track under examination, hence supporting the capability to achieve a situation awareness.

From an operational point of view, the fusion engine can be considered as the responsible of producing a multi-resolution and multi-layer COP (Common Operating Picture), whose definition, as provided by [163] , is the following: ""A single identical display of relevant information shared by more than one command that facilitates collaborative planning and assists all echelons to achieve situational awareness."" The COP therefore provides to the operators at the different levels the capability to view each time a well-suited map, both in terms of proper scale (with respect to the scale of the observed situation) as well as in terms of number and type of information, according to the situation under analysis. This characteristic allows the system to properly support the operator without overloading him with unimportant information and keep him focused on events and information that might be related with his goal in terms of spatial, temporal, and logic correlation.

In the following the main constituents of the fusion engine are described.

The local tracking function processes the measurements provided by the sensor and produces a local track for each of the observed targets present in the surveillance region. The task of the tracking function at the local level is therefore of using the measurements made available by the sensor to estimate the number of targets and their kinematic components [164] [165] [166] . Local tracks provide position and velocity estimates at a given time, together with an indication of track quality; the track may also include other attributes relative to track classification, derived directly from radar measurements, from other sensors (EO/IR, UGPS, UAV) or assigned by a human operator.

In the scenario of a generic land border may be necessary to form low altitude tracks, surface tracks and ground tracks. Tracking of ground targets is especially critical due to the characteristics of the ground environment and of ground targets. The main criticality may be the masking effect due to terrain orography and vegetation. Another interesting feature of the ground environment is the presence of areas, mainly roads, where the probability of finding targets is higher, and areas such as off-road where the presence of targets is less probable. Distinguishing features of ground targets are high maneuverability and move-stop-move dynamics.

Even a well trained operator would be unable to select the correct hypothesis when a ground target is maneuvering since available information is insufficient. In these situations the best strategy is to defer the final decision until more data is available. To take into account these difficulties, the tracking function must be designed so as to handle several concurrent hypotheses and to make final decisions with a deferred logic [167] [168] [169] , i.e., when more data is available which allows to make a final decision with sufficient confidence. The choice of hypotheses is also dependent on the environment and on the target type. The management of multiple hypotheses is then the capability of the function to consider at each time instant a set of hypotheses, such as:

• the target is proceeding regularly/is maneuvering on road; • the target is moving/maneuvering off-road;

• the target has stopped, etc.

The tracking function assigns a score to each hypothesis and identifies the most probable; the function keeps alive for some time not only the most likely hypothesis but also a set of alternative hypotheses which represent different kinematic evolutions of the target. Figure 22 .29 shows an example of the set of hypotheses generated by the function: each hypothesis is relative to a path in the tree from time t0 to time t3 and the single branches may be relative to the choice of a specific dynamic model and/or a specific correlation hypothesis with a measurement in the set. For example in the path highlighted in red it is assumed that the target trajectory in the interval t0-t3 is described by the dynamic model m1; the other branches are relative to alternative hypotheses where it is assumed for example that the target has maneuvered (m2) or stopped (m3), etc. As new information is acquired, the probability of each hypothesis is updated according to new information; hypothesis which initially have a low score may gain credibility and vice versa. This characteristic, i.e., defer the decision until the available information is considered sufficient, allows to resolve most critical situations.

To take into account terrain and geographic information, the tracking solution leverages also context information provided by the GIS (Geographic Information System) in accordance with logics of terrain and road aided tracking. Digital Terrain Elevation Data (DTED) are also used to perform accurate projections of the tracks on the terrain and to identify zones where the target trajectory will be masked by obstacles and thus improve track continuity and the estimate of track kinematic parameters (e.g., maximum target velocity given the terrain type). The following Figure 22 .30 shows, for instance, how environmental knowledge can be exploited to improve the tracking function [170, 171] . Figure 22 .30a shows a landscape covered by forests and crossed by a network of paths; due to the nature of the environment, targets especially if motorized, will preferentially move along the track, avoiding off-road areas more difficult to traverse. The blue line represents the trajectory of a track which moves along a winding path in the forest. Figure 22 .30b on the other side shows how information relative to roads and viability in general can be exploited to improve the tracking performance. When the track approaches a bifurcation or a crossing, different hypotheses are generated to take into account possible target trajectories, such as on-road, off-road and also move-stop motion. More specifically the adoption of techniques such as road aided tracking is specifically important since it allows to improve the accuracy in the estimation of target kinematic parameters and therefore to make longer term projections. Finally weather information is exploited to further improve the tracking processing by feeding in information about areas where target detection is less probable (e.g., flooded areas) and expected target velocity is low given the past days weather conditions (e.g., heavy rain is expected to result in limited target velocity).

The classification function allows attributing a class to the track under examination, i.e., to determine its belonging to a class of targets. Target classification is extremely important since it helps to determine target identity and its threat level. Part of the classification process is the non-cooperative target recognition (NCTR), in order to avoid fratricide and to allow proper allocation of defensive means against the threat. In a coastal scenario NCTR capabilities are needed against ships, potentially involved in terrorism, illegal immigration or contraband operations, in order to assess and prioritize threats and to provide the appropriate response. Sensors such as radar, EO/IR, may provide useful information for classification. In the radar case, the NCTR technology facilitates the identification of non-co-operative targets by transmitting wide band signals and by processing the radar echoes in a suitable multidimensional domain; e.g., time-frequency and range-angle. In the former case the target is discriminated on the basis of the jet engine or the helicopter rotor modulations of the echo [172] [173] [174] [175] ; in the latter case the target is discriminated on the basis of the measured two-dimensional radar image obtained by ISAR techniques [176] [177] [178] (Figure  22 .31 shows a snapshot of the radar image of a ship).

The automatic classification, that the radar is capable of providing by means of these processing techniques, is used directly within the tracking function, to support the plot-track correlation process and to attribute a class to the track. The classification process allows therefore determining the class to which the track belongs (such as pedestrians, vehicles, convoys, helicopters, and small low altitude aircrafts) and performing cueing to other sensors (e.g., EO/IR sensors, high resolution radars) or demanding a patrolling mission (e.g., a mission with UAV).

While data provided by sensors are needed to perform the classification processing, once the target has been assigned to a class, this information can be exploited at sensor level to achieve better accuracy in the performed processing (e.g., target classification can be used to refine kinematic target parameters used in the tracking processing).

The range-Doppler information can be furthermore employed to produce a confusion matrix useful for target classification. The confusion matrix expresses the a posteriori probability that a target has been classified correctly among a finite number of classes that have been a priori established. References [21, 179] give an example of the use of confusion matrix in the classification issue.

Epidemics can impose serious challenges on societies in modern times. The poor health of general population due to a disease causes hardship and pain but also negative trends in the economy through absenteeism from work, missed business opportunities, etc. The ongoing epidemics of AIDS (Acquired Immune Deficiency Syndrome), tuberculosis and the recent outbreaks of SARS (Severe Acute Respiratory Syndrome) and H1N1 (swine flu) provide some revealing examples.

In the absence of an effective cure against an infectious disease, the best approach to mitigate its malicious or natural epidemic outbreak resides in the development of a capability for its early detection and prediction of its further development [180] . This enables typical countermeasures, such as the quarantine, vaccination, medical treatment, to be much more effective and less costly [181, 182] . Therefore this issue can be approached as a surveillance problem in the context of Homeland Protection.

Syndromic surveillance is referred to as a systematic collection, analysis, and interpretation of public health data for the purpose of early detection of an epidemic outbreak and the mobilization of a rapid response [180, 182] . The key idea is to detect an epidemic outbreak using early symptoms, well before the clinical or laboratory data result in a definite diagnosis. The rationale is that a spread of an infectious disease is usually associated with the measurable changes in the social behavior, which can be measured by non-medical means. Recent studies [183] [184] [185] have demonstrated that these non-medical sources of syndromic data streams, such as the absenteeism from work/school, the pharmaceutical sales, internet queries, twitter messages, and alike, can enable one to draw important conclusions regarding the epidemic state in the community. The ""Google Flu"" project [186] (flu-related searches in Google) is a well publicized example of this approach.

The algorithms for syndromic surveillance and have recently attracted significant attention by scientists and practitioners; there is a vast amount of literature devoted to this topic (for more comprehensive review see [180, 182] and references therein). In general, all algorithms applied in this area can be divided into two main groups, the data mining methods and the information fusion (also known as data assimilation) methods. Data mining is primarily concerned with the extraction of patterns from massive amounts of raw data without using dynamic models of the underlying process (i.e., epidemic spread) [183, 185] . Information fusion algorithms, on the contrary, strongly rely of mathematical models: in this case, the dynamic model of an epidemic outbreak and the measurement model of a particular syndromic data stream [187, 188] . Naturally, the accuracy of information fusion algorithms is significantly determined by the fidelity of the underlying models.

This section presents a study of a recursive information fusion algorithm for syndromic surveillance, formulated in the Bayesian context of stochastic nonlinear filtering and solved using a particle filter [134] . While a similar work has been considered earlier, see [189] [190] [191] [192] , this section introduces two novelties. First, in order to overcome the limitations of the standard ""compartment"" model of epidemic spread (the ""well-mixed"" approximation) we employ a more flexible alternative, see [193, 194] . The adopted epidemic model has the explicit parameter of ""mixing efficiency"" (or level of social interaction) and is therefore more appropriate to represent a variety of social interactions in a small community (e.g., self-isolation and panic). An advantage of the adopted epidemiological model is also that it enables to estimate the scaling law of the noise level with respect to the population size of a community. Second, a more flexible model of syndromic measurements, validated with data sets available in the literature [183, 186] , is adopted in the section. This measurement model is robust in the sense that some of its parameters are specified imprecisely, as interval values. The optimal sequential estimator (filter) and predictor are then formulated in the Bayesian framework and solved using a particle filter.

To describe the dynamics of an epidemic outbreak we employ the generalized SIR (Susceptible, Infectious and Recovered) epidemic model with stochastic fluctuations [195] [196] [197] . According to this model, the population of a community can be divided into three interacting groups: susceptible, infectious and recovered. Let the number of susceptible, infectious and recovered be denoted by S, I, and R, respectively, so that S + I + R = P, where P is the total population size. The dynamic model of epidemic progression in time can be then expressed by two stochastic differential equations subject to the ""conservation"" law for the population:

where s = S/P, i = I /P, r = R/P, and ξ, ζ are two uncorrelated white Gaussian noise processes, both with zero mean and unit variance. The terms σ q ξ and σ β ζ are introduced into Eq. (22.47) to capture the demographic noise (random variations in the contact rate α and in the recovery time β) [197, 198] . Parameter ν in Eq. (22.47) is the population mixing parameter, which for a homogeneous population equals 1. In the presence of an epidemic, however, ν may vary as people change their daily habits to reduce the risk of infection (e.g., panic, self-isolation). In general, model parameters α, β, ν can be assumed to be partially known as interval values. In order to insure P {s, i, r ∈ [0, 1]} ≈ 1, standard deviations σ q , σ β need to satisfy [199] :

Assuming that non-medical syndromic data are available for estimation and forecasting of the epidemic, we adopt a measurement model verified by [185, 186] , where a power law relationship holds for the odds-ratio between the observable syndrome z j and the (normalized) number of infected people i:

The power law exponent ς j in Eq. (22.48) is in general syndrome specific. Since at the initial stages of an epidemic (which is of main interest for early detection and forecasting) we have: i 1 and z j 1, Eq. (22.48) can be reduced to a simple power-law model:

where b j is a constant and τ j is introduced to model the random nature of measurement noise. It is assumed that τ j is uncorrelated to other syndromes and dynamic noises ξ,ζ . Since z j ≥ 0 (e.g., number of Google searches), the noise term τ j associated with syndrome j should be modeled by a random variable that provides strictly non-negative realizations. For this purpose we adopt the lognormal distribution, that is τ j = σ j η j , with η j ∼ ln N (0, 1) and N (0, 1) being the standard Gaussian distribution.

Parameters b j , σ j , ς j typically are not known, but with a representative data set of observations the model of Eq. (22.49) can be easily calibrated (see for example the results of the linear regression fits in [186] ). The data fit reported in [183] suggests that ς j may be close to unity, although it is difficult to precisely specify its value because of significant scattering of data points). To cater for this uncertainty, we assume that ς j can take any value in an interval, ς ∈ ς 1 , ς 2 around ς = 1. Unfortunately [185, 186] do not report any specific values of fitting parameters, so we use in this study some heuristic values for b j , σ j in our simulations.

The problem now is to estimate the (normalized) number of infected i, and susceptible s at time t, using syndromic observations z j of Eq. (22.49) , collected up to time t. Let x denote the state vector to be estimated; it includes i and s, but also the imprecisely known epidemic model parameters α, β and ν. The formal Bayesian solution is given in the form of the posterior pdf p(x t |z 1:t ), where x t is the state vector at time t and z 1:t denotes all observations up to time t. Using the posterior p(x t |z 1:t ), one can predict the progress of the epidemic using the dynamic model of Eq. (22.47).

For the purpose of computer implementation, first we need a discrete-time approximation of dynamic model of Eq. (22.47) . The state vector is adopted as: x = i s α β ν T , where T is the matrix transpose.

Using Euler's method with small integration interval δ, the nonlinear differential equations in Eq. (22.47) can be approximated as The optimal Bayes filter is typically presented in two steps, prediction and update. Suppose the posterior pdf at time t k is given by p(x k Z | 1:k ). Then the prediction step computes the pdf predicted to time t m = t k + δ as [194] :

p(x m |z 1:k ) = π(x m |x k ) p(x k |z 1:k )dx k , (22.52) where π(x m |x k ) is the transitional density. According to Eq. (22.50), we can write π(x m |x k ) = N ( f k (x k ), Q). The prediction step is carried out many times with tiny sampling intervals δ until observation z j,k+1 about syndrome j becomes available at t k+1 . The predicted pdf at t k+1 is denoted p(x k+1 |z 1:k ).

In the standard Bayesian estimation framework, the predicted pdf is updated using measurement z j,k+1 by multiplication with the measurement likelihood function [200] . According to Eq. (22.49) , the likelihood function in this case is g(z j,k+1 |x k ) = ln N (h(x k+1 ; ς j ), σ 2 j ), where h(x; ς) = b j · x 1 ς .

The standard Bayesian approach, however, cannot be applied because h(x; ς) defined in this way is not a function: ς is effectively an infinite set (an interval) and therefore h(x; ς) is one-to-many mapping. An elegant solution to the imprecise measurement transformation is available in the framework of random set theory [137] . In this approach h(x; ς) + τ is modeled by a random set x and the likelihood function represents the probability:g(z|x) = Pr {z ∈ x }, and is referred to as the generalized likelihood. More details and a theoretical justification of this approach can be found in [201] . The Bayes update using syndromic measurement z j,k+1 is now defined as [137] :

p(x k+1 |z 1:k+1 ) =g z|x k+1 · p x k+1 |z 1:k g z|x k+1 · p x k+1 |z 1:k dx k+1 . (22.53) For the measurement model Eq. (22.49) with additive Gaussian noise, the generalized likelihood has an analytic expression [201] :g (z j |x) = ϕ z; x , σ 2 j − ϕ z; x , σ 2 j , (22.54) where x = min{h(x; ς ), h(x; ς )}, x = max{h(x; ς ), h(x; ς )} define the limits of the set and ϕ(u; μ, P) = u −∞ ln N (y; μ, P)dy is the cumulative log-normal distribution. The recursions of the Bayes filter start with an initial pdf (at time t k = 0), denoted p(x 0 ), which is assumed known. The proposed Bayesian estimator cannot be solved in the closed form. Instead we developed an approximate solution based on the particle filter (PF) [134, 202] . The PF approximates the posterior pdf p(x k |z 1:k ) by a weighted random samples; details can be found in [134, 202] . The only difference here is that importance weight computation is based on the generalized likelihood function.

Epidemic forecasting will be demonstrated using an experimental data set obtained using a large-scale agent based simulation model [203, 204] of a virtual town of P = 5000 inhabitants, created in accordance with the Australian Census Bureau data. The agent based model is rather complex (takes a long time to run) and incorporates a typical age/gender breakdown, family-household-workplace habits, including the realistic day-to-day people contacts for a disease spread. The blue line in Figure 22 .32 shows the number of people of this town infected by a fictitious disease, reported once per day during a period of 154 days (only first 120 days shown). The dashed red line represents the adopted SIR model fit, using the entire batch of 154 data points and integration interval δ = 0.0052 days, with no process noise, i.e., w k = 0 in Eq. (22.50 ). The estimated model parameters are:α = 0.2399,β = 0.1066,ν = 1.2042. These estimates were obtained using the importance sampling technique of progressive correction [202] . Figure 22 .32 serves to verify that the adopted non-homogeneous mixing SIR model, although very simple and fast to run, is remarkably accurate in explaining the data obtained from a very complex simulation system.

The true number of infected people in forecasting simulations is chosen to be the output of the agent based population model, shown by the solid blue line in Figure 22 .32. The measurements are generated synthetically in accordance with Eq. (22.49) and discussions above, using the following parameters: ς = 1.05, b j = 0.25, σ j = 0.01, for all j = 1, 2, 3, 4 monitored syndromes. Independent measurements concerning all Nz = 4 syndromes are assumed available on a daily basis during the first 25 days. The problem is to perform the estimation sequentially as the measurements become available until the day number 25, and at that point of time to forecast the number of infected people as a function of time.

The initial pdf for the state vector was chosen as p( , and uniform distribution, respectively. The imprecise measurement parameter is adopted as ς ∈ [1.03, 1.07], while its true value The number of particles is set to 10,000. Figure 22 .33 shows the histograms of particle filter estimated values of α, β, and ν, after processing 25 days of syndromic data (i.e., in total 100 measurements). The histograms in this figure reveals that the uncertainty in parameters α and β has been substantially reduced after processing the data (compared with the initial p(α 0 ) and p(β 0 )). The uncertainty in ν, on the other hand, has not been reduced, indicating that this parameter cannot be estimated from syndromic data. While this is unfortunate, it does not appear to be a serious problem in forecasting the epidemic mainly because the prior on ν in practice is fairly tight ( ν ≈ 1). This is confirmed in Figure 22 .34 which shows a sample of 100 overlaid predicted epidemic curves (gray lines) based on the estimate of i, s, α, β, ν obtained after 25 days. Figure 22 .34 indicates that the forecast of the peak of the epidemic is fairly accurate, while the forecast of the size of the peak is more uncertain. Most importantly, however, the true epidemic curve (solid red line) appears to be always enveloped by the prediction curves. More experimental results can be found in [199] .

Integrated sensor systems and data fusion have been the main focus of this chapter. The discussed matter has been subdivided in nine sections which have covered a long trip starting from the description of the Homeland Protection problem, to the illustration of a wide spectrum of information sources (sensors and the like), to the netting of such sensors (both homogeneous and heterogeneous), with a broad range of practical applications: cooperative sensing to defend a urban territory, network of cooperative chemical sensors, detection and localization of radioactive point sources, use of so-called electronic fence to protect long borderlines of a territory, up to the estimation and forecasting of an epidemic. This work, an unofficial collaboration between experts from industry, research centers and academia, has brought together a wide spectrum of competences scientific, technical/technological/systemic and on the field. 

",0.7693372826688204
Leveraging the Laboratory Response Network Model for the Global Health Security Agenda,"Promoting global health security as an international priority is a challenge; the US Centers for Disease Control and Prevention (CDC) in its Global Health Security Agenda has articulated the importance of accelerating progress toward a world safe and secure from infectious disease threats. The goals are to (1) prevent and reduce the likelihood of outbreaks-natural, accidental, or intentional; (2) detect threats early to save lives; and (3) respond rapidly and effectively using multisectoral, international coordination and communication. Foundational to this agenda is the World Health Organization (WHO) Revised International Health Regulations (IHR) of 2005, which provide the legal framework for countries to strengthen their health systems in order to be able to respond to any public health emergency of international concern. This article proposes leveraging the distributed structure of the US-managed Laboratory Response Network for Biological Threats Preparedness (LRN-B) to develop the core capacity of laboratory testing and to fulfill the laboratorystrengthening component of the Global Health Security Agenda. The LRN model offers an effective mechanism to detect and respond to public health emergencies of international concern.","I n recent years, considerable resources have been invested in improving laboratory systems in resourcelimited settings. Noticeable improvements in infrastructure and laboratory diagnostics can be observed in some but certainly not all of these settings. More coordination is needed to implement national laboratory plans, improve the quality of laboratory services, and expand surveillance for emerging infectious disease threats. In February 2014, the Obama Administration launched the Global Health Security Agenda (GHSA) with the aim of moving toward a world safe and secure from infectious disease threats. 1 Foundational to this agenda is the World Health Organization (WHO) Revised International Health Regulations (IHR) of 2005, which provide the legal framework for countries to strengthen their health systems in order to be able to respond to any public health emergency of international concern. The IHR goals are ''to prevent, protect against, control and provide a public health response to the international spread of disease in ways that are commensurate with and restricted to public health risks, and which avoid unnecessary interference with international traffic and trade.'' 2 The regulations call on countries to meet 8 core public health capacities, one of which is laboratory testing.

High-quality laboratory testing is an essential component in initiating a public health response to terrorism, natural disasters, and emerging threats. It allows for effective decision making to close buildings or entire geographic areas, to treat exposed people, and to deploy therapeutics. In a recent editorial coinciding with the launch of the GHSA, Secretary of State John Kerry, then-Secretary of Health and Human Services Kathleen Sebelius, and Assistant to the President for Homeland Security Lisa Monaco provided the sobering update that ''80% of the world's nations still are not prepared to deal with new pandemics.'' 3 The GHSA offers a path forward to support countries in achieving the core capacities of the IHR. This article proposes leveraging the distributed structure of the US-managed Laboratory Response Network for Biological Threats Preparedness (LRN-B) to develop the core capacity of laboratory testing and to fulfill the laboratory-strengthening component of the GHSA. The LRN model offers an effective mechanism to detect and respond to public health emergencies of international concern.

The Laboratory Response Network

The creation of the LRN stemmed from Presidential Decision Directive 39, which outlined antiterrorism policies and missions for federal departments and agencies. 4 One such mission was the ability of the US Department of Health and Human Services (HHS) to identify threat agents, conduct epidemiologic investigations, and provide public health, medical, and pharmaceutical support. To that end, in 1999, the Centers for Disease Control and Prevention (CDC), in partnership with the Federal Bureau of Investigation (FBI) and the Association of Public Health Laboratories (APHL), launched the LRN to strengthen the nation's ability to rapidly detect biological and chemical agents that could be used by violent, nonstate actors. 5 The LRN-B began with only 17 laboratories and has since expanded to approximately 160 member facilities, which include both domestic and international laboratories, and thousands of sentinel clinical laboratories, 6 which form the foundation of the system. The LRN-B is diverse and encompasses public health, military, veterinary, environmental, and food laboratories that provide reference testing for a wide array of sample types including environmental samples and clinical specimens. The network has many strategic partners, which allows for coordination among federal, state, and local public health agencies, clinical laboratories, first responders, and law enforcement. 7 The foundation of the LRN is a unified operational plan and standardization of laboratory testing, so that a test result generated from one LRN member laboratory is the same as a result generated from another network laboratory, thus providing for rapid, high-confidence results to inform public health decisions.

At the beginning stages of the LRN, the primary focus was to prepare for and respond to potential bioterrorism events. In fact, the preparation efforts of the network enabled the US to have a rapid and extensive response to the 2001 anthrax attacks. Lessons learned from this response were used by APHL and CDC to strengthen outreach to clinical laboratories and first responders and to develop tools to assist laboratories in planning for surge capacity. Over the years, the LRN mission has expanded to include response to chemical threats 8 and other public health emergencies, such as severe acute respiratory syndrome (SARS), monkeypox, influenza A virus subtype H5N1 (avian influenza), influenza A virus subtype H1N1 (2009 pandemic influenza), and, in 2014, the Middle East respiratory syndrome coronavirus (MERS-CoV), and Ebola virus. Today's vision for the LRN-B is a laboratory system for rapid, high-confidence results to inform critical public health decisions about biological threats.

The LRN-B is organized as a 3-tiered pyramid (see Figure 1 ). At the base are thousands of sentinel clinical laboratories, which perform initial screening of potential biological threat agents. When sentinel clinical laboratories cannot rule out the presence of a threat agent, they refer specimens and isolates to an LRN reference laboratory.

The LRN is a national security asset that, with its partners, will develop, maintain, and strengthen an integrated domestic and international network of laboratories to respond quickly to biological, chemical, and radiological threats and other high-priority public health emergency needs through training, rapid testing, timely notification, and secure messaging of laboratory results. More than 160 state, local, and federal facilities provide reference testing, producing high-confidence test results that are the basis for threat analysis and intervention by both public health and law enforcement authorities. State and local public health laboratories comprise approximately 70% of the 164 LRN-B member laboratories. At the apex are national laboratories, such as those at the CDC and the Department of Defense (DoD). National laboratories primarily provide specimen characterizations that pose challenges beyond the capabilities of reference laboratories, and they provide support for other LRN members during a serious outbreak or terrorist event. The most dangerous or perplexing pathogens are handled only at BSL-4 laboratories at CDC and the US Army Medical Research Institute of Infectious Diseases (USAMRIID).

The LRN-B is an excellent model of an interconnected yet distributed system that has proven its value by detecting several threats. However, perhaps the most successful aspect of this network is its role in strengthening the US public health laboratory system. With the creation of this network in 1999, US public health laboratories received federal funding to help build laboratory capability and capacity to prepare for and respond to acts of terrorism, natural disasters, and emerging threats. These primary characteristics of the LRN-B model can be used to develop the laboratory framework for the GHSA:

Strengthens existing public health and defense laboratory systems; public health laboratories use CDCprovided funds to ensure they have safe and secure facilities, procure instrumentation and associated maintenance agreements; military laboratories use the DoD resources to support their LRN activities Invests in public health workforce; federal funds support personnel at the state and local levels Provides training to ensure a highly skilled workforce Provides technical assistance such as troubleshooting scientific assays and equipment Provides standardized protocols and tests Uses molecular diagnostics Ensures coverage for human, animal, food, and environmental specimens Provides standardized electronic data messaging with laboratory results that contribute to sound public health decisions Uses a specific system for communications and provides help desk support to member laboratories Uses a restricted access website to house materials that can be accessed by member laboratories Invests in continuous quality improvements, such as conducting multicenter evaluations of assays, seeking feedback on operations from laboratories, providing scientific and policy guidance to laboratories, and collecting and sharing model practices Maintains qualified membership by using performance measures that include ongoing proficiency tests and designated timeframes for results and communications Promotes partnerships by convening member laboratories via routine conference calls and national meetings, and by engaging with subject matter experts across the federal agencies to ensure scientific integrity

In addition to detecting biological threats and emerging infectious diseases, there are 2 other core areas to support the detection of chemical and radiological threats. CDC has initiated plans to develop the LRN for Radiological Threats Preparedness (LRN-R). They are currently working on newer and more rapid methods to analyze clinical specimens for radioactive materials, a vital component of the response to an event involving human radiation exposure. Once funded, the LRN-R will be structured similarly to the LRN-C, with some laboratories having full capability to analyze radiological specimens; others will have more limited capability, and still others will have the capacity for packaging and shipping the specimens to a laboratory with higher functionality.

The LRN for Chemical Threats Preparedness (LRN-C) was established in 1999 and was composed of CDC and 4 public health laboratories, with a fifth public health laboratory joining the network in 2000. It quickly became apparent that 5 public health laboratories would not be sufficient to respond to a large-scale event. Today, there are 55 LRN-C members (CDC and 54 public health laboratories). All laboratories are qualified to package and ship clinical specimens (Level 3); 47 laboratories have the capability to test for exposure to toxic chemical threat agents (Level 2); and 11 laboratories (10 state public health laboratories and CDC) have expanded capability to test for exposure to additional threat agents, such as mustard agents, nerve agents, and other industrial chemicals (Level 1). They also have expanded capacity to provide 24/7 analytical analyses in a large-scale event.

The methods that are developed are all based on mass spectrometry and are quantitative, detecting the actual chemical agent, or more commonly, a metabolite of the agent, in urine or blood. In an overt incident, the agent will most likely be known, based on symptoms and injuries. For those with obvious symptoms or injuries, detecting exposure or the extent of exposure to the agent is probably not necessary. These methods take on importance in identifying those individuals who have been exposed but do not display symptoms or injuries immediately following the incident, and in alleviating the concerns of the majority of individuals who have not been affected but are concerned.

The initial focus of the LRN-C was to develop analysis methods for detecting exposure to chemical threat agents. Today, the methods have expanded to include a variety of different chemicals that may or may not be used overtly but pose a public health risk, including a variety of toxins and poisons ( Figure 2 ).

Both the LRN-B and LRN-C have extensive performance measures to ensure that member laboratories are meeting the requirements and demonstrating scientific integrity in their work. Further, the partnerships aspect of the LRN ensures that new technologies are evaluated in a collaborative manner and that there is a focus on continuous quality improvements. The LRN is constantly seeking feedback from its membership and uses this information to make quality improvements to all operations. In essence, the LRN brings a standardized framework for preparedness and response to public health threats that can be used to support the GHSA.

Promoting global health security as an international priority is a challenge. In its GHSA, CDC has articulated the importance of accelerating progress toward a world safe and secure from infectious disease threats. The goals are to (1) prevent and reduce the likelihood of outbreaks-natural, accidental, or intentional; (2) detect threats early to save lives; and (3) respond rapidly and effectively using multisectoral, international coordination and communication. Encompassed in these goals are 9 specific objectives to ensure a coordinated and targeted approach with partner countries.

The LRN provides a model system that can be leveraged to fulfill the detection goals of the GHSA. Following are some specific examples of how the LRN model can be used.

One of the objectives is to promote biosafety and biosecurity systems. Prior to the development of the LRN, state-operated laboratory facilities were aging, underfunded, and often lacked the BSL-3 capacity to safely handle agents that could be used as biological weapons. The public health infrastructure had deteriorated over the years due in large part to a lack of resources, the migration of laboratory workers away from laboratories and into higher-paying positions, and a decrease in the number of students pursuing careers in microbiology. In the face of these challenges, the LRN employed the existing public health infrastructure as the backbone of its network and rebuilt it through funds awarded to states by HHS's CDC Cooperative Agreement on Public Health Preparedness and Response for Bioterrorism (now called the Public Health Emergency Preparedness [PHEP] Cooperative Agreement). 9 Since the inception of the PHEP Cooperative Agreement, LRN-B public health laboratories have used the funding to build, expand, and maintain BSL-3 suites. 10 A BSL-3 suite is a contained area that must meet stringent biosafety requirements, including biosafety cabinets, controlled double-door access, and engineering controls, such as negative air pressure relative to surrounding rooms and microfiltration of air. BSL-3 agricultural facilities have additional safeguards, including decontamination of liquids prior to release into the sewage system, separate HEPA filtration of exhausted air, and pressure-impervious walls, floors, and ceilings designed to protect workers and the environment from accidental exposure to certain regulated agents. 11 Finally, BSL-3 enhanced facilities have even more safety features.

All US state public health laboratories currently have at least 1 BSL-3 laboratory with BSL-3 suites in the facility. These laboratories also comply with stringent US government regulations, such as those that govern the possession and transfer of select agents and toxins. Given their extensive experiences, LRN-B public health laboratories can serve as ''twinning'' centers to assist international laboratories with strengthening their biosafety and biosecurity systems to protect the laboratorians and the public.

Laboratory twinning initiatives are an effective and efficient way of capacity building, training, mentorship, and skill transfer. The Laboratory Twinning Initiative was launched by the WHO Lyon office, with the support of an independent steering committee, as a mechanism to support national efforts to meet IHR competencies. 12 The twinning agreements were designed to support public health laboratory services by establishing long-term mentoring partnerships between national and state public health laboratories and linking these sites. The requirements of the twinning agreements were: (1) approval of the national government as a prerequisite for a twinning project; these partnerships need to fit in with government priorities and national plans for building a functional public health laboratory system; (2) acknowledgment by the national government that the resource-limited laboratory is its national public health laboratory or a component of its public health laboratory structure; (3) the work of the laboratories participating in twinning projects must be relevant to national and regional plans for the organization Figure 2 . The LRN Structure for Responding to Chemical Threats. A designation level 1, 2, or 3 identifies laboratory capabilities and defines member network participation.

of an epidemic alert and response network; (4) the objectives and expected outcomes, evaluation process, conditions of collaboration, and roles and responsibilities of each partner must be clearly defined; and (5) where possible and appropriate, the development of commonly defined research projects is encouraged, as these often provide good opportunities to strengthen capabilities and attract donors' support.

APHL has supported 4 WHO twinning agreements. The project scopes of work varied from country to country and were carefully crafted based on the laboratory needs and interests of the participating organizations. Examples of the projects supported include: In 2009 APHL established a WHO twinning partnership specific to quality, biosafety, and biosecurity systems between the New Mexico Department of Health, Scientific Laboratory Division, and the Paraguay National Laboratory that could be replicated in other countries to support the GHSA (Figure 3 ). Despite a limited program budget, technical assistance and training exchange visits coupled with distance mentorship provided a solid mechanism for knowledge transfer and capacity building. This partnership yielded the following for the Paraguay laboratory: Development of quality assurance and biosafety manuals; Institution of a pipette calibration program; Biosafety training sessions delivered; BSL-3 facility planning and design completed; and Establishment of a quality committee at the laboratory.

In April 2014, through the support of CDC, APHL launched a twinning partnership between the New Mexico Department of Health, Scientific Laboratory Division, and a GHSA pilot country, Uganda (Uganda National Health Laboratory). This twinning agreement will center on the 6 pillars of the IHR laboratory core competencies outlined by the WHO-Afro office: Coordination of laboratory services; Laboratory capacity for the high-priority diseases; Laboratory quality management systems; Specimen collection and transportation; Biosafety and biosecurity; and Laboratory-based surveillance and public health actions. 13 The twinning model has proven a sustainable and costeffective method for technical assistance and knowledge transfer, in part because of the efficiency gained by linking entire institutions. Technical assistance visits, training, and informational tours are able to be conducted across laboratory disciplines and departments, allowing for results that can affect the accurate identification and control of infectious diseases. Leveraging the LRN model and instituting twinning agreements to support the model could significantly accelerate progress in efforts to strengthen laboratory systems. Laboratory twinning could also be considered and implemented for ''South-to-South'' collaborations, allowing for countries with similar laboratory systems to support each other and establish regional laboratory networks.

There are 4 detection objectives that are intrinsically core LRN principles.

1. Launch, strengthen, and link global networks for real-time biosurveillance. The LRN is a critical system for ongoing surveillance of threat agents. Member laboratories have detected a number of threats ranging from Bacillus Strengthening the existing LRN to be the mechanism that CDC uses to deploy assays for infectious threats such as MERS-CoV, dengue virus, and chikungunya virus will ensure an extensive standard laboratory system for real-time surveillance, detection, and response. Further, expanding the concept of the existing LRN framework and engaging other partner countries in strategic planning discussions to share lessons learned and exchange model practices could help in the development of laboratory networks across the world. Similar to the APHL and CDC partnership, in which APHL assists with the daily operations of the LRN and provides recommendations on strategic issues, 16 CDC can engage with other organizations such as the African Society for Laboratory Medicine (ASLM) to support a standard laboratory response network concept. This approach would eliminate unnecessary costs of establishing a new framework for laboratory response, use existing tools and resources, and thus increase efficiency.

Launched in Addis Ababa, Ethiopia, in March 2011, ASLM was established to advocate for laboratory medicine, laboratory professionals, and laboratory networks throughout Africa. 17 This important organization, and specifically its intent to support laboratory networks, provides a critical platform for the GHSA. The President's Emergency Plan for AIDS Relief (PEPFAR) blueprint outlines the US government's strategy for ongoing efforts to defeat the HIV/AIDS epidemic and specifically calls for groups to ''support the African Society for Laboratory Medicine, and assess whether other country or regional health systems strengthening initiatives are needed to strengthen technical capacity.'' 18 The laboratory networks supported by ASLM could provide the communication system, governance, and management support necessary to respond to a public health emergency, following the LRN model.

Strengthen the global norm of rapid, transparent reporting and sample sharing. One of the hallmarks of the LRN is rapid data exchange. LRN member laboratories must have a secure mechanism to share laboratory data on threat agents with the CDC. Currently, most laboratories use an application called LRN Results Messenger (LRN RM), which allows LRN member laboratories to instantly manage and share standard LRN-related laboratory data. LRN RM represents the first iteration in an incremental approach to providing full standards-based electronic data exchange for this vital laboratory network. However, the nature of the application requires laboratorians to enter their data into LRN RM and their Laboratory Information Management System (LIMS), a time-consuming double entry process that could take up critical time in an emergency. Over time, increased capabilities have allowed for improved methods, and the LIMS Integration (LIMSi) project is the LRN's next step in electronic data exchange. The LIMSi project addresses the delay by aiding laboratories in connecting their existing LIMS to CDC, enabling LRN member laboratories to fulfill electronic data exchange needs for the LRN using their own systems and eliminating the need for LRN RM and double data entry. To implement LIMSi, CDC is collaborating with APHL to provide public health laboratories with necessary resources. There is still much to be done with LIMSi, and thus LRN RM remains a vital platform for many laboratories to rapidly exchange data with CDC.

The area of rapid and transparent reporting will require significant coordination with domestic and international partners and perhaps will be the most challenging aspect of the GHSA. Reviewing US public health laboratories and the LRN approach to data exchange could help to shape the data exchange model of this initiative.

Additional challenges may arise with sample sharing across international borders. However, the WHO IHR (2005) recognized this issue and included language to facilitate sample processing and disposal: ''States Parties shall, subject to national law and taking into account relevant international guidelines, facilitate the transport, entry, exit, processing and disposal of biological substances and diagnostic specimens, reagents and other diagnostic materials for verification and public health response purposes under these Regulations.'' 13 3. Develop and deploy novel diagnostics and strengthen laboratory systems. The LRN has a long and rich history of collaborating with federal agencies to develop new assays; partnering with state and local public health laboratories to evaluate new assays; and working with APHL to deploy these diagnostics to member laboratories. As noted earlier, the LRN is often credited with strengthening the US public health laboratory system.

The LRN-B is a unique asset in responding to all-hazard threats, providing immediate and sustained laboratory testing and communication and performing threat agent surveillance. LRN member laboratories have an impressive MANGAL AND MARYOGO-ROBINSON track record of responding to real-time threats in a timely and efficient manner and building partnerships across all levels of government and with the private sector. During the 2009 H1N1 pandemic, the public health emergency infrastructure built as part of the LRN was key to the response. ''Dual-use'' public health emergency infrastructure built as part of the LRN was integral to the H1N1 response by ensuring the following:

Availability and use of real-time PCR capacity using ABI 7500 Fast in 43 state and 11 county public health LRN reference-level laboratories. Much of this capacity was in place due to LRN approval for purchase of real-time PCR instrumentation using CDC/PHEP Cooperative Agreement funds, followed by ABI 7500 Fast instrument upgrades supported through the CDC Influenza Division. Availability and use of automated extraction systems with many of these in place due to LRN approval for purchase with PHEP funds for LRN capacity. Availability and use of molecular testing staff in public health laboratories that were funded and trained by both the CDC/LRN and the CDC Influenza Division. Availability of appropriate biosafety facilities in public health laboratories. Use of existing CDC LRN PHEP-funded systems enabled rapid and effective communication between clinical laboratories and public health laboratories.

4. Train and deploy an effective biosurveillance workforce. APHL has an extensive history of training laboratorians, 19 including the LRN workforce, and hosting fellowship programs. An example of a successful training initiative is the Emerging Infectious Diseases (EID) Laboratory Fellowship Program, sponsored by APHL and CDC, which trains and prepares scientists for careers in public health laboratories and supports public health initiatives related to infectious disease research. The EID Advanced Laboratory Training Fellowship is a 1-year program designed for bachelor's or master's level scientists, with emphasis on the practical application of technologies, methodologies, and practices related to emerging infectious diseases. The EID Laboratory Research Fellowship is a 2-year program designed for doctoral level (PhD, MD, or DVM) scientists to conduct highpriority research in infectious diseases. The process is competitive both for fellows and host laboratories.

Human resource development is critical to strengthening laboratory systems. Currently, there is a ''lack of sufficient numbers of well-trained laboratory scientists in public health service and inadequate laboratory management and leadership skills.'' 20 Nurturing laboratory leadership and management has to be supported for the effective oversight and administration of public health laboratory networks. APHL instituted the APHL-George Washington University (GWU) Institute for Public Health Leadership and Management in 2007 to provide senior-level public health professionals with essential tools for assessing national laboratory systems and strategies for strengthening the capacities and capabilities of high-quality public health laboratories. Initially taught at the GWU campus, and more recently transferred to the University of Dar-es-Salaam, Tanzania, and the Polytechnic of Namibia, this seminar has convened leaders from all over the world for 2 weeks of intense training on such topics as organizing an effective laboratory network; program evaluation, planning, and resource allocation; performing laboratory-based disease surveillance and response; developing and managing a central laboratory database; promoting professional development and a sustainable workforce; integrating laboratory information management systems and electronic medical records; electronic reporting of laboratory test results; and strategic planning and policy development. This type of training allows for leaders to gain the tools necessary and return to their home countries to implement effective laboratory networks.

Promoting a training culture similar to the LRN and leveraging existing APHL domestic and global partnerships for laboratory leadership and management will greatly enhance the capabilities of the biosurveillance workforce.

One of the objectives here is to develop an interconnected global network of emergency operations centers and a multisectoral response to biological incidents. APHL has provided guidance to US public health laboratories to assist in the development and exercise of continuity of operations plans. 21 Encompassed in these model continuity of operations plans guidelines is information on establishing an incident command system and ensuring linkages with various local, state, and national emergency operations centers. APHL's domestic expertise in supporting and testing continuity of operations plans can translate into the global arena with the goal of ensuring timely notification and sharing of laboratory results with appropriate agencies and partners.

In the anthrax attacks of 2001 (Figure 4) , 22 people were infected, 5 people lost their lives, and the cleanup cost was more than $1 billion. US public health laboratories tested thousands of samples to rule out or confirm the presence of any possible threat agent as well to restore public confidence that postal and other facilities were not contaminated with anthrax spores. CDC estimated that 284,000 people died worldwide during the 2009 H1N1 influenza pandemic. 3 Interconnected global systems are needed to ensure the rapid detection and containment of emerging threats as well as to reassure the public that it is safe to resume their daily living activities. Thus, strengthening the capacities LEVERAGING THE LRN MODEL FOR GHSA Figure 4 . Laboratories in Action: Preparing, Detecting, and Responding to Public Health Threats and capabilities of laboratories must be a priority as the GHSA moves forward. Leveraging the highly successful LRN model allows for internal coordination with CDC to better use subject matter expertise, training models, emergency operations center procedures, data exchange, and other technical resources; continued and expanded partnerships with DoD, the Department of State, and ministries of health; and use of the vast member network including state and local public health laboratories as potential twinning and training centers. Engaging APHL and other partners in strategic discussions to determine how best to meet the overarching goals of ''prevent, detect, and respond'' will ensure that all existing resources are brought to bear in this global effort to strengthen infectious disease detection systems.

",0.7691351076051554
JAMIA Focus on Media-based Biosurveillance Model Formulation Ⅲ HealthMap: Global Infectious Disease Monitoring through Automated Classification and Visualization of Internet Media Reports,"A b s t r a c t Objective: Unstructured electronic information sources, such as news reports, are proving to be valuable inputs for public health surveillance. However, staying abreast of current disease outbreaks requires scouring a continually growing number of disparate news sources and alert services, resulting in information overload. Our objective is to address this challenge through the HealthMap.org Web application, an automated system for querying, filtering, integrating and visualizing unstructured reports on disease outbreaks.","Internet-based resources, such as online newspapers, blogs, and discussion forums, have increased in number, volume, and coverage, and show potential as useful data sources for disease surveillance and early outbreak detection-currently, nearly all major outbreaks investigated by the World Health Organization are first identified through these informal online sources. 1, 2 However, electronic sources of infectious disease news are not well organized or integrated. Reading and assimilating a broad range and large number of reports as they appear on a daily basis has already become increasingly burdensome. 3, 4 The HealthMap project has begun to address this challenge through automated querying, filtering, integration, and visualization of Web-based reports on infectious disease outbreaks, to facilitate knowledge management and early detection. 5, 8 A freely available Web site operating since September 2006, HealthMap.org integrates data from a variety of electronic sources, including news through the Google News aggregator, expert-curated accounts such as ProMED Mail, and validated official alerts such as World Health Organization announcements. Through the use of automated text processing algorithms, the system classifies alerts by location and disease and then overlays them on an interactive geographic map. It currently processes an average of 30 disease alerts per day; with the default 30-day time window, the system typically displays approximately 1,000 alerts at any particular time. The filtering and visualization features of HealthMap thus serve to bring structure to an otherwise overwhelming amount of information, enabling the user to quickly and easily see those elements pertinent to her area of interest.

HealthMap is part of a new generation of health surveillance systems that help supplement existing public health systems by focusing on event-based monitoring of infectious diseases by leveraging Internet news and other electronic media. One of the earliest systems to harness some of these resources is the Global Public Health Intelligence Network (GPHIN). 9 ,10 GPHIN has shown that extensive monitoring and analysis of news media around the world can effectively aid in early detection of emerging disease threats. Most notably, GPHIN was able to identify the 2002-2003 outbreak of Severe Acute Respiratory Syndrome (SARS) well in advance of official reporting. 10, 11 On an ongoing basis, GPHIN also provides a large fraction of initial outbreak reports directly to the WHO for investigation. 1, 2 Another successful online disease alerting service is the ProMED Mail email announcement list, with 38,000 subscribers and a panel of expert moderators. [12] [13] [14] Other systems include MedISys, 15 Argus, 16 and EpiSPIDER, 17 all of which also leverage informal electronic datasets for disease outbreak information.

While projects such as GPHIN and ProMED serve public health authorities, infectious disease Web sites that serve the general public are also gaining in popularity and helping to increase awareness of public health issues, especially for international travelers. One such site, FluWikie.com, which reports on avian influenza and other topics relating to pandemic influenza, is heavily trafficked and was cited along with similar sites by the CDC as ""critical to CDC's ability to prepare for and respond to an influenza pandemic."" 18 In addition to existing online public health resources, recent years have seen the rise of ""Web 2.0"" technologies 19 including the proliferation of Really Simple Syndication (RSS) 20 and Asynchronous JavaScript and XML (AJAX). 21, 22 These tools create new opportunities for interactive software such as HealthMap. On the backend, RSS is a first step towards the goal of a ""semantic Web,"" 23 allowing for greater possibilities in extracting structure algorithmically from a variety of disparate data sources. On the frontend, the Google Maps public API allows the Web developer to create mapping applications using a powerful and well-known user interface. Finally, rich JavaScript and asynchronous HTTP requests, the AJAX building blocks, enable us to create responsive, highly customizable Web user interfaces that begin to approach the desktop software experience.

The power of HealthMap as a disease surveillance tool lies in its potential to bring together automated processing of a broad range of Internet data sources and rich, accessible visualization tools for lay and public health users alike. In this report, we describe the software architecture and implementation, as well as challenges and future plans.

The principal objective of HealthMap is to provide access to the greatest amount of potentially useful health information across the widest range of geography and pathogens, without overwhelming the user with excess information or obscuring important and urgent elements. To accomplish this goal, the system must be able to correctly classify reports, provide flexible and useful visualization output, and be responsive under heavy usage load.

The system is only useful to the extent that it can correctly identify the primary locations, diseases and other outbreakrelated factors of a large percentage of alerts, based on words, phrases and other available contextual information for each report.

In addition to the ""correctness"" of classification, the system must also take end-user objectives into account. For example, if a single alert contains references to fifty different places, the strictly correct classification would generate markers in all fifty locations. However, this alert, likely a summary of known ongoing activity, would then overload the map view with less important information and provide little benefit to the user. Another condition where optimum classification is difficult is in the case of multiple country involvement in a single outbreak. For instance, Switzerland may send disease specialists to help combat a dengue fever outbreak in Paraguay. In this case the primary locations of the alert are Switzerland and Paraguay, but if the system presents alert classifications in such a way as to imply that an outbreak of dengue fever is occurring in Switzerland, the user will be justifiably confused. The classifier must thus be designed to integrate its output with the user display.

With respect to visualization, a key objective of the system is to maximize flexibility in two key areas: in the user interface and in the collection of the underlying data. Specifically, HealthMap is designed to organize data across different dimensions (such as date, location and disease) and allow users to customize the view according to the geographic location, disease, and type of outbreak. However, the system must balance flexibility with simplicity; in certain cases, it should impose assumptions in organizing the data, so as not to overwhelm the user with customization controls. In general, the visualization interface should be intuitive and easy to use for the novice user-who may be a novice with respect to both software interfaces and infectious disease epidemiology-as well as allow the advanced user sophisticated and flexible customization of the display.

Behind the user interface, as the system collects reports, the goal is to allow the underlying data to shape the view as much as possible. Avian influenza, for example, is currently a topic of significant public health concern and extensive media coverage. However, the system should not place a priori emphasis on any given disease; instead it should adapt its mode of display to infectious disease threats as they emerge. The next global threat may come from an unexpected source, or the focus of public health and media attention may shift.

Accordingly, while HealthMap focuses primarily on human disease surveillance, one of our design objectives is comprehensive coverage of disease activity, encompassing animal and plant diseases, as well as some insect pests and other invasive species. This disease coverage is important as many infectious diseases of public health concern are zoonotic, naturally circulating among wildlife reservoir hosts before emerging in the human population. 24 -26 Along the same lines, the system should, where possible, avoid biases towards specific geographic areas. The next Journal of the American Medical Informatics Association Volume 15 Number 2 Mar / Apr 2008 noteworthy outbreak may as easily come from a major urban center in North America as a rural village in Africa.

As the system scales to include more sources and more dimensions of classification, it must be capable of rapidly processing a large number of reports. And as the user interface is enhanced to provide more sophisticated data visualization and customization, it must be able to accommodate a large number of simultaneous users and still be responsive. This scalability is critical, as the Web site could receive a burst of traffic in the event of a broadly publicized disease outbreak.

The HealthMap system consists of five modules: the Data Acquisition Engine, Classification Engine, Database, Web Backend, and Web Frontend. As illustrated in Figure 1 , the system gathers alerts, classifies them by location and disease, stores them in a database, and then displays them to the user.

As the system loads raw data from the Web, it converts each disease outbreak report into a standard ""alert"" format, containing four fields: headline, date, description, and info text. The headline is the alert headline, date is the date of issue of the alert, and the description is a brief summary of the alert, generally the first few sentences of the article. The info text is the text that will be fed into the parsing engine for the initial classification pass. In general, this initial text consists of the alert headline, stripped of elements that may trigger a false positive. For example, with Google News, the system removes the name of the originating publication from the headline.

The standardization of the alerts, when not already available from the RSS structure, is accomplished through the use of basic assumptions about the HTML and text formatting of the input for each feed. The drawback to making these assumptions is that the data source may change its format without warning, creating unexpected results in the data acquisition and requiring rapid adaptation of the system, though this has not yet proven to be a problem.

The classification engine determines the primary locations and diseases associated with each alert. It is comprised of two modules: the Preparation Module, which takes the raw input from the source, segments it and prepares it for input to the parser, and the Parser Module, which takes text input and produces disease and location codes as output.

While many alerts contain references to multiple locations or multiple diseases, the aim of the classifier is to identify the primary locations and diseases for each alert. To this end, the input is processed in stages: if the classifier is unable to identify location and disease from the initial input provided by the feed, namely the modified headline, it can request additional text from the feed. For example, in the case of the Google News aggregator, the system examines the headline, then the description, which generally consists of the first one or two sentences of the article, followed by the article's body text, and finally, the name of the online news source. Frequently, a publication originating in one area will refer to events occurring in another area, making the publication name and location an unreliable source for the location of the alert. However, articles that don't refer to a well-known location, such as ""Suburban school closed after flu outbreak,"" generally refer to a location near the publication headquarters. By processing the input in stages, the classifier avoids the incorrect classification of the first case while capturing the true location in the second case.

The extraction component of the preparation module processes the full HTML body of the article itself. Clearly, the article text contains the best indicators as to the locations and diseases of the event in question. However, blindly feeding the full article into the parser, while increasing sensitivity, would also significantly increase the false positive rate, especially due to JavaScript code, CSS and hyperlinks mixed with the body text, any of which may contain text elements that would trigger an incorrect match. The extractor must also contend with the wide variety of HTML formats of different news sources, including potentially malformed HTML code. By means of a collection of regular expressions and cautious assumptions about the input, the system confronts some of these challenges.

The Parser Module uses a word-level N-gram approach to match input against a dictionary of known patterns (an N-gram, as applied in the HealthMap software, is an Nword text extract, generally 1 to 10 words in length). After the initial data acquisition, the parser receives the input text, strips it of non-alphanumeric characters and splits it into word tokens. It then converts all capital letters to lowercase, except for those tokens that are two characters or fewer in length. The parser then compares the input to its dictionary of place and disease patterns, mapping text patterns to the database IDs of all locations and diseases known to the system. As part of the ongoing development of HealthMap, the dictionary is updated daily to improve the accuracy of the system; at the time of this writing it consists of over 2,300 location and 1,100 disease patterns.

Because the dictionary patterns are stored in memory as a tree, where each node is a hash table that maps single tokens to either subnodes or IDs (leaves), the system can look up each input token in constant time (see Figure 2 ). Thus, the classification time is linear on the number of input tokens, i.e., the length of the input. In the case where a word may have multiple spellings, for example the American ""diarrhea"" and the British ""diarrhoea,"" we simply stock the dictionary with multiple patterns. With the addition of patterns to the dictionary, memory consumption increases, but lookup time does not increase substantively.

The disadvantage of this approach is that because the input is hashed, each token must match exactly, making it difficult to accommodate fuzzy matching, wildcards, or regular expression approaches. Further, if we change the input processing, for example, to retain more of the input data, such as capitalization and punctuation, we must update the entire pattern dictionary. A further disadvantage of the dictionary approach is that the system can only identify locations and diseases already known and stocked in the database. Moreover, a key step in enhancing the parser resolution consists of augmenting the database by capturing correct locations and disease names, often involving careful manual data entry. As national borders shift and names of places change, albeit infrequently, the system must be manually updated to reflect new geography. For example, we have already been affected by this issue, as we needed to update the parsing system to reflect the designation of Serbia and Montenegro as separate nations on June 5, 2006.

A key advantage to the pattern dictionary approach is that it is relatively easily translated to other languages: we can simply employ a different dictionary within the existing architecture. A language expert is needed to perform the initial translation, refine the pattern library, help with capitalization and punctuations subtleties, and provide other adaptations, but the basic approach can be re-applied without major changes to the system. Further, the language expert need have only very minimal technical knowledge with respect to natural language syntax or software development to contribute to the dictionary. With the help of collaborators at the Naval Medical Research Center Detachment in Peru, we have already successfully adapted the classification engine to accommodate Spanish-language input, albeit with a smaller pattern dictionary.

A key component of the location classifier is its use of relationships among geographical entities. Our goal is to identify the most specific primary location or locations for a given alert. In many cases, we are presented with input such as ""UK (England),"" or ""Boston, MA."" In these cases, each input contains two distinct patterns that are coded as separate locations in the dictionary. However, Boston is contained by Massachusetts and England is contained by the United Kingdom. In order to correctly process this type of input, after it has identified a list of locations, the classification engine executes a secondary step, eliminating apparently redundant locations based on container relationships. In the given example, the system will initially identify both Boston and Massachusetts as locations for the alert, and then eliminate Massachusetts, as it is considered to be redundant with Boston.

We also apply container relationships to disease matching, as the input can contain analogous cases. For instance, avian influenza is a type of influenza and Norwalk-like viruses cause gastroenteritis-if the system identifies both Norwalklike virus and gastroenteritis in an alert, it thus eliminates gastroenteritis as a redundant, less specific disease category.

One key difference in the case of disease taxonomy is that unlike a location, a disease can ""belong"" to more than one container disease: E. coli is more specific than food poisoning, while norovirus, cholera and E. coli can each cause diarrhea (or gastroenteritis). If no disease category can be identified from the text, we designate the alert as Not Yet Classified. Such alerts may be non-disease-related news items that have slipped through the filter, but they may be important if they indicate initial investigation of an unknown disease or a rare condition that is not yet represented in the HealthMap database.

Once the alerts are classified by location and disease, the system stores them in a MySQL database. The database is designed according to standard relational database normalization principles. The primary tables store alerts, diseases and locations, while linking tables map alerts to their respective categories as identified by the classification engine. This standardized data model allows the HealthMap software flexibility to perform a variety of queries and display different views of the data. While the database is designed primarily to support features of the Web application, the data as they are stored are readily accessible for retrospective epidemiological studies, public health risk mapping and other research applications.

The initial Web page is loaded by the user's browser from a server-side cache which is updated every hour, following the capture and classification of new alert data. If the user adjusts the viewing parameters, he will trigger an AJAX request to the server. The request indicates the current state of the page controls, and from it the server generates a database query. The database then returns the alerts that match these parameters.

From these query results, the system then tallies the number of alerts, diseases, and feeds for each day at each location. To this tally it applies an algorithm, based on an exponentially weighted average, to determine a ""heat"" rating for each location. In order to give particular emphasis to more recent alerts, through qualitative assessments, we have currently set the decay parameter ""alpha"" of the exponential weighting to 0.17. (A greater alpha value means the weighting will decay more rapidly as we progress into the past.) Locations that have a greater number of feeds and diseases associated with them are also given increased weighting. Our qualitative justification for this boost is that if multiple sources have corroborated an outbreak it deserves more emphasis, and if the same source is reporting the same disease, it deserves less emphasis.

After the computation is complete, the system normalizes the heat scores across the set of markers and assigns each marker an integer value from 0 to 10. Because it computes the Heat scores for the currently requested marker set, the user can, for example, choose a particular disease category and quickly see where the hotspots are for that disease, in addition to the default view indicating general levels of outbreak activity. Figure 3 shows the HealthMap main page, featuring a variety of information boxes and user controls. The ""Available feeds"" box ( Figure 3a ) allows the user to select which sources to display on the map by means of the checkboxes along the left-hand side. Below the feeds menu, the ""Diseases, last 30 days"" box serves both to display the currently active diseases as well as to allow the user to select which diseases to display (Figure 3b) . The ""i"" button brings up a menu with links to further information about the particular disease from the Wikipedia, WHO, CDC, PubMed, and Google Trends Web sites. In the next section, the ""Alerts by country"" box indicates the number of alerts active in each country for the currently selected parameters (Figure 3c ). Clicking on a country name zooms the map view to that country for easy viewing of alerts in that location. The ""Latest alerts"" box displays the most recent alerts in reverse chronological order (Figure 3d ). An icon next to each headline indicates the alert source.

Moving across to the map display window, the date slider at the bottom allows the user to control the date range of displayed alerts (Figure 3e ). The end date is fixed as the current date, but the user can set the start date to any point in the previous thirty days. ""Full Screen"" mode expands the map to cover the full browser window, allowing for richer display and navigation (Figure 3f ). It also allows for ""situation room"" use, allowing the user to display the map on a non-interactive screen and monitor ongoing alert activity. On the map itself, the color of a marker indicates the Heat Index value for the location, with the deeper red color indicating more intense recent activity as contrasted with the paler yellow color.

To illustrate the functioning of the system, we examine a sample report and how it is processed by the HealthMap classification engine. A local newspaper report concerning an outbreak of shigellosis at a school in Wisconsin enters the system via the Google News aggregator. The system begins by examining the article headline: 

As there are no known patterns found for either location or disease, the classifier then progresses to the article ""description,"" an extract provided by Google News: While there is an indication of the location provided in this extract, ""Fond du Lac"" is currently not included in the dictionary, and therefore not recognized. Still lacking both location and disease information, the classifier examines the article body text, as prepared by the parsing engine from the original HTML: "" We want to get the information out to parents: Here it is and here are steps you can take,"" Marian Sheridan, the Fond du Lac school health and safety coordinator said. The concern is that this infection is fast-spreading. Although the Wisconsin health department says 300 to 400 cases are reported each year, the uncomfortable abdominal cramps, fever, and diarrhea are symptoms no one wants running rampant through schools. ""I think we re getting the message out early enough, and I think that s one of the benefits of working with school districts staff to get the word out so we can contain it before it s widespread,"" Joyce Mann of the Department of Health and Family Services said. ""Parents are used to the school sending them health notices, and it s never to alarm but it s rather to inform,"" Sheridan said. ""Normally what we do is go in with a ten-percent bleach solution and everything gets wiped down-telephones, door knobs, desk chairs, desktops, the bathrooms are thoroughly gone through,"" building and As indicated in bold, the classifier now matches three different patterns in the text. The first identifies the disease category as Shigellosis; the second places the report in Wisconsin. The third match corresponds to the Diarrhea disease category, but based on the container relationships described above, the system correctly identifies Diarrhea as redundant with Shigellosis, and eliminates the former. At this point, the classifier has completed its work, and proceeds to the next report. Had it not identified both disease and location from the body text, it would have further examined the name of the publication as provided by Google News:

Upon processing of this text, it would also have identified the location based on the abbreviation WI, which is listed in the dictionary as a synonym of Wisconsin. However, in this particular case, the publication information is ignored as the classifier has already achieved matches using other components of the report.

Because the classification engine places alerts into many hundreds of different location and disease categories (currently over 700 total), as well as combinations of multiple categories of each type, it is not possible to apply traditional binary classification metrics such as precision and recall to measure its performance. However, because we curate all reports on a daily basis to correct misclassifications, we can examine various aspects of performance based on the changes performed.

At the most basic level, the accuracy of the classifier can be measured by the percentage of reports entering the system that need not have their disease or location classifications corrected in any way. At a more detailed level, we can examine the number of alerts requiring a correction of disease classification as compared with the number requiring a location correction. Table 1 provides a full breakdown of the classifier performance both by source and by disease and location. As shown, the overall accuracy of the system is 84%, thus correctly classifying 655 out of 778 reports over the one-month period from October 10 to November 9. As one might expect, performance on ProMED alerts, at 91%, is substantially better than on Google News reports (81%), as ProMED messages represent data curated specifically for disease outbreak reporting and follow a more regular structure.

There are, however, important limitations to this performance analysis. In particular, in some cases, the correction of the classification serves merely to shift between related categories, such as reclassifying Gastroenteritis as Norovirus, or UK as England. In other cases, the correction is more drastic, such as correcting Influenza to Equine Influenza, or Washington, DC to Washington State. Clearly the change is more significant in the latter cases, but we don't capture this distinction in the current analysis. As it is difficult to capture rigorously, for the moment we take the most conservative view in computing accuracy. As part of our ongoing research, we are developing more fine-grained metrics.

As HealthMap is still in the early stages of development, a number of important enhancements are either currently under development or in the planning stage. The primary design goal of HealthMap is to provide broad coverage of ongoing outbreaks without overwhelming the user. In the pursuit of improved coverage, we are exploring the use of other sources, including additional news aggregators-such as Yahoo news, Factiva, and LexisNexis-blogs, and veterinary news sources such as the World Organization for Animal Health (OIE). In pursuit of improved filtering, we are developing natural language processing techniques for additional automated data categorization, such as clustering similar reports, identifying specific outbreak pertinence, distinguishing discrete outbreaks from endemic activity, and identifying reports indicating the absence of disease or the end of a previously identified outbreak. As part of our own evaluation, as mentioned in the Formulation Process, an important goal of the system is to cover as broad a range of geography and disease as possible, without bias toward particular regions or pathogens. While the internal architecture of the system itself largely meets these goals (particularly as we add more geographical subdivisions around the world), the alert data we process and display leaves much to be improved. Because we currently rely heavily on the US edition of Google News for reports, the system is biased toward the US and Canada as well as other English-speaking countries around the world, as shown in Figure 4 . To address this problem, we have developed a Spanish-language version of the system and are currently expanding to other languages and data sources as resources permit. However, given the uneven distribution of media and reporting resources around the world, we will continue to face this issue for the foreseeable future.

In addition to adding new capability, we are also working on improving the accuracy of the existing classifier, both by expanding the pattern dictionary and by improving the preparation module. We will add more locations and diseases, including administrative divisions for countries such as Indonesia, Brazil, Sudan and Mexico as well as major cities worldwide. For diseases, we will be adding more disease categories and refining our disease taxonomy, as well as tagging diseases with category metadata to allow for improved searching. We will also explore more advanced techniques such as fuzzy matching and Bayesian machine learning for improving the resolution and accuracy of our automated classification algorithms, as well as categorizing alerts by relevancy, clustering similar alerts, and extracting other useful attributes. [27] [28] [29] On the human side, taking inspiration from the highly successful Wikipedia model, 30 we plan to work with networks of experts to evaluate community collaboration as a mechanism for alert acquisition and classification.

As we expand functionality, performance will naturally become an increasing concern. We have a few optimizations in progress, such as moving to memory-based caching, more intelligent, ""lazy"" loading of the pattern dictionary, and better optimized database queries. We are also exploring ways to better employ client-side caching without overloading the browser.

On the frontend, we have plans to improve the user experience with added features and improved customization. Examples include keyword searching, RSS output, saved preferences, endemic background disease rates, notification messaging via email, and temporal visualization. (Notably, the EpiSPIDER system has already taken steps in this area, incorporating a timeline view of ProMED reports. 17 ) We also plan to conduct a usability observation study, to gather feedback from our target demographic on priority features as well as how best to improve the HealthMap user interface.

Along with user-level evaluation, we are also working to develop more rigorous evaluation metrics for the integrated system, including its ability to cover a broad range of geography and pathogens, limit noise, detect outbreaks early, and accurately characterize alerts in each dimension of classification.

HealthMap is part of a new generation of disease surveillance systems that process unstructured and unclassified data sources. Comprehensive evaluation of these types of systems and data sources is also an important area and part of our ongoing and future research and collaboration with other disease tracking systems such as GPHIN, EpiSPIDER, MedISys, and Argus, would enable an in-depth comparison. With that said, there are a few broad comparisons we can draw between systems. One key area is accessibility: HealthMap is freely available to the public, whereas some systems are currently closed systems, requiring either paid subscription or approved access. Another key area is in the use of automation. While we certainly perform manual curation in maintaining HealthMap, our goal is to maximize automation in order to leverage the human contribution. The value of a full-time staff of language and domain experts to read and analyze reports around the clock should also be addressed as part of a broader research initiative. 6,7

The promise of HealthMap lies in its ability to extract useful, customizable messaging and views from a mass of unstructured data. While the site has already generated significant interest as a publicly available surveillance tool, many improvements remain to be made for it to be a truly useful resource for both public health professionals and the general public. In particular, adding more languages and expanding our usage of general data sources such as newspapers and blogs will increase coverage and further demonstrate the value of the visualization and filtering features. Moreover, only as time progresses, as more people use the system, and further significant outbreaks unfold in the global disease ecosystem, will we know the true potential of the software, and how best to improve it.

",0.7669271855664646
Application of next generation sequencing technology on contamination monitoring in microbiology laboratory,"The surveillance and prevention of pathogenic microbiological contamination are the most important tasks of biosafety management in the lab. There is an urgent need to establish an effective and unbiased method to evaluate and monitor such contamination. This study aims to investigate the utility of next generation sequencing (NGS) method to detect possible contamination in the microbiology laboratory. Environmental samples were taken at multiple sites at the lab including the inner site of centrifuge rotor, the bench used for molecular biological tests, the benches of biosafety cabinets used for viral culture, clinical sample pre-treatment and nucleic acids extraction, by scrubbing the sites using sterile flocked swabs. The extracted total nucleic acids were used to construct the libraries for deep sequencing according to the protocol of Ion Torrent platform. At least 1G raw data was obtained for each sample. The reads of viruses and bacteria accounted for 0.01 ± 0.02%, and 77.76 ± 12.53% of total reads respectively. The viral sequences were likely to be derived from gene amplification products, the nucleic acids contaminated in fetal bovine serum. Reads from environmental microorganisms were also identified. Our results suggested that NGS method was capable of monitoring the nucleic acids contaminations from different sources in the lab, demonstrating its promising utility in monitoring and assessing the risk of potential laboratory contamination. The risk of contamination from reagents, remnant DNA and environment should be considered in data analysis and results interpretation.","The prevention and control of contamination caused by cultured viruses, bacteria and other infectious materials are the most important part in biosafety management in the laboratory [1] [2] [3] . Microbiological contaminations in laboratories have been frequently reported in instruments [4] , rooms [5, 6] , and the operators [7, 8] . These contaminations are mainly from the performance of experiments, for example, bacteria/virus isolation and culture, gene amplification, and clinical samples preparation. As such, it is important to establish an effective and unbiased method to evaluate and monitor the risk of lab contaminations.

The potential contamination in the environment of a microbiology lab is very complicated, as usually the source and background of contaminates is unknown. However, it is hard to conduct effective contamination surveillance in a common laboratory due to the methodology limitation of contaminant detections. The isolation of microbial species is difficult because of its tedious work and poor sensitivity. Molecular tests such as PCR is sensitive, however it can only detect the gene of known pathogens. It is desired to develop a comprehensive technology which can detect the potential contaminates of unknown resources, characterized by culture-independency and high sensitivity.

The development of next-generation sequencing (NGS) technology provided a culture-independent method to obtain microorganisms genome information with high sensitivity [9, 10] , and has been widely used to detect the pathogenic microorganisms [11] [12] [13] . In this study, we evaluated the performance of NGS as a promising tool on the surveillance and risk assessment of potential lab contaminations. Frequently used microbiology laboratories which included biosafety laboratory level I (BSL-I) and II (BSL-II) were investigated in our study. Various sites were inspected in different rooms. We aimed to establish an unbiased and effective evaluating technique involving NGS to monitor the laboratory contamination.

Four rooms were investigated in the study. Room 1 is a BSL-II used for viral isolation and culture. Room 2 is a BSL-II, used for pre-treatment of respiratory samples from patients with respiratory tract infections and also used for nucleic acid extraction. Room 3 is a BSL-I, where a negative-pressure PCR hood used for nucleic acid template adding was placed. Room 4 is a BSL-I, used for molecular tests and immunological experiments. The sampling sites included the biosafety cabinet, the bench, and the inner sites of centrifuge rotor (Table 1) .

For each site, five different locations were selected, sterile flocked swabs (Copan Diagnostics, Inc., Murrieta, CA) soaked in sterile saline were used to collect samples by scrubbing repeatedly on each sampling point for 10 times. All sampling swabs from one site were rinsed into 1 ml sterile saline in one tube. The swabs were discarded after repeat pressing. Swab rinsed into 1 ml saline without sampling was used as negative control, with code number of H0. A positive control was included, which was sputum collected from a pneumonia patient infected with human coronavirus (HCoV) 229E determined previously by RT-PCR method [14] . All procedures were performed according to the biosafety regulations and requirements.

Total 400 μl of each sample was used for nucleic acids extraction by using QIAamp® viral RNA mini Kit (Qiagen, Hilden, Germany) and the elution volume was 80 μl. Since both the DNA and RNA molecules are of interest to us, no DNase was used in our protocol. All nucleic acids were used for library construction. The OD260/280 value of total nucleic acids was measured by NanoDrop Spectrophotometer (ND-1000, Thermo Fisher, Wilmington, DE, USA). The RNA was specifically quantified by Qubit® 2.0 Fluorometer (Thermo Fisher, Wilmington, DE, USA). The libraries were constructed by using Ion Total RNA-Seq Kit v2 (Thermo Fisher, Wilmington, DE, USA). Total 30-50 ng of RNA was fragmented by RNase III (Thermo Fisher, Wilmington, DE, USA), then hybridized and ligated with the Ion Adaptor Mix v2 at 65°C for 10 min, 30°C for 30 min. The reverse transcribed single-stranded cDNA was amplified with Ion 5′ and 3′ PCR Primer v2. The sequencing libraries were qualified and quantified by using Agilent 2100 Bioanalyzer (Agilent Technologies, Santa Clara, CA, USA) and Qubit® 2.0 Fluorometer.

Each sequencing library was diluted to 15 pM. Templated Ion Sphere Particles were prepared and enriched by using Ion OneTouch 200 Template Kit. Deep sequencing was performed by using Ion Personal Genome Machine™ system with Ion PGM 200 Sequencing Kit in Ion 318 Chips (Thermo Fisher, Wilmington, DE, USA). The sequencing output from each sample was no less than 1 G. The raw data reads were filtered by a minimum length of 36 bp, and the remaining reads were aligned to the NCBI nt database (Feb 2016 version) by MegaBLAST [15] (-evalue 1e-10 -max_target_seqs 10 -max_hsps 1 -qcov_hsp_perc 60). Taxonomy was assigned by MEGAN (-ms 100 -sup 1 -me 0.01 -top 10) [16] . The community composition was analyzed at both the genus and species levels. Only reads that could be mapped to specific species with high confidence were considered for genome mapping. Alpha diversity (observed genera/species and Shannon index) calculation and principal coordinate analysis (PCoA) (based on abundance weighted Jaccard distance) were performed with Qiime [17] (v1.9.1). Mann-Whitney test was performed with GraphPad prism 7.

The quality of nucleic acids measured by OD 260/280 was 1.8-2.2 for all samples. Similar quantity of RNA was yielded from H1-H9 samples (88.8-127.2 ng, median of 108.80 ng) ( Figure 1A ), which indicated similar biomass in all sampled locations. As expected, the amount of nucleic acids from H0 was ultralow (below the detection limit) and all nucleic acids were used to construct the sequencing library. After sequencing and data filtering, a range from 3,046,082 to 6,000,548 reads from H1 to H8 was used for taxonomy classification and more than 66.69% of 

This study investigated the performance of next generation sequencing (NGS) technology in monitoring laboratory microbiological contamination.

Evidence before this study Contamination is a big issue in microbiology laboratories, while it is hard to conduct effective contamination surveillance in a common laboratory due to the lack of proper methodology. The isolation of microbial species is difficult which needs tedious lab work and has low sensitivity. Although molecular tests such as PCR are sensitive, only limited number of known microbes could be detected simultaneously.

A holistic assessment of the biological background in the environment of a microbiology laboratory was conducted through NGS technology in this study. In general, the richness of viral and bacterial sequences is positively associated with the frequency of laboratory activities in the room and on the bench. The data indicated that viral reads were mainly from experimental activities, materials and environment. All types of bacteria seem to be derived from the external environment. The gene fragments from exogenous microorganisms have a great impact on the deep sequencing results, especially for the clinical samples with low microbial biomass. Application of the NGS technique on biosafety monitoring would enable us to disentangle the background noise presenting in the sequencing data, which in turn help to distinguish true contamination caused by microorganisms from false positives.

The study demonstrated that NGS could be a promising approach in monitoring the contamination from different sources in the lab, suggesting its promising usage in monitoring and assessing the risk of potential laboratory contamination.

reads from these samples could be classified. The samples from H0 (480,074 reads) and H9 (1,354,249 reads) had dramatically low amount of reads, and only 15.76% and 23.58% of reads were successfully aligned and classified to a certain taxonomic rank ( Figure 1B) . The data obtained from the positive control was consistent with the real-time PCR results. The reads of known pathogen, HCoV 229E accounted to 72.4% of all microbial reads, thus verified the reliability of NGS procedure.

As the major activities in the laboratory involved respiratory viruses, we first analyzed the viral reads in the data. The results demonstrated that viral sequences were in a relatively low abundance (0.01 ± 0.02%), with the viral reads ranged from 64 to 733 (median of 148). The number of viral species ranged from 8 to 34 (median of 12) in different samples including H0. The distribution of virus species in each sampling site was shown in Figure 2 . The samples collected from Room 4, which was used for molecular biological and immunological experiments, had the highest number of viral species (15 species). The three most abundant viruses were cercopithecine herpesvirus 5 (CeHV-5) (23% reads, observed at 7 sites), influenza A viruses (IFVA) (16%, 8 sites) and lactococcus phage 936 sensu lato (8%, 2 sites).

Due to the high sensitivity of the NGS method, viral reads that derived from routine laboratory work were identified, such as IFVA, human enterovirus 71 viruses, HCoV HKUI and NL63 (seen in Figure  S1 ). These reads were mainly from Room 2 and Room 4. Among these, reads of IFVA accounted for the highest proportion. They were detected in 6 sites except the biosafety cabinet. However, the obtained gene sequences were all close to the primer positions for viral genes amplification (Figure 3) , as PCR tests were performed on the viral positive clinical samples within a month before sampling.

The sequences of bovine diarrhea virus were only found on the biosafety cabinet in Room 1, which was used for viral isolation and culture experiments ( Figure 2 ). The existence of bovine diarrhea viral nucleic acids in fetal bovine serum (FBS) was further confirmed by PCR methods (data not shown) [18] , which may represent contamination of bovine serum used for cell culture as reported also in previous studies [18] [19] [20] [21] .

The reads of CeHV-5 were identified at all sampling sites except H2, H3 and H9. This virus was previously isolated from the tissue of rhesus macaque [22] , and had been detected in the cell line obtained from the kidney of rhesus macaque [23] . There are two rhesus macaque kidney cell lines, LLC-MK2 and Vero cells, used in the lab for virus isolation during the study period. However, we did not find CeHV-5 nucleic acids in these cultured cells by PCR. There were also viral sequences aligned to human mastadenovirus, polyomavirus, hepatitis virus, human metapneumovirus and rotavirus, but their read numbers and covered lengths were very limited, thus were likely to be false positives (Figures 2 and S1 ).

The alpha diversity of genera measured by observed genera and Shannon index did not differ significantly among H1-H9 (Figures 4A, 2B). However, when going down to the species level, H2 and H8 showed much higher diversity than other samples except for the negative control ( Figures 4C, 2D) . Besides H2 and H8, another sample collected from the operating bench, H5, also had considerable higher alpha diversity, indicating a generally high diversity of biological substances on the bench. It is noteworthy that H0 had high evenness of biological substances background, as shown by the high Shannon index at both the genus and species levels ( Figure 4B, D) , which might reflect that the contamination from reagents and/or environment is more severe for low biomass samples.

A tight clustering of H1, H2 and H3, which were all taken from the viral culture room (Room 1), was highlighted on PCoA plot that based on weighted Jaccard distance at the genus level ( Figure 4E ). This suggests a considerable impact of the physical distance/boundary on the spread of biological substances.

Of all the biomass sequences classified to the domain level, Bacteria is the most abundant in all samples (77.76 ± 12.53%), followed by fungi and all other Eukaryota, accounting for 5.89 ± 4.61% and 16.32 ± 12.21% of the classified reads, respectively. The amount of Archaea (0.01 ± 0.01%) and Viruses (0.01 ± 0.02%) is relatively low.

Zooming into the species level, the top 20 abundant ones include four species belonging to the phylum Actinobacteria of Bacteria, twelve species belonging to the phylum Proteobacteria, two species belonging to the phylum Chordata of Eukaryota, and two species belonging to the phylum Streptophyta of Eukaryota. For the Bacteria domain, Micrococcus luteus (M. luteus) is outstandingly abundant, accounting for 58.88 ± 31.72% of the reads classified to the species level. This result is reasonable because M. luteus distributes widely in soil, water, dust and air, and it is part of the normal flora of human skin, mouth, mucosae, oropharynx and upper respiratory tract [24] . The rest of most abundant bacteria includes both gram-positive (Actinobacteria) and gramnegative (Proteobacteria) bacteria, which originate from a diverse range of environments: Escherichia coli, Sphingomonas, Pseudomonas putida and Variovorax paradoxus are frequently observed in soil and water; Cutibacterium acnes is a human skin-associated organism; Moraxella catarrhalis and Acinetobacter baumannii are common opportunistic pathogens. Ralstonia had been identified as a common contaminant of DNA extraction kits or PCR reagents [25] .

For the Eukaryota domain, the abundances of human-originated reads in H1 (10.26%) and H6 (7.93%) were higher than that in other samples (below 2.15%). They were possibly derived from personnel entered the rooms for equipment maintenance at that time. Additionally, H6 had a dramatically high percentage of mouse-originated reads (12.9%) compared to that in other samples (below 0.01%). This could be associated with the isolation of mouse lymphocytes at that location. Regarding plant-originated biological substances, Gossypium hirsutum, known as upland cotton and often present in clothes, had a much higher percentage in H8 (4.89%) than in other samples (below 0.05%, Figure 4F ), suggesting a greater impact of human activity on the operating bench in the BSL-1 room. The relative abundance of Populus trichocarpa, namely California poplar, was generally higher in the BSL-1 rooms with ordinary pressure system comparing with that in the BSL-2 rooms with negative pressure system (1.01 ± 1.32% vs 0.12 ± 0.27%, p = 0.17, Mann-Whitney test, Figure 4F ). This indicates that the environmental contamination could be affected by the season, considering that the samples were taken in April, when poplar blossomed in Beijing.

NGS technology is an effective approach for laboratory management and microbe monitoring [26] . In this study, we carried out a holistic assessment of the biological background in the environment of a microbiology laboratory. In general, the diversity of viral and bacterial sequences is positively associated with the frequency of laboratory activities in the room and on the bench.

We are more concerned about the distribution of viruses in this microbiology laboratory, where respiratory viruses-related experiments were performed regularly. Firstly, all the viral reads obtained from the environment samples were compared to the positive control. It showed the HCoV-229E reads dominant in the positive control was only detected in H1 and H4 samples with less than 10 reads. The two sampling sites were biosafety cabinet bench in Room 1 and 2, used for virus culture and clinical samples treating, indicating an occasional contamination from samples or nucleic acids. No other samples showed positive on HCoV 229E, which helped to ensure us the quality control of NGS procedure in this study. There are viral reads in the negative control (H0) mapping to CeHV-5, IFVA and flock house virus, which similar to the distribution in H7, the PCR hood used for adding nucleic acids templates, indicating a residual nucleic acids contamination. Viral reads related to the experiments performed in recent one month were also identified in these environment samples. In a summary, we considered these viral sequences were mainly from three parts. (1) Experimental activities. The obtained short viral reads are mainly mapped to the terminal gene region or the PCR primers targeting regions (see Figure 3 ). No complete viral genome was identified even in samples collected from viral isolation and culture sites. Moreover, the reads of human mastadenovirus, polyomavirus, enterovirus, and human betaherpesvirus 5, were found only in samples collected from bench, centrifuge rotor (H8, H9) in BSL-I and PCR hood (H7), correlated to the experiments performed in these sites. Of note, since RNA were preferentially amplified in our protocol, DNA contamination (e.g., PCR products) level should be underestimated, thus we are presenting a lower boundary of DNA contamination. The results indicated these viral reads were mainly from the gene amplification products or residual degraded nucleic acids. As the viral reads related to the viruses used in recent one month could be detected, the residual DNA fragments could help to trace experimental activities within a month. (2) Experimental materials. For example, the fetal bovine serum was confirmed to be contaminated by the bovine viral diarrhea virus [18] [19] [20] [21] . Besides that, the reverse transcriptase which derived from murine leukemia virus [27] [28] [29] , and the recombinant protein expression system which involves the use of viral vectors are potential sources of contamination [30] [31] [32] . (3) Environment. Reads of the tobacco mosaic virus and cucumber mosaic virus were found in most of the samples except negative control and the samples collected from biosafety cabinets in BSL-II (H1 and H4). As reported, the two kinds of viruses are widely distributed in water and soil [33, 34] . The hepatitis C virus and rotavirus, not used in the lab, were found in samples from the centrifuge rotor (H6) and the bench in BSL-I with less than ten reads. Whether these viral reads were from environment or not need to be investigated further.

The largest part of biomass in our data is contributed by bacteria, of which M. luteus is the most prevalent. All types of bacteria seem to be derived from the external environment [24] . Room 4 has the most abundant microbial species, as frequent molecular biological experiments and immunology related experiments occurred in this room. A large number of microbial sequences in all centrifuge rotors were found, which emphasized the necessity of routine clean and disinfection for this equipment. The gene fragments from exogenous microorganisms have a great impact on the deep sequencing results, especially for the clinical samples with low microbial biomass, such as cerebrospinal fluid, blood, and bronchoalveolar lavage fluid [25, [35] [36] [37] [38] . Application of the NGS technique on biosafety monitoring would enable us to disentangle the background noise presenting in the sequencing data, which in turn help to distinguish true microorganisms from false positives. Meanwhile, laboratory contamination should be suspected when obtaining the complete genome sequence of cultured viruses, or abnormally enrichment of specific microbes.

NGS method was capable of monitoring the nucleic acids contaminations from different sources in the lab, demonstrating its promising utility in monitoring and assessing the risk of potential laboratory contamination. The risk of contamination from reagents, remnant DNA and environment should be considered in data analysis and results interpretation.

Supplementary data to this article can be found online at https://doi. org/10.1016/j.bsheal.2019.02.003.

",0.7614842887942681
