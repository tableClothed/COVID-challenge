title,abstract,text,similarity
Resistance to synthetic blood penetration of National Institute for Occupational Safety and Health-approved N95 filtering facepiece respirators and surgical N95 respirators,"Background: Surgical N95 filtering facepiece respirators (FFRs), certified by the National Institute for Occupational Safety and Health (NIOSH) as a respirator and cleared by the Food and Drug Administration (FDA) as a surgical mask, are often used to protect from the inhalation of infectious aerosols and from splashes/sprays of body fluids in health care facilities. A shortage of respirators can be expected during a pandemic. The availability of surgical N95 FFRs can potentially be increased by incorporating FDA clearance requirements in the NIOSH respirator approval process. Methods: Fluid resistance of NIOSH-approved N95 FFRs, and FDA-cleared surgical N95 FFRs and surgical masks was tested using the ASTM F1862 method at 450 and 635 cm/sec velocities and compared with the results from a third-party independent laboratory. Blood penetration through different layers of filter media of masks were also analyzed visually. Results: Four N95 FFR models showed no test failures at both velocities. The penetration results obtained in the NIOSH laboratory were comparable to those from the third-party independent laboratory. The number of respirator samples failing the test increased with increasing test velocity.","Surgical mask (SM) or facemask refers to the Food and Drug Administration (FDA)-cleared surgical, laser, isolation, dental, and medical procedure masks with or without a face shield. A SM covers the user's nose and mouth and provides a physical barrier to splashes/sprays of large droplets of body fluids. 1 SMs are used by health care personnel during surgical and nonsurgical procedures to protect both the patient and the health care worker from splashes/sprays of blood or other body fluids. 2 FDA clears SMs based on manufacturer-submitted test data and proposed claims. 3 Manufacturers submit the test results for particle filtration efficiency, bacterial filtration efficiency, fluid resistance, differential pressure, and flammability for FDA clearance. 3 The use of respirators certified by the National Institute for Occupational Safety and Health (NIOSH), at least as protective as a N95 filtering facepiece respirator (N95 FFR), is recommended during care of patients with diseases such as tuberculosis and measles and during aerosol-generating procedures on patients with certain infectious diseases (eg, seasonal influenza, novel influenza A, and Ebola virus disease). [4] [5] [6] [7] NIOSH tests and certifies the performance of FFRs according to requirements outlined in the US Title 42 Code of Federal Regulations (CFR) Part 84. 8 For N95 FFRs, the primary tests are filtration efficiency and airflow resistance.

The need for N95 FFRs with SM capabilities (eg, fluid resistance and flammability) was initially addressed, starting in 1996, by the FDA with the introduction of surgical N95 respirators. These are NIOSH-approved N95 FFRs that have been cleared by the FDA for fluid resistance and flammability. The surgical N95 FFRs offer the protection of both an N95 FFR and a SM. Because of these properties, surgical N95 FFRs are preferably used by health care personnel when protection from either fluids or aerosols, or both, may be needed. Currently, FDA clears only a small percentage of the total number of NIOSH-certified N95 FFR models under the Surgical N95 Respirators category. The use of surgical N95 FFRs in surgical and nonsurgical environments increases during outbreaks involving a known or suspected respiratory pathogen. For example, a scarcity of respirators during the spread of severe acute respiratory syndrome 9 and influenza 10 has been reported.

One possible option to increase the availability of surgical N95 FFRs for protection against inhalational hazards would be to expand NIOSH certification of N95 FFR models to include additional protection for fluid resistance and flammability. To better assess this option, NIOSH published a request for information in the Federal Register (Docket CDC-2014-0005) on the desirability of incorporating additional requirements and tests in the 42 CFR Part 84 respirator approval process to match the FDA clearance requirements for surgical N95 respirators. 11 NIOSH provided data in the docket showing that non-FDA cleared, NIOSH-approved respirators were routinely used in health care and that several models of these types of devices were included in the United States Strategic National Stockpile for use during public health emergencies such as a pandemic. NIOSH solicited data on the performance of non-FDA cleared, NIOSH-approved respirators for fluid resistance against splashes/sprays faced by health care workers. Comments to the docket 11 did not include data on the fluid resistance properties of non-FDA cleared N95 FFRs.

Manufacturers evaluate fluid resistance of SMs and surgical N95 FFRs according to the ASTM F1862 method. 12 This method is also being used to test the fluid resistance of respirators for research purposes. 13 The fluid resistance test is a qualitative method based on visual inspection. Resistance to synthetic blood penetration is tested at 3 different velocities; 450, 550, and 635 cm/sec, corresponding to the range of human blood pressures 80, 120, and 160 mm Hg, respectively. FDA clearance 3 of a surgical N95 FFR requires testing of 32 samples for each model. Of the 32 samples, >29 (>90.6%) must pass the ASTM F1862 fluid resistance test at any of the above 3 velocities. FDA clears surgical N95 FFRs at 3 levels of fluid resistance based on their performance at 3 different velocities. Fluid resistance at low, medium, and high levels refers to the device passing the test at 450, 550, and 635 cm/ sec velocities, respectively. The level of fluid resistance is directly related to the test velocity. 14 Some models may pass the testing only at 450 cm/sec, whereas others may also pass at 550 cm/sec or even at 635 cm/sec. The model that passes the test at the highest velocity would have higher level of resistance compared with other models that pass the test only at the lower velocities (450 and 550 cm/sec).

In this study, NIOSH-approved N95 FFRs commonly used in industrial workplaces were evaluated for fluid resistance. N95 FFRs from 6 manufacturers were tested for resistance to synthetic blood penetration using the ASTM F1862 standard method at NIOSH (Morgantown, WV) and the results were compared with those obtained from a third-party independent (TPI) laboratory (Nelson Laboratory, Salt Lake City, Utah). In parallel, resistance testing was done for 3 FDA-cleared surgical N95 FFR and 2 SM category devices. The pass/fail results of N95 FFRs, surgical N95 FFRs, and SMs at 450 and 635 cm/sec velocities were evaluated. The consistency of the test method was assessed by comparing the results obtained from NIOSH laboratory with the results from the TPI laboratory. The results, limitations of the test method, and future needs are discussed.

Six N95 FFR models, 3 surgical N95 FFR models, and 2 SM models were selected for this study. Two surgical N95 models were chosen for their identical physical appearance with 2 non-FDA cleared N95 models, whereas others were selected randomly from leading manufacturers (based upon market share) and from those in the Strategic National Stockpile. The manufacturers and devices are: 

A synthetic blood penetration test apparatus (Blood Spurt Tester, model SDL, Atlas LLC, Rock Hill, SC), similar to the 1 described in the ASTM standard, 12 was used in our study. The test apparatus consists of a specimen-holding fixture, a targeting plate, a pressurized fluid reservoir, a pneumatically actuated valve with an interchangeable canula (18-gauge stainless steel with an internal diameter of 0.084 cm), and a valve controller. The canula size was suitable to test synthetic blood penetration at arterial blood pressures ranging from 80-120 mm Hg corresponding to 450-635 cm/sec velocities. The specimen holder and the supporting frame of the fixture were rigid to resist the impact of the bloodspraying process. The height of the specimen holder was 420 mm, corresponding to the height of the synthetic blood reservoir. A targeting plate with a 0.5-cm hole was placed 1 cm in front of the mask to ensure that the synthetic blood hit the target area of the mask. The actuated valve was attached to a stable metal stand to withstand any flex during activation by the pneumatic control. The valve was positioned according to the ASTM F1862 method so that the exit of the canula was 30.5 cm from the point of impact on the specimen mask.

The fluid reservoir was filled with approximately 1 L fresh synthetic blood (Johnson, Moen & Co Inc, Rochester, Minn) and a canula was installed on the front of the pneumatically controlled valve. The canula used in the method is a 1.27-cm (0.5-in) long 18gauge stainless needle with an internal diameter of 0.084 cm (0.033 in). The synthetic blood penetration test was performed only at velocities of 450 and 635 cm/sec, corresponding to blood pressures of 80 and 160 mm Hg, respectively. The reservoir pressure was adjusted to approximately 8 psi or 12 psi to achieve a velocity of 450 cm/sec or 635 cm/sec, respectively. The test apparatus was calibrated for each target velocity by delivering the synthetic blood for a 1-second difference in spurt duration. The weight of synthetic blood delivered for a 0.5 second and a 1.5 second spurt were collected in separate small beakers. The 2 weights of the samples were recorded and the difference between the 2 weights was calculated. According to ASTM F1862, the target difference in weight plus lower and upper limits for a velocity range should be within 2% of the target. The target difference in weights for the test at the target velocities of 450 and 635 cm/sec were 2.506 g and 3.537 g, respectively. In this study, the acceptable weight range was between 2.456 g and 2.556 g for the 450 cm/sec velocity and was between 3.466 g and 3.607 g for the 635 cm/sec velocity, which were within the specified ranges.

During testing, 2.0 mL (2.0 g) synthetic blood was directed to the test sample for durations of 0.825 seconds and 0.550 seconds corresponding to target velocities of 450 cm/sec and 635 cm/sec, respectively. After every 15 samples, a check was performed to ensure that the test apparatus was still delivering 2.0 g synthetic blood by collecting and weighing the output passing through the targeting hole. When the blood sample delivered showed a shift of >0.10 g, all prior data since the last calibration were discarded. The canula was also cleaned after testing 15 samples.

Before use, test samples were conditioned in an environmental chamber (Caron Environmental Chamber, model 6001-1, Marietta, Ohio) for 4-6 hours at a temperature of 21 C AE 5 C and 85% AE 5% relative humidity, to simulate the temperature and humidity conditions of the mask on a wearer. Each test sample was removed from the environmental chamber and was mounted on the testing apparatus, centered, and 2-mL synthetic blood was dispersed at the target velocity within a minute. The synthetic blood penetration through the sample was assessed visually. A control mask for each model for all category devices was used for comparison. A drop of the blood was placed on the inner side of the control mask and compared with the color on the inner side of the test sample.

The fluid resistance pass/fail data for each test velocity at the NIOSH laboratory and TPI laboratory were combined for statistical analysis. The data at the 2 different test velocities and the 2 laboratories were compared by Wilcoxon signed-rank test matched pairs using SPSS software (version 20, IBM-SPSS Inc, Armonk, NY). The synthetic blood penetration results obtained at the NIOSH laboratory were compared with the results obtained by the TPI laboratory ( Table 2) . The number of samples tested at each velocity at the NIOSH laboratory varied from 10-15 for each model, whereas, only 10 samples per model were tested at TPI laboratory. Despite the difference in the number of samples tested at the 2 laboratories, the penetration results obtained at NIOSH were comparable to those from the TPI laboratory. For example, the same 4 N95 FFR models (ie, B, C, E, and F) that showed no penetration at the NIOSH laboratory also had no penetration at TPI laboratory. Model A showed penetration for some samples at the 2 test velocities in both laboratories. Similarly, some samples of model D showed penetration at 635 cm/sec at both testing laboratories. No penetration was obtained for 1 surgical N95 FFR model (ie, H) at both 450 and 635 cm/sec in both testing laboratories. In the case of SMs, 1 model showed penetration at both velocities at the NIOSH laboratory, but, no penetration at TPI laboratory. The other model had penetration only at 635 cm/sec at the NIOSH laboratory, but at both velocities at the TPI laboratory. Overall, 11 of 22 test results were the same between the 2 laboratories. Although the NIOSH laboratory found more samples (ie, 7) with higher failure rates than the TPI laboratory (ie, 4), the difference was not statistically significant (P ¼ .327).

For FDA clearance, synthetic blood penetration for 32 samples of each device is evaluated using the ASTM F1862 standard test method to achieve an acceptable quality limit of 4% as defined in the American National Standards Institute/American Society of Quality Control 15 standard. An acceptable quality limit of 4% includes minor deviations from the standard, such as the acceptance of synthetic blood penetration for <3 samples (<9.4%). To pass the test, <3 samples can show penetration at 450 cm/sec (the lowest of the 3 test velocities) at a minimum. A device that passes the test only at 450 cm/sec indicates its lower fluid resistance level. A very high fluid resistant device passes the penetration test at all 3 velocities. Table 3 shows the blood penetration results for the total number of samples for all models tested in the study. The results for the NIOSH and TPI laboratory samples were combined, because only a limited number of samples were tested at each laboratory. Moreover, a similar trend in penetration was obtained between the 2 laboratories. Samples from 4 out of 6 models of NIOSH-approved N95 FFRs showed no penetration. Of the other 2 N95 FFR models, model A had penetration for 2 of 24 samples at 450 cm/sec and 7 of 25 samples at 635 cm/sec, indicating that model A may pass the resistance test at 450 cm/sec, but not at 635 cm/sec. Model D showed penetration for several samples at the lower velocity at 1 of the laboratories (see Table 2 ), but not at the other. Because of the contradictory results obtained at the lowest velocity, whether model D will meet the fluid resistance requirement is uncertain. Three surgical N95 FFR models were tested in the study, of which only model H had no failures at either velocity. All samples of model G passed the test at 450 cm/sec, whereas model I had 1 sample that failed the test at 450 cm/sec. Two SM models were tested and only 1 of 20 samples of both models failed at the lowest velocity. For this initial study, we did not test the full recommended sample size of 32, so it is not possible to say with 100% certainty whether the N95 FFR models with <3 failures would meet the FDA clearance requirements or not. However, because four of the models had no failures even at the highest velocity for the first 20-25 samples, it would seem likely that they would pass if testing had continued to the recommended sample size. Surgical N95 FFR models H and I were specifically included in this study because they appear to be identical to 2 non-FDA cleared N95 FFRs models (ie, C and E). Models C and I are both flat-folding respirators from the same manufacturer and visually appear to be identical except for color (1 is orange and the other is white). Similarly, E and H are identical in appearance, except for the labeling and packaging. As shown in Table 3 , both pairs exhibited similar fluid resistance properties.

Overall, the results showed an increase in synthetic blood penetration with increasing test velocity (Fig 1) , similar to other studies. 16 For comparison between the 2 velocities, the pass/fail data obtained in the 2 test laboratories were combined.

The number of samples of the 3 categories of masks that showed penetration increased with increasing velocity from 450-635 cm/sec. N95 FFR, surgical N95, and SM masks showed penetration for 7, 1, and 2 samples at 450 cm/sec, which increased to 16, 4, and 8 samples at 635 cm/sec. The percentage of samples that showed penetration was significantly (P ¼ .043) higher at 635 cm/sec than at 450 cm/sec. Penetration for large numbers of samples at higher velocity can be expected because an increase in the test velocity is likely to increase the permeability of the masks for fluids, including synthetic blood. Other factors include the configuration of the different types of filter media used in the multilayer construction of the mask. In general, the hydrophobic filter media-containing models are less likely to show penetration because of their ability to retard the penetration of a hydrophilic challenging test agent. The presence of a hydrophobic filter media on the outer surface may provide a barrier to the entry of hydrophilic water-based synthetic blood. 17 The lack of penetration of the devices may be maintained when the outer surface is hydrophobic and dry. Penetration can be expected when the outer layer is wet.

To gain more information on synthetic blood resistance of the mask, penetration through the different layers of the masks were analyzed visually. All of the models block the initial spray, but differences were found in how the synthetic blood moved through the layers of the device. Figure 2 shows the blood penetration through different layers of respirator models. A representative N95 FFR sample of model C, 1 of the 4 N95 models that passed the resistance testing, was analyzed for blood penetration through the different layers. Blood color was seen on the outer and inner sides of the outer layer (model C, 1a and 1b, respectively) and middle layer (model C, 2c and 2d, respectively). There was no red color on the outer or inner side (model C, 3e and 3f, respectively) of the innermost layer of the mask demonstrating no blood penetration. Two N95 FFR models (A and D) failed the test as shown by the blood color on the inner side of the masks. Model A had 3 layers of filter media. The outer and inner side (model A, 1a and 1b) of the outermost layer showed a wide area of the synthetic blood color. The middle layer had a relatively smaller area with color on the outer surface (model A, 2c), which diminished on the inner side (model A, 2d), indicating very little blood penetration. Surprisingly, a larger area of blood color was seen on the outer surface of the innermost layer (model A, 3e and 3f), which increased along the crease line on the inner side (model A, 3f) exposed to the face. The result was consistent between the different samples of the same model. The results are supported by the design of the respirator with different layers of filter media. The outer layer was thin and hydrophobic and blood was able to penetrate at the velocities tested in the study. The dense middle hydrophobic layer can be separated into 2 layers, but is considered as a single layer for simplicity. Although the hydrophobic middle layer appears to decrease blood penetration dramatically as shown by the reduction in the area of blood color, it actually allowed the blood to pass through it. This can be seen by the appearance of a wide area of blood color on the innermost hydrophilic layer, because of its affinity toward the water-based synthetic blood. In the case of model A  24  22  2  92  25  18  7  72  N95 FFR  B  25  25  0  100  25  25  0  100  N95 FFR  C  25  25  0  100  25  25  0  100  N95 FFR  D  25  20  5  80  25  16  9  64  N95 FFR  E  20  20  0  100  20  20  0  100  N95 FFR  F  20  20  0  100  20  20  0  100  Surgical N95 FFR  G  24  24  0  100  25  23  2 Test Velocity (cm/sec) D, there was an outer shell and 2 hydrophobic layers with a second shell layer in between (Fig 2, bottom panel) . The 2 hydrophobic layers were not sufficient to prevent blood penetration at the test velocities. The results indicate that the numbers of hydrophilic and hydrophobic filter media, packing density of the layers, and the arrangement of the layers on the outer or inner side of the mask may influence blood penetration. The penetration of synthetic blood through hydrophobic filter media layers raises a question on the interpretation of the test method. In the case of model A, the inner side of the middle hydrophobic layer showed only traces of blood color. However, blood penetration through the middle layer could be seen by the wide area of color on the outer and inner sides of the innermost hydrophilic layer. This indicates that the innermost layer should be made of a hydrophilic material to reveal penetration of synthetic blood. In the absence of a hydrophilic layer, the device may still allow blood penetration, but it may not be easily identified by the test method. The results indicate the need for the development of a more accurate test method that can identify blood penetration on the inner side of the mask with either a hydrophilic or hydrophobic layer.

The synthetic blood penetration test addresses the potential for infectious biologic fluids reaching/touching the human face in a surgical environment. There are scenarios in which splashes/sprays occur outside of surgical procedures. For example, significant volumes of respiratory secretions from infected individuals are released at high velocity in the form of a sneeze or cough, which can spray or splash on a nearby individual wearing an SM or FFR. The possibility that some devices may allow the penetration of biologic fluids exists because of the wide variation in their construction. The design of many surgical N95 FFRs and N95 FFRs prevents the inner surface of the respirators from touching a user's face. On the other hand, some models with a flat-fold type respirator may touch the facial skin during breathing, indicating that nasal secretions can diffuse through the mask under high humidity conditions of the mask. One study tested human subjects wearing SMs to evaluate the physiologic, thermal, and subjective influence of an SM on the wearer. 18 Those authors 18 reported that 11% of subjects complained about the SM sticking to the face during inhalation. Further studies are needed to understand the diffusion of biologic fluids through filter media in SMs, surgical N95 respirators, and FFRs.

The results for synthetic blood penetration tests obtained in our study may have implications for respirator use in the health care environment. FDA clears only a small percentage of NIOSHapproved N95 FFRs as surgical N95 respirators. The extensive use of surgical N95 FFRs in surgical and nonsurgical health care practices results in shortages during emergencies and pandemic events involving a respiratory pathogen. To address this issue, NIOSH could incorporate additional test requirements in 42 CFR Part 84 respirator approval process to parallel the protections in the FDA clearance of surgical N95 respirators. Current FDA clearance procedures 3 accept NIOSH respirator certification in lieu of filter efficiency performance and differential pressure. In theory, similar arrangements for streamlined approvals could be made if NIOSH began evaluating fluid resistance as part of its certification process. Our study showed 4 out of 6 N95 FFR models approved by NIOSH but not cleared by FDA likely also meet the fluid resistance requirement for surgical N95 FFR clearance. Even the 2 N95 FFR models that demonstrated lesser fluid resistance ability still had pass rates of 80% and 92% at the lowest velocity, insufficient to meet requirements of the standard, but suggestive of ability to provide some level of fluid resistance. A detailed analysis of the pros and cons of NIOSH incorporating fluid resistance requirements into 42 CFR Part 84 respirator approval and its influence on infection control policies and respirator shortages is outside of the scope of this article, but is needed.

The ability of all of the N95 FFRs tested to pass 80% or greater at the lowest velocity also presents an opportunity to scrutinize the need for this specific test in determining suitability of respirators for use in medical environments. For situations with increased respirator use like a pandemic, the need for protection against projectile blood at 435 cm/sec may be less common than the need for protection against lower-velocity splashes/sprays from coughing, sneezing, and talking. Additional studies are needed to determine whether non-FDA cleared N95 FFRs would be sufficient for these types of situations, but the preliminary data here are promising.

Limitations of this study include that only 6 non-FDA cleared NIOSH-approved N95 FFR models were tested for synthetic blood penetration. Additional models need to be tested to provide conclusive information on whether most N95 FFR models would meet existing FDA requirements for penetration resistance of synthetic blood. The ASTM F1862 standard test method requires 32 samples per model to obtain an acceptable quality limit of 4%. This means that 29 or more samples should pass the test. In our study, only 10-15 samples per model in each laboratory were tested for synthetic blood penetration. Future studies should use the 32 samples per model described in the ASTM F1862 standard test method. Other limitations include the subjective nature of the blood penetration test as well as the variation in the test results obtained by different test performers in the same laboratory as well as between laboratories.

Nevertheless, the synthetic blood penetration results obtained in the study indicate that many NIOSH-approved N95 FFRs may meet the FDA clearance requirement for synthetic blood penetration. Although many models would likely pass the synthetic blood penetration criterion, whether they would pass the flammability tests for FDA clearance remains to be evaluated. Studies on the blood penetration for longer times may provide information on any change in the penetration pattern, when the exposed mask is worn for a protracted period.

Four out of 6 NIOSH-approved N95 FFR models that were not cleared by FDA that were tested in our study showed resistance to synthetic blood penetration at 450 and 635 cm/sec velocities. Similar results were obtained from a TPI laboratory. The combined results for resistance to blood penetration from the 2 laboratories indicate that these models may pass the FDA clearance process provided they also pass the flammability requirement. As expected, the numbers of respirator samples that failed the test increased with increasing test velocity. Respirator design, using different numbers of both hydrophilic and hydrophobic filter media layers at different packing densities, may influence resistance to blood penetration.

",0.8025469164349966
The efficacy of medical masks and respirators against respiratory infection in healthcare workers,We aimed to examine the efficacy of medical masks and respirators in protecting against respiratory infections using pooled data from two homogenous randomised control clinical trials (RCTs).,"There is currently a lack of consensus around the efficacy of medical masks and respirators for healthcare workers (HCWs) against influenza, with only five published randomised control trials (RCTs) in HCWs conducted to date. [1] [2] [3] [4] [5] While N95 respirators have been shown to be superior to medical masks in preventing clinical respiratory infection (CRI), influenza illness (ILI) and other outcomes, none of the studies were adequately powered to examine laboratory-confirmed influenza.

In the smallest of the trials, involving only 32 HCWs, there was no difference in the rates of respiratory illnesses between HCWs who used medical masks and the control group. 1 A Canadian study of 422 hospital nurses compared targeted use of N95 respirators and medical masks and found that the rate of serologically defined influenza was 25% in both arms. 2 However, in the absence of a control arm for comparison, the finding of no difference in outcomes between the intervention arms could represent either equal efficacy or equal inefficacy of the two interventions. The other two published HCW RCTs used a more specific and less sensitive definition of influenza based on nucleic acid testing (NAT) of respiratory specimens in symptomatic subjects.

As such, even these substantially larger RCTs were unable to demonstrate any significant difference in influenza infection between N95 respirators and medical masks. 3, 4 Finally, a recent study examined the efficacy of cloth masks compared to medical mask and control groups, and found that cloth masks may increase the risk of infection in HCWs. 5 Guidelines for respiratory protection have been driven by presumed transmission mode alone, and under an assumption that influenza and other pathogens are spread by one mode alone. 6 However, the paradigm of unimodal droplet or airborne spread is based on outmoded experiments from the 1940s, which concluded that only large droplets are found at close proximity to the patient, while small droplet nuclei and airborne particles are found at a longer distance. [7] [8] [9] It has since been shown that both small and large particles can exist at short distances from the patient, and that aerosolised transmission can occur at close proximity. 9 In our two published RCTs conducted in China, 3,4 we used the same outcomes, case definitions and measurement tools, and used the same testing methods for a range of different pathogens transmitted by different routes. This afforded an opportunity to pool the data from both trials for improved statistical power to examine the outcomes by pathogens and mode of transmission. The aim of this pooled analysis was to examine the efficacy of medical masks and respirators in HCWs against respiratory infection.

We pooled the results of our two RCTs on mask and respirator use in hospital HCWs in Beijing, China. The first RCT (Trial 1) was conducted from December 2008 to January 2009, 3 

HCWs randomised to: medical mask arm (n = 492), N95 fit-tested arm (n = 461) and N95 non-fit-tested arm (n = 488). The rate of fit-test failure was very low (5/461) in this trial, so data from both N95 arms were combined for analysis.

An additional 481 healthcare workers from nine hospitals were recruited to a control arm. These hospitals were purposefully selected as they indicated low levels of routine mask/respirator use during a pretrial assessment. Participants in the control arms continued their usual mask wearing practices and were followed using the same protocol as applied to the other arms. 3 The second trial (Trial 2) was conducted from 28 December 2009 to 7 February 2010, using the same design. 4 In Trial 2, participants were randomised to three arms: medical masks at all times on shift (n = 572), continuous N95 respirators at all times on shift (n = 516) and targeted/intermittent use of N95 respirators only while doing high-risk procedures or barrier nursing of a patient with known respiratory illness (n = 521). Fit testing was not performed in the second RCT. In both trials, participants were followed for 4 weeks of wearing the medical masks or respirators, and an extra week of non-wearing of masks for the development of symptoms. Demographic and clinical data were collected, including gender, age, smoking, vaccination status, pre-existing medical illnesses, hand hygiene and high-risk procedures. Pharyngeal swabs were collected from symptomatic participants, and samples were tested at the laboratories of the Beijing Centers for Disease Control and Prevention. There was no major difference in the products used in both clinical trials. In the first trial, we used medical masks (3M, catalogue number 1820) and N95 fit/ non-fit-tested respirator (3M, catalogue number 9132). The following products were used in the second trial: medical masks (3M, catalogue number 1817) and respirator (3M, catalogue number 1860).

The interventions compared in the pooled analysis were as follows: (i) continuous use of N95 respirators (pooled data from both trials -1530 subjects); (ii) targeted N95 respirator use (data from trial 2-516 subjects); (iii) continuous use of medical masks (pooled data from both trials -1064 subjects) and (iv) and a control group (data from trial 1-481 subjects).

Only laboratory-confirmed outcomes were included in the analysis, which were defined and measured identically in both trials, and The laboratory testing has previously been described. 3, 4 Laboratory-confirmed bacteria and viruses identified in participants were categorised according to droplet (n = 285), contact (n = 6) and airborne (n = 3) transmission modes (Table S1A) . Sixty-one coinfection cases with multitransmission were categorised separately. (Table S1A) . As the largest number of confirmed infections was in the droplet category, we conducted a subgroup analysis of droplet-transmitted infections. Given there were a large number of RSV cases (n = 33) in our data set and RSV is variously categorised as | 513

either ""droplet"" 11 or ""contact"" spread 12 in different guidelines, we performed a sensitivity analysis by including RSV into the droplet transmission category instead of contact.

Ethics approvals of two clinical trials were obtained from the Institutional Review Board and Human Research Ethics Committee of the Beijing Center for Disease Prevention and Control.

We did not involve patients and their families in the design and conduct of the study. We have acknowledged the support of participants, and the results will be published in open access journal.

The data sets from the two trials were pooled incorporating the common variables. We calculated the attack rate (proportion of outcome) of each of the four outcomes by the study arms.

We conducted a fixed effect individual patient data (IPD) metaanalysis by fitting a multivariable log binomial model, using generalised estimating equation (GEE) to account for clustering by hospital/ward. We used a fitted fixed effect model because there are only two trials.

Two studies were conducted in the same setting with similar participant characteristics, and they examined the same underlying effect.

In the analysis, relative risk (RR) was estimated using the control arm as the referent category after adjusting for potential confounders and their interaction terms with a trial ID number. The overall rates of seasonal infection were higher in the second trial than the first. The consistency assumption (ie between study homogeneity) for the IPD meta-analysis was tested by fitting an interaction term between trial ID and trial arms where a significant interaction is indicative of inconsistency. 13 Any interaction term (between trial ID and covariates other than trial arm) that was not a confounder was subsequently excluded from the model using backward elimination approach. This approach is described in detailed elsewhere. 4 We repeated the above-described methods for each of the outcomes.

After combining the data sets from the two trials, 3591 cases were In the IPD meta-analysis, none of the interaction terms between trial arm and trial ID was significant for any of the outcome variables.

Thus, the consistency assumption for the IPD meta-analysis was satisfied. However, a significant interaction was observed between trial ID and hand washing for laboratory-confirmed bacterial colonisation only; therefore, we estimated the RR for trial ID stratified by hand washing. In the similar analysis, the risk of influenza was also lower in medical mask arm compared to control; however, the difference was not statistically significant (RR 0.81 and 95% CI 0.25-2.68) arm. Table 5 compares the results of this analysis with the individual studies.

We demonstrated superior clinical efficacy of continuous use of N95 respirator (also known as ""airborne precautions"") against infections presumed to be spread by the droplet mode, including influenza. This suggests that transmission is more complex than assumed by traditional classifications, and supports the fact that both large and small droplets are present close to the patient, and that aerosol transmission may occur for presumed ""droplet"" infections. Respirators are designed to provide respiratory protection through filtration and fit, and properly fitted respirators provide better protection compared to medical masks. 3, 4 We could not demonstrate efficacy of medical masks against any outcome, but the non-significant trend appeared to be towards protection. Medical masks may well have efficacy, 5 but if so, the degree of efficacy was too small to detect in this study, and larger studies are needed, given the widespread use of these devices in health care. a diagnosis of influenza requires the detection of virus from respiratory specimens, or a fourfold rise in serological titres, both of which are highly resource-intensive and depend on daily subject follow-up and on optimal timing of specimen collection. For all these reasons, the published studies to date have been unable to determine whether there is a difference in efficacy against influenza infection between medical masks and N95 respirators. This study can therefore usefully inform policies for prevention of influenza.

In the first RCT, compared to medical masks, N95 respirators were found to be protective against CRI, but not against ILI or laboratoryconfirmed influenza. 3 When compared with the control arm, rates of laboratory-confirmed virus and bacterial colonisation were significantly lower in N95 arm (Table 5 ). In the second RCT, continuous use of N95 respirators was associated with lower rates of CRI and laboratory-confirmed bacterial colonisation compared to the medical mask use. 4 Pooled analysis of these studies improved the power to analyse other infectious outcomes by intervention and to allow analysis by mode of transmission.

An important finding of this analysis was the efficacy of N95 respirators against droplet-transmitted infections. Generally, medical masks are considered sufficient for droplet-transmitted infections such as influenza. 18 However, this study has demonstrated a clear benefit of using N95 respirators (both continuous and targeted) to protect HCWs against droplet infections and does not show significant protection of medical masks. In the light of these findings, it may be prudent to use respirators when the transmission mode of a disease is unknown or when HCWs exposed to droplet-transmitted infections with a high-case fatality rate. 6 This study has some limitations. Firstly, the reporting of the results included in Figure 1 is different from the IPD meta-analysis results. This is due to the uneven distribution of randomisation arms and differing seasonal attack rates between the trials. In Figure 1 , these between-trial differences were not taken into account. The IPD meta-analysis takes into account of these and gives an unbiased association. Secondly, the control arm in trial 1 was not randomised; however, the risk of bias is less due to similar study setting, outcome measures and participant characteristics. Moreover, whether infection was acquired in the community or the hospital cannot be determined, but the RCT design should result in community exposure being distributed equally across all arms. Finally, we categorised pathogens according to various transmission modes, while certain viruses are transmitted via multiple routes. The pooled data were suggestive of an effect of respirators against influenza, but probably did not have enough statistical power for this outcome. The major strength of this study is the use of the same endpoints, measurements and methods in the two trials, which allowed valid pooling of the data.

It is a long-held belief in hospital infection control that a mask is adequate for droplet-transmitted infections. We showed that the use of respirators provides better protection against respiratory infections, even those presumed to be spread predominantly by the droplet mode. The targeted use of a respirator was also effective, whereas no efficacy was demonstrated for medical masks alone.

However, the trends suggest some degree of protection from medi- 3. For many infections, more than one mode of transmission is possible, and our data suggest that transmission of infections is more complex than suggested by these paradigms.

Clinical efficacy data are a higher level of evidence than theoretical paradigms of transmission, and show better protection afforded by respirators.

",0.7991656720014243
Cost-effectiveness analysis of N95 respirators and medical masks to protect healthcare workers in China from respiratory infections,"Background: There are substantial differences between the costs of medical masks and N95 respirators. Costeffectiveness analysis is required to assist decision-makers evaluating alternative healthcare worker (HCW) mask/ respirator strategies. This study aims to compare the cost-effectiveness of N95 respirators and medical masks for protecting HCWs in Beijing, China. Methods: We developed a cost-effectiveness analysis model utilising efficacy and resource use data from two cluster randomised clinical trials assessing various mask/respirator strategies conducted in HCWs in Level 2 and 3 Beijing hospitals for the 2008-09 and 2009-10 influenza seasons. The main outcome measure was the incremental cost-effectiveness ratio (ICER) per clinical respiratory illness (CRI) case prevented. We used a societal perspective which included intervention costs, the healthcare costs of CRI in HCWs and absenteeism costs.","Healthcare workers (HCWs) are at increased risk of contracting influenza and other respiratory infections compared to the rest of the adult working population [1] . The use of respirators and masks to reduce transmission of these infections within hospitals can decrease the costs associated with HCW absenteeism and the costs of nosocomial infections in vulnerable patients. Mask/respirator availability can also be crucial in the context of emerging respiratory infection threats to

HCWs where effective pharmaceutical interventions may not be available, e.g. the 2003 severe acute respiratory syndrome (SARS) epidemic and the Middle East Respiratory Syndrome (MERS) outbreaks since 2012 [2, 3] .

Medical masks, referred to as surgical masks in some countries [4] , were not designed to protect the wearer from aerosol transmission of droplet nuclei and viral particles [5, 6] . Respirators are specially engineered for this purpose [7] . The N95 respirator models have been tested and proven to have at least 95% particle filter efficiency [8] . The World Health Organization (WHO) and the U.S. Centres for Disease Control and Prevention (CDC) recommend the use of a mask in low-risk settings and a respirator in high-risk settings (e.g. during aerosol generating procedures) to protect healthcare workers (HCWs) from seasonal influenza [9, 10] . In the context of influenza A(H1N1)pdm09, the WHO recommended similar precautions to those advised for seasonal influenza while the CDC recommended at least the equivalent of a fit tested N95 respirator for HCWs in contact with pandemic influenza patients, even when aerosol-generating procedures were not being conducted [11, 12] .

There are substantial differences between the costs of respirators and masks that may affect the development of country specific mask/respirator guidelines for HCWs [4] . Another potentially important consideration is fit testing, which adds to the cost of respirator use, but may help ensure the seal of a respirator to a HCW's face [7] . A recent review identified the lack of economic evaluations that used clinical efficacy estimates to assess the cost-effectiveness of mask/respirator use in healthcare settings [13] . The aim of this present study is to compare the cost-effectiveness of respirator and mask interventions in HCWs using data from two large clinical trials conducted in Beijing hospitals [14, 15] .

The two previously published cluster randomised trials used in this economic evaluation [14, 15] were designed to measure the efficacy of N95 respirators and medical masks to protect HCWs from respiratory infections in Beijing hospitals. In these trial designs, the units of randomisation were entire emergency departments or respiratory wards from Level 2 and 3 hospitals, assigned to each intervention. The participants were the HCWs working in each of the enrolled wards, i.e., all nurses, doctors and administration staff. These wards were selected as they were considered to be high-risk settings for occupational exposure to respiratory infections. The intervention period in the first trial (Trial 1) was during the winter of 2008/09, from December 2008 to January 2009 [14] . The second trial (Trial 2) intervention period followed in the winter of 2009/10, from December 2009 to January 2010 [15] .

In Trial 1 continuous use of fit tested and non-fit tested N95 respirators was compared to medical masks [14] . Continuous use referred to the wearing of N95 respirators or medical masks for the entire shift. It was deemed unethical to randomise wards to a control arm (i.e. no mask use), so a convenience sample of HCWs from hospitals with documented pre-study low rates of mask use was recruited. This arm was excluded from this economic analysis due to the lack of randomisation. In Trial 2 there were two fit tested N95 respirator arms and the difference between these arms was that one arm employed continuous respirator use while the other carried out targeted (i.e. selective) respirator use by HCWs only whilst conducting high-risk procedures such as common aerosol-generating procedures, or when barrier nursing patients with known respiratory illness. These arms were compared to a continuous use medical mask arm (as used in Trial 1).

In Trial 1, the number of HCWs per arm was 492, 461 and 488 for the continuous medical mask, continuous N95 fit tested and continuous N95 non-fit tested arms respectively. In Trial 2, the number of HCWs per arm was 572, 516 and 581 for the continuous medical mask, targeted N95 fit tested and continuous N95 fit tested arms respectively. The criterion for clinical respiratory illness (CRI) in both trials was the presentation of two or more respiratory symptoms or one respiratory symptom and one systemic symptom [14, 16] . Respiratory symptoms considered were cough, nasal congestion, rhinorrhoea, sore throat and sneezing. Systemic symptoms considered were a temperature > 38°C, perceived chills and/or fever, lethargy, loss of appetite and myalgia.

The respirators and masks used in both trials were sourced from the manufacturer 3 M China [14, 15] . As the models supplied in Trial 1 had been discontinued for China by the following season, different models of the same respirator and mask types were supplied in Trial 2. Both trials included at least one arm that applied qualitative fit testing for participating HCWs once at the beginning of the trial period, according to the manufacturer's instructions [17] .

We adopted a societal perspective, as recommended by the WHO cost-effectiveness analysis guidelines [18] . We included the costs for the interventions in addition to inpatient and outpatient costs to the healthcare system for HCW CRI cases. Indirect (productivity) costs were included for 15 min of staff time lost while being fit tested for respirators and due to HCW absenteeism for CRI. The only out-of-pocket costs included were the costs of medications and outpatient visits to healthcare centres/fever clinics and emergency wards for CRI. Other potential out-of-pocket costs incurred to HCWs with CRI, such as healthcare co-payments and direct non-medical costs (e.g. transport costs) were excluded as no trial data was collected on these items.

We applied a decision analytic model using Microsoft Excel to construct a separate economic evaluation for each trial. Costs and health outcomes were not discounted as the time horizon of the analysis was less than one year (28 days). The primary outcome was the incremental cost effectiveness ratio (ICER) per CRI case prevented. This was chosen as CRI in HCWs was the primary endpoint in both trials (CRI cases in patients were not recorded). A one-way sensitivity analysis was carried out on a range of parameters to identify those that most substantially impacted on the ICER. In scenario analysis we examined seasonal variation in attack rates for CRI (from 1-30%) [1] to capture values outside of those observed in the years the trials were run.

Before adjusting for confounding, Trial 1 found that only the continuous use non-fit tested N95 arm was significantly more protective against CRI than medical masks [14] . However, a combined ' All N95' arm, which included both fit tested and non-fit tested N95 groups (there was no significant difference between these groups), was found to be significantly more protective in post-hoc cluster confounder adjusted analysis compared to medical masks [14] . For these reasons, we calculated our ICER results for this trial using the efficacy estimated for this ' All N95' arm. However, to explore the impact of fit testing on cost-effectiveness, we selectively either included/excluded the cost of fit testing for those in the ' All N95' arm. For Trial 2, after the results were cluster and confounder adjusted, only the continuous use fit tested N95 arm had a significantly more protective effect compared to medical masks [15] . We excluded the targeted use fit tested N95 arm from the economic analysis as there was no significant difference in results for this arm when compared to medical masks [15] .

The CRI rates observed in each of the arms of the trials were used when reporting preliminary results for all arms, however when estimating ICERs, CRI rates were generated from the intention-to-treat cluster and confounder adjusted significant efficacy results from both trials [14, 15] . Information on intervention efficacy, the number of respirators or masks used per shift and shift durations, were obtained from the trial publications [14, 15] . Data on HCW resource use due to CRI cases, the exact proportions of each staff type in each arm, the number of shifts worked and the number of days of leave taken, were extracted from the trial databases. Healthcare resource use costs for treatments were sourced from the Beijing pharmaceutical sunshine procurement platform [19] . Estimates were used for the costs of visits to healthcare centres or emergency departments and staff monthly salary costs (Xiaoli Wang, Beijing CDC, personal communication, July 2014). The estimated salary costs were comparable (approximately) with the National Bureau of Statistics China average health and social work salary for 2014 [20] . Costs are reported in 2014 US Dollars and 2014 Chinese Renminbi using the exchange rate of 1 USD = 6.2RMB ( Table 1) .

For both trials separately, respirator and mask costs per HCW for each arm were calculated by multiplying the mean number of shifts worked in the 28 day trial periods, by the cost of either two N95 respirators or three medical masks as provided per HCW for each shift worked in the trials [14, 15] . HCWs worked an average of 20 shifts in Trial 1 and 22 shifts in Trial 2 over the trial duration, with a typical shift being eight hours in duration.

For fit tested arms, the mean cost of 15 min of HCW time to be fit tested was included, taking into account the proportion of each staff type (doctors, nurses, etc.) in the trial. Fit tester time was included as the cost of 15 min of an administration staff member's time per HCW, US $1.98 (12 RMB) in Trial 1 and US $1.81 (11 RMB) in Trial 2. This cost (calculated from monthly salaries) was estimated to be different between the trials as HCWs worked slightly more shifts per month on average in Trial 2. As test operators can be self-taught we did not include any training costs [17] . The respirator, mask and fit test kit costs applied are shown in 

Information on the direct healthcare resource use of each HCW who was documented as having a CRI during the trials was collected through surveys completed in person. HCWs who had symptoms were required to report to the ward head nurse for survey completion. This provided data on the different types of treatment used by the HCW for a specific CRI episode and on the number of healthcare centre/fever clinic visits and emergency ward visits. This was used to calculate the mean cost of CRI for a HCW in each trial.

Indirect costs, in terms of productivity loss due to HCWs taking leave for a CRI episode, were estimated using the human capital approach [21] . The mean leave cost per HCW with CRI in each trial was calculated taking into account the proportions of each staff type that took leave. The productivity cost per day of leave was calculated by dividing mean monthly income by the average number of shifts for all HCWs in the 28 days trial period (i.e. 20 shifts in Trial 1 and 22 in Trial 2).

In Trial 1 the CRI attack rates for those allocated to continuous N95 use were 4.6% and 3.3% (with/without fit testing respectively) and 6.7% for those allocated to the medical mask use arm (Table 2 ) [14] . In Trial 2, the CRI attack rate was 7.2% for those allocated to fit tested N95 respirators compared to 17.1% for those allocated to the medical mask use arm (Table 2 ) [15] . These were also compared to a CRI attack rate of 11.8% for the targeted use fit tested N95 arm in Trial 2 [15] , which was excluded from further analysis due to lack of statistical difference compared to the medical mask arm.

Intervention costs per HCW in Trial 1 for the 28 days were US $32.07 (199 RMB) in the continuous use nonfit tested N95 arm. They were nearly two-fold higher for the continuous use N95 fit tested arm at US $60.40 (374 (12) Beijing pharmaceutical sunshine procurement platform [19] Antitussives (e.g. Apricot cough syrup 250 ml bottle) 4 .03 (25) Beijing pharmaceutical sunshine procurement platform [19] Antipyretics (e.g. Paracetamol 12 tablets)

1.45 (9) Beijing pharmaceutical sunshine procurement platform [19] Antivirals (e.g. Oseltamivir 10 tablets) 35 .65 (221) Beijing pharmaceutical sunshine procurement platform [19] Traditional. Chinese Medicine (e.g. Ganmao Qingre Granules) 10 bags 1.93 (12) Beijing pharmaceutical sunshine procurement platform [19] Healthcare [20] RMB) and were US$8.53 (53 RMB) for the medical mask arm ( Table 2) . Results for Trial 2 were similar, with intervention costs per HCW of US$61.31 (380RMB) for both N95 arms and US $9.35 (58 RMB) per HCW for the medical mask use arm (Table 2) .

The mean CRI costs per HCW case were low in all arms compared to intervention costs ( Table 2 ). The most commonly reported treatment used by those with CRI in both trials (56% in Trial 1 and 30.5% in Trial 2) was traditional Chinese medicines (commonly Ganmo Qingre Granules, US $1.93 [12 RMB]). A breakdown of mean CRI costs per HCW and mean intervention costs per HCW for respective trial intervention arms is shown in Fig. 1 

The cost-effectiveness estimates described below are focused around the intention-to-treat trial efficacy results for N95 respirators which showed a significant protective effect against CRI, when compared to medical masks, after adjusting for clustering and confounding (shown in bold in Table 2) .

In Trial 1, when we included the cost of fit testing, the ICER for continuous N95 respirator use was US $1224 (7589 RMB) per CRI case prevented when compared to medical mask use. In Trial 2 the ICER was US $489 (3032 RMB) for continuous fit tested N95 respirator use when compared to medical mask use. The difference between the trials is primarily explained by the higher CRI attack rates in Trial 2 ( Table 2) .

In Trial 1, when we excluded the cost of fit testing, the ICER for continuous N95 respirator use was US $549 (3404 RMB) per CRI case prevented when compared to medical mask use. In response to the relatively low fit test failures observed in both trials of 1.1-2.6% [14, 15] , we 

One-way sensitivity analysis indicated that CRI attack rate and intervention effectiveness have the greatest impact on the ICERs (Fig. 2) . In scenarios where we assumed the attack rate was greater than approximately 4% for continuous non-fit tested respirators and 8% for fit tested respirators, the ICERs were below US $1000 (6200 RMB) per CRI case prevented (see Fig. 3 ). The importance of the attack rate is also shown by the overlap in the Trial 1 and 2 results for the N95 continuous fit tested arms when we modelled the same background CRI attack rate in the medical mask arm (see Fig. 3 ).

In both trials the ICER worsened substantially when the lower effectiveness values from the trial confidence intervals were applied (see Table 3 and Fig. 2) . Sensitivity analysis was also carried out on costs for treatment including healthcare visits and the impact of doubling and halving the cost of N95 respirators (see Table 3 and Fig. 2 ). The potential for the interventions to be cost-saving was only estimated when we assumed a severe illness treatment cost for each CRI case (US $525, 3255 RMB) [22] . This is an extreme scenario and is unlikely except in a highly pathogenic influenza epidemic/pandemic where a mean case requires substantial healthcare treatment. 

We estimated that the incremental cost to prevent a CRI case in a HCW for continuous N95 respirator interventions compared to medical masks ranged from US $490-$1230 (3000-7600 RMB) in this setting, which is in the acceptable range. We found that including fit testing in a N95 respirator intervention approximately doubles the cost of the intervention and substantially decreases the cost-effectiveness per CRI case prevented compared to medical masks during seasons with a low CRI attack rate. However, these results must be interpreted with caution as the low respirator fit test failure rates (1.1-2.6%) observed in the trials may be specific to the N95 respirator models used in both trials [14, 15] . A potential policy option could be to forego fit testing if respirators with known low fit test failure rates were used (such as those used in the trials), although this decision requires careful consideration and would depend on the severity of circulating pathogens. This incremental approach to considering the additional costs and benefits of fit testing may be particularly important in settings where resources are limited and choices must be made between fit testing and other potential lifesaving interventions. At present there is insufficient literature to support that the low failure rates seen in the trials would apply for all respirator models.

We also found that variation in the CRI attack rate was a major factor in determining the cost-effectiveness of respirators (see Fig. 2 ). The higher attack rate in Trial 2 was most likely due to the more active influenza season observed in the 2009/10 influenza season [14, 15] . The incidence and severity of CRI cases which occur in any given year will vary in accordance with the transmissibility and pathogenicity of the annual influenza strains that are circulating during that season. The incremental cost per CRI case prevented for continuous use N95 respirators compared to medical masks was found to be substantially lower in high attack rate seasons (Fig. 3) . It is important that this seasonal variation is accounted for when evaluating the cost-effectiveness of influenza prevention measures [23] .

Whilst the results of our study are indicative of costeffectiveness, economic evaluations are not usually seen as transferable between settings. Mask/respirator interventions in HCWs need to be evaluated for countries separately to account for inter-country variations in factors such as intervention acceptability [24, 25] , healthcare costs and productivity costs. Variation within countries is also possible and hence the results of this study which only includes trial data from Beijing hospitals may not be generalisable to all settings in China.

China has comparatively high cultural acceptability of mask/respirator use compared to western countries [26] . Furthermore, a study of Beijing HCWs regarding A(H1N1)pdm09, suggests that some HCWs in this setting may continue to attend work with symptoms of influenza like illness [27] . This may partially explain the relatively low levels of absenteeism for HCWs with CRI in the trials. The low mean healthcare costs for CRI in both trials may have been due to the relatively modest influenza seasons and low levels of healthcare seeking by staff [14, 15] . The existing economic studies on masks/respirators have suggested that the interventions were likely to be cost-effective in the high income settings they examined [28] [29] [30] [31] [32] . However, it is difficult to compare the results of our evaluation to these previous high income setting studies as they often did not report results in an easily comparable format (e.g. cost per case prevented) and most did not use clinical trial efficacy data to inform their analyses [33] .

A limitation of the original trials was the 28 day duration [14, 15] meaning that the results may not translate to longer term interventions which may have different adherence levels. A limitation of our analysis is that the effect of the interventions on CRI rates in the patients or family members of HCWs could not be included due to the absence of data. The exclusion of these factors will make our results more conservative. HCWs are known to transmit various types of nosocomial infections to patients [34] and the literature indicates that there are likely to be substantial benefits if the number of patients with CRI is reduced [22] . For example, the benefits of preventing HCW infection transmission through vaccination have been observed in long-term care facilities that found an associated decrease in mortality in their elderly residents [35] [36] [37] . The difference in mean direct healthcare costs per HCW with CRI between the trials (i.e. US $5.45 [34 RMB] in Trial 1 and US $2.60 [16 RMB] in Trial 2) may partly reflect variation in the thoroughness of the sick follow-up data collection between the trials. Another potential limitation of this study is that stochastic uncertainty was not directly explored using the individual level data from the trials [21] . Instead, we adopted a decision-model based approach using clinical trial data to inform input parameter values and explored the uncertainty of these values in deterministic sensitivity analyses. This approach facilitated a focus on forms of uncertainty unrelated to sampling, such as the potential inter-year variation in the CRI attack rate. Finally, as data on quality of life were not collected in the trial we chose to focus the economic analysis on the primary trial outcome (CRI). This limits the ability to compare the value for money offered against other interventions.

This economic evaluation is the first economic analysis of mask/respirator interventions to be conducted for a middle income setting and it is one of the first to make use of clinical trial evidence [14, 15] . This evaluation provides valuable evidence that can be used by decision makers to help assess the costs and benefits of alternative HCW mask/respirator protection strategies. The determination of cost-effectiveness will depend on the willingness to pay to prevent a CRI case in a HCW and this varies between countries and is not easily transferrable between different settings. The extent to which a decision maker is likely to focus on cost-effectiveness evidence when it comes to HCW protection will in part depend on the seriousness of the infections being prevented [33, 38] . In the case of a highly pathogenic pandemic, respirator use in HCWs would likely be a cost-effective intervention. 

We would like to thank Abrar Chughtai for his contribution to the study.

The work was supported by the NHMRC Centre for Research Excellence Integrated Systems for Epidemic Response (ISER), grant number APP1107393. 3 M provided supplies of respirators and medical masks for the original investigator-driven trials in China.

The data used in this study that were not published in the Beijing mask/ respirator HCW clinical trials [14, 15] were obtained from the researchers who led these studies. Enquiries regarding these data should be directed to Dr. Holly Seale (h.seale@unsw.edu.au). High and low efficacy estimates calculated from the confidence intervals generated for the clustering and confounder adjusted results from Trial 1 and 2 respectively b This severe illness treatment cost for each CRI case [22] is unlikely except in a highly pathogenic influenza epidemic/pandemic where an average case requires substantial healthcare treatment

",0.7887591539646305
Clinical Infectious Diseases Healthcare Workers' Strategies for Doffing Personal Protective Equipment,"Background. Personal protective equipment (PPE) helps protect healthcare workers (HCWs) from pathogens and prevents cross-contamination. PPE effectiveness is often undermined by inappropriate doffing methods. Our knowledge of how HCWs approach doffing PPE in practice is limited. In this qualitative study, we examine HCWs' perspectives about doffing PPE.","Effective use of personal protective equipment (PPE) by healthcare workers (HCWs) is an important component of infection prevention in healthcare settings. PPE (eg, gowns, gloves, masks) protects HCWs from contamination with infectious agents and helps prevent cross-contamination to other patients. However, PPE effectiveness is influenced by how HCWs wear and doff (remove) PPE, which was highlighted prominently by the recent outbreak of Ebola virus disease (EVD) [1] .

Despite wearing PPE for their safety, HCWs routinely selfcontaminate while doffing PPE, with self-contamination rates as high as 46%-90% across PPE types (eg, gowns, gloves) and scenarios [2] [3] [4] . For example, Kwon et al [5] found that among HCWs asked to doff either contact precautions or EVD PPE, 26% and 44% contaminated themselves, respectively. Casanova et al [6] found contamination on 53% of inner gloves and 13% of scrubs worn by HCWs trained specifically in EVD PPE. In an observational study, Kang et al [3] estimated that 66% of HCWs potentially contaminated themselves when doffing PPE after caring for patients in isolation precautions.

Contamination commonly results from critical doffing errors [2, [7] [8] [9] [10] , even when HCWs believe they are proficient in doffing [11] . When HCWs doff complex PPE for a high-risk scenario such as EVD, they often make errors during key ""vulnerable processes, "" including when reaching for equipment during the doffing process and when removing respirators and hoods [8] [9] [10] . During more routine contact precautions, HCWs often selfcontaminate when removing gloves [2, 12] and gowns [7, 13] . Several factors may contribute to self-contamination, including poorly fitting or ""universally sized"" PPE [14] [15] [16] , difficulty distinguishing between dirty (outside) and clean (inside) surfaces while doffing [14] , and forceful or rushed movements [14, 17] . HCWs may use incorrect doffing sequences or methods that do not work well with the PPE design [17] . Furthermore, doffing protocols are often not standardized [15] , and HCWs may receive suboptimal and inconsistent PPE training [18] , leading to further confusion regarding appropriate doffing approaches.

Our understanding of doffing practices and factors that contribute to self-contamination is growing but is largely based on examination of PPE doffing protocols for high-consequence infectious agents, such as Ebola virus. Furthermore, we have limited knowledge about HCWs' perceptions and thoughts about doffing PPE. In this study, we focused on HCWs' perceptions of doffing PPE used in routine care, and we examined how HCWs approach doffing, what they think about and pay attention to while doffing, and what factors facilitate or inhibit their ability to doff.

This qualitative study was part of a larger simulation study to investigate doffing practices with methods that include task analysis, contamination count and location analysis, eye tracking, basic anthropometry measurements, and participant thinkaloud interviews. We briefly describe the larger study to provide context. All findings reported here are based on qualitative participant interviews; findings that pertain to other data collected will be reported in future articles. The study was reviewed and approved by the University of Iowa Institutional Review Board.

We recruited 30 HCWs and students (medical and nursing students doing clinical rotations who use PPE) at a large teaching hospital in the Midwestern United States. We excluded faculty and staff who did not have clinical patient care duties and students who were not doing clinical rotations. After obtaining written consent, we conducted anthropometry measurements and asked participants to fill out a demographics questionnaire.

Participants were assigned to 1 of 3 doffing simulation scenarios. The first 10 participants used standard gloves and 3 mask designs: procedure mask with ear loops, surgical mask with ties, and pouch-style mask with headbands. The next 10 participants used standard gloves and 2 gown designs: over-the-head isolation gown with break-away neck closure and thumb loops and isolation gown with tape-tab neck closure and elastic cuffs. The last 10 participants used 2 glove designs: standard nonsterile nitrile exam gloves and Doffy gloves (nonsterile exam gloves with a Doffy flap, a doffing aid positioned in the wrist area [19] ). We examined the participants with a black light to assess baseline contamination, asked them to don the PPE items, and sprayed them with Glo Germ fluorescent marker. We then instructed participants to doff PPE as they would in practice. Because participants were not familiar with Doffy gloves, we showed them the Doffy flap and explained that it was to help them doff the gloves. After participants doffed the PPE, we reexamined them with a black light to assess self-contamination and asked them to thoroughly wash their hands and faces. The study was conducted in a simulation room where the whole sequence was video-recorded from 4 angles.

We reviewed the video recordings with the participants and conducted short (typically about 10 minutes) semistructured interviews using the retrospective think-aloud method [20, 21] . In these interviews, we asked participants open-ended questions to explain their doffing approach and to share what they were thinking about or paying attention to at each step in the process. We paused or rewound the video, asked follow-up probing questions, and reviewed the donning process as necessary. The interviews were audio-recorded (after obtaining verbal consent) and transcribed verbatim.

We analyzed the transcripts using both a priori (deductive) and emergent (inductive) codes [22] . The a priori codes were overarching themes that reflected our research questions, and the emergent codes were subthemes identified within each overarching theme. One investigator (J. B.) started developing and refining the codebook based on a sample of transcripts and met periodically with 2 medical anthropologists on the team (H. S. R., K. D.) to discuss and refine the themes. After the codebook was finalized, J. B. coded the remaining transcripts. To further enhance reliability, a second coder (J. P. S.) randomly selected and coded 2 transcripts from each simulation scenario (6 total, or 20% of all transcripts). The 2 coders met to compare the coded content and found that the codebook did not need to be revised. They discussed coding differences until they reached agreement. After coding the overarching themes, J. B. examined the coded content within each theme to identify and enumerate the most prominent response patterns, which he compared and grouped together into subthemes using comparative analyses [23] . Finally, to identify any systematic differences, we determined whether occurrence of subthemes varied across PPE types and designs and by HCW type. Table 1 . We identified 3 overarching interview themes: doffing strategies, cognitive processes, and barriers and facilitators. Doffing strategies focused on how participants generally approached doffing PPE. Cognitive processes focused on what participants thought about or paid attention to while doffing PPE, chiefly reflecting how they carried out the strategies or how they overcame unanticipated issues and doffing barriers. Barriers and facilitators addressed factors that helped or hindered doffing (eg, PPE design, personal factors). Table 2 includes exemplar quotes to illustrate each theme.

In the following sections we describe each theme and its subthemes and we highlight differences across PPE types and designs and by HCW type (as applicable). We also include the number of participants who discussed each subtheme (in parentheses); however, the numbers are provided for illustrative purposes only and should not be used for statistical inference. Furthermore, comparison across HCW types should be interpreted with caution because the sample size was small, different groups of HCWs were unequally represented in the 3 doffing scenarios (which could bias group comparisons), and since the subthemes emerged later in our analyses, we did not solicit responses that pertained to specific subthemes during the interviews (ie, absence of evidence is not evidence of absence).

We identified 2 subthemes of doffing strategies: doffing safely and doffing expediently. Most participants (n = 29) described trying to doff safely and minimize the likelihood of selfcontamination, primarily by avoiding contact with the surfaces they perceived as contaminated (eg, front of the gown, outside surface of the gloves) and using gestures to better control PPE (eg, not ripping PPE off or ripping in a careful, controlled manner). About half of the participants (n = 17) also described doffing expediently, which involved approaches to doffing PPE quickly and with minimal burden (eg, ripping PPE off) or using shortcuts and work-arounds (often initiated at donning; eg, not fastening gown straps). Participants who described both strategies did not specify which strategy was their priority, but some noted that doffing expediently could undermine safety.

We found that response patterns for doffing strategies varied across PPE types and designs. In the mask simulation scenario, the tension between safety and expediency tended to be most pronounced for the surgical mask with ties (which can be ripped off). For example, several participants tried to untie the mask because they thought it would be safer to remove that way, though some admitted that in practice they would probably rip the mask off. However, most participants described using both strategies to doff gowns and typically did not see much conflict or tension between them. While ripping gowns was not perceived as inherently unsafe, some participants described difficulties ripping gowns off in a controlled manner or described other barriers (see Cognitive Processes and Barriers and Facilitators). For gloves, most participants described only doffing safely; they mentioned expediency (or lack thereof) only in reference to alternative glove doffing methods (eg, the ""beak method""), which they rarely use in routine practice. We also found that doffing expediently was less commonly reported by physicians (2/6) than other HCWs (15/24).

Participants described several things they thought about or paid attention to when doffing (and also donning) PPE. Most commonly (n = 20) they described tracking PPE surfaces they thought were most likely contaminated and trying not to touch them. About half of the participants (n = 14) also described looking for PPE design cues (eg, the type of fastener used), often starting this process while donning the PPE. These cues helped suggest the optimal doffing method, particularly when the HCW was not familiar with the PPE item. In unforeseen circumstances (eg, doffing unfamiliar PPE designs, encountering doffing barriers), participants also tended to improvise approaches that made sense to them, typically relying on training or experience with similar PPE designs (n = 7).

Participants' responses regarding cognitive processes did not vary notably across different PPE types and designs. Tracking contaminated surfaces and looking for design cues were more common with gowns than with masks and gloves, and improvising was more common with masks and gowns than with gloves. Four participants described relying on muscle memory and not thinking much at all when doffing gloves. Furthermore, we found that tracking PPE surfaces was more commonly reported by students (5/5) than other HCWs (15/25) and that looking for PPE design cues was also more commonly reported by students (4/5) than other HCWs (10/25).

Doffing barriers and facilitators typically pertained to PPE design. Participants identified the fasteners (eg, bands, straps) on masks and gowns as particularly problematic. For example, a common barrier was the (perceived) need to untie certain mask and gown designs (n = 14). Knots were often behind participants' heads or backs, making them hard to find or hard to reach (particularly for HCWs with mobility issues). Sometimes knots were also hard to untie. Furthermore, when untied, the loose fasteners or the PPE itself could be hard to control and could pose a contamination risk. Several participants described workarounds that prevented or minimized the problem of untying PPE (n = 5), such as tying just 1 knot, not tying the fasteners while donning, or simply ripping the PPE off rather than untying the fasteners. However, ripping off PPE was not easy with certain designs (n = 7), particularly the masks with bands and the gowns with thicker belts. Some participants also found the gown with the tape-tab neck closure harder to rip off in a predictable and controlled way. While gloves were not associated with the barriers described above, several participants (n = 6) described difficulty safely doffing the glove on the second hand (because the other hand was exposed). PPE fit was also a barrier to doffing all types of PPE (n = 10), typically when PPE fit too tightly. However, while 2 participants found tighter-fitting gowns harder to doff, 2 participants found looser-fitting gowns harder to doff. Participants also identified personal barriers (n = 10), such as wearing personal items (glasses, watches), having long hair, and having mobility issues. However, some PPE designs helped mitigate these barriers. For example, procedure masks with ear loops were the easiest to doff for participants who wore glasses. Some participants also admitted that they struggled to recall the correct doffing approach, but they generally described remembering or ""figuring out"" how to doff correctly. Finally, 3 participants explicitly commented on the benefit of using familiar PPE designs because it allowed them to rely on their doffing habits.

In this study, we examined how HCWs perceive and think about doffing PPE in routine care settings. Our findings indicate that HCWs seek a balance of safety and expediency when doffing PPE. While doffing, they track and avoid contact with PPE surfaces they think are likely contaminated. When doffing unfamiliar PPE items or in other unforeseen circumstances, HCWs tend to improvise and rely on PPE design cues, prior training, and experience with similar PPE. We identified several factors that facilitated or impeded doffing, most of which were related to PPE design, such as type and location of fastener and fit.

HCWs are often aware that they violate doffing protocols [17, 24] and are cognizant of the trade-offs between safety and expediency. HCWs in clinical practice are busy and use PPE frequently, which likely influences them to doff more expediently than they would otherwise. They may be more likely to doff expediently in routine care, which they perceive to be low risk, particularly if they see PPE as self-protection rather than a measure to prevent cross-contamination [24, 25] . These findings suggest that efforts to improve PPE use and doffing should address both safety and expediency through new and improved PPE designs, doffing methods, training approaches, and organizational policies and procedures.

We found some differences between groups of HCWs. Physicians were less likely to report doffing expediently, which could either mean they are less likely to acknowledge during an in-person interview that they doff expediently or that doffing expediently is less salient to them. The difference in salience could be due to differences in clinical practice workflows. For example, Harrod et al found that during routine care, physicians (and physical therapists) don and doff PPE much less frequently than nurses [26] . This suggests that different HCWs groups have unique PPE needs and challenges and that each group may require a training program tailored to their clinical practice. We also found that students were more likely to report tracking potentially contaminated PPE surfaces and looking for PPE design cues. While other HCW types may have simply omitted this information from their responses (eg, it may be self-evident to them that one would do those things while doffing), it may also suggest that more experienced HCWs have internalized cognitive processes associated with specific tasks and, thus, may perform tasks such as PPE doffing without consciously processing relevant information, relying rather on muscle memory and habits.

Our findings indicate that PPE should be redesigned in ways that facilitate expedient and safe doffing methods. Design cues could help HCWs envision and execute appropriate doffing methods; for example, color-coding PPE surfaces to differentiate ""dirty"" outside surfaces from ""clean"" inside surfaces could help HCWs track where these surfaces are at each step of the doffing process [16, 27] . Fasteners (eg, straps, belts) that do not require untying and are easy to undo (or rip) quickly would facilitate speed and ease of doffing [16, 27] . PPE also must fit people of different sizes and physical abilities and should be either adjustable or available in several sizes [14, 27] . In addition, new doffing methods and additional training may be required to optimize HCWs' doffing of redesigned PPE. The new PPE designs and doffing methods also must be rigorously tested, not only for efficacy in ""ideal"" and controlled settings but also for effectiveness in practice. If HCWs use work-arounds to avoid doffing PPE with cumbersome but safe methods, it may be prudent to design PPE that leads to fewer work-arounds and allows for better compliance with doffing methods in practice, even if such designs and methods are shown to be somewhat less safe in controlled settings. In addition to efficacy and effectiveness studies, well-designed ethnographic and human factors approaches can help us better understand the variety of factors that influence HCWs' ability to doff in routine clinical practice, where and why critical errors occur, and how to improve usability of PPE and doffing methods.

New training approaches may help improve HCWs' doffing performance [2, 18] . Our findings indicate that HCWs draw on prior training experiences when encountering new PPE designs or facing doffing barriers, suggesting that PPE training should cover the range of PPE types and designs HCWs may encounter in clinical practice and the most appropriate doffing methods for each. HCWs should also be given just-in-time training if their standard PPE is replaced with a new style during shortages or vendor changes. Furthermore, HCWs could benefit from training that would help them assess how to doff unfamiliar PPE or improvise solutions when they encounter doffing barriers or PPE failures (eg, if the gown shreds into multiple pieces). New training approaches must be tested for effectiveness [18] . While computerized training may be prevalent [18] , HCWs may prefer hands-on practical training [24] , which would also allow for feedback on self-contamination with fluorescent markers [2] and would allow HCWs to develop muscle memory. HCWs at different stages (eg, in-school vs on-the-job training) may also need different training approaches. Thus, training protocols should accommodate HCWs' level of experience and the work they perform.

Finally, hospitals and other healthcare organizations can play an important role in implementing needed changes and sustaining high performance over time by providing necessary support [3, 16, 28] . Hospitals should consider assembling interdisciplinary teams to periodically review and revise their PPE protocols [16] . PPE protocols must be clear and unambiguous in order to provide guidance for key processes, from PPE selection to its use in practice. After carefully examining their PPE needs, hospitals could eliminate unnecessary variation in PPE designs to minimize the likelihood that HCWs would encounter unfamiliar PPE, and they could procure PPE that is safe and expedient to use and doff. Furthermore, hospitals could tailor their PPE training approaches for the PPE available at their institution in order to increase the likelihood that HCWs use appropriate doffing methods. HCWs may require refresher training, particularly if new PPE designs are introduced into practice or they start working in new settings that use different PPE designs. To maintain or improve performance over time, hospitals should monitor compliance with PPE use and doffing protocols and investigate reasons for poor performance.

Our study had several limitations. First, all participants were recruited at 1 teaching hospital and its affiliated schools. Common influences (eg, institutional policies and procedures, training, available PPE) may have limited the range of perspectives we identified in the study. However, participants' work experience (in years) varied substantially. Thus, participants likely were initially trained at different times, in different institutions, and with different PPE designs, which should mitigate this limitation. Second, the simulation context of our study (eg, presence of observers, simulation room, recording, fluorescent marker, other prompts) may have influenced participants to pay closer attention to doffing and particularly to avoiding self-contamination, leading them to adopt different doffing approaches than they use in practice, or bias their interview responses. Furthermore, in a simulation study, we could not account for the range of tasks and circumstances that HCWs encounter in day-to-day practice but may influence doffing performance (eg, carrying objects while doffing [17] ). Thus, we may have not explored the full range of factors that influence HCWs' PPE doffing practice.

This study contributes to the literature on PPE doffing performance and self-contamination by focusing on HCWs' perspectives. HCWs try to balance safety and expediency when doffing PPE, which triggers various cognitive processes during doffing. Different PPE designs can facilitate or inhibit HCWs' doffing practices. These findings have implications for designing the next generation of PPE and new doffing methods, developing and implementing PPE training protocols, and revising policies and procedures in hospitals and other healthcare organizations.

Notes

",0.7843259239652067
SPEECH INTELLIGIBILITY ASSESSMENT OF PROTECTIVE FACEMASKS AND AIR-PURIFYING RESPIRATORS HHS Public Access,"Speech Intelligibility (SI) is the perceived quality of sound transmission. In healthcare settings, the ability to communicate clearly with coworkers, patients, etc. is crucial to quality patient care and safety. The objectives of this study were to 1) assess the suitability of the Speech Transmission Index (STI) methods for testing reusable and disposable facial and respiratory personal protective equipment (protective facemasks [PF], N95 filtering facepiece respirators [N95 FFR], and elastomeric half-mask air-purifying respirators [EAPR]) commonly worn by healthcare workers, 2) quantify STI levels of these devices, and 3) contribute to the scientific body of knowledge in the area of SI. SI was assessed using the STI under two experimental conditions: 1) a modified version of the National Fire Protection Association 1981 Supplementary Voice Communications System Performance Test at a Signal to Noise Ratio (SNR) of −15 (66 dBA) and 2) STI measurements utilizing a range of modified pink noise levels (52.5 dBA (−2 SNR) − 72.5 dBA (+7 SNR)) in 5.0 dBA increments. The PF models (Kimberly Clark 49214 and 3M 1818) had the least effect on SI interference, typically deviating from the STI baseline (no-mask condition) by 3% and 4% STI, respectively. The N95FFR (3M 1870, 3M 1860) had more effect on SI interference, typically differing from baseline by 13% and 17%, respectively for models tested. The EAPR models (Scott Xcel and North 5500) had the most significant impact on SI, differing from baseline by 42% for models tested. This data offers insight into the performance of these apparatus with respect to STI and may serve as a reference point for future respirator design considerations, standards development, testing and certification activities.","Speech Intelligibility (SI) and clear communication among healthcare workers (HCWs) are vital components of healthcare delivery systems and occupational safety. This is especially true in times of public health emergencies and disaster situations. With approximately 13 million HCWs in the United States, clear communication in healthcare has a broad scope with significant impacts. SI is the quality or condition of speech being intelligible and clearly understood. It is well-documented that hospitals are often loud environments, which makes the issue of SI challenging. Hospital noise levels have been rising consistently since the 1960s. The background noise levels in hospitals rose from 57 dBA in 1960 to 72 dBA today during daytime hours, and from 42 dBA in 1960 to 60 dBA today during nighttime hours (1) . The World Health Organization (WHO) guidelines for hospital noise levels are 35 dBA during the day and 30 dBA at night in patient rooms, with recommended nighttime peaks of 40 dBA (2) . Many studies indicate that peak hospital noise levels often exceed 85 dBA to 90 dBA (3) (4) (5) (6) (7) (8) . Noise from alarms and certain equipment that exceeds 90 dBA (for example, portable X-ray machines) are comparable to walking next to a busy highway when a motorcycle or large truck passes. These increased noise levels can pose significant challenges to communication among hospital staff and with patients. Busch examined hospital noise levels reported in 35 published research studies over the last 45 years (1) . It was found that not one published study reported noise levels that complied with the WHO guidelines for noise levels in hospitals (1) .

(which includes SI) was recently deemed not practical for inclusion in a draft B95 standard (19) . The Institute of Medicine (IOM) has also identified communication interference as a key issue to be studied and rectified in the next generation of facial and respiratory PPE developed for HCWs (14) .

Previous studies involving SI have primarily employed the use of the Modified Rhyme Test (MRT) in clinical settings or controlled listener/speaker orientations (20) . The MRT is standardized under the American National Standards Institute (ANSI) S3.2 1960 and involves a listener attempting to properly identify certain key words preceded by a carrier sentence. For example, Radonovich et al. found that the odds of correctly hearing a word spoken by a HCW wearing an EAPR in an Intensive Care Unit (ICU) setting was approximately 0.46, compared with other commonly used respirators in the same location, on average (20) . However, the MRT involves human test subjects, causing results to be variable and validity to be diminished based on each individual's unique variations in speech and the way listeners interpret those variations in speech. Sample size has also been small in previous studies, which may have decreased reliability (20) . Human subject testing is also time-consuming, expensive, and often leads to incomplete data sets due to test subject attrition. Furthermore, the spoken words in the MRT are not industry specific, which plays a vital role in a field such as healthcare where highly technical words and sentence structures are used, as well as numerous acronyms.

Recently, an alternative method for assessing speech transmission, called the Speech Transmission Index (STI), has been applied to respirators and included in a voluntary consensus standard for Self-Contained Breathing Apparatus (SCBA) by the National Fire Protection Association (NFPA) in their 1981 Standard on Open-Circuit SCBA for Emergency Services (2013 edition). STI testing is a quantitative and objective method of speech transmission quality assessment in the presence of ambient (pink) noise. The STI was developed in the 1970s and is standardized under the International Electrotechnical Commission (IEC) Standard 60268-16. In contrast to subjective methods used to measure SI, the STI offers the advantages of being objective, highly repeatable, reproducible and time-efficient. A single value is calculated by the Modulation Transfer Function (MTF) using the signal-to-noise ratios per octave band with weightings that reflect the SI. The STI uses seven octave bands in the range of 125Hz to 8000Hz.

The objectives of this collaborative study between the National Institute for Occupational Safety and Health (NIOSH) (Pittsburgh, PA) and respirator manufacturer Scott Safety Inc. (Monroe, NC) were to 1) assess the suitability of the STI method in the NFPA 1981 standard for testing facial PPE commonly worn by HCW, 2) quantify STI levels of these devices, and 3) contribute to the scientific body of knowledge for Project BREATHE and other research in the area of SI.

The facial and respiratory PPE models and sizes selected and used in this study are summarized in Table I . Three types of facial PPE were tested: 1) N95 FFR, 2) PF and 3) EAPR. Each model was selected based on U.S. market share, ubiquity in healthcare workplace settings, use in previous studies (20) , and tolerability among healthcare workers based on previous occupational health studies (21, 22) . SI interference of these PPE have not been previously investigated to this degree under such controlled conditions as utilized in this study. Furthermore, SI interference of these types of PPE has not been extensively investigated utilizing a quantitative methodology such as the STI. It must be noted that the EAPR models tested did not contain voicemitters (also known as speaking diaphragms).

The STI component of the NFPA 1981 standard method was developed for tight-fitting, full facepiece SCBA respirators and thus is in need of validation for use on other respirator types. To assess the method for respirator and facial PPE use it was desirable to examine both repeatability measurements within each sample donning, and reproducibility measurements between each sample donning. The NFPA method requires three facepiece samples, each of which is donned on the manikin five times, with three measurements taken during each donning, for a total of 45 measurements. To assess repeatability within each donning, it is desirable to have a sample size larger than three repeats. Ideally, 28 measurements per sample and donning would need to have been performed in order to achieve the desired statistical power of 0.90. This would have led to a total of over 1,500 measurements for the six models tested. However, due to time constraints, this power level was not within the scope of this study. In an effort to increase the number of repeat measurements, the current study used three respirator samples, which were donned three times with five measurements taken during each donning. Utilizing this type of measurement protocol allowed for a better assessment of repeat measurements in a consolidated timeframe, while still maintaining a sufficient quantity of replicates.

The test system setup conforming to the NFPA 1981 standard for SI testing was used for all experimental conditions. Testing took place at Technicon Acoustics (Concord, NC) inside a hemi-anechoic chamber. The test setup schematic is shown in Figure 1 per the NFPA 1981 Standard. Outside the hemi-anechoic chamber, a computer (Dell, Round Rock, TX), two graphic equalizers (Behringer-Willich, GE), pink noise generator and acoustic analyzer (NTI Audio AG, Schaan, LS) and STI test output signal were used. Inside the hemi-anechoic chamber, a K.E.M.A.R HATS Manikin (GRAS, Holte, DE), pink noise speaker and microphone (NTI Audio AG) were used. Prior to initiating each test, each model containing a nasal bar (3M 1860, 3M 1870, KC Tecnol 49214 and 3M 1810F) was molded to the K.E.M.A.R manikin in the same manner that a human would in order to achieve the best fit possible, not a protective fit. Figure 2 further depicts the STI testing setup inside the hemianechoic chamber and specifies equipment distances. All equipment was set up and calibrated conforming to the NFPA 1981 standard each day prior to testing by staff familiar with the testing setup, system and calibration of equipment.

SI was measured for each PPE sample utilizing the STI under two different experimental conditions: 1) STI measurements using a modified version (3 samples × 5 replicate measurements) of the NFPA 1981 standard and a signal to noise ratio (SNR) of −15 (66 dBA) and 2) STI measurements utilizing modified pink noise levels of 52.5 dBA (−2 SNR) to 72.5 dBA (+7 SNR) in 5.0 dBA increments to further characterize the SI of each facepiece. Three donnings of each facial PPE sample were performed under each experimental condition with five replicate measurements per donning. To ensure consistency, the same investigator performed each donning. Each STI value was measured directly in front of the K.E.M.A.R HATS Manikin at 1.5m per NFPA 1981. This distance was re-measured and readjusted inside the hemi-anechoic chamber when necessary to ensure the utmost accuracy ( Figure 2 ).

Five STI measurements were taken for each sample (n=3) of each facepiece model (facepiece model n=6) per background noise decibel range (52.5, 57.5, 62.5, 67.5 and 72.5 dBA. This resulted in 25 STI measurements per sample (5 measurements × 5 background ranges) for a total of 75 STI measurements (25 measurements × 3 samples) per model.

Data analysis was completed using Statistical Analysis Software (SAS) and Microsoft Excel. For this study it was desirable to examine both repeatability (defined as variability in measurements within each sample donning) and reproducibility (defined as variability in measurements between sample donnings).. The NFPA method requires three face piece samples, each of which is donned on the manikin five times with three measurements taken during each donning for a total of 45 measurements. To assess repeatability within each donning it is desirable to have a sample size larger than three repeats, ideally 28 measurements per sample and donning would have been performed in order to achieve the desired power of 0.90 (the implemented modification had a negligible impact on the power). This would have lead to a total of over 1500 measurements for the six models under test. The modified version of the NFPA method was utilized in order to yield more STI measurements per facepiece sample to assess the variability and repeatability. An analysis of variance (ANOVA) was performed for each respirator model comparing the means by sample (3 samples per model) and donning (3 donnings per sample) as well.

To assess the repeatability of measurements, standard deviations for this testing were compared against two sets of data; one from MRT testing performed by Coyne and Barker and another STI study performed by Symons (23, 24) . For the STI method to be considered a suitable SI measurement for facial and respiratory PPE worn by HCW, the standard deviation should be less than those found by Coyne and Barker using the MRT to evaluate full facepiece air-purifying respirators (24) . The standard deviations found during the tests should also be similar to those found by Symons (23) when testing SI of full facepiece respirators using the NFPA 1981:2013 method. At the time of this study, no STI testing had been done on the respirator models utilized in this study, so the data from full facepiece respirators was used as a comparison of the means and standard deviations. This is illustrated in the data shown in Table II .

To assess reproducibility of the measurements, the means of each sample were compared between donnings of the same sample. An analysis of variance (ANOVA) was performed for each full facepiece respirator tested comparing the means by sample and donning. The differences in means between each donning were again compared to data from full facepieces tested using the NFPA method from Symons (23) . The differences in means should be similar to data from Symons (23) . Upon closer examination of the standard deviations in Table III of each sample donning, it is noted that the largest standard deviation is 0.026 (3M 1860), with the average deviation across all models, samples, and donnings being 0.012. A chi-square test for SD less than 0.03 shows that the standard deviations of 41 of the 54 sample donnings were less than 0.03 STI or 3% of full scale with a 90% confidence interval.

From Coyne and Barker, the average standard deviation among listeners across all 12 full facepiece samples using the MRT method was 9.9% (24) . From Symons, the average standard deviation across all three facepieces and 7 test runs was 0.014 STI when using the NFPA STI method (23) . The standard deviations found in this study (0.012 STI) were less than those found by Coyne and Barker using MRT (9.9%) and similar to those found by Symons (0.014 STI) (23, 24) . Day 1 Testing-For the first experimental condition, the difference in means were assessed using a one-way ANOVA for each model sample. For both N95 FFR models (3M 1860 and 1870), the data from each sample donning is not statistically different (p > 0.05). Similarly, for the PF (KC 49214 and 3M 1818), the data from each sample donning can be considered statistically equivalent with p > 0.05. For the EAPR's (North 5500 and Scott Xcel), only sample 3 in each case was found to be statistically equivalent. For the North 5500, the maximum difference in means between donnings was 0.052 for sample 1 and 0.042 for sample 2. For the Scott Xcel, the maximum difference in means between donnings was 0.024 for sample 1 and 0.052 for sample 2. Figure 3 shows data from the second experimental condition (STI measurements utilizing modified pink noise levels of 52.5 dBA (−2 SNR) to 72.5 dBA (+7 SNR) in 5.0 dBA increments. The graph in Figure 3 illustrates that significant differences in SI exist between the different classes of PPE tested and the effect of background noise. This is shown in the boxplot illustrating STI scores by model in Figure 4 at a background noise level of 57.5 dBA (−15 SNR). Overall, the PF (Kimberly Clark 49214 and 3M 1818) had the least effect on SI interference, typically deviating from the STI baseline (no-mask condition) by 3% and 4% STI for the Kimberly Clark 49214 and 3M 1818, respectively. The N95FFR had more effect on SI interference, typically differing from baseline by 13% for the 3M 1870 and 17% for the 3M 1860. The EAPR's had the most significant impact on SI, differing from the baseline by 42% for the Scott Xcel and 45% for the North 5500.

The STI score ranges from 0 to 1.0 as shown in Figure 5 and predicts the likelihood of words and sentence comprehension. Table IV illustrates the relationship between the STI, subjective intelligibility measures, and intelligibility ratings. A value of 0 is equivalent to a very poor SI, while 1.0 is an ideal channel with excellent speech transmission. The products tested in this study fall into the poor/fair (EAPR), good (N95 FFR), and excellent (PF) ranges.

From the results of both experimental conditions, it is seen that PF have the least impact on SI under these test methodologies followed by N95 FFR and EAPR. PF yielded the highest STI scores during both experimental conditions, most likely due to the thinness and type of materials used in their design and that they do not adhere as firmly as N95 and EAPR to the face, allowing sound to dissipate through gaps in the PF-to-face contact area. However, unlike the N95 and EAPR, the PF is not intended for respiratory protection. From a design perspective, the potential gains that could be made to both the N95 FFR class and PF class in terms of SI would be incremental.

Some of the overall trends observed here (EAPR < N95 FFR < PF) agree with those from human subject studies (20) . In one set of experiments, Radonovich et al. (20) reported that the North 5500 EAPR showed a speech intelligibility rating of 72% compared to an 85% average from six disposable N95 FFRs (including the 3M 1860 used in this study) and one powered air purifying respirator. However, unlike this study, word intelligibility between PFs and N95 FFRs were not found to be statistically different. According to Table IV , the STI value of 0.45 found for the North 5500, falls in the upper range of the ""poor"" quality category or lower range of ""fair"", corresponding roughly to an intelligibility between 67% and 87%, that is consistent with a previous study which reported an average three foot MRT score of 73% and 88% (Tables II, III Radonovich et al. (20) ), depending upon the experimental conditions. Likewise, the one N95 FFR (3M 1860) common to this study (average STI = 0.71) and the Radonovich (20) study resulted in an average three foot MRT score of 91%, which falls in the middle of the ""good"" quality category.

Based on the data from this investigation, a minimum pass/fail criterion of ≥70 (0.70 STI) with respect to the NFPA STI standard is suggested as a baseline for current facial PPE, in the development of future B95 respirator standards (19) . Facial and respiratory PPE with an STI of ≥70 fall within the ""good"" quality range according to IEC 60268-16 (Table IV) . Further support for setting this level as a baseline can be found when comparing the results of this study with the Radonovich et al. study (20) . The 3M 1860 N95 FFR with an STI of 0.71 was not found to be statistically different from control (no facial PPE) using the MRT (see Table II , Radonovich et al. (21) ). Thus, facial and respiratory PPE with STI values ≥70 likely have little negative impact on SI.

Beyond facial and respiratory PPE design factors, controlling background noise in the healthcare environment will be paramount in improving SI in future healthcare environments. This can be accomplished through architectural design improvements, engineering controls and quieter equipment. As shown in Figure 3 , with increasing background noise SI decreases and the differences between the PPE types quickly shrinks. Furthermore, a HCW using either an N95 FFR or a PF loses little with respect to SI. Thus, reducing background noise will be one of the most effective ways to improve SI in healthcare environments.

Limitations of this study include time, non-human testing, uni-directionality and difficulty to generalize findings based on the limited number of samples used for each PPE type. A nonhuman modality was undertaken for this study for the purposes of objectivity and time constraints. The uni-directionality of testing was performed in order for the results to be valid, consistent and reproducible. Testing in multiple angles or distances would considerably increase the amount of time and resources needed. The surgical masks used were a flat-fold design whereas the N95 FFRs were cup-shaped (3M 1860) and tri-fold (3M 1870), rendering them further away from the face when donned. No models tested contained exhalation valves or voicemitters, which may have an effect on SI.

If SI becomes a performance requirement for future ""B95"" respirators, the STI methodology used in this study could be used for testing and certification requirements and standards development. Also, independent replication of this experimental work would provide validation of the STI method as a reliable methodology for testing different types of PPE. Data could also be used for benchmark testing and design improvements for manufacturers of facial and respiratory PPE. Further investigation into a more diverse range of models and sizes under different conditions (different directions, reverberation, etc.) would be valuable contributions as well. Future studies should identify the design features that could lead to EAPRs and N95 FFRs with STI scores in the excellent range, which would allow a higher B95 standard STI pass/fail criterion to be considered (e.g., 0.75) in the future.

The PF models studied here (Kimberly Clark 49214 and 3M 1818) had the least effect on SI interference, typically deviating from the STI baseline measurement (no-mask condition) by 3% and 4% STI. The two N95FFR models (3M 1870 and 1860) had a greater effect on SI interference compare to the PF models, typically differing from the STI baseline measurement by 13% for the 3M 1870 and 17% for the 3M 1860. The two EAPR models (Scott Xcel 742 and North 5500) had the most significant impact on SI, differing from the baseline STI measurement by 42% for the Scott Xcel and 45% for the North 5500 shows the sounds pressure levels per octave band for each respirator model during the testing with the background noise at 52.5 dbA (−15 SNR). Figure 6 illustrates why the EAPRs performed worse than the N95's and surgical masks. Examining the sound pressure level in the 1kHz to 4 kHz range, it is noted that the sound pressure level for both EAPR models is lower than baseline by approximately 10 dBA at 1kHz, 20 dBA at 2kHz and 15 dBA at 4kHz. This indicates that the STI signal sound pressure level has been significantly attenuated by the EAPR facepiece in these frequency ranges. Furthermore, at the 2kHz and 4 Khz frequencies, the sound pressure level of both EAPR models is nearly equivalent to the background noise level. Thus, the STI signal is masked by the background noise and intelligibility in these key frequency ranges is significantly degraded. To a lesser degree the same observation can be made about the N95 respirators (3M 1860 and 3M 1870) .

The thinness and thickness of the materials used in the construction of the respirators and the materials themselves (e.g. silicone vs. polypropylene) may also be contributing factors to the variation in STI scores between respirator models and samples. The rigidity, type and number of materials used in the speech path are all contributing factors to the STI score. These factors should be taken into consideration and investigated further as the next generation of facial PPE is developed. 

",0.7721405938606671
Reusable elastomeric air-purifying respirators: Physiologic impact on health care workers,"Background: Elastomeric air-purifying respirators offer the benefit of reusability, but their physiological impact on health care workers is unknown. Methods: Ten health care workers exercised at 2 health care-associated work rates wearing an elastomeric air-purifying respirator. Mixed inhalation/exhalation respirator dead space gases (oxygen, carbon dioxide) were sampled, and physiological parameters were monitored (heart rate, breathing rate, tidal volume, minute volume, oxygen saturation, transcutaneous carbon dioxide). Numerical rating scales were used to evaluate comfort and exertion. Results: Compared with controls (no respirator), significant decreases in the breathing rate at both work rates (P , .05) and increases in tidal volume at the lower work rate (P , .01) were noted with respirator use. Approximately half the subjects had transcutaneous carbon dioxide levels above the upper limit of normal after 1 hour of use. Although well tolerated, comfort was negatively impacted by elastomeric air-purifying respirators wear. Conclusion: Reusable elastomeric air-purifying respirators impose little additional physiological burden over the course of 1 hour at usual health care work rates. However, the potential for carbon dioxide retention in a significant proportion of users exists and requires further investigation.","The current pandemic influenza and previous experience with other respiratory infectious outbreaks (eg, avian influenza, severe acute respiratory syndrome) have raised concerns about the availability of disposable N95 filtering face piece respirators (N95 FFRs). Given the very real possibility of N95 FFR shortages, elastomeric air-purifying respirators (EAPRs) for health care workers (HCWs) have been suggested as one alternative. 1 These are reusable, air-purifying respirators with face pieces made of pliable materials (eg, silicone, rubber, plastic) that employ 1 or 2 particulate filters and come in full face piece or half-mask models, of which the latter is the more commonly used in health care. 2 Compared with disposable N95 FFRs, EAPRs offer advantages that include improved face seal (for some wearers), easier donning and doffing, enhanced user seal check capability, ability of the face piece to be decontaminated multiple times, capacity for use by single or multiple HCWs, and potential cost savings during a pandemic. [2] [3] [4] [5] Widespread use of EAPRs in the health care industry has not occurred, 5 and little is known about their physiological impact on HCWs. This study, part of a larger investigation of multiple types of respiratory protection equipment that was carried out over 6 months, 6 was undertaken to determine the physiological burden imposed on HCWs when wearing an EAPR.

Ten HCWs (7 women, 3 men), none of whom had previously used an EAPR, were recruited. Demographic variable means included the following: age, 25.1 years; body weight, 76.0 kg; height, 169.1 cm; and body mass index, 26.4. Nine subjects had never smoked, and 1 subject had not smoked in .1 year (20 pack year smoking history). The study was approved by the National Institute for Occupational Safety and Health's Human Subject Review Board, and all subjects provided oral and written informed consent.

Physiological parameters (heart rate, breathing rate, tidal volume) were monitored with the LifeShirt Ò System (VivoMetrics, Ventura, CA), a lightweight spandex vest incorporating physiological sensors and circumferential respiratory inductive plethysmography (RIP) bands. Minute ventilation was calculated as the product of breathing rate 3 tidal volume. The LifeShirt Ò was calibrated against a fixed volume immediately prior to each trial. Oxygen and carbon dioxide concentrations (percentage) in the EAPR dead space were sampled at 18 samples/second (total sampling volume of 500 mL/ min) via a 2-mm internal diameter sampling line attached to a port in the EAPR face piece (positioned equidistant between nares and mouth) that directed samples to gas analyzers (AEI Technologies, Naperville, IL). The gas analyzers were calibrated before each trial with gas mixtures weighed into the cylinder using a balance that has been calibrated with weights that are certified to the National Institute of Standards and Technology standards. 7 Continuous oxygen saturation and transcutaneous carbon dioxide values were obtained with the Tosca 500 Monitor (Radiometer, Copenhagen, DK), a heated (428C) combination pulse oximeter and Severinghaus-type PCO 2 sensor that is earlobe mounted. The unit was calibrated over a 10-minute period immediately prior to use.

A single model EAPR (North 5500; North Safety, Providence, RI) that incorporates 2 P-100 filters was selected for the study because it had previously been shown to be well tolerated by HCWs 8 (Fig 1) . To ensure proper fit, quantitative respirator fit testing was carried out with the PortaCount Ò Plus (TSI, Shoreview, MN). All subjects attained fit factors $100 (ie, ratio of ambient particles to within-face piece particles), indicating #1% leakage, the level required by the Occupational Health and Safety Administration for half mask respirators. 9 Subjects donned the LifeShirt Ò and were tested in athletic shorts, tee shirts, and athletic shoes (no headgear of any type [eg, caps, head nets, or others] was worn). The EAPR was donned according to the manufacturer's instructions, negative and positive user seal checks 10 were carried out with the sample line pinched off, and the Tosca 500 sensor was attached to the left earlobe. Subjects were exercised for 1 hour (cumulative length of respiratory protective equipment use per shift by nursing staff 11 ) in a randomized fashion at each of 2 treadmill rates representative of HCW activities 12 that have been used in other studies 13, 14 : (1) 1.7 mph (2.74 km/h) treadmill speed (0% grade) that equates to stationary work (eg, writing nursing notes, using a telephone, and others) and (2) 2.5 mph (4.03 km/h) treadmill speed (0% grade) that equates to some bedside nursing patient care activities. Data were compared to 15-minute control values (no EAPR use) for the same subjects, at the same randomized work rates, and obtained no more than 3 weeks prior (15-minute values were considered valid for control purposes because, at relatively low intensity steady state exercise, steady state respiratory parameters are achieved in 3-6 minutes in healthy subjects 15, 16 ). Numerical rating scales (ie, modified Borg Rating of Perceived Exertion [numerical range, 0-5; least to most exertion 17 ]; modified Perceived Comfort Scale [numerical range, 1-5; most comfortable to least comfortable 18 ]) were utilized for subjective evaluations of exertion and comfort. Speaking was allowed ad lib by subjects throughout the trials to mimic HCW communicating with staff, patients, and visitors. At the end of each trial, subjects filled out questionnaires related to any subjective sensations experienced (eg, facial heat, sweating, and others) or design features (pinching, odor, and others) causing discomfort. EAPRs were weighed pretrial and post-trial to determine moisture retention. A new EAPR was utilized for each of the 2 sessions, and there was a minimum 30-minute respite between sessions. The study laboratory average temperature was 21.768C (range, 20.18C -22.48C) and the relative humidity averaged 58.3% (range, 47.4%-71.5%).

All physiological data and respirator dead space CO 2 and O 2 data are reported as means (standard deviation). The time of the sessions is 1 hour, and all variables are reported as mean 1-minute values at 5 time increments (1, 15, 30, 45 , 60 minutes [Tables 1 and 2]). One-hour averages were used for the statistical analysis because no significant changes over time were observed at the individual time increments. To assess differences between the EAPR and controls at the 2 intensity levels during 1 hour of exercise, a 1-way (4 conditions) repeated measures analysis of variance (ANOVA) was performed. To determine differences for physiological variables, repeated-measures ANOVAs for oxygen saturation, partial pressure of transcutaneous carbon dioxide, breathing rate, tidal volume, minute volume, and heart rate were performed. Significant differences were further analyzed utilizing pair-wise comparisons tests with least significant differences adjustments with the a level set at P 5 .05. Paired t tests were performed to examine respirator dead space oxygen and carbon dioxide responses to EAPR at the 2 exercise intensities. Exertion scores, comfort scores, and EAPR weights were analyzed by paired t tests. SPSS version 16.0 (SPSS, Inc., Chicago, IL) was used for statistical analyses.

All subjects were able to complete all trials. Compared with controls, the EAPR resulted in significant decreases in breathing rate at both work rates and significantly increased tidal volume at the 1.7-mph work rate; otherwise, there were no statistically significant differences in measured physiological variables (Tables 1 and 2) There were no significant differences in mean mixed inhalation/exhalation respirator dead space carbon dioxide concentrations at 1.7 mph and 2.5 mph (P 5 .61) or respirator dead space oxygen concentrations at 1.7 mph or 2.5 mph (P 5 .80) ( Table 2 ). There were no significant differences between controls and EAPR in mean exertion scores at 1.7 mph (P 5 .67) and 2.5 mph (P 5 .96), mean comfort scores (P 5 .67 for both comparisons), or EAPR moisture retention (P 5 .72) ( Table 3) . Subjective complaints and EAPR features associated with discomfort are listed in Table 3 .

The study data indicate that the use of an EAPR by healthy HCWs, over 1 hour at work rates associated with the health care environment, was associated with statistically significant decreases in the breathing rate at 1.7 mph (P 5 .02) and 2.5 mph (P 5 .03) that was compensated by a significant increase in the tidal volume at 1.7 mph (P 5 .009) and nonsignificant increase at 2.5 mph (P 5 .14) compared with controls (Table 3) . This is not unexpected because all respirators alter breathing patterns, and the increased ventilation associated with the (generally) greater dead space of the EAPR compared with FFRs (eg, N95 FFR, and others) usually employed by HCWs, favors an increase in tidal volume over breathing rate because it is more efficient from an energy standpoint. 19 A recent review concluded that respirator use has little impact on minute volume during resting or low-intensity work conditions like those normally encountered in health care environments. 20 Mean absolute increases in transcutaneous carbon dioxide with the EAPR at 1.7 mph (13.2 mm Hg) and 2.5 mph (12.1 mm Hg) were not significantly different from controls (P 5 .09, P 5 .27, respectively). Of concern is the finding that mean transcutaneous carbon dioxide levels, averaged over the course of the last 15 minutes of the EAPR use, were elevated (ie, .45 mm Hg) in 4 of 10 subjects at the 1.7-mph work rate (range, 46-56 mm Hg) and 5 of 10 subjects at the 2.5-mph work rate (range, 45.4-62.8 mm Hg), despite the EAPR being equipped with an exhalation valve that presumably allows for a smaller proportion of the exhaled breath (and associated carbon dioxide) to be retained in the respirator dead space (all subjects were asymptomatic of hypercapnia). 21 Furthermore, at the 2 work rates, the mean mixed inhalation/exhalation respirator dead space oxygen concentrations (17.85%, 17.81%, respectively) and respirator dead space carbon dioxide concentrations (2.50%, 2.47%, respectively) did not meet Occupational Health and Safety Administration ambient workplace standards (ie, ,19.5% is considered oxygen deficient; maximum 0.5% carbon dioxide as an 8-hour time weighted average), 22 although these standards apply to the workplace, not to respirators. Oxygen saturation was not adversely affected. Nonetheless, this raises concerns that extended continuous EAPR wear (.1 hour) might lead to further increases in transcutaneous carbon dioxide that could be deleterious to the wearer. Also, the impact of mild-to-moderate EAPRassociated increased retention of carbon dioxide upon specific subgroups of HCWs who might be more susceptible to hypercapnia (eg, pregnant, asthmatics, and others) needs to be considered. Although the use of other air-purifying respirators (ie, gas masks) for upwards of 2 hours by pregnant women in active labor without adverse effects on mother or fetus has been reported, 23 as has tolerance to EAPR use by controlled asthmatics over short periods of mild-to-moderate work activities, 24 data are scarce overall.

Comfort is an important determinant of compliance with the use of respiratory protective equipment. 8 In the current study, mean comfort scores with the EAPR were low (indicating less discomfort) and were not significantly different from controls at either work rate, suggesting that EAPRs are reasonably comfortable. Part of this comfort may be related to the low exertion work rates employed in this study, as supported by the fact that no significant differences were noted in the (low) mean exertion scores reported when comparing controls and EAPR use at either work rate. Furthermore, recent findings on HCWs respirator tolerance (a measure of comfort) reported that the same model of an EAPR as used in the current study was tolerated, on average, for 6.8 hours of use. 8 Nonetheless, numerous complaints were offered by the current study subjects regarding subjective symptoms and design features ( Table 3 ) that lend some credence to other recent findings that an EAPR, although tolerable, has a greater adverse subjective impact on wearers than N95 FFRs. 24 Moisture retention in respiratory protective equipment has been anecdotally suggested as a possible mechanism for increased respirator breathing resistance with prolonged use because of trapping of moisture in filter pores 4,25,26 but has not been subjected to scientific scrutiny of any significant degree. Although no significant differences in moisture retention were noted at the 2 work rates (P 5 .72), we did not perform airway pressure measurements and cannot comment on any physiological effect of the moisture retention. We observed that there was significant moisture on the inner surface of the EAPR, including the exhalation valve, no doubt related to the relatively nonporous nature of the materials.

Limitations of the current study include the relatively small sample size (n 5 10). There are many differences between this model and the many EAPRs available on the market with respect to materials (eg, silicone, rubber, plastic), price, size, weight, tethering device configuration, filters and performance so that we are unable to generalize our findings to other EAPRs. The study subjects had no prior experience with an EAPR, and that could have negatively impacted performance, but this may be a more plausible study group given that most HCWs have not had experience with EAPRs. 6 The use of RIP for ventilation data is subject to intra-and interpersonal variability 19 and is not as reliable as standard laboratory monitoring equipment (eg, spirometer, pneumotachygraph), but refinements in RIP have led to improved accuracy in recent exercise studies. 27, 28 Similarly, transcutaneous carbon dioxide levels are not as precise as arterial measurements, but improvements in sensors have led to greater precision, 29, 30 and this technique is not discomforting to the subject and avoids needle puncture-associated complications. Last, the current study was not carried out in a health care facility; however, laboratory studies have been suggested as actually representing the upper boundary of study parameter measurements. 24 

Compared with controls over the course of 1 hour at 2 work rates associated with the health care environment, EAPR use by HCWs results in a lower breathing rate and compensatory higher tidal volume. Absolute increases in transcutanous carbon dioxide levels over control values were not statistically significant over the course of 1 hour and not associated with symptomatology of hypercapnia, but variable retention of carbon dioxide occurred in a significant proportion of subjects and is a cause for concern. This will have to be evaluated further in a larger study and over more prolonged periods of continuous use. Subjective ratings indicated that, although an EAPR was tolerable over 1 hour and not associated with significant perceptions of exertion, comfort was negatively impacted.

",0.7664231234865201
Protecting healthcare staff from severe acute respiratory syndrome: filtration capacity of multiple surgical masks,"Guidelines issued by the Centers for Disease Control and Prevention and the World Health Organisation state that healthcare workers should wear N95 masks or higher-level protection during all contact with suspected severe acute respiratory syndrome (SARS). In areas where N95 masks are not available, multiple layers of surgical masks have been tried to prevent transmission of SARS. The in vivo filtration capacity of a single surgical mask is known to be poor. However, the filtration capacity of a combination of masks is unknown.","Severe acute respiratory syndrome (SARS) is a highly contagious, potentially life-threatening condition that frequently affects healthcare workers caring for infected patients. 1 The exact mode of transmission is unknown but may involve airborne as well as respiratory droplet and fomite spread. In view of the possibility of airborne transmission, current guidelines issued by the Centers for Disease Control and Prevention (CDC) and the World Health Organisation (WHO) state that healthcare workers should wear N95 masks or higher-level protection during all contact with suspected SARS patients. These masks are expensive and not necessarily easily available in poorer countries. In some areas, multiple layers of surgical masks have been tried to prevent SARS transmission.

The filtration capacity of a single surgical mask is known to be poor. 2 It is not known whether this improves when more than one mask is worn simultaneously.

This was a prospective unblinded study of six healthy volunteers using combinations of one, two, three or five surgical masks (Surgikos, Johnson & Johnson, Arlington, TX, USA). The Surgikos mask is a pleated rectangular three-ply mask with a bacterial filtration efficiency of 95% at 3 mm. All volunteers gave written informed consent. Approval was obtained from the Clinical Research Ethics Committee of The Chinese University of Hong Kong.

All six volunteers underwent a set of tests with each of the combinations of masks. These involved standard testing procedures using a protocol described previously. 3 In brief, the tests consisted of comparisons of particle counts inside and outside the masks during a series of activities: normal breathing, deep breathing, turning the head from side to side, flexing and extending the head, talking loudly, and bending over followed by normal breathing again. The tube for sampling the mask particle count was connected to a test probe that was inserted through the fabric of the protective device. The probes were provided by TSI (TSI Incorporated, St Paul, MI, USA) for this purpose. The design of the probe is such that there is no leak around the insertion point, so the efficiency of the mask at filtering ambient particles should remain unchanged. The insertion site was centrally in the area directly in front of the mouth, as per the instructions for use provided by TSI. The tube for sampling the ambient particle count was fixed approximately 3 cm from the sampling probe.

A PortaCount Plus (TSI Incorporated) connected to a computer running FitPlus for Windows software (TSI Incorporated) was used to count particles and calculate the ratio of ambient to device particle counts. This device counts all particles with a diameter between 0.02 and 1 mm. It calculates a fit factor, which is the average ratio of atmospheric to device particle concentrations. The equation used is:

where N is the number of exercises performed and ff j is the fit factor for the individual exercise. One modification was made to the PortaCount Plus. The re-usable tubing supplied by the manufacturer was replaced with disposable PVC tubing of the same internal diameter and length to minimize any risk of cross-infection. To ensure an adequate ambient particle count throughout the testing, the 8026 Particle Generator (TSI Incorporated) was used to generate saline particles throughout the testing procedures. Each surgical mask was tied separately.

The American National Institute for Occupational Safety and Health requirements for a half mask respirator are that it should have an assigned protection factor of 10. 4 Further to this, a safety factor of 10 is required when conducting performance or fit testing, so a half face respirator should achieve a minimum fit factor of 100.

Data obtained while wearing one mask were compared with data obtained while wearing five masks using a paired t-test (Statview 5.0, SAS Institute, Cary, NC, USA). A P value !0.05 was considered to be significant.

Results of the filtration capacity of the devices are shown in Figure 1 . The median reduction in particle count for a single surgical mask was 2.7. This increased to 5.5 with five surgical masks. The difference in particle count reduction in a given subject between one and five surgical masks ranged from 1.6 to 4.2. The best particle count reduction with five surgical masks was 13.7 times, which is less than the required value of 100 for a half face respirator.

Our data confirm previous findings that the filtration of submicron-sized airborne particles by a single surgical mask is minimal. The ratio of the concentration of particles inside the mask to the concentration in ambient air was only 2.7. Although greater filtration was afforded by multiple masks, with an approximate doubling in the filtration factor when five masks were worn compared with a single mask, the absolute filtration factor remained low and well below the minimum fit factor of 100 required for a respirator. For this reason, even multiple masks are not a suitable alternative to N95 masks when the latter are available.

The more difficult question to answer is whether the use of multiple masks provides significant, albeit suboptimal, protection against infection with SARS Co-V. This is likely to depend on the route of transmission of SARS Co-V, the viral load required to cause infection and the degree of viral shedding by the patients.

Surgical masks are designed to prevent the wearer from transmitting infection to others, but do provide some protection against respiratory droplet and fomite spread. If SARS Co-V is not transmitted by airborne particles but only by respiratory droplets and fomites, even one surgical mask is likely to protect the user to a significant degree. If the virus is spread by airborne transmission, the likelihood that surgical masks will provide significant protection is dependent on the viral load required to cause infection and the degree of viral shedding by the patient(s). If the number of viruses required to produce clinically significant infection is low and large numbers of viruses are shed by patients, it is unlikely that even multiple surgical masks will provide significant protection. If, however, large numbers of viruses are required and small numbers are shed, it is more likely that multiple surgical masks will provide significant protection. Unfortunately, those data are not available, although an epidemiological study has suggested that SARS is only moderately infectious. 5 Data from a recent retrospective multiple logistic regression study suggest that surgical masks may afford significant protection against SARS. This study showed that wearing either a N95 mask or a surgical mask reduced the risk of contracting SARS with little difference in risk reduction. 6 These data must be treated with considerable caution for two reasons. Firstly, the authors took no account of the degree of exposure of the wearers to high-risk situations. It is likely that staff exposed to high-risk situations would be more likely to wear a N95 mask, while those only exposed to low-risk situations would be more likely to wear a surgical mask. Without controlling for this confounding factor, it is not reasonable to compare the two types of mask. Secondly, the number of staff who contracted SARS was too small to allow meaningful multiple logistic regression analysis.

One limitation of the study is that the Portacount measures dust particles of less than 1 mm in size rather than SARS CoV. If SARS CoV is carried on larger particles, it is possible that the masks may provide better protection than our results suggest. On the other hand, surgical instruments are known to produce submicron-sized particles that carry viable viral particles. 7 Furthermore, a study has shown that particles of up to 22 mm in size enter the respiratory zone when these masks are worn. 8 In conclusion, our data show that no combination of multiple surgical masks was able to meet the requirements for a respirator. If protection against airborne organisms is required, an N95 respirator or better should be used, as currently recommended by the CDC and WHO guidelines for SARS prevention. Multiple surgical masks will reduce the number of viruses inhaled, but whether the degree of reduction is sufficient to produce significant protection is unknown and cannot be predicted at present. Multiple surgical masks should, therefore, only be used if N95 masks are not available.

",0.7653716285024096
Review of economic evaluations of mask and respirator use for protection against respiratory infection transmission,"Background: There has been increasing debate surrounding mask and respirator interventions to control respiratory infection transmission in both healthcare and community settings. As decision makers are considering the recommendations they should evaluate how to provide the most efficient protection strategies with minimum costs. The aim of this review is to identify and evaluate the existing economic evaluation literature in this area and to offer advice on how future evaluations on this topic should be conducted. Methods: We searched the Scopus database for all literature on economic evaluation of mask or respirator use to control respiratory infection transmission. Reference lists from the identified studies were also manually searched. Seven studies met our inclusion criteria from the initial 806 studies identified by the search strategy and our manual search. Results: Five studies considered interventions for seasonal and/or pandemic influenza, with one also considering SARS (Severe Acute Respiratory Syndrome). The other two studies focussed on tuberculosis transmission control interventions. The settings and methodologies of the studies varied greatly. No low-middle income settings were identified. Only one of the reviewed studies cited clinical evidence to inform their mask/respirator intervention effectiveness parameters. Mask and respirator interventions were generally reported by the study authors to be cost saving or cost-effective when compared to no intervention or other control measures, however the evaluations had important limitations. Conclusions: Given the large cost differential between masks and respirators, there is a need for more comprehensive economic evaluations to compare the relative costs and benefits of these interventions in situations and settings where alternative options are potentially applicable. There are at present insufficient well conducted cost-effectiveness studies to inform decision-makers on the value for money of alternative mask/respirator options.","Both the World Health Organisation (WHO) and the Centre for Disease Control (CDC) guidelines recommend the use of a mask in low-risk settings and a respirator in high-risk settings (e.g. during aerosol generating procedures) to protect healthcare workers (HCWs) from seasonal influenza [1, 2] . The use of a respirator at all times is also advised for HCWs caring for patients with suspected infectious tuberculosis [3, 4] . These measures are important to protect HCWs as well as to reduce the spread of respiratory infections within hospitals. This can help to reduce both the costs associated with HCW absenteeism and the costs of nosocomial infections.

Mask/respirator availability may also prove crucial in the context of newly emerging respiratory infections, particularly as some diseases such as SARS (Severe Acute Respiratory Syndrome) and MERS-CoV (Middle East Respiratory Syndrome Coronavirus) may initially have no vaccine or treatment available, leaving nonpharmaceutical measures as the only available protection for HCWs. For other diseases such as pandemic influenza, reliance on vaccines for protection is not always possible due to time delays in vaccine development, manufacturing and distribution [5] . Furthermore, the stockpiling of relatively expensive antivirals for influenza pandemics may not be cost-effective in low and middle income settings [6] .

In the absence of standardised mask/respirator nomenclature [7] , we will use the term 'mask' to indicate standard surgical masks, also referred to as ""medical masks"" in some countries. These are not specially engineered to protect the wearer from aerosol transmission of droplet nuclei and viral particles [8, 9] . 'Respirator' will be used to denote all personal protective facemasks engineered for filtration and fit to prevent the transmission of respiratory viruses and aerosol droplets. Several air purifying respirators that filter the inhaled air through filtering materials are available for use by HCWs [10] , these include: N95, HEPA (high-efficiency particulate air), PARP (powered air purifying respirator), DM (dust-mist) and DMF (dust-mist-fume).

There are substantial differences in cost between different mask/respirator options. These cost differences may be an important determinant in the development of country specific mask/respirator guidelines for HCWs. For example, the more costly PARP is only recommended in the guidelines for high income countries [7] . Many countries' guidelines recommend fit testing and training sessions for respirator use, but contain limited descriptions of what this should entail [7] . Fit testing can be qualitative or quantitative, with the latter being more expensive and adding a substantial cost to respirator use but not to mask use, which does not require fit testing [10] .

Two studies evaluating mask/respirator use [11, 12] were included in a previous economic review of influenza pandemic measures [13] . There are a small but growing number of economic evaluations for masks/respirators. The aim of this review is to identify and evaluate this existing literature and offer advice on how future evaluations on this topic should be conducted.

The Scopus database was searched for all Englishlanguage literature on the economic evaluation of mask or respirator use for the control of respiratory infection transmission. Scopus includes 100 % coverage of both MEDLINE and EMBASE [14] . The majority of the relevant literature identified in the initial Scopus search included influenza or tuberculosis as either the single focus or one of the diseases to control. For this reason, these terms (influenza OR tuberculosis) were used in addition to the generic terms related to infection and transmission, i.e. they did not prevent the identification of articles focused on other infectious respiratory diseases. The final search strategy contained publications until the 1st of August 2014, and used the search terms (as keyword, title or abstract): 'facemask*' (or 'mask*' or 'respirator' or 'N95' or 'non$pharm*' or '{personal protect*}') AND 'economic*' (or 'cost*') AND 'infect*' (or 'transmi*' or 'influenza' or 'tuberculosis').

The 806 results from this initial Scopus search were screened (Fig. 1) . The abstracts of these articles were reviewed on the basis of whether they were economic evaluations (e.g. cost-effectiveness, cost-utility or costbenefit studies), and whether the intervention being evaluated involved masks and/or respirators as a strategy to prevent the transmission of respiratory infections. From this process, 112 full text articles were considered potentially relevant and their full texts were further reviewed for eligibility. Of these, only six were confirmed to be economic evaluations of mask or respirator infection control interventions. One additional study by Dan et al. [12] was identified from the reference list of a systematic review [13] . These were the main studies used in our qualitative synthesis. Four other costing studies [15] [16] [17] [18] have been published but these examined the cost of the intervention only and were not classified as full economic evaluations (i.e. they did not examine the health impacts or the cost savings from prevented illness). Data from the included studies was independently extracted intro a spread sheet by SM and this was reviewed by ATN. Disagreements were resolved by discussion between these authors.

Seven economic evaluations of mask/respirator use in the control of respiratory infections were identified (Table 1) [11, 12, [19] [20] [21] [22] [23] . These studies varied widely in their settings and methodologies. The studies by Adal et al. [19] and Nettleman et al. [23] were published in 1994 and were on tuberculosis in healthcare settings. Five others (published post 2008) were focused on seasonal or pandemic influenza [11, 12, [20] [21] [22] . One of these by Dan et al. [12] also considered a SARS scenario. Other than this study, to date, no other mask/respirator economic evaluations have been identified that focus on SARS, MERS-CoV or other respiratory viruses (other than influenza). There were also no economic evaluation studies identified on mask or respirator use to prevent transmission of Ebola.

The interventions evaluated by the studies included N95 respirators [12, 20, 22] , HEPA, DM and DMF respirators [19, 23] , and surgical masks [19] [20] [21] 23] . Amongst the studies that focused on influenza, two of the five, by Dan et al. [12] and Chen and Liao [21] , integrated mask/respirator use in a scenario in conjunction with other non-pharmaceutical control measures e.g. natural ventilation [21] or isolation measures [12] , as opposed to evaluating the use of masks/respirators exclusively. This makes it difficult to assess to what degree the mask/respirator aspect of the intervention is driving the cost-effectiveness, or if the results are more attributable to the other control measures included.

The settings of the evaluated studies varied more broadly for the influenza studies than for those on tuberculosis. Three of the five influenza studies were in a community setting [11, 20, 22] . Of the others, one considered control measures for both the community and hospital setting [12] and the last was set in a primary school [21] . All of the seven identified studies were set in the USA or other developed countries, limiting the generalisability of the findings, e.g. for decision making in low resource settings. The lack of studies in low resource settings has been cited as one of the major impediments to the use of cost-effectiveness analysis for pandemic influenza preparedness planning in this context [24] .

Four of the five influenza studies included the number of infection cases as one of the outcome measures of intervention effectiveness (Table 1) [11, 12, 21, 22] . The remaining influenza study quantified and reported the consequences of infection on other outcomes e.g. prevented deaths, hospitalisations, outpatient visits and absenteeism [20] .

Both tuberculosis studies measured conversion rates of newly positive protein derivative tests in HCWs at study hospitals [19, 23] . A positive test indicates a 5-10 % chance that the individual will develop active tuberculosis in their lifetime [25] . One of the two studies also estimated the number of patients isolated for known tuberculosis per month, confirmed pulmonary tuberculosis cases in patients in the past year and active cases of pulmonary tuberculosis in HCWs in the last 5 years [23] . This additional information provided a more complete measure of the impact of the intervention.

Only three [12, 19, 23] of the seven studies reported results as cost per unit of effect. The evaluation by Dan et al. [12] of influenza and SARS reported an incremental cost per death averted [12] . The other two were the tuberculosis studies, with one reporting the cost to prevent a single occupational case of tuberculosis in the next 41 years [19] and the other reporting the cost per tuberculosis case prevented and the cost per life saved [23] . Two of the pandemic influenza studies evaluating combinations of interventions in the community concluded that mask/respirator interventions were cost saving in a pandemic setting [11, 22] . The first estimated substantial net savings if 10 % of the population had worn N95 respirators during influenza A(H1N1)pdm09, assuming an effectiveness of 20 % [11] . The second estimated that surgical mask use at 60 % compliance would yield savings of $US100-250 million, far exceeding the estimated intervention cost of $US20 million [20] . The influenza modelling studies by Jones and Adida [22] focused on demonstrating the feasibility of the methods rather than reporting key economic results. The influenza study by Chen and Liao [21] calculated a cost per individual to implement control measures, but limited the inclusion of costs to intervention and outpatient treatments costs.

Approaches to incorporate intervention effectiveness amongst the seven studies varied ( Table 1 ). Both of the tuberculosis evaluations by Adal et al. [19] and Nettleman et al. [23] reported that no efficacy studies were available and thus no specific measures of mask or respirator effectiveness were included in their evaluations. Nettleman et al. [23] assumed that in a best case scenario, HEPA respirators would prevent 25 % of HCW exposure to tuberculosis, but no data was cited to support this estimate. Adal et al. [19] implicitly assumed that all HCW cases of tuberculosis that may have been acquired from patients in isolation with active tuberculosis would be prevented by the intervention.

Of the five influenza studies, Tracht et al. [11] was the only study that attempted to utilise clinical efficacy data. They obtained this from a randomised trial in a university residence setting [26] that found a significant decrease (35-51 %) in influenza-like illness if hand hygiene and medical masks were used together compared to a control, but no difference for medical mask use alone. Tracht et al. [11] uses this result to estimate N95 respirator use provides a 50 % decrease in susceptibility to influenza A(H1N1)pdm09. This may not be robust as the clinical trial measured different outcomes (i.e. influenzalike illness, not influenza A(H1N1)pdm09 cases) and it assumes there is no difference between the efficacy of medical masks and N95 respirators based on the findings of Loeb et al. [27] , although other trials have found evidence that there is a difference [28] . The study by Jones and Adida [22] derived efficacy estimates from the assigned protective factor (APF) measure for N95 respirators released by the National Institute for Occupational Safety and Health [29] . The APF is estimated from laboratory testing completed by this organisation, including laboratory testing of the quantitative measure of fit when the respirators are fit tested to ensure a protective seal around the wearer's face. Cahill et al. [20] also used efficacy estimates from laboratory investigation data [30] . These estimates may have limited applicability to measuring real-world effectiveness [31] . Dan et al. [12] estimated baseline intervention effectiveness rates of 50, 80 and 90 % as protective equipment (including masks) and isolation precautions were increased. They did not cite data to support these estimates, however a 5 % failure rate where transmission still occurs despite the use of protective equipment and isolation measures, was obtained from a hospital simulation study [32] . Chen and Liao [21] applied a relative efficacy estimate of masks in combination with other control measures which was developed in a previous modelling study that did not cite supporting data for efficacy input assumptions [33] . Other than Tracht et al. [11] , none of the analyses used intervention effectiveness estimates from clinical trials such as the mask/respirator randomised trials that have been published to date on interventions in community and healthcare settings [26] [27] [28] [34] [35] [36] [37] [38] .

Only two of the seven evaluations, by Dan et al. [12] and Jones and Adida et al. [22] , explicitly stated the economic perspective from which they had conducted their evaluation, these being a policy developer view [22] and the healthcare institution perspective [12] . On the basis of costs included and excluded, four of the seven studies are most aligned with healthcare payer perspectives [12, 19, 21, 23] and the remaining three with a societal perspective [11, 20, 22] (e.g. they included some form of productivity costs). Both tuberculosis evaluations by Adal et al. [19] and Nettleman et al. [23] , considered costs from a healthcare provider perspective, reflecting the objective of preventing the burden of nosocomial cases in HCWs and patients. The influenza studies [11, 20, 22] more frequently applied a societal perspective, consistent with the substantial economic impact of productivity losses due to influenza absenteeism [39] .

The reporting of costs included in the evaluations was often not transparent. One evaluation by Dan et al. [12] identified the omission of the indirect costs of lost revenue from the cancellation of elective surgeries, decreased outpatient attendance, lost clinical teaching time and administration costs of senior staff meetings. These costs were not discussed in other influenza modelling studies where they may have been relevant [11, 20, 22] . The tuberculosis studies by Adal et al. [19] and Nettleman et al. [23] relied on hospital databases for the number of masks/respirators used, and multiplied this by unit costs to calculate total costs. Administration costs were most thoroughly reported in the tuberculosis study by Adal et al. [19] , which included staff program planning time and staff medical evaluation time.

All of the studies that estimated a cost per case, included the cost of infected individuals [11, 12, [20] [21] [22] . For example, one influenza modelling study by Jones and Adida [22] assumed a fixed average cost for each infection. This may not always be an ideal method to cost resources used as the cost of an average case may vary amongst patients [40] . Tracht et al. [11] allocated a separate average hospital cost per day due to influenza A(H1N1)pdm09 infections for three age groups.

Three of the studies evaluating the intervention in the community included the impact of compliance [11, 20, 22] . These included simple approaches, as used by Cahill et al. [20] of assessing 60 and 100 % adherence scenarios, as well as by Jones and Adida [22] where an estimate of 50 % compliance was assumed. Tracht et al. [11] conducted a more thorough sensitivity analysis by dividing the population into three age groups and testing three scenarios with different proportions of compliance in each group. No study attempted to use compliance rates from real-world investigations such as clinical trials [28, 36] .

There were a relatively small number of economic evaluations of mask/respirator use that met the inclusion criteria and no existing studies were found that address the costeffectiveness of these interventions in low-middle income countries. The seven evaluations identified have limited utility to advise decision makers on the value for money that masks and respirators offer compared with other health spending choices. This is due to the reporting of results in the form of intermediate outcomes (e.g. case prevented) and the analysis of combinations of masks/ respirators with other protection measures in evaluations [12, 21, 22] . There was also limited inclusion of clinical data to inform the effectiveness estimates and the impact of intervention compliance in the identified studies. Compliance has major implications for a mask/respirator intervention targeting HCWs [9] . For example, obtaining high adherence in HCWs has not been feasible in some high-income countries such as Australia [41] . Variation in HCW mask/respirator compliance has been observed between countries, such as the lower rates seen in UK hospitals compared to Hong Kong and Singapore during influenza A(H1N1)pdm09 [42] . Mask/respirator adherence is primarily driven by perceived susceptibility to the infectious disease threats present [43] [44] [45] [46] [47] [48] .

What clinical evidence is there on comparative mask and respirator effectiveness?

Only one of the reviewed studies [11] cited clinical evidence to support their mask/respirator intervention effectiveness parameters. However, there is a growing body of research in this area. An initial systematic review on the topic reported pooled efficacy measures from case control studies for N95 respirators and medical masks of 91 and 68 % respectively for the prevention of respiratory viruses [49] . A weakness of this initial review was that the case control studies included in the metaanalysis focused exclusively on SARS [50] . As a consequence, it should not be assumed that the conclusions of this meta-analysis are necessarily true for influenza or other respiratory infections [51] .

The updated edition of this review concluded that there was no evidence of a significant difference in effectiveness between N95 respirators and medical masks [50] . However, this conclusion was heavily influenced by a single cluster randomised trial by Loeb et al. [27] that compared N95 respirators and medical masks, both used selectively in high-risk situations. This trial contained only 446 HCWs and may have been underpowered to detect a difference between the arms [28] . Two larger trials not included in this review have been published [28, 36] . One of these by Macintyre et al. [28] , involving 1669 HCWs, found significantly greater protective efficacy for continuous N95 use when compared to continuous medical mask use, but no evidence that selective N95 use was superior to continuous medical mask use for the prevention of clinical respiratory illness [28] .

The limitations of the review include the restriction to English language articles used in the search of the Scopus database. Further potential limitations are that the identification and screening process was carried out predominantly by one of the authors (SM). Finally, the limited number of studies identified for inclusion made it difficult to make general conclusions about costeffectiveness.

One key recommendation is that future economic analyses should attempt to apply clinical mask/respirator efficacy data, preferably from clinical trials, where this data is deemed applicable to the infectious agent, intervention and setting, rather than using estimations derived from expert opinion or laboratory testing studies [31] . In some cases this may not be possible, for example, it is not appropriate to extrapolate clinical trial results for respiratory viruses to tuberculosis and for ethical reasons, randomised trial data cannot be collected on the effectiveness of a respirator intervention in HCWs for tuberculosis prevention. While the use of other types of efficacy data applied in the studies identified by this review have limitations, the results of the studies may still have validity. However, the underlying assumptions made in the analyses do need to be carefully considered.

Although economic evaluations have been conducted for the use of mask/respirator strategies in HCWs for tuberculosis, the way these evaluations should be used to inform policy needs to be carefully considered. Costeffectiveness criteria should only be one part of the decision making process for any intervention and there may be specific cases where this factor should be given less weight. Economic evaluations would be of less relevance to a decision maker in situations and settings where a respirator would be used regardless of its cost-effectiveness, but they may be more useful in evaluating situations where these devices are not currently recommended in a given setting.

Future evaluations should report their results in such a way that would allow them to be easily compared to other non-pharmaceutical or pharmaceutical interventions (e.g. cost per quality-adjusted life year (QALY) gained). If an evaluation fails to report results in an appropriate format, this limits its use for decision making as it means that the value of mask/respirator interventions cannot be compared with spending on healthcare interventions targeted at other diseases [40] . However, in some cases the use of intermediate outcomes (e.g. cases prevented) can still be useful for comparing alternative ways of reducing specific infection events. This may provide useful information to decision makers.

Future analysts may also want to consider whether masks/respirators are cost-effective for use by HCWs in the seasonal influenza context, or if they are only costeffective in extreme pandemic scenarios which may necessitate a stockpiled supply of masks/respirators.

Although the WHO and the CDC recommend that HCWs use masks for low-risk influenza exposure and respirators for high-risk influenza or tuberculosis exposure [1] [2] [3] [4] , there is currently a lack of economic evidence to support these recommendations. Further robust economic evaluations on mask/respirator interventions are needed.

Abbreviations HCW: Healthcare worker; HEPA: High-efficiency particulate air; PARP: Powered air purifying respirator; DM: Dust-mist; DMF: Dust-mist-fume.

Competing interests RM receives funding from influenza vaccine manufacturers GSK and CSL Biotherapies for investigator-driven research. She has also been on advisory boards for Wyeth, GSK and Merck.

Authors' contributions ATN and RM initiated the study. ATN and SM developed the search strategy and selection criteria. SM carried out the systematic review and drafted the initial manuscript. ATN assisted with the interpretation of economic data. RM assisted with the interpretation of available efficacy data. All authors contributed to revising the manuscript and read and approved the final manuscript.

",0.7643743342404887
The Respiratory Protection Effectiveness Clinical Trial (ResPECT): a cluster- randomized comparison of respirator and medical mask effectiveness against respiratory infections in healthcare personnel,"Background: Although N95 filtering facepiece respirators and medical masks are commonly used for protection against respiratory infections in healthcare settings, more clinical evidence is needed to understand the optimal settings and exposure circumstances for healthcare personnel to use these devices. A lack of clinically germane research has led to equivocal, and occasionally conflicting, healthcare respiratory protection recommendations from public health organizations, professional societies, and experts. Methods: The Respiratory Protection Effectiveness Clinical Trial (ResPECT) is a prospective comparison of respiratory protective equipment to be conducted at multiple U.S. study sites. Healthcare personnel who work in outpatient settings will be cluster-randomized to wear N95 respirators or medical masks for protection against infections during respiratory virus season. Outcome measures will include laboratory-confirmed viral respiratory infections, acute respiratory illness, and influenza-like illness. Participant exposures to patients, coworkers, and others with symptoms and signs of respiratory infection, both within and beyond the workplace, will be recorded in daily diaries. Adherence to study protocols will be monitored by the study team.","Healthcare personnel (HCP) are exposed to respiratory pathogens in many clinical settings [1] . Infected HCP may spread infection to their patients [2] [3] [4] [5] or coworkers [3] [4] [5] [6] , to family members [4, 7] , or to other community members [4, 8] . Respiratory viral infections among healthcare workers can negatively impact delivery of healthcare services [9] [10] [11] .

United States national guidelines call for modes of transmission to dictate infection control measures [3] . For most human respiratory viruses, the precise mode(s) of person-to-person transmission is incompletely understood [12, 13] . The predominant mode of transmission for some human respiratory pathogens, such as influenza virus, respiratory syncytial virus, and coronavirus is believed to be droplet transmission. Airborne transmission plays a role with some human respiratory pathogens via small aerosol particles, often called droplet nuclei [3] . Airborne transmission is the predominant mode of transmission for Mycobacterium tuberculosis [3, 14] and recent evidence has suggested a larger role than previously thought for Influenza A and B viruses [15, 16] .

Disposable respiratory protective devices (RPD) that fit tightly to the wearer's face, sometimes called airpurifying respirators or filtering facepiece respirators, are primarily designed to protect the wearer against infection spread by ill patients. N95 filtering facepiece respirators (commonly known as ""N95 respirators"") are one type of RPD capable, with proper facial fit and usage, of reducing inhalation of airborne particulates by a factor of 10 or greater [17] . Medical masks (MM), typically called surgical masks in operative settings, are primarily devised to protect patients against infection spread by the wearer [18] . Both types of devices also serve as a physical barrier keeping sprays and splashes of infectious materials and contaminated hands and objects away from oronasal region of wearer. Although RPD and MM are capable of filtering particulates [19] , RPD are designed to filter smaller particulates that may remain airborne for long periods. A tight seal between the respirator and the wearer's face is designed to prevent leakage of particulates, a feature not provided by loose-fitting MM. The U.S. Department of Labor's Occupational Safety and Health Administration (OSHA) requires employers to ensure each HCP, who may be exposed to airbornetransmissible infections in the workplace, receives an RPD with an adequate respirator-to-face seal that is determined during a mandated annual ""fit-test"".

However, evidence is inconclusive that RPD are better than MM at protecting HCPs from respiratory infections in clinical settings [20] [21] [22] [23] [24] [25] , despite tight-fitting RPD produced by manufacturers, with higher levels of exposure reduction validated by numerous laboratory studies [19, [26] [27] [28] , and the use of a complete respiratory protection program (e.g., training, initial and annual fit test) as defined by OSHA to protect HCP. Intuitively, RPD should better protect HCP against airborne infections than MM, but objective evidence has not validated this supposition. One possibility that may explain this discrepancy between expectations and observations is pragmatic: HCP, in general, do not tolerate N95 respirators as well as medical masks [29, 30] , perhaps prompting them to remove respirators more frequently and/or for longer periods, increasing the likelihood of exposure to infections. Models have shown that 25 % or more non-wear time during exposure negates any significant differences in protective ability between types of RPDs [17, 31] . Given the difficulty with HCP adherence to guidelines [4] and general dissatisfaction [4, [32] [33] [34] with RPD, medical masks worn more consistently may provide similar levels of reduction in respiratory viral disease transmission as N95 respirators.

This key gap in knowledge has contributed to discrepant clinical and public health recommendations about respiratory protection for HCP [35, 36] . Needed are additional well-designed clinical trials conducted in patientcare settings during outbreaks of respiratory infections. The following is an abridged version of the full research protocol for the Respiratory Protection Effectiveness Clinical Trial (ResPECT).

To compare the effectiveness of N95 respirators and medical masks at protecting HCP from acquiring viral respiratory illnesses in the workplace.

Null Hypothesis: The incidence of laboratory confirmed influenza (primary), influenza-like illness (ILI), acute respiratory illness (ARI) and other respiratory infections will not be different between HCPs who practice 2007 guidelines (medical masks) or 2009 guidelines (N95 respirators).

Alternative Hypothesis: The incidence of laboratory confirmed influenza (primary), influenza-like illness (ILI), acute respiratory illness (ARI) and other respiratory infections will be different between HCPs who practice the CDC's 2007 guidelines for influenza protection (medical masks) versus 2009 guidelines for influenza protection (N95 respirators).

ResPECT is a prospective comparison of respiratory protective equipment to be conducted at multiple, geographically distributed U.S. study sites. HCP who work in outpatient settings will be cluster-randomized to wear N95 respirators [37] or MM [38] for protection against infections during respiratory virus season, the ""intervention"" period.

The null hypothesis assumes N95 and MM intervention groups will have no differences in outcomes, including (1) laboratory confirmed influenza or (2) influenza-like illness (ILI), (3) acute respiratory illness (ARI), and (4) laboratory confirmed respiratory illness (LCRI). The alternative hypothesis asserts the incidence of at least one outcome would be different between intervention groups.

Because respiratory virus season varies year-to-year in onset, severity, and duration, multiple season-years of the study will be necessary to account for expected variance and optimally generalize the resulting knowledge. The beginning of each season's data collection will be independently determined for each study site using an epidemiologic predictive tool designed for ResPECT to capture the largest possible number of respiratory infections. These data will be collected for twelve weeks each season.

Participant exposures to patients, coworkers, and others with symptoms and signs of respiratory infection, both within and beyond the workplace, will be recorded in daily diaries. Adherence to study protocols will be measured by the study team at each site. Since periodic changes in infection control guidance and practice may occur over the study years, participants will be expected to adhere to the most up-to-date guidance issued by the Centers for Disease Control and Prevention (CDC) and local policies at each study institution, at a minimum. For example, a participant randomized to the MM arm will be expected to don an N95 when participating in an aerosol-generating procedure, assuming no further changes in pertinent national guidance [39] .

The study participants will be recruited from outpatient settings where patients are relatively likely to present with symptoms and signs of acute respiratory infection. Participants will be eligible to enroll for multiple study seasons, yet each will be provided with informed consent and complete enrollment procedures prior to each study season.

Clinical Study sites will be distributed geographically: 

Participants will be cluster-randomized to one of the following N95 respirators or MM models, selected because they are commonly used in U.S. medical facilities, including the ResPECT study sites. Participants who participate in more than one of the study years will be cluster-randomized anew each year. N95 Respirators: 

(1) Precept 15320 or (2) Kimberly Clark Technol Fluidshield 47107.

All subjects participating in the study will be required to pass an OSHA-accepted respirator fit test for the N95 respirator model(s) available at the study site. No fit testing of medical masks will be performed as these devices are not designed to be tight-fitting to the face and studies [19, 20] have shown that their fit capabilities are generally low.

Filter Performance Although medical masks are loose-fitting, they create a physical barrier that helps prevent splashes and sprays from reaching the wearer's mucous membranes. In addition to passage around the mask, some of the small particle aerosols are able to pass through the mask's filter media. Therefore, in addition to RPDs, filtration testing was done on medical masks prior to enrollment of subjects to ensure consistency between models across study locations. The filtration performance of the N95 respirators and medical mask models in the study were tested in a manner similar to that used by the National Institute for Occupational Safety and Health (NIOSH). Devices were attached to a test fixture and placed in a TSI 8130 automated filter tester operated with an air flow rate of 85 liters per minute. The TSI 8130 uses a photometer to measure the flux of light scattering from aerosol particles. Polydispersed particles (mass median diameter of~0.3 microns) were generated from a 2 % NaCl solution and passed through each device being tested for 1 min. Each test was repeated 3 times with a fresh N95 respirator or medical mask. To be certified as an N95 respirator, filter penetration needs to be less than 5 % (or 95 % efficient). As shown in Table 1 , the average penetration percentages for the NIOSH certified N95 respirators were an order of magnitude lower than those of medical masks, which are not NIOSH certified. Filter results between N95 respirator models and between medical mask models were comparable.

Filter airflow resistance was measured simultaneously using the TSI 8130. As filter airflow resistance increases, more energy expenditure is required for ventilation during device wear and the greater potential for perception of discomfort [40] . The medical mask models selected for this study have filter airflow resistance levels about half of that of the N95 respirators. However, one study [40] found that subjective and physiological responses were not different among subjects exercising while wearing devices purposely made with different filter airflow resistance levels (3 mm H 2 O, 6 mm H 2 O, and 9 mm H 2 O) in the range similar to those of the devices in this study (Table 1) .

Participants will be instructed to don a new N95/MM with each patient interaction, every time a participant encounter occurs within 6 feet of a patient who has suspected or confirmed respiratory infection. Hand hygiene will be recommended to all participants in accordance with CDC guidelines [41] and policies at each study institution. Trained research assistants will observe participants during study periods to assess adherence to their assigned intervention arms and hand hygiene. A portable computer equipped with data recording software (HandyAudit; Toronto, Canada) will be used to document adherence. Participants will be expected to complete surveys about their attitudes and opinions concerning personal protective equipment before and after each seasonal study period.

During the twelve week data collection period each year, participants will self-document (a) perceived occupational exposures to patients or coworkers who have symptoms or signs of respiratory infection, (b) perceived 

Anterior nasal and pharyngeal swabs [42] [43] [44] [45] [FLOQSwabs UTM (99-08024), Diagnostic Hybrids; Athens, OH] will be collected by research assistants when symptomatic with study defined respiratory symptoms, as well as two, randomized asymptomatic swabs during each seasonal study period. Swabs will be collected when (a) participants self-report respiratory symptoms within a 24 h period, and again if participants remain symptomatic after 7 days; and (b) randomly, on all participants, twice during the active intervention period. The Primary Outcome Measures will be the incidence of:

Laboratory-confirmed influenza (LCI) A or B infection in participants, defined as a) detection of influenza virus by reverse-transcription polymerase chain reaction (RT-PCR) in an upper respiratory specimen swab collected within seven days of symptom onset, or b) influenza seroconversion defined as at least a 4-fold rise in hemagglutination inhibition antibody (HAI) titers to influenza A or B virus from the pre-to post-season serological samples that is not deemed attributable to vaccine.

The Secondary Outcome Measures will be the incidence of:

(1) Acute Respiratory Illness (ARI) defined as the occurrence of one sign or two symptoms ( The incidence rate ratios between participants randomly assigned to wear N95 respirators or medical masks will be estimated for each of the primary and secondary outcomes.

Investigators will be paired and provided with blinded information about clinical and laboratory data to determine if a participant meets a primary or secondary outcome. If the paired investigators do not agree, a principal investigator will adjudicate the outcome.

Assays will be performed at Johns Hopkins University.

Collected respiratory specimens will be stored at −80°C until analyzed using multiplex PCR (PLEX-ID, Abbott Labs, Chicago IL). Automated extraction of nucleic acid (NA) from respiratory specimens will be performed utilizing NorDiag's Arrow instrument and the Magna Pure robotic system (Roche Indianapolis, IN) per manufacturer instructions. Each extraction run will include a quality control (NATrol Respiratory Validation Panel 3, Zeptometrix Inc., Buffalo NY); runs with control failures will be repeated. Purified NA will be amplified via RT-PCR using a broad respiratory virus identification kit (PLEX-ID RVS 3.0, Abbott Molecular, Des Plaines, IL). Desalting of RT-PCR product and electrospray mass spectrometry-based NA analysis will be performed on the PLEX-ID analyzer instrument. If funding is sufficient, samples will also be assayed by RT-PCR for Bordetella pertussis, Mycoplasma pneumoniae, and for Chlamydophila pneumoniae. 

Each study season, blood samples will be collected twice from each participant; one sample will be collected within two weeks of the beginning of the intervention period and a second within two weeks of the end of the intervention period. Hemagglutination inhibition (HAI) antibody assays will be performed on serum for influenza A and B virus strains, dependent on the antigens in each annual trivalent vaccine using standard methods [46, 47] . In brief, serial 2-fold dilutions of serum samples will be incubated with 8 hemagglutinin units of influenza antigen and a turkey red blood cell suspension. The serum HAI antibody titer will be defined as the dilution factor of the highest serum dilution that completely inhibits agglutination of turkey red blood cells in the presence of type-specific hemagglutinin antigen. Assays will be performed at the immunology core lab for the study at the VA Saint Louis Veterans Affairs Healthcare System.

To optimize compliance and generalizability, a clusterrandomized design will be utilized. All participants working in the same clinical unit will be assigned to wear the same respiratory protective equipment (i.e., an N95 or MM) during patient interactions for the entire 12 week seasonal study period. Clusters will be pairmatched within each study site based on the characteristics of each clinical cluster, including the (a) number of participants (b) occupational location, such as an emergency department, urgent care or primary care, (c) patient population served, such as children or adults, and (d) requirements for participants to wear additional protective equipment, such as goggles donned by dental hygienists. For each study season, the clinics in each matched pair will be randomly assigned to opposing study arms. For matched pairs participating in multiple study seasons, random sequences of arm assignments will ensure each is assigned to both study arms during the multi-year study. Each study season, an individual not involved in the study implementation and data analyses will perform the randomization scheme for each study site, using a random number generator in Microsoft Excel. The principal investigators will be blinded to the randomization scheme prior to assignment.

Incidence rates of LCI, ARI, ILI, and LCRI among cluster-randomized participants will be compared. The relationships between incidence of clinically diagnosed and laboratory-confirmed illnesses will be analyzed with attention to potential confounders, such as participants' demographics, study arm compliance, attitudes and opinions about infection control, receipt of influenza vaccination, and infectious exposures within and beyond the workplace. Standard statistics will describe baseline characteristics and follow-up measures, summarized by treatment arm and stratified by study site.

To assess the primary outcome, a logistic regression model will be fit using a dichotomous variable to indicate whether a participant became infected with a respiratory pathogen. The odds of infection between the two treatment groups will be reported with a 95 % confidence interval. For secondary outcomes, Poisson loglinear mixed effects regression models will assess the difference in seasonal respiratory infection rates between intervention groups. Cluster-and individual-level random effects will be considered to account for clustered observations. Additional covariates may be added to the models to adjust for confounding.

Participants will be encouraged to complete the study. Those who withdraw from an intervention arm will be encouraged to complete follow-up laboratory specimen collection. An intent-to-treat analysis, in which all available data on all randomized participants are included, will be used for the primary comparison of interventions. A per-protocol secondary analysis will compare treatment effectiveness, accompanied by a planned sensitivity analysis that accounts for participants from whom researchers were not able to obtain a second serological sample. 

To detect a 25 % reduction (i.e., a relative risk of 0.75) in the incidence of laboratory confirmed influenza or laboratory confirmed respiratory illness among participants wearing an N95 respirator, compared to participants wearing a medical mask, ResPECT will need to accumulate approximately 10,024 or 5104 personseasons of data over four seasons respectively.

Sample size calculations are based on several assumptions about the incidence rate and levels of withincluster correlation. The attack rate laboratory-confirmed influenza during a single study season is assumed to be 20 % among unvaccinated individuals in the medical mask group. We assume 65 % of our population will be administered a vaccine that is 65 % effective in preventing influenza infection. Vaccine effectiveness at the higher end of published reports (86 % in health care workers) will lead to a reduction in the yearly attack rate to approximately 8.8 %, and effectiveness at the lower end of published reports (51 % in the general population) would lead to an increased yearly attack rate of approximately 13.4 %. Importantly, the anticipated effect on the needed sample size of annual variations in influenza incidence is larger than the expected impact of variation in vaccine effectiveness.

The ResPECT study will need 157 independent clusters with a median size of 16 participants each to achieve 80 % power to detect a relative risk of 0.75 between N95 and surgical masks at preventing laboratory-confirmed influenza infection, with a Type-I error rate of 0.05. The total number of individuals participating each season will need to be approximately 2506, with 10,024 total person-seasons accumulating over the multi-year study. For the secondary outcome of laboratory confirmed respiratory illness, the estimated total number of clinics will need to be 80, the total number of individuals participating each season will need to be 1276, and total person-seasons accumulated need to be 5104 (Table 4) over the multi-year study. The sample size are made using the clusterPower software package for R [48] .

Power is estimated using an expected annual attack rate of 12 % {12 % = 0.35*0.2 + 0.65*(1-0.65)*0.2} [13] . This yearly attack rate translates into a 4-year attack rate of 39 % {39 % = 1-(1-(0.35*0.2 + 0.65*0.35*0.2)) 4 . Accounting for correlation of outcomes within clusters by assuming the correlation coefficient is 0.1, leads to a design effect of 2.5.

For scenarios representing the lower and higher ends of anticipated attack rates in the medical mask group, two quantities were calculated (a) the power to detect a relative-risk of 0.75 between the N95 group and the medical mask group and (b) the relative-risk that can be detected with 80 % power (Table 5 ). For all of these calculations the two-sided Type I error probability is 0.05.

Potential outcome analysis for laboratory-confirmed influenza Some data on the primary outcome may be missing due to participants withdrawing from the study early and missing the second serological sample. To account for the unavoidable uncertainty posed by missing primary outcome data, due to participant withdrawal or loss of follow-up, a sensitivity analysis will be conducted that randomly assigns binary outcomes to participants who did not complete the study. A two-dimensional grid will be created that varies the influenza attack rates among participants who withdraw. Withdrawal attack rates in both arms will be fixed between half and twice the observed attack rates, based on complete data. By varying these two parameters across the grid, and for each combination, the adjusted odds ratio will be calculated by averaging across n = 50 imputed datasets for each point on the grid.

Analysis of differential withdrawal The characteristics at the time of randomization for participants without complete follow-up will be examined. To assess the potential biases introduced by differential withdrawal among different N95 respirators, a comparison of withdrawal rates and time to withdrawal will be included as an ancillary analysis to the analyses of the primary and secondary outcomes.

ResPECT will be approved by the institutional review board at each participating study site and the Centers for Disease Control and Prevention, prior to study initiation. (An unabridged version of the ResPECT protocol was approved by the intitutional review board at each study site and the Centers for Disease Control and Prevention). 

Viral respiratory infections cause a wide range of illnesses, varying from mild to severe, in HCPs who may spread infection to their patients, family members, and other community members. Healthcare-associated infections cost $10B annually in U.S [49] . Factors influencing transmission of respiratory infections in healthcare facilities include the population density of ill patients in healthcare settings, the types of exposures within healthcare settings, the administrative and physical structures of healthcare facilities, and intrinsic characteristics of virulence [3] . Measures to prevent transmission within healthcare facilities include HCP vaccination, handhygiene, cleaning and disinfection of inanimate surfaces, pre-and post-exposure antiviral chemoprophylaxis, patient isolation, and personal protective equipment [3, 6] .

ResPECT is designed to better understand the extent to which PPE, specifically represented by differences in exposure reduction afforded by N95s and MMs, reduces clinical illness among HCPs.

While it may seem that N95 respirators should better protect HCPs than MM against airborne infections in the workplace, this notion has not been validated by objective clinical evidence. Low tolerance to respirator wear among HCPs may prompt more frequent or longer periods of removal, compared to MM, to an extent that the benefits of higher levels of filtration and lower levels of leakage around the facial seal afforded by respirators is offset or subjugated.

Key sources of variability in HCP health outcomes are difficult to control for, even in a rigorously designed clinical study such as ResPECT. For example, the inability to prevent HCP community exposures to respiratory infections and the inherent year-to-year variation of viral respiratory infections provide a challenging setting in which to evaluate the effectiveness of personal protective equipment. While community-acquired infections may pose a significant source of exposure for HCPs, this type of exposure, if occurring non-differentially between study arms, would bias the results from ResPECT towards the null hypothesis.

Key reasons for choosing a cluster-randomized design are (a) to increase compliance by equipping all members of a healthcare team with the same equipment and (b) to capture indirect effects of the intervention at the cluster-level, such as herd immunity [50] .

A fully successful study would produce clinically relevant results that help clinician-leaders make reasoned decisions about protection of HCPs against occupationally acquired respiratory infections and prevention of spread within healthcare systems.

Abbreviations ARI, acute respiratory illness; CDC, centers for disease control and prevention; DSMB, data safety monitoring board; HAI, hemagglutination inhibition antibody; HCP, healthcare personnel; ILI, influenza like illness; LCRI, Laboratory confirmed respiratory illness; MM, medical mask; N95, N95 respirator; NIOSH, National Institute for Occupational Safety and Health; OSHA, Occupational Safety and Health Administration; PPE, occupational protective equipment; ResPECT, respiratory protection effectiveness clinical trial; RPD, respiratory protective devices; RT-PCR, reverse-transcriptase polymerase chain reaction; US, United States. 

",0.7621971537597012
User acceptance of reusable respirators in health care,"Background: Inclusion of reusable respirators, such as elastomeric half-face respirators (EHFRs) and powered air-purifying respirators (PAPRs), in hospital respiratory protection inventories may represent 1 solution to the problem of N95 respirator shortages experienced during pandemics. User acceptance of these devices is 1 potential barrier to implementing such a strategy in respiratory protection programs. Methods: To assess user attitudes toward various respirators, health care workers enrolled in respiratory protection programs in a medical system using EHFRs, N95s, and PAPRs and completed an online questionnaire that addressed attitudes, beliefs, and respirator preferences under different risk scenarios. Responses were compared between user groups. Results: Of 1,152 participants, 53% currently used N95s, 24% used EHFRs, and 23% used PAPRs. N95 users rated their respirators more favorably compared with EHFR and PAPR users (P < .001) regarding comfort and communication, however, EHFR users rated their respirators much more highly regarding sense of protection (P < .001). For all user groups, reusable respirators were significantly more likely (odds ratios 2.3-7.7) to be preferred over N95 filtering facepiece respirators in higher risk scenarios compared to ""usual circumstance"" scenarios. Conclusions: Despite somewhat less favorable ratings on comfort and communication, experienced EHFR and PAPR users still prefer reusable respirators over N95s in certain higher risk scenarios. This suggests that reusable respirators are an acceptable alternative to N95 respirators in health care and offer 1 viable solution to prevent pandemic-generated respirator shortages.","Health care workers (HCWs) face potentially hazardous occupational exposures to infectious organisms, many of which are spread through an airborne or aerosol route. 1 In these situations, respirators are required as 1 of the mechanisms to protect HCWs from exposure. Conventionally, most health care settings employ the use of N95 filtering facepiece respirators (N95-FFRs) to protect their HCWs. 2 These respirators are meant to be disposable, provide protection against 95% of airborne particles as low as 0.3 microns in size, and rely on creation of a seal between the HCW's face and the mask. 3 N95-FFRs have been used in health care to protect HCWs from exposure to various pathogens, including tuberculosis (TB), severe acute respiratory syndrome (SARS) coronavirus, and others. 1 Over the last 20 years, all major infectious disease pandemic threats have prompted the use of respiratory protection as 1 element of a comprehensive approach to minimize risk of transmission to HCWs caring for infected patients. These events created a high demand for N95-FFRs and led to local, or even global, shortages in every case. 4, 5 During the SARS 2002 outbreak, 25% of respondents at a facility that treated at least 1 possible or confirmed SARS case experienced N95-FFR shortages. 4 With the 2009 H1N1 influenza pandemic, hospital managers r eported shortages and many HCWs reported that N95-FFRs were not readily available. 5 The 2014 Ebola pandemic led to actual and perceived shortages of personal protective equipment overall. [6] [7] [8] [9] These shortages left HCWs less protected and, therefore, more vulnerable to the risk of occupationally acquired infection.

Current respirator manufacturer and distributor supply chain flow structure may lead to future shortages with high product demand periods, such as those occurring during global pandemics. 10 As expressed by a major US respirator distributor representative to a committee of the National Academies of Science in 2016 (previously known as the Institute of Medicine [IOM] ), the order of magnitude of increased use of and, therefore, demand for respirators to prevent airborne pathogen transmission ""is so great that none of the traditional supply chain strategies that are available would ever be sufficient to meet the demand and the expectations that our 6,000 or so health care customers would have."" 10 Proposed solutions to addressing N95-FFR shortages include stockpiling of these respirators and permitting extended and limited reuse of these often single-use disposable respirators in some cases. However, each of these solutions also has drawbacks or violates other infection control precepts. 5, [11] [12] [13] [14] [15] An additional solution to this challenge of providing adequate respiratory devices during a national or global outbreak would be to include the use of reusable respirators as part of a facility-based supply.

In this approach, reusable respirators would be assigned and fit tested for each HCW and already be present and available when required. Because they are reusable, they would not be disposed of after use and, therefore, would not contribute to creating a supply shortage, mitigating a demand for new respirators. One such alternative product is the reusable elastomeric half-face respirator (EHFR), a tight-fitting device with the same assigned protection factor (APF) as an N95-FFR. 16 Another example is a powered airpurifying respirator (PAPR), a loose-fitting device with a higher APF than an N95-FFR. 16 Although EHFRs are often used in other industries outside of health care (eg, manufacturing or construction) where significant airborne hazards are present, they are less familiar to most HCWs. 16 These devices are somewhat larger than N95-FFRs, made of synthetic materials such as silicone, and contain filter-bearing cartridges. Their size and appearance present challenges to user acceptance, given this unfamiliarity and perceptions related to possible discomfort during use, difficulty with communication, interference with work tasks, and potential fear experienced by patients. 17 Yet, some health care settings have used EHFRs as part of their routine or emergency protocols for respiratory protection. 2, [18] [19] [20] Understanding the experience of workers in these environments would provide insight quantifying the potential concerns about user acceptance and could guide actions to best address these concerns.

Loose-fitting PAPRs are often used as alternatives to N95-FFRs among HCWs, who typically are unable to wear a tight-fitting N95-FFR, whether because of their inability to obtain an acceptable fit (eg, the presence of facial hair or facial structure) or because of a medical inability to wear a tight-fitting mask. In addition, loose-fitting PAPRs are appropriate when fit testing has not occurred, and some health care facilities may exclusively rely on PAPRs as their primary form of respiratory protection to avoid the need for fit testing. PAPRs are recommended for use during certain high-hazard tasks, such as aerosolgenerating procedures in patients suspected to have an aerosol-transmissible disease, as they provide a higher level of protection (APF ≥ 25) and have an added benefit of including facial protection. 21 These features may make PAPRs a preferred from of respiratory protection during pandemics. Although loose-fitting PAPR use does not require fit testing, training that includes appropriate donning, doffing, and use technique is still required. PAPRs have higher initial costs and may require use of product-specific auxiliary components, such as hoods. In health care, PAPR hoods are often reused among individuals for care of specific patients, but frequently are disposed of subsequently. A 2015 survey of US occupational health nurses revealed that 77% had used PAPRs in their health care facilities over the past year. 2 Therefore, PAPR users represent an important group whose comparative preferences should also be examined to understand acceptance of these devices in health care.

One hospital setting, with more than 5,000 employees enrolled in its respiratory protection program (RPP), has used EHFRs as 1 form of respiratory protection since the 2009 H1N1 pandemic, when they were incorporated into the RPP for several reasons, including (1) N95-FFR shortages that ensued subsequent to requirements by the Occupational Safety and Health Administration (OSHA) for use during care for patients with pandemic influenza-like illness, 22 and (2) professional expertise by the occupational safety staff, who were familiar with the respirators from previous employment outside of health care. 19 In the fall of 2016, HCWs from this facility and its affiliated institutions were surveyed about their experiences with the use of respirators. The primary objective of this study was to understand whether EHFRs are acceptable alternatives to N95-FFRs among HCWs based on user preferences and perceptions of comfort, communication, and protection afforded by the mask. The secondary objective was to understand similar user acceptability outcomes about PAPRs compared to N95-FFRs. This study sought to determine whether regular EHFR and PAPR users have different preferences, when given a choice of respirator, and to compare respirators with respect to comfort, communication, and sense of protection from disease, compared to regular N95-FFR users.

A cross-sectional survey was conducted of HCWs enrolled in RPPs at 5 sites within a single medical system, where collectively 3 different forms of respiratory protection (N95-FFR, EHFR, and PAPR) were in use. Partner sites were recruited, after conversations with directors of employee health, safety, and their supervising leadership. Site A was a large, urban teaching hospital where all 3 forms of respiratory protection were in use during the study period. Sites B and D were suburban and urban community hospitals, respectively, where the primary form of respiratory protection was N95-FFR. Site C was a suburban rural-based community hospital, where the primary form of respiratory protection used was PAPR. Site E was a collection of urban ambulatory practices affiliated with site A, where the primary form of respiratory protection was EHFR. Each site had existing RPP policies and procedures for training and fit testing as needed that complied with the OSHA Respiratory Protection Standard (29 CFR 1910.134 ). The study was approved by the University of Maryland-Baltimore institutional review board.

The survey feedback was provided by HCWs who participated in a focus group about respiratory protection during an earlier qualitative phase of this study. 19 Additionally, survey questions designed to address issues raised by RPP leadership during key informant interviews also performed in this earlier qualitative study phase were included. 19 Additional questions focused more generally about respiratory protection were included that were adapted from prior respiratory protection surveys and research, including the National Institute for Occupational Safety and Health Respirator Use Evaluation in Acute Care Hospitals study and from research conducted by the Workers' Compensation Board of British Columbia. 17, 23 An online survey consultant administered and hosted the survey. The draft survey was converted into a web-based platform and then pilot-tested for readability, ease of use, and length. After incorporation of revisions after pilot-testing, the survey was structured to take 15-20 minutes to complete, able to be completed in intervals, and accessible in multiple browser options, both on desktop and mobile electronic options devices.

To facilitate recruitment, study team members made announcements at nursing unit shift changes, unit ""huddles,"" academic divisional meetings, and at nurse managers meetings, describing the purpose of the survey, the voluntary nature of completion, and the method of survey dissemination. Flyers were also posted on bulletin boards in common areas in nursing units. Participants who completed the survey received $20 electronic gift cards as reimbursement for their participation.

The study team obtained rosters of HCWs included in the RPP at each of the 5 sites with their e-mail addresses, when available. The online survey consultant delivered individual messages to all e-mail addresses included on the RPP rosters. The content included (1) an introductory e-mail, announcing the forthcoming, voluntary survey, (2) an invitation e-mail containing a personalized link to the survey, and (3) up to 3 reminder e-mails over a 6-week period to those participants who had not completed the survey. Incorrect or incomplete e-mail addresses were resolved if possible on a case-by-case basis, but represented only a small portion of the e-mail addresses (<1%).

Because some HCWs did not have e-mail addresses on file with employee health rosters, study staff also scheduled clinical unit visits with study-supplied laptops to facilitate on-site survey completion. Clinical units that historically had been designated to use EHFRs were prioritized (emergency department, medical intensive care unit, medicine and pediatric units, respiratory therapy, radiology, and phlebotomy units). The study staff visited clinical units at 3 of the 5 participating sites: A, C, and D. At sites where e-mail addresses were available for all HCWs on RPP rosters (sites B and E), the study staff did not visit units to facilitate on-site completion.

The survey was administered over a 6-week period between August 2016 and October 2016. Participants were eligible to complete the survey if they were assigned to wear a respirator, they were at least 18 years old, they had worked for their current employer for at least 3 months, and if they had worn a respirator at least once in the last year outside of training.

At the time of study design, approximately 35% of site A's and site E's RPP participants (the only locations where EHFRs were in use) were assigned to use EHFRs, with only 2.5% in N95-FFRs and the remaining 62.5% in PAPR. As the primary objective of the study was to compare attitudes and beliefs of EHFR users to N95-FFR users, HCWs from additional sites primarily using N95-FFRs were recruited, and EHFR users were oversampled. The study budget was structured to provide participant payments to 1,000 survey respondents, and enrollment was structured to end after recruitment of 1,000 respondents.

Early survey data feeds after the first week of e-mail distribution revealed that no participants from site C had accessed the survey. We learned that an organizational ""spam"" filter was active and impeding the ability of that site's participants to complete the survey. This created an unfair advantage to participants at the other 4 sites in being able to complete the survey before the recruitment limit of 1,000 was reached. After problem resolution in collaboration with the site's information technology staff and after institutional review board approval, enrollment was extended for an additional 2 weeks specifically at the site that had faced a systemic e-mail blockade. Thus, total participation exceeded 1,000 because of this unexpected issue.

The electronic survey was sent to the e-mail addresses of 9,687 HCWs among the 5 institutions. A total of 1,152 participants completed the survey, yielding a total participation rate of 12%.

Analyses compared current EHFR users, current N95-FFR users, and current PAPR users (user groups). Differences in frequency of responses for categorical variables among these groups were tested using the Pearson x 2 test. For continuous variables, we used analysis of variance to look for significant differences between the groups. Demographic variables found to be significantly different between the 3 groups were included as covariates in subsequent multivariable group comparisons about comfort, communication, sense of protection, and confidence in fit testing and training outcomes, along with other variables thought to be important in influencing responses. These covariates included sex, age, race, education level, site, job category, primary unit setting, frequency of use, frequency of training, years worked in health care, years worked for current employer, assigned respirator, respirator status prior to the 2009 H1N1 pandemic, and supervisor status.

For the 5-point Likert-type scale questionnaire responses, 2 different types of analyses were performed. First, the distribution of responses between the 3 groups were compared with unadjusted means and standard deviations and graphically using diverging stacked bar charts, with the neutral point centered at 0. Second, to formally compare differences between groups, 5-point Likert scale responses were analyzed as continuous variables, ranging from 1 (representing the most negative response) to 5 (representing the most positive response). An overall F test from analysis of covariance was used to identify whether there were any significant differences between the groups while adjusting for covariates, followed with pairwise comparisons using Tukey's honestly significant difference tests.

Finally, preferences for respirator types (3 options) under different threat levels were compared within 3 respirator user groups. First, for each group, the percentage of the group endorsing a respirator preference was calculated under different threat-level scenarios: (1) ruleout TB, also considered ""usual circumstances,"" (2) active TB, and (3) pandemic H1N1 influenza or SARS. Then, multinomial logistic regression modeling was used to estimate the relative odds of preferring EHFR and PAPR (vs N95-FFR) between 2 increased threat-level scenarios versus the usual circumstances scenario. Generalized estimating equations were used for this analysis to account for intraindividual correlation of responses to the 3 threat scenario questionnaire items.

For the data analysis of preferences within each user group, the number of covariate terms in each generalized estimating equation multinomial regression model was limited by the distribution of the 3-level categorical outcome. Following guidelines outlined in Babyak 24 and Harrell, 25 we determined overall that the maximum number of covariate terms would ideally be no more than 12. We devised a strategy to: (1) identify a potentially critical set of covariates, (2) collapse categorical covariates where stratification was not critical, and (3) fit the regression models and reduce the number of covariate terms to a maximum of 12 (highest P values first), as long as there was a <10% change in the beta coefficients of interest (ie, for threat scenario). The a priori identified initial critical set of covariates were: age, sex, race (white or nonwhite), assigned respirator, employer (binary), primary unit (3 levels), job category (3 levels), percent of time wearing a respirator (3 levels), and years working in health care. The maximum change in the beta coefficients for threat level from covariate reduction in the 3 user group models was 1.4%

Analyses were conducted using SAS version 9.4 (SAS Institute Inc, Cary, NC). Diverging stacked bar charts were constructed using R software (R Foundation for Statistical Computing, Vienna, Austria) HH. 26 

Eleven hundred fifty-two participants completed the survey, 280 of whom were currently using EHFRs. The majority of participants in each group were women. Current EHFR users differed from current N95-FFR users and PAPR users by several demographic and occupational characteristics as shown in Table 1 .

When asked, ""With regard to comfort, how much do you like your respirator?"" most responses were neutral to favorable (Fig 1 Panel a) . N95-FFR users rated their respirators significantly more favorably than did either EHFR (P < .001) or PAPR users (P < .001) ( Table 2) . Similarly, when asked ""With regard to communication, how much do you like your respirator?"" N95-FFR users again rated their respirators more favorably in comparison to EHFRs (P < .001) or PAPRs (P < .001), which were both rated similarly in the neutral to negative categories (Fig 1 Panel b and Table 2 ).

In contrast, when participants were asked ""How well do you think your respirator protects you?"" EHFR users rated their respirators most favorably (Fig 1 Panel c and Table 2 ). Both EHFR (P < .001) and PAPR users (P = .012) rated their respirators significantly more favorably than did N95-FFR users. EHFR users were more confident that their respirator would protect them based on their fit testing or training in contrast to either N95-FFR users (P = .003), who would require similar fit testing, or in comparison to PAPR users (P = .005), who still require training despite not needing to undergo fit testing (Fig 1 Panel  d and Table 2 ). Multivariable analysis, including adjustment for frequency of fit testing or training, did not decrease the significance level of these comparisons.

To understand respirator preference and the impact of escalated threat levels on preference, users were asked to select their preferred respirator given 3 choices (EHFR, N95-FFR, or PAPR). First, the question, ""What respirator would you prefer to wear under usual circumstances, such as caring for a patient who is being ruled-out for TB?"" was asked. The risk scenario was then escalated to caring for a patient with known, active TB and finally to a setting of pandemic H1N1 or SARS. The majority of each user group preferred to stay with their current respirator type under usual circumstances ( Table 3) . As risk increased to exposure to active TB, however, the percentage staying with or switching to EHFR or PAPR increased in each user group. When exposure was to pandemic H1N1 or SARS, the propensity to stay with or switch to EHFR was not as strong as with exposure to active TB, but propensity to prefer PAPR was higher. For all user groups, reusable respirators were significantly more likely to be preferred over N95-FFRs in higher risk scenarios compared to usual circumstance scenarios (Table 4 ). Adjustment for covariates increased the odds of preferring either EHFR or PAPR compared to N95-FFR in all user groups and in each threat scenario compared to usual circumstances. To understand whether EHFR and PAPR users perceived their susceptibility differently than N95-FFR users, we asked participants how likely they believed they would be to contract various communicable diseases from caring for an infected patient while not wearing a respirator. Whereas most respondents reported their belief that it would be likely or very likely that they would contract TB, H1N1, SARS, or Ebola, there were no significant differences in the frequency of reporting of the different responses among the user groups (data not shown). EHFR, elastomeric half-face respirator; N95-FFR, N95 filtering facepiece respirator; PAPR, powered air-purifying respirator. *Significance level unchanged after adjustment for sex, race, education level, employer, assigned respirator, respirator status prior to 2009 H1N1 pandemic, unit setting, supervisor status, frequency of use, frequency of training, years in health care. y 1 = ""very much dislike,"" 2 = ""dislike,"" 3 = ""neither like nor dislike,"" 4 = ""like,"" and 5 = ""very much like."" z 1 = ""not well at all,"" 2 = ""somewhat,"" 3 = ""not sure,"" 4 = ""well,"" and 5 = ""very well."" x 1 = ""strongly disagree,"" 2 = ""disagree,"" 3 = ""neither agree nor disagree,"" 4 = ""agree,"" and 5 = ""strongly agree.""

This study examined whether EHFRs and PAPRs could serve as user-acceptable solutions to N95-FFR shortages. Respirator shortages have been repeatedly demonstrated during the last 3 pandemics and will predictably recur with future pandemics. Thus, the health care sector must plan to address these foreseeable shortages.

The use of a reusable respirator that could be purchased in advance and be on hand in a health care setting would avoid the need for just-in-time purchasing of N95-FFRs and reliance on an insecure supply chain during a surge in demand. EHFRs have not conventionally been used in health care, but IOM, OSHA, and others have suggested their use as an option to mitigate shortages of disposable N95-FFRs during emergencies. 27 Although PAPRs may have found greatest use in health care historically among workers who are unable to use tight-fitting N95-FFRs, expanded use could also assist in limiting N95-FFR shortages.

Although EHFR users rate their respirators less favorably than do N95-FFR users, with respect to comfort and communication, they rate them significantly more favorably with respect to sense of protection afforded. Despite the barriers of comfort and communication, when given a choice to wear an N95-FFR, the majority of current EHFR users would still choose to wear an EHFR under usual and escalated respiratory protection scenarios.

There are several explanations why EHFRs may be preferred over N95-FFRs. First, there may be greater confidence in obtaining a reliable fit, given the more durable design of the EHFR. Further, the mask has a larger surface area in contact with the face, which may promote a better seal or even a perception of a better seal. Second, the EHFR users may wear their respirators more frequently than the N95-FFR users, yielding a greater familiarity with the mask and assessment of how well it protects. When adjusted for frequency of use, however, there was still a pattern of preference for EHFR. Another hypothesis was that this EHFR preference may have been driven by a dominant choice by a specific worker group (eg, nurses compared to doctors). When we adjusted for job category, however, there was still a statistically significant preference for EHFR under increasing threat levels. Finally, we explored whether having an increased perception of risk susceptibility might influence preference for respirator type. To understand underlying perceptions among different respirator users, this study queried whether routine EHFR users were influenced more by fear of the potential diseases they could encounter, compared to N95-FFR users. They were not. They rated the likelihood of contracting TB, SARS, or Ebola when not wearing a respirator similarly to N95-FFR users, suggesting that they view the diseases themselves similarly as other respirator users.

Poorer comfo.rt of EHFR masks has been anecdotally cited as a barrier to use in the health care setting. 17, 19 In a Canadian pilot study where HCWs were newly assigned to wear EHFRs, HCWs reported comfort as a reason for not choosing an EHFR. 17 Thus, there may be resistance from HCWs when newly introduced to these masks as a form of required respiratory protection. In the current study's population of experienced EHFR users, the comfort ratings for these devices were not dramatically different from the ratings of N95-FFRs, and mean response values fell in the neutral or positive range. This suggests that comfort of EHFRs is not an insurmountable barrier to their use in health care settings, and that experience with these devices (usual circumstance)  56  37  6  11  78  12  10  40  50  Active TB  69  15  16  29  44  28  16  18  66  Pandemic H1N1 or SARS  61  18  21  23  46  31  18  21  62 EHFR, elastomeric half-face respirator; N95-FFR, N95 filtering facepiece respirator; PAPR, powered air-purifying respirator; TB, tuberculosis; H1N1, H1N1 influenza; SARS, severe acute respiratory syndrome. NOTE. Unadjusted odds ratio point estimates were calculated using multinomial regression, however these can be calculated directly from the percentages in Table 3 (subject to rounding error). For example, the first uOR estimate in this Table, 3.0, equals (69%/15%) divided by (56%/37%). EHFR, elastomeric half-face respirator, N95-FFR, N95 filtering facepiece respirator; PAPR, powered air-purifying respirator; ref, reference comparison; TB, tuberculosis; uOR, unadjusted odds ratio; aOR, adjusted odds ratio; H1N1, H1N1 influenza; SARS, severe acute respiratory syndrome. *uOR = probability of preferring EHFR (or PAPR) divided by probability of preferring N95-FFR under an active TB (or pandemic H1N1) scenario divided by the same probability ratio under a usual circumstance scenario. y aORs were estimated adjusting for a limited set of critical covariates (see Data analysis section for details).

creates familiarity and ease with use, such that the EHFR is the preferred device among the experienced user cohort. Communication, however, was rated negatively for EHFRs. This is a challenge in health care, where staff must communicate not only with each other but also with patients. Although this does not seem to impair ultimate preference, this aspect clearly demonstrates a limitation of this device's use in the health care setting. This user rating echoes that found in the Workers' Compensation Board of British Columbia study, where speech intelligibility test scores for workers using EHFRs were lower, but still above the minimum acceptable level according to the National Institute for Occupational Safety and Health. 17 Similarly, in a study of intelligibility of words spoken when wearing EHFRs under real and simulated ambient intensive care unit noise conditions, speech intelligibility was significantly lower compared to controls and compared with other common forms of respiratory protection, but could be improved with use of a voice augmentation device. 27 The results from the current study support previous recommendations from the IOM that communication interference be rectified in the next generation of respiratory protective devices developed for HCWs. 27 However, in general, the familiar EHFR user cohort numbering several hundred still preferred this device for all threat scenarios for which they were queried.

Responses of PAPR users in this study shared some similarities with the limited number of prior published works evaluating PAPR user acceptability in HCWs. Communication and comfort ratings among PAPR users were the lowest of the 3 respirators. With respect to communication, in a study of different types of respirators worn by HCWs, hearing clarity while wearing a PAPR was 79% compared to 90% clarity without the use of a PAPR. 27 In another study of HCWs who had used 2 different PAPR models during the 2003 SARS outbreak, between 5% and 14% percent of respondents reported significant or unacceptable hearing impairment, only 5%-14% could speak normally when using the PAPR, and 25% reported having to raise their voice significantly. 28 These HCWs, however, had also worn N95-FFRs underneath their PAPR hoods, per hospital policy, which may have added an additional impairment to communication. Research on comfort of PAPRs, however, has produced variable results. In the study among HCWs experienced with PAPR use during SARS, the majority of respondents found PAPRs to be ""at least tolerable,"" with 23%-46% reporting them to be ""very comfortable,"" but 9%-14% reporting to be ""uncomfortable."" Other studies have reported increased perception of facial heat and eye dryness in PAPR users. 29, 30 In the current study, PAPR users rated their respirators more favorably than N95-FFR users on sense of protection. Similarly, in the study of HCWs familiar with PAPR use during SARS, PAPRs were perceived to be more protective than N95-FFRs. 28 Of the 3 respirators queried in the current study, PAPRs have the highest APF by OSHA. In our study population, PAPR users rated their respirators slightly lower than EHFR users on their perceived level of protectiveness. This finding suggests an opportunity for improved education among HCWs on the levels of protection provided by respiratory protective equipment in general.

PAPR users also reported higher ratings related to confidence that their respirator would protect them based on the training they had received compared to N95-FFR users, but significantly lower ratings compared to EHFR users. This may reflect differences in the content and delivery of respiratory protection training among the different user groups. In the study of HCWs experiences with PAPR use during SARS, the majority of HCWs received PAPR training by an experienced trainer, but approximately 30% received video instruction and some relied only on printed instructions. 28 There may be an additional belief in the protectiveness of a respirator that is instilled during a fit testing process, which is absent in a loose-fitting PAPR training program.

Similar to that reported by the EHFR users, despite the less favorable responses on comfort and communication, PAPR users expressed preference for use of PAPR over N95-FFR in increased threat scenarios, as compared to usual circumstances. This response pattern is similar to the findings among HCWs using PAPRs during SARS, where 84% of respondents agreed or strongly agreed to the statement, ""for potential SARS cases, routine use of the PAPR. . ..is preferable to using the N-95 respirator, despite the significantly higher cost of the PAPR."" 28 Interestingly, only 51% of that population believed that routine use of the PAPR was preferable for infectious cases, such as TB. Similar to that seen among EHFR users, however, when given a choice to wear an N95-FFR, the majority of current PAPR users would still choose to wear a PAPR under escalated respiratory protection scenarios.

This study has several strengths. First, these findings, to our knowledge, represent the largest collection of user acceptance data from EHFR and PAPR users specifically focused on respirator use to date. Second, these results come from a large population of HCWs familiar with the use of EHFRs over more than 8 years of use. Elastomeric respirators were first introduced in this setting in 2009 during the H1N1 pandemic and had continued in routine use since that time. At least 13% of the current EHFR respondents had used these devices since their debut in this setting, reflecting familiarity with use of this device. The mean age of EHFR users was 37 years, and they had worked an average of 12 years in health care, with an average of 6 years at their current sites.

The survey included photos for each question that required a response about a specific type of respirator, which likely increased surety that the responses refer to the intended respirator. Another strength is the high number of responses from outpatient clinical HCWs and patient support staff, who often are not included in HCW research. They represent a vitally important component of the care team and must be considered with respect to personal protective equipment.

Prior to initiation of this survey, we had become aware that some HCWs engaged in a practice of wearing different respirators than what they were assigned to use (ie, some HCWs who were assigned to wear an EHFR would usually use an N95-FFR instead). Our additional research into respirator availability, storage, and cleanliness will help to understand why some EHFR users wear different respirators than what they are assigned to use. Our findings here suggest that user acceptance is not a significant driver of this practice.

This study has limitations as well. Participants worked at different sites, each with different respiratory protection training programs, all of which complied with established protocols to meet the expectations of the OSHA respiratory protection standard. The analyses in this study incorporate frequency of respiratory protection training as a potential confounder, but are unable to differentiate between organizational differences in content or approach to respiratory protection training. By incorporating site, job category, and primary clinical unit, however, influences imparted by training content and delivery likely were captured. Also, the preference odds ratios indicate a preference for EHFR or PAPR in comparison to preference for N95-FFR. The methodology does not allow a head-to-head comparison of EHFR compared to PAPR and should not be interpreted in this way.

Finally, our participation rate was 12%, but this was expected based on study design. We aimed to recruit at least 1,000 participants and provided gift cards for participation on a rolling basis. HCWs may have been less motivated to participate after the gift cards were exhausted. The breadth of job categories of our participants, however, suggests that an appropriately representative sample of HCWs engaged in respiratory protection activities was assembled. The number of current EHFR users is smaller than that originally anticipated and on which power calculations were based. Some of this is owing to changes in respirator assignment surrounding the time of survey deployment. For example, out of 1,152 participants, 153 reported using EHFRs in the past but were no longer using them (data not shown). Also, participants were asked what respirator they were most recently assigned to use and what respirator they usually use. To account for the small group of respondents who usually used respirators that were different from their respirator assignment, we adjusted for assigned respirator in all of our analyses, and the unadjusted outcomes did not change significantly. Because we wanted to focus on the experiences of current users, we have a smaller sample size than originally anticipated. Despite this smaller sample size, we still saw significant differences between the respirator user groups, suggesting that we were not underpowered to detect important differences.

User acceptance has been cited as a barrier to wide-scale implementation of the use of reusable respirators, such as EHFRs in health care. Based on the experience of 1 health system, user acceptance does not appear to be as important a barrier as potentially anticipated. Even when given a choice to use a standard N95-FFR, most current EHFR users will still elect to use an elastomeric respirator under increasing risk levels, despite perceptions of somewhat lower comfort and communication. This suggests that EHFRs are an acceptable alternative to N95 respirators in health care and offer 1 viable solution to prevent pandemic-generated respirator shortages. Similar patterns were observed among PAPR users. These results suggest that user acceptance should not uncritically continue to be cited as a major barrier to widespread adoption of reusable respirator use in health care.

",0.7564210592110693
CONTINUING EDUCATION Proper Use of Surgical N95 Respirators and Surgical Masks in the OR Purpose/Goal Approvals Sponsorship or Commercial Support Proper Use of Surgical N95 Respirators and Surgical Masks in the OR N95 RESPIRATORS AND SURGICAL MASKS,To enable the learner to correctly use surgical masks and surgical N95 respirators.,"S urgical personnel are vulnerable to a variety of hazardous substances, including potentially infectious agents present in surgical smoke given their prolonged exposures to surgical smoke during the course of their career. [1] [2] [3] A growing body of scientific evidence indicates that 95% of surgical smoke consists of water, but the remaining 5% may contain potentially hazardous particles, including dead and live cellular material; blood fragments; bacteria; viruses; toxic gases and vapors (eg, benzene, hydrogen cyanide, formaldehyde); and lung-damaging dust. 1, 4 Typically, within five minutes of the beginning of an electrosurgical procedure, particulate matter in the immediate area increases from a baseline measurement of approximately 60,000 particles per cubic foot to more than one million particles per cubic foot. 5 Burning 1 g of tissue releases the same level of mutagenic toxins as smoking three to six cigarettes. 6 In addition, it takes the typical OR airflow recirculating system approximately 20 minutes to return particle concentrations to normal after a surgical procedure is complete. Several reports within the past decade have indicated that health care workers are inconsistent with and have suboptimal adherence (ie, less than 60%) to recommended infection control precautions. [7] [8] [9] For example, the lack of adherence to proper infection control precautions, including use of respiratory personal protective equipment (PPE), was documented during an H1N1 influenza outbreak. [10] [11] [12] Both the Occupational Safety and Health Administration (OSHA) and the Centers for Disease Control and Prevention Healthcare Infection Control Practices Advisory Committee (CDC/HIC-PAC) have stated that, based on the evidence, there appears to be marginal compliance with proper use of respiratory protection guidelines by health care workers. In addition, OSHA warns that, given the emergence of ""new infectious diseases that affect both patients and [health care workers], compliance with recommended infection control practices is an increasingly important issue."" 13 Therefore, reinforcing and monitoring day-to-day compliance are necessary steps that must be undertaken by both the individual employee and employer. 13 Surgical masks are the most commonly used protective facemask in perioperative and other hospital settings. 14 These masks are intended for use as a barrier to protect the wearer's face from large droplets and splashes of blood and other body fluids. In certain clinical situations, however, potential exposure to airborne contaminants and infectious agents also necessitates the use of respiratory PPE, such as an N95 particulate filtering facepiece respirator (ie, surgical N95 respirator). 15, 16 The term N95 refers to a National Institute for Occupational Safety and Health (NIOSH)-approved and US Food and Drug Administration (FDA)cleared particulate filtering facepiece respirator that can filter at least 95% of airborne particles. The term surgical mask refers to an FDA-cleared laser, isolation, or medical procedure mask, with or without a face shield, worn ""to protect both the surgical patient and perioperative team members from transfer of microorganisms and body fluids. Surgical masks are also used to protect health care providers from contact with large infectious droplets (> 5 micrometer [mcm] in size)."" 17(p357) The term protective facemask refers to a surgical N95 respirator or surgical mask that covers at least the nose and mouth to reduce the wearer's risk of inhaling hazardous airborne particles (including dust particles and infectious agents).

The primary objective of this article is to differentiate between surgical N95 respirators and surgical masks, a most significant and perhaps easily misunderstood issue. The secondary objective is to reinforce awareness of common workplace hazards in which voluntary and precautionary use of surgical N95 respirators may be advantageous to the health and safety of surgical health care workers.

Surgical N95 respirators prevent the passage of a wide size range of hazardous airborne particulate matter from entering the wearer's breathing space. Airborne particulate matter is measured in micrometers, formerly called microns. The Greek letter m is often used to show the prefix micro, and mm is used for the unit of measure micrometer. This Greek letter, however, can be mistaken to mean unit, 0, cc, or mg; therefore, the Institute for Safe Medication Practices has placed m on its list of abbreviations, symbols, and designations that should never be used when communicating medical information. As a result, practitioners should spell out the word micrometer or use the abbreviation mcm. 1

Varying degrees of protection are associated with different types of respiratory PPE. 18 Although several types of respirators are available, those most commonly used by health care workers usually fall into the category of air-purifying filtering facepiece respirators. These fit-tested devices are personal protective devices that are worn on the face, cover at least the nose and mouth, and are composed of a filter that prevents the passage of a wide size range of hazardous airborne particulate matter, including dust particles and infectious agents, from entering the wearer's breathing space.

All filtering facepiece respirators must pass certification tests conducted by NIOSH. 18 To help ensure adequate performance, the NIOSH certification test challenges filtering facepiece respirators at a high flow rate using charged-neutralized aerosols in the most penetrating size range for most filters. 19 Those filtering facepiece respirators that prevent at least 95% of particles from passing through the filter during a worst-case test are given a 95 designation. Similarly, those that prevent 99% and 99.97% of the particles from passing through the filter are given the designation of 99 and 100, respectively. 19 As part of the OSHA-required respiratory protection program (29 CFR 1910 .134), every health care worker who must use a respirator to control hazardous exposures in the workplace must be trained to properly use the respirator and pass a fit test before using it in the workplace. 20 Fit tests can be performed in a qualitative or quantitative manner. During a qualitative fit test, the taste or smell of the test aerosol is a sign of an improperly fitting respirator. It is a subjective test that is dependent on the sensitivity of the health care worker. Quantitative fit tests require the use of an instrument that permits a technician to monitor particles in the room air as well as particles inside the respirator while it is being worn by the health care worker. The ratio between the room count and the count inside the mask determines the health care worker's fit factor for that surgical N95 respirator. For a passing test, the fit factor must be greater than or equal to 100. 20 The fit test ensures that the health care worker is wearing a surgical N95 respirator that can provide a good facial seal and, therefore, expected levels of protection. One key aspect of determining the effectiveness of a surgical N95 respirator is performing a user seal check. Every time a person dons a N95 respirator, he or she should perform the manufacturer's recommended user seal check method to ensure that an adequate seal has been obtained. The surgical N95 respirator only provides protection when the respirator is adequately sealed to the wearer's face, and a user seal check aids the health care worker in determining whether the respirator is fitting properly.

If the health care worker feels air coming in or going out around his or her eyes or chin or feels his or her glasses fogging during a user seal check, the surgical N95 respirator should be adjusted or replaced. User seal checks are not substitutes for qualitative or quantitative fit tests.

The CDC/HICPAC infection control transmission precautions instruct health care workers to use droplet precautions for certain pathogens and airborne precautions for others. This guidance is based on a pathogen's known epidemiology (ie, patterns of transmissibility and infectivity). 15 Particle size does not affect the infectivity of the pathogen; however, the principle that smaller airborne particles can travel farther and remain suspended in room air longer than larger particles (ie, droplets) is also an important factor to consider in selecting the best protective facemask ( Figure 1 ). Filtering facepiece respirators, such as N95 respirators, are designed to protect the user from both droplet and airborne particles, and they come in many sizes and are designed to seal to the face. Both surgical N95 respirators and surgical masks are disposable, single-use devices that should be worn during a single patient encounter by a single person and should not be shared between wearers. 18 High-filtration surgical laser masks were designed as a form of barrier or source control. When placed on a contagious patient, surgical masks limit the spread of large-sized droplet respiratory secretions to others. When worn by a health care worker, the patient's incisions are protected from infectious agents present in the worker's mucus and saliva, while at the same time, the worker is protected from any sprays of blood or body fluid coming from the patient. Only protective facemasks cleared by the FDA as medical devices are recommended for use in health care workplaces. The FDA does not independently test the devices but rather reviews the manufacturer's testing data for n filter efficiency, n breathing resistance, n flammability, and n fluid resistance. 19, 21 In addition, with regard to the filter efficiency requirements for FDA clearance, a surgical mask must perform as well as one other cleared surgical mask currently on the market. 19 Two key features associated with the level of protection provided by high-filtration surgical laser masks are filtration efficiency and fit. Studies have shown that the filtration efficiency for surgical masks is highly variable depending on the type of mask and the manufacturer. 22, 23 The filtration efficiency can be as high as that of a surgical N95 respirator, but even when surgical masks with the most efficient filter media (ie, high-filtration surgical laser masks) are properly worn, the fit factor obtained is quite low. Oberg and Brosseau 22 conducted filtration performance and fit tests with nine types of surgical masks and found that none of the models tested exhibited adequate filter performance and facial fit characteristics to be considered equivalent to a surgical N95 respirator. Surgical masks are not designed to seal to the face. Without an adequate seal to the face, inhaled breath is not forced through the filter and instead flows through the gaps around the seal area, providing minimal protection by allowing potentially hazardous contaminants to enter the workers' breathing zone through gaps between the wearer's face and the mask. Therefore, surgical and high-filtration surgical laser masks do not provide the degree of protection to be considered respiratory PPE.

Several characteristics of airborne contaminants should be taken into consideration for choosing the proper type of protective facemask:

n What is the hazard? n How infectious is the hazard? n What is the dominant mode(s) of transmission (ie, contact, droplet, aerosol)? n What is the particle size of the airborne hazard?

If any of these factors are unknown, being cautious and using at least a surgical N95 respirator may be beneficial. Because of its greater filtration capacity, a surgical N95 respirator will greatly reduce a wide size range of particles from entering the wearer's breathing zone. Therefore, a surgical N95 respirator provides more protection from a wider range of pathogen-carrying particles than a surgical mask.

When people speak, sneeze, or cough, they release particles that may contain pathogens. The size of the airborne pathogen is important because the smaller the particle, the longer it can remain aerosolized (ie, suspended in the air). In addition to suspension time, particle-size range affects how far an inhaled particle can travel; smaller particles can travel deeper into the airway, which increases the risk of potentially adverse health effects. Bacteria can be as large as 30 mcm or smaller than 0.3 mcm. 24 Viruses are smaller and can range in size from 0.01 mcm to 0.3 mcm. 14 Primary infection for Mycobacterium tuberculosis occurs deep within the lung, whereas smallpox and pneumonic plague can occur in both the upper and lower respiratory tract. 25 Every day, health care workers encounter hazardous particulates while treating patients, and these encounters necessitate different forms of protective precautions. Droplet precautions are used to prevent large droplets generated from coughs and sneezes from reaching the mucous membranes of the nose and mouth of the health care worker. This level of protection can be achieved with a surgical mask or a surgical N95 respirator. Diseases requiring droplet precautions include meningitis, pneumonia, mumps, and rubella. As an example, occupational transmission of Neisseria meningitides was reported in 2009 as a result of exposure of health care workers who were not wearing any type of protective facemask. 26 Another case reported health care worker transmission of bacterial meningitis to five patients after intrapartum spinal anesthesia where established infectioncontrol recommendations, including the use of a mask by health care workers, were not followed. 27 Regardless of their size, certain diseases can be transmitted through airborne routes and require more stringent precautions: negative pressure rooms, isolation rooms, and respiratory protection at least as protective as a surgical N95 respirator. Various pathogens, their size ranges, and the corresponding comparison of surgical mask and surgical N95 respirator ranges of particulate protection are shown in Figure 2 with examples of airborne-transmissible diseases (ie, tuberculosis, chickenpox, rubeola) depicted by the dotted boxes. 28 Certain treatments may require health care workers to convert from using droplet precautions to using higher order control measures provided with airborne precautions. Aerosol-generating procedures create smaller droplets than those generated by sneezing or coughing, thereby increasing the suspension time of the particles. 29 Aerosolgenerating procedures include bronchoscopy, endotracheal intubation, suctioning, and nebulized medication administration. Assisting in such procedures requires health care workers to be within 3 ft of the patient, which leaves them vulnerable to droplet sprays as well. Health care worker involvement in these high-risk procedures has been linked to increased transmission of severe acute respiratory syndrome (SARS). 29, 30 A systematic review of studies revealed that health care workers who performed endotracheal intubation on patients diagnosed with SARS were 13 times more likely to contract the illness than were health care workers who cared for patients with SARS but did not assist in the intubation. 31 Various surgical techniques also generate aerosols known as surgical smoke or surgical plume. Health care workers assigned to surgical suites must be aware that this environment has two types of particulate hazards: the particles themselves and the viable biological pathogens that account for some particles. As stated earlier, the size of the particle affects how long it remains suspended in the air and how far it can travel into the respiratory tract. Electrosurgical procedures generate particles about 0.07 mcm in size, laser procedures create particles about 0.31 mcm in size, 2,32 and ultrasonic scalpels produce particles that range in size from 0.35 mcm to 6.5 mcm. 2 Particles smaller than 5 mcm are categorized as lung-damaging dust, and working in surgical smoke can result in acute and chronic respiratory changes including emphysema, asthma, and chronic bronchitis. 2 It has been reported that small particles less than 1.1 mcm in diameter constitute 77% of the particulate matter found in surgical smoke. 33, 34 Surgical laser masks do not seal to the face and offer no protection from particles smaller than 1 mcm in size. 32 In fact, ""if the wearer wants to reduce inhalation of smaller, inhalable particles (those less than 100 [mcm]), they need to obtain and properly use a NIOSH-certified respirator."" 16 Cells, including aerosolized blood, 35 bacteria, and viruses, make up the biological components of surgical smoke. 34 The viability of the pathogens released during surgery depends on n the length of the surgery, n the type of instrumentation used, n the presence of bacteria or virus in the patient, and n the type of procedure. 2 Bacteria and virus cells have been detected in surgical smoke and can remain viable for up to 72 hours. 34 Surgical smoke generated during laparoscopic procedures has been found to contain whole mesothelial and blood cells. 36 One study found that nine out of 10 surgeries using high-speed surgical instruments and 16 of 17 coagulation devices produced aerosolized blood mists in the OR. 37 Biologically active bacteria (ie, Staphylococcus, Corynebacterium, Neisseria) have been detected in laser resurfacing plume. 38 Human papillomavirus (HPV) DNA has been detected in carbon dioxide laser smoke during laser vaporization of warts. 39, 40 There are two documented cases of health care workers contracting HPV as a result of occupational exposure. In 1990, a 44-year-old surgeon was treated for removal of laryngeal papillomas. The DNA tests of the lesions indicated HPV types 6 and 11, and the only source of contamination was traced back to the surgeon's patients who had undergone laser surgery. 41 A second case involved a 28-year-old gynecological OR nurse who repeatedly assisted in laser surgical and electrosurgical excisions of anogenital condylomas. This case was defined as an occupational disease because of the high correlation between the nurse's repeated exposures and her contraction of HPV. 42 

Given the known hazards, several professional and national organizations have established recommended practices to use during smoke-generating procedures in the OR. AORN, 15 the Laser Institute of America, 43 the American National Standards Institute, 43 and The Joint Commission 44 each recommend that surgical smoke be filtered and evacuated through the use of room ventilation and local exhaust ventilation methods; NIOSH recommends a combination of OR air exchanges and local exhaust ventilations as the first line of protection for controlling surgical smoke. 4, 18, 19 Despite these recommendations, a 2007 survey of 623 AORN members indicated weak compliance with recommended control measures. 45 In 2010, a follow-up survey of 1,356 AORN members indicated that the use of wall suction, a less-effective local exhaust ventilation method, had increased significantly for almost all smoke-generating procedures, as did the use of high-filtration surgical laser masks. 46 However, the use of smoke evacuators and the use of NIOSH-approved surgical N95 respirators had not changed significantly. 46 In addition, a recently published comprehensive analysis of all literature pertaining to lasergenerated air contaminants suggests that the known exposure risks coupled with the inconsistent use and marginal adoption of recommended local exhaust ventilation and respiratory control measures warrant a campaign for targeted health and safety training. 47 Based on the compendium of evidence, the authors of the literature review recommend the use of a surgical N95 respirator in the presence of laser-generated air contaminants as a prudent course of action. 47 High-filtration surgical laser masks are not designed to provide protection from the atmospheric contaminants present in surgical smoke, 43 and high-filtration surgical laser masks provide less protection to the wearer from particulate hazards than a fit-tested surgical N95 respirator. 47 According to the AORN ""Recommended practices for laser safety in perioperative practice settings,"" during high-risk or aerosol-generating procedures in patients with or suspected of having transmissible infections (eg, HPV, tuberculosis, rubeola, varicella), respiratory protection that is at least as protective as a fit-tested surgical N95 respirator should be used in conjunction with local exhaust ventilation. 15 compliance with recommended precautions and practices is an important indicator of a health care organization's commitment to a culture of safety. This includes the appropriate selection of protective facemasks. The differences in the protective features of high-filtration surgical laser masks and surgical N95 respirators for commonly encountered respiratory hazards are illustrated in Figure 3 , which can be used as a selection guide. Health care administrators should encourage individual health care workers, in conjunction with infection preventionists and occupational health or industrial hygienists, to examine the appropriate selection and use of protective facemasks. Health care workers should personally consider the patient's diagnosis, how closely they will be working with the patient, and the treatments being performed.

When working in the OR during smokegenerating procedures, especially laser procedures, if a health care worker can smell the plume, potentially dangerous and infectious debris and contaminants are being released into the atmosphere that could cause adverse health effects. 47, 49 All health care workers should be vigilant because bloodborne pathogens are known to be released during procedures on patients infected with HPV, HIV, and hepatitis. 50 In such situations, at a minimum, health care workers should use a fit-tested surgical N95 respirator to ensure appropriate protection. Respiratory PPE is the health care worker's last line of defense, but the best respirator will do little to protect an individual who does not know when to use it or how to use it properly.

",0.7560659773265379
Evaluation of the rationale for concurrent use of N95 filtering facepiece respirators with loose-fitting powered air-purifying respirators during aerosol-generating medical procedures,"The concurrent use of N95 filtering facepiece respirators with powered air-purifying respirators during aerosol-generating medical procedures in patients with severe respiratory pathogens has been promoted as offering additional protection against infectious agents. The purpose of this article is to examine the impact of this additional respiratory equipment upon protection and personal performance. The presumed additive protective effect of an N95 filtering facepiece respirator used concurrently with a powered air-purifying respirator has not been subjected to rigorous scientific investigation. The burden imposed by additional respiratory protective equipment should not be discounted, and the potentially minor contribution to protection may be offset by the negative impact on personal performance. Novel uses of protective equipment occasionally are spawned during crisis situations, but their generalized applicability to healthcare workers should ultimately be evidence-based. (Am J Infect Control 2008;36:135-41.) ","The recent outbreak of severe acute respiratory syndrome (SARS) served to highlight the risk of disease transmission among health care workers (HCWs). The personal toll on HCWs has been distressing, as they have accounted for sizeable proportions of early cases of SARS and 20% of critically ill SARS cases. 1, 2 The concurrent threat of other emerging severe respiratory pathogens (eg, avian influenza, pandemic influenza, etc) has amplified the concerns of HCWs for adequate personal protective equipment (PPE). These respiratory viral pathogens are thought to be transmitted primarily by direct contact through exposure to large respiratory droplets (.5 mm in diameter) expelled during coughing and sneezing, or by contact with infected surfaces and fomites. [3] [4] [5] Airborne transmission of viral pathogens is also considered to be possible via evaporation of larger droplets that form droplet nuclei (,5 mm in diameter) or by viral attachment to dust particles, either of which allow for prolonged air suspension. 6 A recent investigation that obtained positive air samples in hospital SARS units in Toronto added plausibility to the theory of airborne transmission of SARS. 7 Medical procedures that result in aerosolization and subsequent airborne dissemination of respiratory pathogens (eg, endotracheal intubation, oral suctioning, etc) were identified as placing HCWs at increased risk for SARS infection. 2, 6, 8, 9 The finding that HCWs were infected with SARS during some of these aerosol-generating procedures, despite the use of accepted universal precautions (ie, gowns, caps, gloves, eye protection [eg, face shields, goggles], N95 [or equivalent] filtering facepiece respirators [N95FFR]), resulted in medical specialists, 4,10,11 health care agencies, 12,13 professional societies, 14 and medical institutions 15 promoting the use of powered airpurifying respirators (PAPRs) for HCWs involved in these procedures. Ancillary recommendations included the concurrent use of N95FFR (or equivalent respirators) and goggles with PAPRs, 4, 13, [15] [16] [17] based upon the assumption that this combination of PPE would act in an additive fashion to provide maximal protection 10 (Fig 1) . However, the respiratory protection afforded by the concurrent use of PAPRs with N95FFR (N95FFR/PAPR), as well as any recommendations to the contrary, have not been subjected to scientific scrutiny, as is true for many recommendations regarding the prevention of transmission of SARS-related coronavirus in health care settings. 18 Improper use of PPE can negatively impact the wearer in such areas as personal performance, safety, physical and emotional comfort, communication, and hearing such that it is incumbent upon PPE users and hospital respiratory protection program managers to determine the relative merits of employing additional PPE in novel ways, particularly if the novel aspects of use have not been thoroughly evaluated for effectiveness. Any additional burden imposed on the user must also be carefully considered. This article examines the use of N95FFR/PAPRs in the setting of respiratory pathogens during aerosol-generating medical procedures to encourage a more thorough evaluation of this regimen by professional societies, regulatory bodies, and users of this combination of PPE.

The most common respirators utilized by HCWs, N95 filtering facepiece respirators (N95FFR) (Fig 2) are disposable filtering facepiece PPE devices that are worn on the face, cover at least the nose and mouth, and are used to reduce the wearer's risk of inhaling hazardous airborne particles (including dust particles and infectious agents) or aerosols. 19 To be approved by the National Institute for Occupational Safety and Health, the U.S. agency responsible for the certification of respiratory protective devices, filtering facepiece respirators must pass a number of tests. Letter designations (eg, N, R, P) reflect the respirator's resistance to oil particles (N 5 not resistant to oil particles; R 5 somewhat resistant to oil particles; P 5 oil proof). 20 Numerical designations (95, 99, and 100 [99.97 actual]) indicate the minimum filtration efficiency of the respirator filter (particle penetration of #5%, #1%, and #0.03%, respectively) to a challenge aerosol consisting of particles in the most penetrating particle size range (approximately 0.3 mm test particles) delivered at a flow rate of 85 L/min. 19, 21 Therefore, an N95FFR has a minimum 95% filtration efficiency (or a maximum of 5% penetration rate through the respirator filter using a small test aerosol), and has an assigned protection factor (APF) (the minimum anticipated protection provided by a properly functioning respirator or class of respirators to a given percentage of properly fitted and tested users, when used in a complete respiratory program) of 10, indicating that properly fitted and trained users could expect to inhale no more than one-tenth of the airborne contaminant present. 22, 23 APFs are based on laboratory and workplace studies that measure the ratio of the ambient contaminant concentration to the contaminant concentration inside a respirator and are used for selecting what type of respirator to employ in a given situation. 24 Use of a respirator with an APF greater than the calculated hazard risk (ie, ambient concentration of a contaminant O established permissible exposure limit) generally assumes that the exposure inside the respirator will be less than the exposure limit. 24 However, it is important to recognize that, as opposed to particulates and chemicals, governmental regulatory agencies have not established safe exposure levels for biological aerosols; thus, there is no assurance that any respirator will completely eliminate the inhalation of pathogenic microorganisms. Nonetheless, it is assumed that the higher the APF, the more protection afforded the wearer. 19 Powered air-purifying respirators (PAPR) PAPRs (Fig 3) are respiratory protective devices in which a belt-mounted, battery-powered blower pulls ambient air through attached air-purifying filters (housed in cassettes or canisters) through a hose and into a facepiece. The facepiece can be either tight-fitting (ie, half facepiece or full facepiece) or loose-fitting (ie, shroud, helmet). 19 The continuous airflow (170 L/ min) through loose-fitting hoods or shrouds limits entrainment of contaminated air. 25 Additionally, PAPRs possess several other features that make them attractive to HCWs and hospital administrators (Table 1 ). In the health care setting, the loose-fitting facepiece/visor PAPR is the predominant model, 19 although shrouded PAPRs are increasingly advocated in the context of health care chemical, biological, radiation, and nuclear response because they offer greater dermal protection to the head/neck regions than helmeted PAPR. 26 Loosefitting PAPRs (eg, hoods, helmets) have an APF of 25. 22

The rationale for N95FFR/PAPR use has been based on the desire to maximize respiratory protection via a presumed additive protective effect of dual respiratory PPE use. 8, 10 Proponents cited years of personal experience with PAPRs during bronchoscopy on patients with suspected pulmonary infections such as tuberculosis without subsequent transmission of infection to HCW as supportive of this concept, but it is unclear whether PAPRs alone or N95FFR/PAPRs were employed during these procedures. 4,10 Additional rationale supporting N95FFR/PAPR use included backup protection in the event of battery failure 14 or from over-breathing (momentary episodes of negative pressure in a PAPR brought about when the user's maximum peak inspiratory airflow exceeds the PAPR airflow delivery) 27 resulting in loss of the positive pressure effect of the PAPR. 28 Central to the discussion of N95FFR/PAPR use is the issue of whether the presumed (but unproven) benefit of this combination outweighs the increased burden imposed on the user by the additional PPE equipment employed and how this might affect HCW performance.

For instructional purposes, let us examine endotracheal intubation in a patient, a high-risk procedure 29 and the operator's face is in close proximity to the patient's mouth during airway procedures. 30 To ascertain the potential exposure to HCW, the pathogen emission rate is determined from the product of the number of coughs per hour, respirable volume per cough, and pathogen concentration per milliliter of respiratory fluid. 31 It would also be informative to have data regarding the number of pathogen particles needed to infect and the number carried on any individual respiratory droplet; however, these data are currently unknown, though it is recognized that some serious respiratory pathogens (eg, tuberculosis, influenza) require as few as 1-3 organisms to cause infection. 32 Distance from the patient is also a consideration inasmuch as the concentration of airborne particles in still air decreases in proportion to 1/d 3 (where d is the distance from the source of the aerosol), so that someone who is 2 meters away from a coughing patient has one-eighth the exposure concentration of someone who is 1 meter away. 33 Thus, in this scenario, potential exposures are probably influenced more by pathogen particles generated acutely during the procedure than those extant in the room that have been diluted by the ventilation system's hourly room air exchanges. The APF of 25 assigned by the Occupational Safety and Health Administration to a loose-fitting PAPR indicates a potential 4% penetration into the unit's breathing zone, 22 a not-insignificant proportion when dealing with infectious agents that may require relatively few particles to infect. Although the use of a concurrent N95FFR (APF 10) could potentially decrease the in-PAPR exposure by 90% (depending on such factors as the N95FFR model employed, respirator condition, fit-testing, etc), no studies have yet evaluated the efficacy of an N95FFR/PAPR combination; consequently, no firm conclusions can be drawn. Alternatively, recent human studies on loose-fitting PAPR 27, 34 have concluded that they afford actual workplace protection many times the APF, thereby offering even greater protection than officially assigned. Published reports from the health care environment suggest that PAPRs alone offer sufficiently high levels of respiratory protection during aerosolizing medical procedures. Caputo et al 35 reported that no SARS developed in HCW who used a Stryker T4 surgical helmet (filters air through the hood material itself; airborne reduction factor of 3.1 for particles .0.5 mm in diameter 8 ) with tandem N95FFR respirator (APF 10) during intubations on SARS victims, despite the fact that this combination offers significantly less respiratory protection than a loose-fitting PAPR (APF 25). Furthermore, the conditional risk of a respiratory-transmitted disease such as tuberculosis (one tuberculosis bacterium can cause seroconversion 32 ) in high-risk situations such as aerosol-inducing procedures (ie, bronchoscopy) has been estimated to be as low as 0.3 cases per 1000 procedures when using a PAPR. 30 Use of a PAPR during bronchoscopy, in patients with tuberculosis, results in a 238-fold risk reduction of seroconversion. 36 Perhaps most importantly, no reports of well-documented, active tuberculosis or other serious infections to HCWs wearing PAPRs have been reported in association with bronchoscopy (.500,000 bronchoscopies performed annually in the U.S.), an aerosol-generating procedure for which PAPR use is recommended. 37 All of this suggests that properly used and maintained loose-fitting PAPRs offer a high degree of protection from respiratory pathogens. Hospital engineering controls (eg, negative pressure rooms, room ventilation systems with high efficiency particulate filters, ultraviolet radiation, etc 8 ) and the use of medications to suppress coughing and salivation during airway procedures 4,10,35,38,39 further limit the airborne spread of respiratory pathogens and would additionally decrease the PAPR wearer's potential inhalational exposure. With regard to the use of N95FFR as a backup in the event of battery failure, PAPR low battery-life alarms (visual and/or audible) allow sufficient time for room egress. Overbreathing, 27 as occurs with strenuous physical activity, and momentarily during nonrespiratory air exchanges (eg, yawning, sighing, preparatory to coughing or sneezing, etc), can result in loss of positive pressure effects within the PAPR and subsequent entrainment of outside air. However, even when such activities result in peak inspiratory flow rates that exceed the PAPR flow rate, aerosol penetration into the PAPR has been shown to remain below 0.1% of the ambient concentration. 40 The presumptive benefits of the added protection of PPE must always be weighed against the negative aspects and, ultimately, the impact on personal performance of the wearer. Areas of potential concern with the tandem use of N95FFR/PAPR include:

1. Increased breathing resistance. One of the important benefits of PAPR use is the decreased work of breathing brought about by the motor-driven delivery of air to the user's breathing zone. 41 However, N95FFR increase breathing effort because the user has to overcome the resistance of the filter media, 10 thereby resulting in increased breathing exertion and rate. Difficulty breathing and increased respiratory rates with N95FFR have been heretofore identified. 42, 43 As breathing resistance through a respirator increases, less air is drawn through the respirator 44 and hypoventilation occurs that leads to increases in the fraction of expired CO 2 (FECO 2 ), due to a decrement in the volume of expired air, and decreases in the fraction of expired O 2 (FEO 2 ) secondary to greater extraction of oxygen from each breath. 45 Elevated CO 2 levels have also been suggested as one of the reasons why one-third of HCWs who use N95FFR for prolonged periods experience headaches. 46 Approximately 14% of HCWs who used N95FFR/PAPRs during the Singapore SARS outbreak had complaints ranging from a moderate workof-breathing to feelings of suffocation. 16 Thus, use of N95FFR/PAPR will actually negate, to variable degree, the ease of breathing that is a major beneficial feature of PAPR. 2. Fit-testing. Another significant benefit of PAPRs is that they do not require the annual fit-testing and the time commitment and costs that are associated with N95FFR 47 (although HCW instruction in the use of PAPR would be needed). Use of N95FFR/PAPR would not negate this requirement. 17 Another beneficial feature of PAPRs is that they can be used by individuals with facial hair; however, such individuals could not be properly fit-tested for N95FFR, and use of an N95FFR/PAPR would not be applicable. An improperly fitting N95FFR can be associated with significant leakage 48 and noteworthy decrements in respiratory protection 5 such that any theoretical additive protective effects of the N95FFR would be lost. Another theoretical concern is the fact that the continuous airflow of the PAPR within the hood or shroud could make it more difficult for the user to detect a poor face seal of the N95FFR. 3. Communication difficulties. Verbal communication when using PAPRs is hindered by the excess noise generated by the motor and airstream sounds. 49, 50 This problem could be compounded by the muffling effect on voice 51 of the (concurrent) N95FFR. In a HCW survey in Toronto following the SARS outbreak, 47% reported difficulty communicating when using filtering facepiece respirators. 52 Communication issues with the use of PAPR are a recurrent concern among HCWs, 53 56 Unfortunately, the beneficial cooling effects of the PAPR on the user's face, an especially important feature in emergency work, 57 will be negated to variable degree by use of N95FFR/PAPRs, inasmuch as filtering facepiece respirators have been shown to increase facial temperatures at the mask/face interface by 7.58F, on averge. 58 PAPRs are also intimidating to patients and frightening to children, 54 and N95FFR/ PAPRs dehumanize facial features to an even greater degree than PAPRs alone. 5. Increased risk of infection. As Nicolle 18 has so astutely noted with regard to the use of PPE during the SARS outbreak in Toronto, increasing layers of PPE result in increased complexity of patient care, as well as a heightened risk for confusion and contamination. Wei et al 59 have also expressed similar concerns about the removal of complicated respirators increasing the risk of self-contamination or contamination of nearby HCW. These apprehensions could apply to N95FFR/PAPR use because of the need to remove the additional N95FFR and goggles. Concurrent use of PAPR hoods and N95FFR with goggles has been reported to result in an inability to maintain balance when removing PPE equipment, with resultant increased risk of self-contamination. 46 

HCWs treating patients infected with severe respiratory pathogens have every right to be concerned about their own safety. In crisis situations such as the SARS outbreaks, where failure to undertake precautions can be disastrous, early recommendations are often made without the benefit of reliable scientific information, and this is understandable. In such situations, as Nicas 31 has suggested, if risk assumptions are not well defined, HCWs should use their best judgment. Ultimately, however, the choice of appropriate PPE should be based not on fears, but on solid science. 18 Although the use of an N95FFR/PAPR in providing greater respiratory protection over that of PAPR alone is intuitively rational based only on APFs, this remains unproven, and the additional negative impact of this combination upon the user should not be discounted. When an N95FFR/PAPR is used for short-duration procedures (eg, endotracheal intubation, airway suctioning, etc), the presumptive added respiratory protective benefit of the N95FFR may be so nominal as to be offset by its negative impact on the personal performance of the wearer and the risk of self-contamination or dissemination of pathogens to nearby HCWs or patients. Providing accurate information to HCWs and hospital respiratory protection program managers regarding the optimal respiratory protective equipment to employ when faced with outbreaks of severe respiratory pathogens will require additional research. Studies addressing the potential penetration of intra-PAPR pathogens through concurrently used N95FFR are needed. Ultimately, a balance must be struck between optimal protection and optimal personal performance issues for HCW.

",0.7485536143954423
Contamination during doffing of personal protective equipment by healthcare providers,"Objective In this study, we aimed to describe the processes of both the donning and the doffing of personal protective equipment for Ebola and evaluate contamination during the doffing process.","Ebola was first identified 40 years ago. 1, 2 However, little interest has given to this highly contagious pathogen until an outbreak was confirmed by the World Health Organization in 2014 in Congo. 3, 4 Disease spreads across nine countries and its death was toll of over 11,000 person in three West African nations, and people around the world began to concern about the Ebola nowadays. Ebola spreads through human-to-human transmission via direct contact (through broken skin or mucous membranes) or indirect contact with infected materials, such as clothing. [5] [6] [7] As other infectious diseases, healthcare workers are at risk of infection because they have to work at the frontline, often without protections. 8, 9 Cases of contamination while treating Ebola patients rose rapidly during the current outbreak, and the Centers for Disease Control and Prevention (CDC) announced the new personal protective equipment (PPE) guidelines for healthcare providers treating Ebola patients. [10] [11] [12] However, even with protective clothing, a healthcare worker can be contaminated if removal is not done in a manner that prevents exposure. [13] [14] [15] A limited numbers of studies have been performed regarding contamination with PPE usage. In this study, our primary aim was to evaluate contamination during doffing. The secondary purpose was to describe errors and delays during donning and doffing.

This study was performed in a single tertiary-level academic hospital (Samsung Medical Center, Seoul, Korea). The hospital has a disaster plan and equipment such as PPE. However, no official training or education was provided before this study. We recruited 29 participants for the study from the emergency department physician and nursing staff. They were informed of the purpose of the study, and each gave written consent.

Participants received a 20-minute lecture. After the lecture, a 20-minute demonstration with PPEs was given, along with an educational movie produced by the Korea Centers for Disease Control and Prevention. The course content contains donning and doffing procedure for PPE (gowns, gloves, respirators, and goggles), according to a 2014 CDC protocol. A 10-minute question and answer session followed the demonstration. The lecturer was a certified advanced disaster life support instructor, experienced with several training sessions.

After the training, each participant was paired with another, and completed the donning and doffing procedures with help from the partner. Each team was blinded from the others; however, the second participants were more exposed to the process after watching the first. Each person was allowed to watch the protocol and to consult their partners. Though the 2014 CDC protocol was close to level D (level of PPE is divided A to D and level D is the lowest protection), we modified the airway protection by upgrading the N95 mask (particulate filtering face-piece respirators) to a gas mask. We also modified the 2014 CDC leg cover process. Fig. 1 demonstrates the overall look of our study PPE. Table 1 shows the difference between the CDC guideline and study protocol.

A demographic survey was performed with all participants. The survey also included questions on job experience and previous training with PPE. During a simulation study, two separate cameras with high-density capability were set up at an approximate 120 degree angle to document the process. All processes were videotaped during PPE donning and doffing. Afterward, a trained examiner reviewed all video recordings and coded timer intervals and errors. Time stamps were determined according to a 2014 CDC protocol. Each procedure was initiated when the participant picked up the equipment. The procedure ended when the next procedure was initiated. Errors were determined when the participants violated the order of procedures even with the help of their partners. For example, if a participant skipped putting on a second glove and proceeded to the next procedure, this was counted as an error. Errors during the process were explained by partners and instructors, so participants could resume the normal process.

The primary outcome was a potential incident of self-contamination during the doffing procedure, defined as the touch of the outside of PPE to the participant's body or clothing. The determination of contamination was performed by a single examiner on the basis of two recordings. If one of the recordings did not have sufficient information, the determination was carried out with only one. If two recordings suggested opposite conclusions, the outcome was determined as negative. A single trained examiner was considered sufficient for the examination because the outcome measure was relatively simple. This choice was supported by pilot cases before the study began.

Statistical analysis was performed with STATA ver. 13 (Stata Corp., College Station, TX, USA). Demographic data were reported in a descriptive manner. Continuous variables were presented as means with standard deviations, medians and interquartile ranges, or A pilot study on the contamination of PPE frequencies. Categorical variables were described as numbers and percentages. Differences between the two groups were tested using the independent two-sample t-test or the Mann-Whitney Utest for continuous variables and the chi-square test for categorical variables. P < 0.05 was considered significant.

Demographic characteristics of the study participants are shown in Table 2 . Overall, 29 participants enrolled in the study. Twenty (69.0%) were female, and mean age was 29.2 years (standard deviation [SD], 2.39). The mean work experience was 3.33 years (SD, 2.67). Among participants, 20.7% had previously received PPE training (Table 2 ). Values are presented as median (interquartile range) or number (%). One to twelve number of the Table 3 shows step by step process. PPE, personal protective equipment. Values are presented as median (interquartile range) or number (%). One to seventeen number of the Table 4 shows step by step process

The average donning process interval was 234.2 seconds (SD, 65.7) from start to finish. The most time-consuming process was putting on the gown, putting on shoe covers, and putting on the respirator. The most frequent errors occurred while putting on outer gloves (27.6%), respirator (20.7%), and hood (20.7%). The entire donning procedures refer to Table 3 .

The average interval during doffing was 183.7 seconds (SD, 38.4) from start to finish. The most time-consuming processes were removing the shoe covers, putting on gloves, and removing outer gloves. The most frequent errors occurred during disinfecting feet (38.0%), discarding scrubs (17.2%), and putting on gloves (13.8%). The entire doffing procedures refer to Table 4 . Fig. 2 illustrates contamination locations. During the overall doffing process, 65 contamination incidents occurred. The most vulnerable process was removing respirators, which caused 23 contaminations (79.3%). Two of these were on the head (6.9%), and 21 were on the neck (72.4%). Removal of shoe covers was also associated with a high probability of contamination; 19 incidents (65.5%) were reported. All locations of contamination were consistent with the doffing step related to that part of the body.

Even after standardized education, 65 numbers of contamination were reported, or 2.2 per participant. Further studies are required to minimize this number.

This study provides a valuable first step in the evaluation of PPE used by healthcare workers. This study suggests healthcare work- A pilot study on the contamination of PPE ers should be cautious about decontamination and that they need training. Donning, doffing, and decontamination procedures should be optimized for specific clinical situations. The strengths and limitations of each protective system need to be considered when recommendations are made about PPE implementation.

This study shows that a significant number of contamination incidents occurred during the process of removing PPE. This is consistent with previous reports, which have pushed the CDC into announcing recommendations for PPE handling. 16, 17 Although the study could not conclude which factors resulted in contamination, it is important to comment that more training with technical support is required for the safety of workers. Potential measures include interactive audiovisual devices to guide the procedures, or trained personnel specialized in assisting others with the procedures. Intensive and repetitive training is also required.

Recommendations for decontamination mainly emphasize hand washing. However, despite hand washing, healthcare workers could touch other parts of their bodies or clothing that has not been properly decontaminated and consequently infect themselves. 18 More intensive education and training is required for safe doffing. Evaluation of the effectiveness of training is also required.

Previous studies have focused on the importance of PPE, potential risks of doffing procedures, and doffing procedure experiments comparing different systems with a few subjects. 18 One study demonstrated contamination rates of 26% and 96% with two distinct methods; this study included only one subject for each arm, which makes it difficult to compare the outcome with the current study. 18 This study gives additional information because of the larger numbers of subjects, and because the scenario has more generalizability than previous studies.

This study does have some limitations. First, the study setting is a single center without an existing PPE training program. Inhospital staff people were inexperienced, which may have been a factor increasing errors and contamination rates. However, a majority of hospitals are inexperienced with hazmat and PPE incidents, so these study results have general applicability.

Second, the study number was very small, including only emergency department staff people. This makes it difficult to generalize to a broader population of hospital staff.

Third, contamination sometimes appeared obscure on video and was subject to examiner's decision. Though the examiner reviewed recordings several times from different angles, there could be blind spots and unobservable touches. This could have made the rates underestimated, in other words the false negative rate of the outcome measure could have increased. Also, the video review could have missed subtle contacts. Depending on a single examiner also could have influenced the accuracy of the outcome.

However, even if contaminations were underestimated, the number of reported incidents is still alarming.

Finally, the study protocol was not identical to 2014 CDC guidelines. It excluded aprons, leg covers, and tape seals between parts of the gear. The donning and doffing procedures refer to Tables 3  and 4 . This could be the reason that donning and doffing procedures were finished in very short intervals.

The advantage of this study is as a pilot study, exploring the need of further, more accurate investigations.

",0.7484744239072719
Evaluation of respiratory protection programs and practices in California hospitals H1N1 influenza pandemic,"Background: Emergence of the novel 2009 influenza A H1N1 virus in California led to an evaluation of hospital respiratory protection programs (RPPs) and practices by the California Department of Public Health during the 2009-2010 influenza season. Methods: Onsite evaluation of 16 hospitals consisted of interviews with managers and health care workers about RPPs and practices, review of written RPPs, and limited observations of personnel using respirators. Data were analyzed using descriptive statistics. Results: All hospitals had implemented policies requiring the minimum use of N95 filtering facepiece respirators when working with patients with H1N1 virus infection; 95.5% of health care workers (n ¼ 199) reported they would wear at least this level of protection when in close contact with a patient with confirmed or suspected H1N1 virus infection. However, evaluation of written RPPs indicated deficiencies in required areas, most commonly in recordkeeping, designation of a program administrator, program evaluation, employee training, and fit testing procedures. Conclusions: Health care workers were aware of respiratory protection required when providing care for patients with confirmed or suspected H1N1 virus infection. Hospitals should improve written RPPs, fully implement written procedures, and conduct periodic program evaluation to ensure effectiveness of respirator use for health care worker protection. Increased accessibility of resources tailored for hospital respirator program administrators may be helpful.","Before the emergence of 2009 H1N1 pandemic influenza (pH1N1), the US government had committed substantial resources toward planning and preparedness for pandemic influenza. This effort included an assessment conducted by the Institute of Medicine (IOM) of the personal protective equipment (PPE), including respiratory protection, needed by health care workers in the event of an influenza pandemic. 2 The US Occupational Safety and Health Administration (OSHA) issued guidance in 2007 for workplace preparedness, including control measures appropriate for a pandemic influenza virus. For health care personnel working in close contact with infected patients, OSHA recommended the use of respiratory protection with an N95 or higher rated filter for most situations and higher levels of respiratory protection (supplied-air or powered air-purifying respirator) for procedures likely to generate bioaerosols. 3 During May 2009 , the California Department of Public Health issued infection control guidance consistent with OSHA pandemic influenza preparedness recommendations for the use of respiratory protection, and the Centers for Disease Control and Prevention took a similar position in its July 2009 guidance. 4 On August 5, 2009, a new California occupational standard for the prevention of aerosol transmissible diseases (ATDs) became effective. 5 The new ATD standard, which had been under development for several years by the California Division of Occupational Safety and Health (Cal/OSHA), was designed to make applicable public health guidance for worker protection measures legally enforceable in certain California workplaces where employees are at higher risk of infection, including acute care hospitals.

Under the Cal/OSHA ATD standard, employers are required to implement infection control practices, including the use of respiratory protection for aerosol transmissible infectious pathogens. Novel pathogens such as pH1N1 are included under the standard as requiring airborne precautions based on the recommendations of public health agencies. Therefore, the use of an N95 filtering facepiece respirator or equivalent (N95 respirator), or a higher level of respiratory protection, was required during 2009-2010 for health care workers providing care for patients with suspected or confirmed infection with pH1N1.

All respirator use in the workplace must be implemented through a comprehensive respiratory protection program (RPP) that is compliant with the applicable OSHA respiratory protection standard. The standard in California is essentially identical to the federal OSHA standard. 6 RPPs must include written procedures and designation of a respirator program administrator (RPA), who is responsible for ensuring effective implementation of required elements such as respirator selection, medical clearance, fit testing, training, and program evaluation.

Despite the years of experience accumulated by health care workplaces in which respirators have been used to protect health care workers from tuberculosis and other ATDs, relatively little information exists to describe comprehensively acute care hospital implementation of RPPs. Investigations related to severe acute respiratory syndrome outbreaks have identified difficulties achieving compliance with PPE policies, especially for respiratory and facial protection. [7] [8] [9] A more recent study of hospital nurses found poor adherence to respirator use policies, based on both self-report and observation, as well as low competence when asked to demonstrate respirator use. This study recommended that hospitals improve adherence by focusing on ready availability of equipment, training and fit testing, organizational support for worker health and safety, and good communication practices. 10 In August 2009, the California Department of Public Health, in collaboration with the National Institute for Occupational Safety and Health, National Personal Protective Technology Laboratory, initiated a public health evaluation of a sample of California acute care licensed facilities with the aim of assessing the status of RPPs for the protection of health care workers during this pandemic involving a novel pathogen. The objectives of this evaluation, titled Respirator Use Evaluation in Acute Care California Hospitals, were to describe the extent to which hospitals implemented required elements of a RPP for pH1N1, assess the use of respiratory protection for pH1N1 among health care workers, and understand health care workers' knowledge and beliefs regarding the appropriate use of respiratory protection.

A list of all licensed hospitals in California was obtained from the Office of Statewide Health Planning and Development. From this list, acute care facilities located in the greater San Francisco area with an emergency department (ED) and at least 1 intensive care bed were eligible to participate. A sample of hospitals was selected to reflect the distribution of hospitals in California based on several characteristics: size (<200 beds vs 200 beds), rural status (rural vs nonrural), and type (city/county, district, nonprofit, for-profit, or university). The 14 counties surrounding the San Francisco Bay Area comprised the geographic area accessible to the project staff, and a stratified random sample of 16 facilities was selected from the 88 hospitals in the identified catchment area. The target goal of 16 facilities was based on available project staffing resources. Facilities were recruited by a project staff, who contacted the director of nursing or equivalent by telephone, explained the content and goals of the evaluation, and invited participation of the facility. Replacements for facilities declining to participate were selected randomly from the same stratum as the declining facility.

The California Department of Health and Human Services Committee for the Protection of Human Subjects determined that this evaluation was public health practice (ie, nonresearch). Participation of hospitals, individual managers, and health care workers was voluntary. Investigators first obtained facilities' approval to participate in the evaluation, including conducting observations of hospital units. Once onsite at a participating facility, project staff members explained to potential health care worker participants the purposes of the evaluation and confidentiality of responses, and secured their consent for individual interviews. No identifying information was collected for nonmanagerial health care workers or unit managers.

Separate evaluation instruments were designed by project staff for use in interviewing health care workers on specific units likely to care for patients with pH1N1 infection, managers of those units, and hospital managers with higher-level responsibilities related to the RPP. All 3 instruments were pilot tested with similar types of personnel at facilities not solicited for participation in the evaluation, and revised based on input obtained.

Questions for the 26-item health care worker interview instrument were developed to obtain demographic characteristics, information about respiratory protection practices (eg, what they would use when caring for a patient suspected or confirmed with pH1N1 infection), and knowledge and attitudes regarding use of respiratory protection (eg, protection afforded by N95 respirator vs surgical mask). Questions about use of respiratory protection when caring for patients with pH1N1 were modified from questions developed by Gershon et al 11 and Turnberg 12 as well as developed by the investigators.

A 1-page checklist was developed for use by project staff performing observations of respirator use by health care workers. The patient type, location of the observation, availability of respirators and hand hygiene facilities, and type of health care worker were noted. Essential components of respirator donning, use, and doffing were listed, as well as the duration of health care worker patient contact.

The unit manager interview instrument consisted of 50 questions developed by the investigators to identify each unit manager's roles and responsibilities in developing and implementing their facility's RPP; to assess various aspects of the RPP, including procedures and practices related to respirator use for pH1N1; and to determine knowledge and attitudes regarding respiratory protection.

The 39-item hospital manager instrument was similar to the unit manager instrument in design, but focused on identifying responsibilities for developing, implementing, and evaluating the RPP at the facility held by individual upper-level managers in employee or occupational health, infection control, or other key hospital functions.

Onsite hospital evaluations were performed in January and February 2010. Within each participating hospital, 15 to 21 interviews were performed using a tiered approach: 3 hospital managers, 3 unit managers, and 3-5 health care workers from each unit. The hospital managers interviewed were upper-level managers from nursing, employee health, and infection control. Three unit managers were selected by the hospital management from the ED, an intensive care unit (ICU), and pediatrics. When no pediatrics unit was present, a medical/surgical unit was substituted. These managers were interviewed, and each unit manager selected 3-5 health care workers from the unit for invitation to participate in the health care worker interview. Health care workers were selected based on availability to leave their current task for 5-7 minutes for completion of the interview; when fewer than 3 health care workers were available on a unit, 1 or 2 were interviewed. All interviews were performed in English.

After completing the health care worker interviews, investigators performed observations outside the rooms of patients with a suspected or confirmed ATD requiring the use of respiratory protection. Observers waited for up to 30 minutes outside the patient room in an area where health care workers could be observed donning and doffing respirators, or until 1 or more health care workers had entered the patient room. To avoid bias, silent observations were conducted using the checklist to record results.

A hospital manager at each facility was asked to provide investigators with a copy of the facility's RPP, any written identification of activities that place workers at high risk of exposure to ATDs, program evaluation protocol or forms, any written plan for respirator conservation or prioritization, any policy or procedure for respirator re-donning, or infection control policy for pH1N1. These materials were collected and reviewed by an investigator and a staff industrial hygienist for comparison to the OSHA requirements for a written RPP.

Hospital characteristics were analyzed using Freeman and Halton's extension of the Fisher exact test to assess if the sampled facilities were representative of acute care facilities in California. 13 Evaluation interview responses and observation results were summarized using descriptive statistics. Analyses were performed using Microsoft Excel 2003 or SAS version 9.2 (SAS Institute Inc, Cary, NC).

Sixteen hospitals participated in the evaluation. Four of the initially selected hospitals declined participation, and a replacement facility was randomly selected from the same stratum as each declining facility, resulting in a participation rate of 16 out of 20 (80%). The sample of 16 participating facilities was similar to all 309 general acute care hospitals in California in terms of hospital size (50% <200 beds) and location (87% nonrural). Regarding type of ownership, university hospitals were slightly overrepresented (6% in sample vs 2% overall) and for-profit hospitals slightly underrepresented (12% in sample vs 21% overall).

Evaluation interviews were completed with 204 health care workers, 45 unit managers, and 48 hospital managers, as described below. No health care workers or managers declined participation when asked to be interviewed. Because individuals could choose not to answer any question, multiple responses were permitted for some questions, and some responses involved skip patterns, the total samples may vary for individual evaluation items.

Of the 204 health care workers interviewed, the majority (n ¼ 145; 71.1%) were registered nurses. The language spoken at home was English for most respondents (n ¼ 118; 92.6%), followed by Tagalog (n ¼ 4; 2.0%) and Spanish (n ¼ 2; 1.0%). More than half (n ¼ 113; 55.4%) reported working in their present position for >5 years, and 53 (26.0%) reported working in their present position for 2-5 years. Sixty-five (31.9%) respondents worked in an ED, 63 (30.9%) in an ICU, 55 (27.0%) in a medical/surgical unit, and 21 (10.3%) in a pediatrics unit. Only 8 (3.9%) respondents were contractors, with the remaining 196 (96.1%) being employees of the hospital. Thirty-one (15.2%) interviewees reported that they were at risk for complications from pH1N1 due to conditions such as pregnancy or asthma.

Among the 45 unit managers interviewed, 14 (31.1%) supervised an ED or ICU, 12 (26.7%) supervised a medical/surgical unit, and 5 (11.1%) supervised a pediatrics unit.

Among the 48 hospital managers interviewed, infection control was the most common department with 18 (37.5%), followed by nursing and employee/occupational health with 16 (33.3%) each, and environmental health and safety with 1 (2.1%); 2 (4.2%) reported management duties in another area (multiple responses were permitted for managers working in >1 department).

Selected responses from interviews of health care workers are summarized in Table 1 . Of the health care workers who reported that they had or expected to have close contact with a patient with suspected or confirmed pH1N1 infection, nearly all (95.5%) stated that they would wear an N95 respirator or higher level of protection. When asked about the availability of their preferred size and model of respirator when needed, more than threequarters reported that they were available ""always."" Some health care workers (42.3%) reported that they had reused an N95 respirator when in close contact with a patient with pH1N1 infection; the most common reasons cited for reuse were ""standard practice"" and ""shortage."" The most common way health care workers reported knowing that they were required to wear a respirator was a sign posted on the door of a patient's room. Nearly all health care workers (94.1%) said they strongly agreed or agreed with the statement, ""N95 respirators are more effective at protecting me from influenza than surgical masks."" The most commonly cited problem health care workers reported experiencing while wearing an N95 respirator was feeling uncomfortably warm; however, 34.7% of health care workers reported having no problems.

When health care workers were asked if they had received medical clearance to wear an N95 respirator, 182 (91.5%) said they had, 6 (3.0%) had not, and 11 (5.5%) did not know if they had received clearance. One hundred eighty-nine (95.0%) health care workers stated they had been fit tested for N95 respirator use within the past 2 years (the Cal/OSHA ATD standard has a temporary provision that allows employers to increase the interval for repeat fit testing to 2 years under certain circumstances, until January 1, 2014.). Most health care workers (n ¼ 180; 90.9%) had received respirator training within the past year, 8 (4.0%) had received training >1 year ago, 4 (2.0%) said they had never received training, and 6 (3.0%) did not know when they had last received respirator training. Just less than half (n ¼ 99; 49.5%) of health care workers had received training specifically on pH1N1, whereas 94 (47.0%) had not, and 7 (3.5%) did not know if they had received such training. When asked about their agreement with the statement, ""I think my supervisor would correct me if I did not wear a respirator when it was required by my facility,"" 138 (68.0%) strongly agreed with the statement, 51 (25.1%) agreed, 8 (3.9%) disagreed, 1 (0.5%) strongly disagreed, and 5 (2.5%) responded that they did not know.

A total of 18 observations of health care workers using respiratory protective equipment were performed. Of these, 7 (38.9%) occurred in an ICU or medical/surgical unit, 2 (11.1%) in a pediatric unit, 1 (5.6%) in an ED, and 1 (5.6%) in another area of the hospital. Eleven (61.1%) patients receiving care at the time of the observation had suspected or confirmed pH1N1 infection; the other 7 (38.9%) were suspected or confirmed to have another ATD requiring airborne precautions. The majority of observed health care workers (55.6%) were registered nurses; other job titles included nursing assistant, respiratory therapist, technician, and phlebotomist. All of the observed health care workers donned an N95 respirator. The elements of proper respirator use most commonly lacking were user seal check (performed for 3 of 15 observations; 20.0%) and correct doffing (performed for 1 of 14 observations; 7.2%). Most of the health care workers touched the front of the respirator when doffing, rather than handling it only by the straps, and 8 (47.1%) did not perform hand hygiene after doffing the respirator. Waste receptacles were available in the immediate area for 71.4% of observations, and hand-washing facilities or alcohol-based hand rub for 94.1% of observations.

Of the 45 unit managers interviewed, all reported having responsibilities related to administering the RPP. The most common responses were that they communicated hospital policies and procedures regarding the RPP to health care workers on their unit (n ¼ 44; 97.8%), reported problems with the RPP to the hospital management (n ¼ 42; 93.3%), and that they observed health care workers to see if they were wearing respiratory protection when required by the RPP (n ¼ 41; 91.1%). Forty (88.9%) unit managers reported that they were asked to provide input on the RPP at their facility. Almost all unit managers (n¼ 43; 95.6%) reported that respirators were located close to the point of use in their unit. Twenty-eight (62.2%) unit managers reported that they had an employee on their unit who could not be fitted with an N95 respirator; of these, 23 (82.1%) stated that powered air purifying respirators were available for these staff members.

Unit managers commonly reported informing their staff of changes to the RPP via meetings (n ¼ 42; 93.3%), verbally 1-on-1 (n ¼ 40; 88.9%), and by signs and/or e-mail (n ¼ 36; 80% for both) (multiple responses permitted). Most unit managers did not report performing formal observation of respirator use on their unit (n ¼ 32; 71.1%) as a component of respirator program evaluation; however, all but 1 reported informally observing use of respirators by their staff (n ¼ 44; 97.9%). All unit managers (n ¼ 45; 100%) reported that they would counsel health care workers who repeatedly violated the RPP requirements. Thirty-eight (84.4%) unit managers reported that a patient with confirmed pH1N1 infection had been treated on their unit, and 34 (75.6%) reported that they would be notified if a pH1N1 case occurred among their staff. Most unit managers (n ¼ 42; 93.3%) reported that airborne precautions (including use of an N95 respirator or better) were required for close contact with patients with suspected or confirmed pH1N1, and the remaining 3 (6.7%) said that droplet precautions (which calls for use of a surgical mask) were required.

OSHA requires each worksite to have 1 RPA with primary responsibility for the RPP, although other employees may assist with some parts of the program. At some facilities more than 1 hospital manager claimed to be the RPA, and 1 hospital was unable to provide an RPA to respond. A limitation of our design (identified in hindsight) is that the hospital manager interview questions were asked of 3 managers at each facility and the responses combined, rather than focusing questions on the 1 person with primary responsibility for the RPP (if 1 was identified).

All but 1 of 48 managers reported having a written RPP at their facility; however, 1 of 16 hospitals failed to produce a written RPP for review. When asked which department at their facility decided on respirator policies (multiple responses permitted), 48 (100%) managers responded that the infection control department made these decisions. Other commonly named responsible parties were unit managers (n ¼ 45; 93.8%) and the materials management department (n ¼ 43; 89.6%). Forty (85.1%) hospital managers reported that their RPP included written identification of high-risk activities for exposure to ATDs, 1 (2.1%) reported that it did not, and 6 (12.8%) did not know.

The hospitals' respiratory protection policies and practices as described by interviewed managers are summarized in Table 2 . Nearly all hospital managers reported that all staff were medically evaluated (95.8%) and always fit tested (93.8%) before being permitted to use an N95 respirator. Fit testing was most frequently performed by in-house personnel, and a qualitative fit testing method was most often used. When asked about frequency of fit testing, 83.3% of managers reported that fit testing was conducted at hire and then annually; 6.3% said fit testing was done at hire and then ""as needed."" Most hospital managers (91.7%) reported that their facility offered respirator training, and most reported (79.6%) requiring training at hire and then annually thereafter. In-person training was the most frequently cited type of training offered (77.1%), and the majority of managers (79.2%) reported having offered training specific to pH1N1. Less than half of managers responded that their facility had a formal mechanism or method for evaluation of their respirator program and, of these, only 57.1% obtained input from employees as part of evaluation (as required by the OSHA respiratory protection standard). For health care workers in close contact with a patient with suspected or confirmed pH1N1 infection, 85.4% of hospital managers reported that an N95 respirator was the minimum level of protection required. Most hospital managers (n ¼ 40; 83.3%) reported their facility formally documented respirator supplies and use. Half of hospital managers (n ¼ 24) reported that they had experienced a shortage of respirators during the pandemic. The most common reasons given for a shortage being experienced (multiple responses permitted) were higher patient loads (n ¼ 22; 91.7%), orders not filled by suppliers (n ¼ 20; 83.3%), and allotment from suppliers* (n ¼ 16; 66.7%). For facilities that did not experience a shortage, the presence of respirators stockpiled by the facility (n ¼ 12; 54.6%) was the most common reason given for a shortage being prevented. More than half of hospital managers (n ¼ 23; 53.5%) reported that their facility had received a brand or model of respirator that had not previously been used by their employees. Of these, 47.8% (n ¼ 11) said that all employees were fit tested with the new respirators before use, whereas 47.8% (n ¼ 11) acknowledged that some employees were fit tested before use.

Most respondents (n ¼ 45; 93.8%) reported having a plan to conserve N95 respirators in the event of a shortage, with the most common methods (multiple responses permitted) being redonning (81.3%, n ¼ 39), cohorting of patients (52.1%, n ¼ 26), and extended use (12.5%, n ¼ 6). Fewer hospital managers (n ¼ 37; 77.1%) reported having plans to prioritize use of respirators; the most common methods (multiple responses permitted) were to prioritize respirators for health care workers performing high-hazard (aerosol-generating) procedures (n ¼ 32; 66.7%), for tuberculosis or other patients on airborne precautions (n ¼ 29; 60.4%), and for staff at high risk for complications of pH1N1 infection (n ¼ 12; 25.0%). Thirty-four (70.8%) hospital managers said that their facility had a written policy for redonning of respirators by health care workers in close contact with patients with pH1N1 infection, and of these the most common method for storing respirators between uses was in a paper bag (n ¼ 28; 58.3%).

The assessment of written RPP documents provided by each facility is summarized in Table 3 , including the presence (complete or partial) or absence of elements required under the OSHA respiratory protection standard (ie, designated program administrator, medical evaluation of respirator users, fit testing of respirator users, recordkeeping, training and information, respirator selection, use of respirators, maintenance and care of respirators, and program evaluation). Most (93.8%) of the facilities had a written RPP including at least 1 of the required elements; only 1 facility was completely lacking a written RPP. Four facilities (25%) did not name a RPA. The most problematic element, considering both partial and absent elements, was recordkeeping. Nine (56.3%) facilities only partially addressed the recordkeeping requirements, and 3 (18.8%) did not include this element at all. Considering completely absent elements, the most common omission was program evaluation, with 37.5% of facilities failing to include a written procedure addressing program evaluation.

The emergence of pH1N1 in 2009 provided an opportunity to evaluate hospital preparedness for a widespread novel influenza virus where, in the absence of a vaccine or knowledge about its health consequences, the use of N95 filtering facepiece respirators or equivalent had been widely recommended by public health officials as a minimum level of respiratory protection for health care workers performing patient care. Transmission of pH1N1 was documented among health care workers who treated the initial cases identified in California and associated with inadequate use of personal protective equipment. 14 Once the novel pathogen was recognized, hospitals were expected to quickly implement their * In allotment, suppliers allow hospitals to order only a certain number of respirators, based on their order quantities in the past. pandemic influenza plans for comprehensive infection control measures, including the early identification of suspected cases and use of respiratory protection by exposed workers. This onsite evaluation assessed respiratory protection programs and practices in a randomly selected set of hospitals several months after pH1N1 had spread throughout California, public health guidance on infection control measures had been widely disseminated, and a new state OSHA standard on ATDs had become effective.

We found that all participating hospitals had implemented policies requiring the use of N95 respirators as the minimum level of protection for health care workers in close contact with suspected or confirmed pH1N1 patients, consistent with guidance from state and federal public health agencies as well as the enforceable requirement of the Cal/OSHA ATD standard. Responses from unit and hospital managers indicated a high level of knowledge of this policy (93.3% and 85.4%, respectively). Health care workers from those units overwhelming (95.5%) stated they would select an N95 respirator or a more protective PAPR when caring for a patient with suspected or confirmed pH1N1, demonstrating a high level of knowledge of the policy even if it may not have been consistently followed in practice. We did not assess awareness of the Cal/OSHA ATD standard; thus it is not possible to determine whether or not having an applicable new state regulation was a key factor in promoting the implementation of these policies in California. In contrast, a survey of medical students and residents at a Washington, DC, hospital (November-December 2009) showed that only 13% of medical students and 21% of residents would wear an N95 respirator when caring for a patient with influenza symptoms. 15 Another study conducted at a New York City hospital identified 277 unprotected health care worker exposures related to 44 patients with pH1N1 infection (May-July 2009), explained by suboptimal adherence to PPE recommendations in addition to other factors. 16 In general, the basic elements required with respirator use (eg, medical clearance, fit testing, and employee training) were in place in all hospitals, as demonstrated by consistent responses across health care workers, unit managers, and hospital managers. Because onsite evaluation visits were conducted in January-February 2010, we are unable to report on the extent of N95 respirator readiness in these facilities at the start of the pandemic. Jaeger et al 14 found that 52% of health care workers exposed to the earliest California patients with pH1N1 infections after admission to the hospital were ""N95 ready,"" defined as having been fit tested within the past year and knowing the appropriate size and location of N95 respirators. Data collected from 22 states on 48 health care workers with clinical care duties who had been infected with pH1N1 showed that 69% had ever been fit tested, another assessment of respirator readiness. 17 A National Institute for Occupational Safety and Health survey of internal medicine residents and fellows at 4 Utah hospitals conducted August-September 2009 showed a lower level of training on N95 respirator use (43%) and lower level of fit testing (22% between the beginning of their training and June 2009) than found among this California health care worker sample. 18 Interviewed health care workers overwhelmingly (94%) believed that N95 respirators would be more effective than surgical/ medical masks at protecting them from pH1N1 infection. Given that clearly understanding the differences in protection and appropriate use between respirators versus surgical/facemasks had been cited as a potential challenge for the health care field in pandemic influenza preparedness, 2 our results may reflect progress made in this area. In contrast, 24% of respondents in the Utah study believed that surgical masks and N95 respirators provided equal protection. 18 The heightened awareness among California health care workers about the role of respiratory protection against pH1N1 may have been due to publicity regarding the new ATD standard, and/or employer or union-based educational efforts. Thirty-five percent of health care workers reported experiencing no problems while wearing respirators, and of those who did experience problems, feeling uncomfortably warm was the most frequent issue mentioned (49%), followed by interference with eyeglasses (21%).

We had difficulty drawing conclusions about how health care workers know when to wear a respirator, because multiple responses to this question were permitted. Signage on patient doors, information from coworkers and shift reports, and the health care worker's patient assessment were common responses. Future investigations could look more closely at how hospital respirator policies address this topic, particularly for the earliest health care workerepatient contacts in the hospital, before diagnosis, and for nonclinical staff who may not be included in communications about suspected or confirmed disease status. The New York City hospital study cited earlier, which identified almost 5 unprotected health care worker exposures for each patient with pH1N1 infection who presented with influenza-like illness, highlighted the need to better understand how to more effectively implement screening protocols as well as to achieve adherence to respirator use requirements. 16 In the limited number of observations of respirator users, we did not observe health care workers failing to don a respirator when appropriate; however, frequently identified problems were failure to perform user seal checks, touching the outside of the respirator during doffing, and failure to perform hand hygiene after doffing. Since reuse of filtering facepiece respirators was fairly common (42% of health care workers reported ever reusing a respirator), these latter practices could result in disease transmission due to contamination of the respirator. Further training may be warranted in these facilities on how to properly don and doff respirators, as Table 3  Assessment of written hospital respiratory protection programs   Program element required by OSHA   REACH facility number   1  2  3  4  5  6  7  8  9  10  11  12  13  14  15 16

25.0 Training and information well as how to conduct user seal checks (which should be spelled out in the manufacturers' instructions). These deficiencies in proper respirator use are significant, as they may result in a failure of the respirator to provide its intended level of protection. A recent study with 100 observations of N95 respirator users showed that 76% failed to perform a user seal check and 60% touched the outside of the respirator while removing it. 10 Another observational study performed in 11 hospitals showed deficiencies in proper sequence of PPE removal and only 57% of health care workers performing hand hygiene after removal of respiratory or facial protection. 19 Review of written respiratory protection programs revealed instances where written procedures for 1 or more program elements were lacking or incomplete. Of the 16 hospitals, only 1 had a program that was considered to be complete, and 1 hospital failed to provide a written program. Achieving an effective level of protection from respirator use relies on having comprehensive written procedures for all of the required elements, implementing those procedures, regularly evaluating the implementation of each element (with respirator user input), and making necessary improvements. Such an effort is required under the OSHA respiratory protection standard for any workplace where respirators are used. The most frequently missing program element in the hospitals' written RPPs was program evaluation, followed by the designation of a program administrator. These results suggest that, although hospitals have made substantial progress in implementing the use of respiratory protection, it may be necessary to assign clearer responsibility for overall oversight of the program. Conducting periodic program evaluation, including observations of health care workers using respirators and soliciting input from respirator users, should be broadly implemented. Other areas for improvement of written programs include delineating required recordkeeping procedures, and specifically how fit testing and training are conducted. We are not aware of any other published assessments of written hospital respiratory protection programs.

Given California's specific OSHA requirement for the use of respiratory protection by health care workers in close contact with a patient with suspected or confirmed pH1N1 infection, we were aware of hospitals' concerns regarding the potential for respirator shortages. Our results provide some insight on how hospitals planned for a potential shortage, most commonly through having employees reuse respirators and store them in a paper bag between uses. Half of interviewed hospital managers reported experiencing a shortage of respirators; they cited increased demand due to higher patient loads and supplier inability to fill orders as the key reasons for a shortage. Those facilities that did not experience a shortage stated that stockpiling respirators helped them maintain adequate supply levels. Most facilities formally documented their respirator supplies and use, as encouraged by Cal/OSHA; this information could be useful for their future pandemic influenza planning efforts. Due to respirator supply issues, some hospitals were forced to use alternate respirator brands or models, and some managers acknowledged an inability to fit test all employees with the new respirator before use.

Several limitations should be taken into consideration when generalizing the results of this public health evaluation. First, California was in a unique position regarding pH1N1 because the first cases occurred here, and California enacted the nation's first occupational standard for aerosol transmissible diseases in August 2009 during the peak of the pandemic. Hospitals in California may have been faster to mobilize respirator use because they had been preparing to meet the new standard. Because our evaluations were conducted later in the pandemic, hospitals may have had earlier deficiencies in respirator use that we could not have documented. Another consequence of the timing of our evaluation (influenza activity in California had moved from widespread to sporadic by early 2010) was that some hospital units no longer had any patients on airborne precautions, seriously limiting the number of respirator use observations we could conduct. Therefore, our results and conclusions based on interview data assess knowledge and intended practices, rather than observed practices. Our sample of 16 facilities was small, comprising 5.2% of acute care California hospitals. Hospitals that declined participation (4 out of 20 invited) may have been less successful at implementing respirator use. Although we obtained a sample that was generally representative in terms of size, rural versus nonrural, and type of ownership, generalizing the findings to all facilities in the state should be done with caution. This small sample size precluded analysis of the data by hospital characteristics. Finally, our aim was to evaluate a sample of California hospital RPPs and health care worker respiratory protection practices during a novel pandemic, and the findings are likely not applicable to seasonal influenza or other ATDs.

Studies conducted during pH1N1 documented transmission to health care workers in both inpatient and outpatient environments 14, 17, 20 as well as unprotected exposures. 16 However, available studies lacked the ability to evaluate the effectiveness of respiratory protection. One problem identified in the assessment of the use of PPE 14, 17 was that questions did not distinguish between respondents' use of N95 respirators versus surgical/ medical masks. Improved surveillance of PPE use in health care workplaces has been recommended by the IOM. 21 Observational studies of actual practice during a pandemic, as well as of respiratory protection use during more usual circumstances, could further help to inform efforts to protect health care workers from aerosol transmissible diseases. The IOM has made numerous recommendations regarding the role of respiratory protection in preventing the transmission of pandemic influenza and other viral respiratory diseases to health care workers, and continues to track the nation's progress in this important area of occupational health and safety. 21 

We found that California hospitals evaluated during pH1N1 were able to implement many of the required elements of respiratory protection programs. However, several deficiencies were commonly noted. To provide a comprehensive occupational infection control program, hospitals should ensure that they have a written respiratory protection program, fully implement programs and procedures, and conduct periodic program evaluation to ensure the effectiveness of respirator use for health care worker protection. Increased accessibility of information and resources tailored for hospital respirator program administrators may be helpful in this regard.

",0.7475430534609783
"The individual, environmental, and organizational factors that influence nurses' use of facial protection to prevent occupational transmission of communicable respiratory illness in acute care hospitals","Background: Communicable respiratory illness is an important cause of morbidity among nurses. One of the key reasons for occupational transmission of this illness is the failure to implement appropriate barrier precautions, particularly facial protection. The objectives of this study were to describe the factors that influence nurses' decisions to use facial protection and to determine their relative importance in predicting compliance. Methods: This cross-sectional survey was conducted in 9 units of 2 urban hospitals in which nursing staff regularly use facial protection.","The individual, environmental, and organizational factors that influence nurses' use of facial protection to prevent occupational transmission of communicable respiratory illness in acute care hospitals Background: Communicable respiratory illness is an important cause of morbidity among nurses. One of the key reasons for occupational transmission of this illness is the failure to implement appropriate barrier precautions, particularly facial protection. The objectives of this study were to describe the factors that influence nurses' decisions to use facial protection and to determine their relative importance in predicting compliance. Methods: This cross-sectional survey was conducted in 9 units of 2 urban hospitals in which nursing staff regularly use facial protection.

Results: A total of 400 self-administered questionnaires were provided to nurses, and 177 were returned (44% response rate). Less than half of respondents reported compliance with the recommended use of facial protection (eye/face protection, respirators, and surgical masks) to prevent occupational transmission of communicable respiratory disease. Multivariate analysis showed 5 factors to be key predictors of nurses' compliance with the recommended use of facial protection. These factors include full-time work status, greater than 5 years tenure as a nurse, at least monthly use of facial protection, a belief that media coverage of infectious diseases impacts risk perception and work practices, and organizational support for health and safety. Communicable respiratory illness is an important cause of morbidity among health care workers each year. In Ontario, this problem gained international recognition with the outbreak of severe acute respiratory syndrome (SARS) in Toronto in 2003. In Toronto, SARS resulted in the deaths of 3 health care workers and ongoing morbidity in many others. In a review of the scientific literature on the efficacy of personal protective equipment to prevent the transmission of SARS, it was determined that failure to implement appropriate barrier precautions was one of the key reasons for occupational transmission of communicable respiratory disease. 1 Facial protection (respirators, surgical masks, and eye/face protection) was identified as the personal protective equipment that was least complied with by health care workers, yet it is an important barrier precaution against respiratory illness. [2] [3] [4] Understanding why health care workers fail to appropriately use facial protection has not been well researched.

The Predisposing, Reinforcing, and Enabling Factors in Educational Diagnosis and Evaluation (PRECEDE) model provides a framework to examine the factors that influence health behavior. 5 This model has been adapted for application to self-protective behavior at work. 6 Predisposing factors are individual characteristics such as beliefs, attitudes, and values. Enabling factors are environmental factors such as knowledge and availability of equipment and resources. Reinforcing factors are organizational factors such as communication, policies and procedures, and management commitment to health and safety. 1 The PRECEDE model was used to frame recent literature reviews to identify knowledge gaps and research priorities for effective prevention against occupationally acquired communicable respiratory diseases. 1 These reviews categorized factors as organizational, environmental, and individual. Results showed that an abundance of studies have examined factors related to compliance with universal precautions among health care workers, 7-10 and the majority have found that environmental and organizational factors played a more important role in compliance than individual factors. Results also showed that there has been very little work done regarding factors that influence compliance of health care workers with precautions taken to protect against communicable respiratory illness. The authors suggest that determinants of adherence to universal precautions are likely applicable to many types of selfprotective behavior, including those taken to prevent transmission of communicable respiratory illness. 1 The objectives of this study were to describe the individual, environmental, and organizational factors that affect nurses' compliance with the use of facial protection and to determine the relative importance of these factors. Once the most influential factors are identified, strategies and interventions to enhance compliance can be formulated, tested, and implemented to reduce the prevalence of worker morbidity and mortality from communicable respiratory illness.

This research study was designed as a preliminary investigation to inform a larger and more comprehensive project. A cross-sectional survey design was used. The study took place in 2 acute care hospitals in Toronto, Canada. The vice president and/or chief nursing officer of each hospital were approached to discuss recruitment of the hospital as a site for study. Ethics approval was obtained from the research ethics boards in each hospital.

Units in which nurses were more likely to require regular use of facial protection were identified by the vice president and/or chief nursing officer of each hospital. Five units from one hospital and 4 units from another agreed to participate. Approximately 500 full-and part-time nurses were employed on the 9 units at the time of the study. Taking summer vacation activity, limited time available to collect data on the units, and the demanding work environment into consideration, the researcher aimed to collect completed surveys from 150 nurses or 30% of the total population. Estimating a 35% to 40% response rate, 400 questionnaires were distributed over a 6-week period during the summer of 2006. The researcher (K.N.) spent 2 to 4 days over different shifts on each unit handing out and collecting surveys. A survey drop box was also placed on each unit.

A new, 5-page, 61-item questionnaire was developed for the study. The questionnaire was divided into 5 parts: demographics, individual factors, compliance, environmental factors, and organizational factors.

Part 1 included 7 items that measured basic demographic data. Respondents answered by checking boxes or filling in the blanks. Part 2 examined individual factors that may influence compliance including knowledge of droplet and airborne spread respiratory disease (8 items), perception of effectiveness of preventive actions (4 items), exposure history (2 items), perception of occupational risk (3 items), and personal barriers to the use of facial protection (13 items). The measure to assess knowledge was developed based on government guidelines on preventing the occupational transmission of airborne and droplet spread communicable disease in health care facilities. 11 A response scale of true/false/don't know was used. The remaining individual factors were measured using elements and scales from established tools. 8, [12] [13] [14] Most questions used a 5-point Likert response scale of strongly agree/agree/neutral/disagree/strongly disagree for answers.

Part 3 of the survey examined compliance with recommended use of facial protection. An 8-item scale was developed to measure compliance based on government guidelines. 11 Participants were asked about their compliance with N95 respirators, surgical masks, and eye protection when they suspected a patient had a communicable respiratory illness and when a diagnosis had been made. Responses were measured with a 5point Likert scale of always/mostly/sometimes/rarely/ never. ''Compliant'' was defined as answering always or mostly to at least 7 of the 8 items.

Part 4 of the survey examined environmental factors that could influence use of facial protection including training (8 items), cleanliness/orderliness of the workplace (3 items), availability of facial protection (3 items), and media coverage of infectious diseases (2 items). Training measures included frequency and content of the training program, as well as fit testing of respirators. The measures for the training program content were determined using government guidelines, 11 and a response scale of yes/no/don't know was used. Cleanliness and orderliness of the workplace and availability of facial protective equipment were measured using elements from established scales. 15, 16 Measures related to media coverage were based on a qualitative study that examined the factors that influenced compliance with bloodborne precautions. 10 A 5-point Likert response scale of strongly agree/agree/neutral/disagree/ strongly disagree was used.

Organizational factors were measured in part 5 of the survey and included organizational support for health and safety (5 items), absence of job hindrances (3 items), peer and supervisor feedback (4 items), and conflict/communication (3 items). These factors were measured using elements from established scales. 15, 16 Where necessary, wording was changed to make the statements relevant to preventing the transmission of respiratory illness as opposed to bloodborne illness. A 5-point Likert response scale of strongly agree/agree/ neutral/disagree/strongly disagree was used. At the end of the survey, nurses were encouraged to share any further relevant information on the back of the last page.

The questionnaire was reviewed by occupational health and infection control experts on facial protection and airborne and droplet spread illness, senior nursing officials at both hospitals, and one local of the Ontario Nurses Association. Two focus groups were held to test the survey tool. Nurses participating in the focus groups completed the survey and provided feedback on the accuracy and format of the tool and the time it took for completion. As a result of the focus groups, minor changes were made to the tool. The final version of the questionnaire contained 61 items and was completed by most respondents within 15 minutes.

All statistical analysis was performed using Statistical Analysis Software (SAS) Version 8.0 (1999; SAS Institute Inc., Cary, NC). Descriptive statistics consisted primarily of frequency distributions and means. Reliability of scales was assessed using Cronbach coefficient a. x 2 tests for categorical variables and t tests for continuous variables were conducted to examine the direct effects of each factor on compliance. Variables with a univariate P value , .15 were selected for inclusion in a stepwise logistic regression model to determine those factors with independent predictive value. 17 Interpretation was based on odds ratios (OR) where an OR of 1.0 refers to the equal probability of exposure to the factor in nurses classified as compliant and those classified as noncompliant.

A total of 177 completed surveys were returned for a response rate of 44%. The sample was predominantly female and young (one third of respondents reported being less than 30 years of age) ( Table 1 ). Most of the respondents were from an intensive care unit (44%), whereas the rest represented inpatient units or outpatient clinics (30%) and emergency (26%).

Results showed that 42% of respondents met our definition of compliance and answered always or mostly to at least 7 of the 8 items within the compliance scale. Twenty-one percent of respondents answered always or mostly to all 8 items.

Cronbach coefficient a estimates the reliability of a scale. It is suggested that a score $0.70 is an acceptable reliability coefficient. 18 Cronbach a raw scores were calculated for each measure, and 3 scales (knowledge, effectiveness of preventive actions, and perception of risk) had scores less than 0.70. The scale to measure knowledge demonstrated a reliability coefficient of 0.32. Although this low score might be considered problematic for scales measuring a single trait or content domain, a high a statistic cannot be expected for a multidimensional knowledge scale such as the one used. The scale to measure perception of risk demonstrated a reliability coefficient of 0.64. When the item measuring risk was separated from those measuring impact, the raw score increased to 0.79, suggesting that risk and impact, need to be measured separately. The scale to measure perception of effectiveness of preventive actions demonstrated a reliability coefficient of 0.50. This could be due to the discrepancy between nurses' perception of effectiveness of respirators and hand hygiene as opposed to surgical masks and eye protection. Equipment may need to be evaluated on an individual basis. Univariate analysis Table 2 presents the results of the univariate analysis of associations between explanatory variables and compliance. One demographic variable was found to be significantly associated with compliance: nurses with more tenure reported better compliance with recommended use of facial protection. No individual factors demonstrated a significant association. Of the 4 environmental factors measured, 3 showed a significant association with enhanced compliance: cleanliness, availability of facial protection, and media coverage. Two of the 4 organizational factors assessed in this study expressed a significant association with compliance: organizational support for health and safety and an absence of job hindrances.

Significant variables and variables of interest were entered into a stepwise logistic regression model. Five significant predictors of compliance were revealed (Table 3) .

According to the 2005 Canadian Nurses Association RN Workforce Profile by Area of Responsibility, our sample is fairly representative of the population of nurses working in medicine/surgery, critical care, and emergency. 19 The Canadian Nurses Association profile indicates that the average age of this population was 

Health care workers' compliance with safe work behaviors to prevent the spread of infectious disease is historically poor. 3, 9 Although adherence with hand hygiene, glove use, and immunization has been well studied, compliance with the use of facial protection to prevent the spread of communicable respiratory disease has not been as well studied. One study of 3 US hospitals over 3 years found that health care workers wore appropriate respiratory protection with tuberculosis patients 44% to 97% of the time. 20 Another study showed compliance with respirator use to be 57% when the diagnosis of tuberculosis was unconfirmed and 84% when it was confirmed. 21 A third study retrospectively reviewed health care workers who worked during the SARS outbreaks and their compliance with respirator use. 22 Sixty-six health care workers reported exposure to a patient who was coughing and later found to be SARS positive, yet 40% of these workers did not use a respirator. 22 Our study of acute care nurses in 2 hospitals in Toronto described a comparable rate, with 42% of responding nurses reporting compliance with the recommended use of facial protection.

Demographic factors such as sex, education level, and occupation have not been found to be consistently associated with compliance with infection control procedures. 7 Our study was consistent with this finding and did not show a relationship between age, education, job tenure, or supervisory status and compliance.

Work status was shown to be significantly associated with compliance. Full-time nurses were 3 times more likely to report compliance with the recommended use of facial protection than part-time nurses. This finding is important because part-time nurses may need more intervention than full-time nurses to enhance their level of compliance, and interventions with this group may be logistically more difficult because they spend less time at the workplace. We also found that tenured nurses were more likely to report compliance than new nurses. The literature provides conflicting reports. In a study of correctional workers, it was found that young workers were more likely to be compliant with universal precautions than older workers. 8 On the other hand, another study showed that longer job tenure was related to health care worker compliance with universal precautions and suggests that health care workers with more time on the job have had the opportunity to incorporate experience and judgment into their clinical practice, which could promote the use of appropriate preventive behaviors. 4 This finding is important because managers could enhance compliance by placing nurses with greater tenure into supervisory and mentoring roles.

Our study found that nurses who reported using facial protection at least monthly were more likely to report compliance than nurses who reported using facial protection rarely or never. Although this relationship may have some inherent contributory bias, it is important to note that nurses who report daily, weekly, or monthly use of facial protection should be the ones to care for patients with communicable respiratory disease or supervise those who are providing the care.

Cleanliness and orderliness of the workplace were shown to be associated with compliance at the univariate level. In a study on adherence to universal precautions, it was found that cleanliness and orderliness of the worksite were significantly associated with enhanced compliance. 15 Ensuring that there are resources to keep the workplace clean, allocating adequate storage space, and ensuring that this storage space is used are important strategies to improve compliance on a unit. Availability of facial protection was also significantly associated with enhanced compliance at the univariate level. One hospital study in the United States found availability of protective equipment to be associated with compliance with universal precautions. 15 In a study on SARS transmission in health care workers in Hong Kong, it was found that workers who perceived the amount of available personal protective equipment to be poor were more likely to have developed SARS. 23 It is possible that, in our study, availability of facial protection was not found to be significant at the multivariate level because of a correlation with the frequency of use of facial protection. Having dedicated and convenient areas to store facial protection and the resources to keep these areas well stocked may assist with compliance.

Media coverage was shown to be very strongly associated with compliance at both the univariate and multivariate level. Nurses who thought that media coverage of communicable diseases made them more aware of their risk at work and work more carefully were more likely to report compliance with the recommended use of facial protection. One qualitative study found that media coverage of HIV and hepatitis B was an important factor in health care workers' compliance with universal precautions. 10 The author comments that, although first-and secondhand experience of events are more emotionally loaded, mass media coverage of bloodborne disease has resulted in a sharpened attention to the problems. This finding provides opportunities for further research. Using the media to communicate risk and affect healthy work behaviors to prevent occupational transmission of communicable respiratory illness is an area that has not been well studied.

Several studies have found organizational factors to be the most significant predictor of safe work behaviors, specifically compliance with universal precautions. 8, 9, 15, 16, 24 Our study found that nurses who felt they had organizational support for health and safety were significantly more likely to report compliance with the recommended use of facial protection. This finding was significant at the univariate and multivariate levels of analysis. Measures for organizational support included management making health and safety a high priority, taking all reasonable steps to minimize hazards, encouraging employees' involvement in health and safety matters, and actively working to protect employees. This finding shows how important it is that nurses think their health and safety are valued by their employer. Those who think that they are valued will engage in healthier work behaviors. Interventions targeted at improving how supportive the organization is of employee health and safety can result in enhanced compliance. This finding is supported in the literature related to universal precautions. 4, 25 An absence of job hindrances was shown to be linked to enhanced compliance at the univariate level. Proper use of facial protection can be hindered by the type of duty carried out (eg, carrying out a long procedure while using a tight-fitting respirator), a lack of time to properly use and dispose of the equipment (eg, busy unit or emergency situation), and the desire to provide good quality patient care (eg, having the patient unable to see your facial expression while explaining a risky procedure). One study found that a worker's perception that the use of universal precautions interfered with their work (job hindrance) was a strong predictor of failure to comply with universal precautions. 16 Reducing or eliminating these or other identified job hindrances is a good strategy to enhance compliance. The literature has also shown that a lack of available time and a heavy workload negatively influenced compliance with hand hygiene precautions. [26] [27] [28] [29] 

Our study used a new data collection tool. Reliability testing for 3 of the explanatory measures fell below the acceptable range and require further evaluation. The cross-sectional study design precludes the determination of causality. Study results may not be generalized to all professions, geographic location, or type of health care facility because these findings are from a convenience sample from 2 acute care, urban hospitals with a 44% response rate. Self-selection bias may be a limitation because participation in the study was voluntary and a decision to participate may be correlated with traits that affect the study, making the participants a nonrepresentative sample. For example, people who have strong opinions or substantial knowledge may be more willing to spend time answering the survey than those who do not. Subject recall and social desirability bias may be a problem given the reliance on self-report data for this study. Self-reported compliance has been found to be higher than actual compliance, [30] [31] [32] and it is possible that our data might be an overestimate of our respondents' true compliance.

The objectives of this study were to describe the factors that influence nurses' decisions to use facial protection and to determine their relative importance in predicting compliance. Multivariate analysis showed 5 factors to be key predictors of nurses' compliance with the recommended use of facial protection. These factors include full-time work status, greater than 5 years tenure as a nurse, at least monthly use of facial protection, a belief that media coverage of infectious diseases impacts risk perception and work practices, and organizational support for health and safety. Strategies and interventions based on these findings should result in enhanced compliance with facial protection and, ultimately, a reduction in occupational transmission of communicable respiratory illness.

",0.7431798501342661
N95 filtering facepiece respirators do not reliably afford respiratory protection during chest compression: A simulation study,"Background: N95 filtering facepiece respirators (N95 respirators) may not provide adequate protection against respiratory infections during chest compression due to inappropriate fitting. Methods: This was a single-center simulation study performed from December 1, 2016, to December 31, 2016. Each participant underwent quantitative fit test (QNFT) of N95 respirators according to the Occupational Safety and Health Administration protocol. Adequacy of respirator fit was represented by the fit factor (FF), which is calculated as the number of ambient particles divided by the number inside the respirator. We divided all participants into the group that passed the overall fit test but failed at least one individual exercise (partially passed group [PPG]) and the group that passed all exercises (all passed group [APG]). Then, the participants performed three sessions of continuous chest compressions, each with a duration of 2 min, while undergoing real-time fit testing. The primary outcome was any failure (FF < 100) of the fit test during the three bouts of chest compression. Results: Forty-four participants passed the QNFT. Overall, 73% (n = 32) of the participants failed at least one of the three sessions of chest compression; the number of participants who failed was significantly higher in the PPG than in the APG (94% vs. 61%; p = 0.02). Approximately 18% (n = 8) of the participants experienced mask fit failures, such as strap slipping. Conclusions: Even if the participants passed the QNFT, the N95 respirator did not provide adequate protection against respiratory infections during chest compression.","Emergency departments (EDs), the principal portals of entry into healthcare systems, are increasingly required to screen and treat patients with communicable infections [1, 2] . In 2015, a large outbreak of Middle East respiratory syndrome (MERS) coronavirus infection occurred after exposure to a single patient in an overcrowded ED of a hospital in South Korea; several individuals, including healthcare workers (HCWs), were infected [3, 4] . The World Health Organization and the U.S. Centers for Disease Control and Prevention recommend that HCWs must use a particulate filtering facepiece respirator that is at least as protective as the National Institute for Occupational Safety and Health (NIOSH)certified N95 filtering facepiece respirator (N95 respirator) or its equivalent when treating patients with airborne infectious diseases [5, 6] . However, such facepiece respirators can provide protection only when the face seal fits tightly. Therefore, fit testing is essential; a qualitative or quantitative approach must be used to identify respirators that best suit each individual [7, 8] .

The quantitative fit test (QNFT) objectively determines the adequacy of respirator fit by measuring leakage around the face seal using the respirator fit tester [9, 10] . This device measures the fit factor (FF) (the number of ambient particles divided by the number inside the respirator when simulating eight workplace activities). An overall FF !100 is considered the passing level [9] . However, although the overall FF may be !100, the FFs for individual exercises may be <100 (for example, during bending).

Cardiopulmonary resuscitation (CPR), a common ED procedure, generates infectious aerosols, and this is associated with an increased risk of pathogen transmission to HCWs [11, 12] . Some exercises for the conventional QNFT mimic chest compression, which include bending at the waist and head up-and-down movement [9] . However, chest compression during CPR is significantly more dynamic and rapid than QNFT exercises. Therefore, it is unclear whether the protective effects of the N95 respirators will be maintained during chest compression particularly in those who failed at least one individual conventional QNFT exercise. Previously, Shin et al. have evaluated the effects of movements during chest compression on the protective performances of various N95 respirators in the simulated setting [13] . They demonstrated that the FFs of certain respirators decreased during chest compression, thereby seriously compromising respiratory performance.

No study has yet explored the stability of N95 respirators in a group that only partially 'passed' the QNFT. Thus, we compared the respirator failure (FF < 100) rates during chest compression between a partially passed group (the overall fit factor was adequate, but at least one specific exercise was failed; the PPG) and an all passed group (group that passed all exercises: the APG).

This was a single-center simulation study that explored potential issues that may be encountered when wearing an N95 respirator during chest compression. The study was conducted in a laboratory in Samsung Medical Center (a tertiary, universityaffiliated, referral hospital located in a large city in Korea) from December 1, 2016, to December 31, 2016. The temperature and humidity of the room were controlled at approximately 23°C and 30%, respectively, to minimize the impact of environmental factors on outcomes. The institutional review board of our institution approved the study, and a written informed consent was obtained from each participant.

The inclusion criteria were as follows: HCWs aged !20 years, those certified for the delivery of basic life support or advanced cardiovascular life support by the American Heart Association (AHA) or those who had completed our institutional training program, and those who delivered CPR in the clinical field [14] . The exclusion criteria were as follows: HCWs who were pregnant, those with any musculoskeletal diseases that compromised the capacity to deliver chest compression, and those with medical conditions, including asthma, congestive heart failure, or coronary heart disease. Moreover, the participants who failed the fit tests for all three respirators were not included.

At the beginning of the simulation, the investigators conducted a brief training session for the participants, which included providing instructions for the overall flow of the study using slides and via demonstration and practice in using the standardized N95 respirator donning technique. They were instructed to complete questionnaires about the demographic characteristics of the participants after the training session. Then, every participant took the QNFT for the N95 respirator. We divided the participants into two groups (PPG and APG) (Fig. 1 ).

Since the MERS epidemic in 2015, all employees in our institution must be fit tested using three N95 respirators: the 1860 and 1870+ (3 M, St. Paul, MN) and the 46,727 (Kimberly Clark, Irving, TX). The best-fitting respirator is identified based on the QNFT FF and comfort of the person who wears such device. We selected respirators based on earlier data available for all participants. However, if the shape of the face had changed because of weight change, plastic surgery, or dental correction, the fit test was repeated.

We used the PortaCount Pro+ 8038 Respirator Fit Tester (TSI Inc., Shoreview, MN) for QNFT. The QNFT for the N95 respirator was conducted according to the Occupational Safety and Health Administration (OSHA) protocol [9, 15] . While wearing the respirator, eight test exercises were performed in the following order: normal breathing, deep breathing, head side-to-side moving, head up-and-down motion, talking, grimacing, bending over, and normal breathing. For the talking exercise, the participants read identical text prepared in advance. Each exercise was performed for 1 min except for grimacing (15 s). The FF of grimacing was excluded from the final calculation according to the OSHA protocol [9] . An FF > 200 was scored as 200 by the tester. All FFs were continuously monitored and considered passing if the final score was !100.

After the fit test, the participants were instructed to perform continuous chest compression on a Resusci Anne mannikin (Laerdal Medical, Stavanger, Norway) three times for 2 min each (with 4-min rest between each session) while undergoing further fit testing (Fig. 1) ; they were not allowed to touch or adjust the mask. If the mask strap loosened, it was re-adjusted during the break. To ensure that the CPR was of high quality, which is in accordance with the 2015 AHA guidelines, all data were collected using a Laerdal PC Skill Reporting System (Laerdal Medical) [16] . One investigator provided feedback to all participants in real time while watching the computer monitor. The participants rested for 20 min after the three sessions of chest compression, followed by an additional compression for 2 min while wearing the same respirator after performing a user-seal-check.

The primary outcome was any failure (FF < 100) of the fit test during the three bouts of chest compression. The secondary outcome was the slipping down of respirator during chest compression.

A priori sample size calculations were made in terms of primary outcome achievement; we assumed an a value of 0.05 for twosided hypothesis testing and a b error of 0.20 (power = 80%). A preliminary study of 10 participants has revealed a failure rate of 50%. We considered that a 40 percentage point increase in the failure rate was clinically significant; we assumed that the PPG might evidence failure. A total of 42 patients were required to detect this hypothesized failure rate.

Standard descriptive statistics were used to present all data. Continuous variables were provided as medians with interquartile ranges (IQRs), and the Wilcoxon rank-sum test was used for comparisons. Categorical data were presented as numbers with percentages and compared using the chi-square test. STATA version 13.0 software (STATA Corporation, College Station, TX) was used to perform all statistical analyses.

We recruited 45 participants, of whom 1 was excluded due to failure in the baseline QNFT using all three N95 respirators; 44 participants were ultimately included, of whom 66% (n = 29) were female. The median age of the participants was 31 (IQR: 26.5-36) years. Most participants were nurses (52%, n = 23) with an average clinical experience of 6 (IQR: 3-10) years. Baseline data, such as age, sex, career duration, body mass index, occupation, CPR training, and respirator type, did not significantly differ between the two groups ( Table 1 ). The 3M 1870 + N95 respirator (n = 25, 57%) was most frequently used, followed by the Kimberly Clark 46727 (n = 15, 34%) and the 3M 1860 (n = 4, 9%).

No significant differences were observed in the quality of chest compression between the two groups except in terms of compression rate during the second cycle (PPG vs. APG: 113.5, IQR: 109-116.5 vs. 108.5, IQR: 105-114, p = 0.04) ( Table 2 ).

The outcomes are shown in Table 3 and Fig. 2 . Overall, 73% (n = 32) of the participants failed at least one of the three chest compression sessions; the failure rate was significantly higher in the PPG than in the APG (94 vs. 61%; p = 0.02). In total, 18% (n = 8) of the participants experienced respirator failure, such as strap loosening. The overall failure rate of the fit test after userseal-check was 59% (n = 26), and it was not different between the PPG and APG (63% vs 57%, p = 0.73).

Even when the participants passed the QNFT, N95 respirators did not afford adequate protection during chest compression. Notably, in 94% of the participants in the PPG, the FF decreased to <100 during at least one session of chest compression. Facepiece respirators only work properly when the face seal is tight [17, 18] . Body movements during chest compression are both dynamic and intense, and sweat further compromises respirator fit, creating a gap permitting disease transmission. Therefore, our findings are clinically significant in terms of the safety of HCWs who are at high risk for airborne disease transmission during chest compression even when wearing adequately fit-tested N95 respirators.

The conventional QNFT is widely used to measure N95 respirator performance in HCWs. However, the exercises performed during the fit test are not similar to those executed in real-world setting. Suen et al. have used a portable aerosol spectrometer to evaluate the performance of N95 respirators during various nursing procedures, including suction and nasogastric tube insertion for 10 min [19] . The average FF decreased significantly from 184.85 to 134.71 after completing the procedures, and the FF fell to <100 in 33% of the participants. This study indicated that N95 respirators may not provide consistent protection against respiratory infection for HCWs.

The QNFT failure rates during chest compression after the user-seal-check did not differ between the two groups. Several previous studies have suggested that this user-seal-check alone inadequately evaluates respirator fitting [20, 21] . Nevertheless, in clinical practice, all treatments are performed after a user-sealcheck alone. Therefore, our results suggest that pre-passing the N95 QNFT did not ensure respiratory safety during chest compressions.

It is known that the risk of disease transmission from patients to rescuers during CPR is extremely low [22, 23] . One review article has shown that the number of infections acquired during CPR is approximately <1/200,000 [24] . However, previous studies have Data were presented as median with interquartile range or n (%). One retrospective cohort study has reported that one of nine HCWs who participated in cardiac compression developed severe acute respiratory syndrome (SARS) [25] . Of the six HCWs who performed CPR on a patient with MERS, one acquired the infection [11] . Experiences from the outbreaks of highly contagious diseases, such as SARS and MERS, taught us that HCWs should be protected from airborne disease transmission when performing CPR [11, 12, 26, 27] . The current international CPR guidelines do not address the extent of airway protection required by HCWs when performing CPR on patients with suspected or confirmed airborne diseases [22] . Infection-prevention strategies for HCWs tend to take second place in life-threatening situations requiring minimization of noflow time [11, 12] . However, the safety of HCWs is in fact paramount. Mechanical compression devices can be used to minimize HCW participation in CPR. In addition, HCWs engaging in chest compression of patients with airborne diseases could wear powered air-purifying respirators with hoods (PAPRs) rather than N95 respirators. However, this may result in resuscitation difficulties, and both movement and communication are compromised [28, 29] . In addition, the protective effects of PAPRs during chest compression have not been explored, and further studies are warranted.

Our study had certain limitations. First, we aimed to maximally reflect actual clinical settings. However, we worked in a simulation laboratory, and the outcomes of the present study might differ from those of real-world settings. The participants performed continuous chest compression based on the assumption that the patient had an advanced airway. However, in patients without an advanced airway, chest compressions are briefly paused to provide ventilation [16] . CPR is complex, featuring chest compression, endotracheal intubation, defibrillation, bag-valve ventilation, intravenous line insertion, and drug administration. However, we focused on chest compression only. If the participants carried out other tasks, then the outcomes might have differed. In addition, in the present study, the participants were instructed not to talk as much as possible. We believed that such action was reasonable when providing CPR to patients with air-borne disease. However, HCWs need to talk for communication in real settings, which can loosen the fitting of the N95 respirator. Second, we had only three respirator types available; thus, our results cannot be generalized to other models. Third, although chest compression lasted for 2 min, the FF was obtained after excluding data from the first 20 s because the time was used for ambient purge, ambient sample, and mask purge.

Even in individuals who passed the initial fit test, N95 respirators did not provide adequate protection during chest compression. The participants in the PPG were at particular risk of airborne disease transmission during chest compression. Further study must be conducted to establish specific guidelines about the level of respiratory protection for HCWs during CPR of patients with airborne diseases.

None.

",0.7404277144714031
Universal and reusable virus deactivation system for respiratory protection OPEN,"Aerosolized pathogens are a leading cause of respiratory infection and transmission. Currently used protective measures pose potential risk of primary/secondary infection and transmission. Here, we report the development of a universal, reusable virus deactivation system by functionalization of the main fibrous filtration unit of surgical mask with sodium chloride salt. The salt coating on the fiber surface dissolves upon exposure to virus aerosols and recrystallizes during drying, destroying the pathogens. When tested with tightly sealed sides, salt-coated filters showed remarkably higher filtration efficiency than conventional mask filtration layer, and 100% survival rate was observed in mice infected with virus penetrated through salt-coated filters. Viruses captured on salt-coated filters exhibited rapid infectivity loss compared to gradual decrease on bare filters. Salt-coated filters proved highly effective in deactivating influenza viruses regardless of subtypes and following storage in harsh environmental conditions. Our results can be applied in obtaining a broad-spectrum, airborne pathogen prevention device in preparation for epidemic and pandemic of respiratory diseases.","Aerosols take a prominent role in airborne transmission of respiratory diseases. Droplets with aerodynamic size (d a ) < 10 μ m and 10 < d a < 100 μ m are known to infect the alveolar regions and upper respiratory tract, respectively 1, 2 . Notably, aerosols can also be a route of infection in diseases that, contrary to for instance influenza, do not specifically target the respiratory tract, as it could be the case of Ebola virus 3 . While vaccination can greatly reduce morbidity and mortality, during a pandemic or epidemic new vaccines matching the specific strain would be available, at the earliest, six months after the initial outbreak. Additionally, following development of an effective viral vaccine, several potential problems would remain, such as limited supply due to insufficient production capacity and time-consuming manufacturing processes. As a result, individuals close to the point of an outbreak would be in imminent danger of exposure to infectious diseases during the non-vaccine period. In the absence of vaccination, respirators and masks can be worn to prevent transmission of airborne pathogenic aerosols and control diseases, such as influenza 4 .

The main alternative, the N95 respirator, requires training prior to use, must be expertly fitted to address the risk of faceseal leakage at the face-mask interface, and must be disposed of as biohazard 5 . Due to these factors, the use of N95 respirators on a large scale is impractical and expensive during an epidemic or pandemic. Past experiences of severe acute respiratory syndrome (SARS), H1N1 swine flu in 2009, and Middle East respiratory syndrome (MERS) indicate that surgical masks have been most widely adopted by the public as personal protective measure, despite controversy on their effectiveness [6] [7] [8] [9] . Currently, among other factors, filtration in respirators and masks depends on filter characteristics, including fiber diameter, packing density, charge of fibers and filter thickness, as well as particle properties, such as diameter, density and velocity [10] [11] [12] [13] [14] . However, in the lack of a system to deactivate the collected pathogens, safety concerns naturally arise about secondary infection and contamination from virus-laden filter media during utilization and disposal. Furthermore, since re-sterilization is not possible without causing damage, respirators and masks are recommended for single use only 9, 15, 16 . Scientific efforts have been focused on treatment of filters with materials possessing well-known antimicrobial properties, such as iodine, chlorine and metals [17] [18] [19] [20] [21] [22] [23] [24] [25] , although with limited effectiveness against virus aerosols [26] [27] [28] . Therefore, a key challenge is the development of an easy-to-use, universal virus negation system, which is reusable without reprocessing and capable of deactivating pathogens, thereby reducing potential risk of secondary infection and transmission.

Here, we report a simple but efficient virus inactivation system exploiting the naturally occurring salt recrystallization. Our strategy is to modify the surface of the fibrous filtration layer within masks with a continuous salt film for virus deactivation via two successive processes: i) salt is locally dissolved by the viral aerosols and ii) supersaturation is followed by evaporation-induced salt recrystallization. Consequently, viruses are exposed to increasingly higher concentrations of saline solution during drying and physically damaged by recrystallization.

To demonstrate the concept of virus deactivation system based on salt recrystallization, the middle layer of three-ply surgical mask, polypropylene (PP) microfiber filter, was coated with NaCl salt as an active virus negation unit (see Supplementary Fig. S1 for bare PP filter). The coating formulations contained surfactant to enhance wetting of saline solution on the surface of hydrophobic PP fibers. Bare PP filters (abbreviated as Filter bare ) were pre-wet to contain about 600 μ L of coating solution (abbreviated as Filter wet ). The amount of NaCl salt (W salt in mg/cm 2 ) coated on the filter per unit area, considering that the filters thickness is constant, was easily controlled by changing the coating solution volume (V salt in μ L) during drying of pre-wet filter (radius: 3 cm, W salt = 3.011 + 0.013 × V sat , n = 7) (Fig. S2 ). Scanning electron microscopy (SEM) and energy dispersive X-ray (EDX) mapping analysis showed the formation of homogeneous NaCl coating during drying, as also confirmed by X-ray diffraction (XRD) (Fig. 1a,b and Supplementary Fig. S3 ). Both the formation of NaCl coating on PP fibers and presence of surfactant in the coating formulation appeared to alter the filter surface properties from hydrophobic (bare filter; contact angle, θ c = 133.0 ± 4.7°) to completely hydrophilic (salt-coated filter; θ c ~ 0°, n = 10) ( Fig. 1c and Supplementary Fig. S4 ). Hydrophilic nature of salt coating can greatly improve adhesion of viral aerosols to PP fibers compared to Filter bare , as seen in Raman microscope images ( Fig. 1d and Supplementary Fig. S5 ). Filtration efficiency against viral aerosols and protective efficacy in vivo. Filtration efficiency of salt-coated filters was tested against aerosols with volumetric mean diameter (VMD) of 2.5-4 μ m containing H1N1 pandemic influenza virus (A/California/04/2009, abbreviated as CA/09) at different pressure conditions (see Fig. 2a for transmission electron microscope (TEM) image of H1N1 virus). Interestingly, as shown in Fig. 2b , Filter bare did not exhibit any significant level of resistance against penetration of virus under our experimental conditions (i.e., 0% filtration efficiency). Conversely, salt-coated filters showed substantially increasing filtration efficiency with pressure and amount of coated salt. In particular, in the case of Filter wet+600μL , filtration efficiency varied from 43 to 70%, with increasing pressure from 3 to 17 kPa, and Filter wet+1200μL exhibited persistent, high-level efficiency (~85%) (one-way ANOVA, P = 0.85).

To probe the effects of filtration efficiency on protective efficacy, in vivo experiments were performed using mice intranasally (IN) infected with penetrated dosages of H1N1 virus under breathing pressure (~10 kPa) 29 . As shown in Fig. 2c , similarly to negative control groups (mice infected with lethal dose of virus stock and aerosolized virus), mice exposed to a dose penetrated through the bare filter showed rapid body weight loss, followed by death within 10 days after infection, in good agreement with the observed 0% filtration efficiency (Fig. 2b) . In contrast, mice groups exposed to virus derived from salt-coated filters resulted in 100% survival rate (Fig. 2d) . Furthermore, lungs of mice from negative control groups exhibited severe lung infection 4 days after challenge (Fig. 2e) . Conversely, mice groups exposed to virus derived from salt-coated filters showed significantly lower levels of lung viral titers (t-test, P < 0.005). This is consistent with lower levels of inflammatory cytokines, interferon-γ (IFN-γ ), from salt-coated filter groups compared to negative control and bare filter groups (t-test, P < 0.001) (Fig. 2f ).

investigate the effects of salt coating. The same amount of recovered viruses from the PP fibers was used, and, in the case of bare filters, viral aerosols exposure was conducted in the absence of pressure due to 100% penetration of viral aerosols. Unlike bare filters ( Fig. S6a (i)), formation of micron-sized NaCl phase represents a typical feature of salt-coated filters due to recrystallization of NaCl salt, following local dissolution upon aerosols exposure (SEM images in Fig. S6a , ii to iv, and EDX mapping in Fig. S6b ). In contrast to 8% HA activity loss of virus adsorbed onto Filter bare , salt-coated filters exhibited almost complete HA activity loss within 5 min of incubation (Fig. 3a) . Such dramatic virus destabilization on salt-coated filters is further supported by negligible levels of viral titers compared to Filter bare with incubation time (t-test, P < 0.001) (Fig. 3b ). It is also noted that virus titers exhibited significant decrease with increase of incubation time and amount of coated salt (ANOVA general linear model, P < 0.001). TEM analysis showed that influenza virus on Filter bare experiences morphological change into non-spherical shape during aerosol drying ( Fig. 3c(i) ). Notably, influenza virus was severely damaged on salt-coated filters even at 5 min of incubation ( Fig. 3c(ii) ). From microscopic analysis, aerosol drying time was about 3 min, indicating that destruction of virus observed at 5 min is associated with drying-induced salt crystallization. Physical damage of virus due to crystallization was similarly reported as a major destabilizing factor of inactivated influenza virus 30, 31 . Lower levels of native fluorescence and nile red fluorescence from virus recovered from salt-coated filters accounted for more severe conformational change of antigenic proteins and destabilization of viral envelope, respectively, consistent with TEM analysis (t-test, P < 0.001) (Fig. 3d ). In parallel, we investigated the separate effect of salt concentration increase on virus stability during the aerosol drying process, irrespective of crystal growth. As displayed in Supplementary Fig. S7 , the materials collected in suspension from Filter wet+600μL induced visible morphological transformation of the virus (Supplementary Fig. S7b ) compared to suspension of Filter bare ( Supplementary Fig. S7a ). This can be attributed to the high salt/surfactant concentration and osmotic pressure, which have been well-known to destabilize proteins and viruses [31] [32] [33] . Therefore, the marked virus destabilization on salt-coated PP fibers can be explained by the combined effects of salt concentration increase during drying and evaporation-induced salt crystallization.

To verify in vitro virus stability on the filters, an in vivo study was performed by infecting mice with virus incubated for 60 min on PP filters. As shown in Fig. 3e , Filter bare group exhibited 5% body weight loss at day 9 post-infection, reaching a body weight lower than that of salt-coated filter groups by 10-15%. Thus, significantly higher lung virus titers in the negative control group were observed in contrast to no detectable titers in the salt-coated filter groups (Fig. 3f ).

on salt coating stability. Broad-spectrum protection of salt-coated filters against multiple subtypes of viral aerosols was evaluated by investigating both lethal infectivity by penetrated virus in vivo and infectivity by virus collected on filters during filtration in vitro using A/Puerto Rico/08/1934 (PR/34 H1N1) and A/Vietnam/ 1203/2004 (VN/04 H5N1). Similarly to CA/09 H1N1, 100% of mice survived viral infection (PR/34 and VN/04), with no evidence of weight loss, due to higher filtration efficiency of salt-coated filter than that of bare filter (Fig. 4a ). This is supported by no significant level of viral titer in the lung. In addition, as shown in Fig. 4b , salt-coated PP filters destroyed adsorbed influenza viruses irrespective of both subtypes and amount of coated salts.

The stability of salt coating on PP fibers was tested under harsh environmental conditions. Incubation at 37 °C and 70% relative humidity (RH) for 1 day did not cause any significant difference in filtration efficiency (t-test, P = 0.718) (Supplementary Fig. S8 ). As a result, all mice infected with dosage of penetrated virus through the filter stored at high temperature and RH displayed 100% survival with 7% of body weight loss (Fig. 4c,d) . Even after 15 days of incubation, salts remained to coat PP fibers (Fig. 4e, and Supplementary Fig. S9a,b) , despite change in grain orientation due to recrystallization (Fig. 4f, and Supplementary Fig. S10a,b) . (c-f) Effects of filtration efficiency on protective efficacy in vivo. Body weight change of mice after infection with the dosages of penetrated virus (n = 12, mean ± SD) (c), survival rates (mean; 100% means that all mice in the group survived as penetrated dosages were lower than lethal dose) (d), lung virus titers (n = 4, mean ± SD) (e), and lung inflammatory cytokine (interferon-γ (IFN-γ )) assay (n = 11, mean ± SD) (f). Legends: filters are labelled as in Fig. 1b . Discussion Development of a universally applicable, low-cost, and efficient mechanism for virus negation is regarded as a major challenge in public health against general airborne biological threats. This led us to propose a new concept of personal/public preventive and control measures using salt-recrystallization against pathogenic aerosols based on two hypotheses. The salt-coating can enhance adsorption of virus on the filter fibers and inactivate virus by the increase of osmotic pressure followed by the crystallization of salts. As shown in Fig. 2b , salt-coated filters exhibited significantly higher levels of filtration efficiency than bare filters. Notably, the bacterial filtration efficiency (BFE) reported by the mask manufacturer is 99%. The different value of filtration efficiency for bare filters obtained under our experimental conditions may be partially due to the use of aerosols with different biological origins. The FDA-recognized ASTM F2101 -14 standard for evaluation of BFE exposes surgical masks to Staphylococcus aureus aerosols, by employing S. aureus ATCC 6538 34 , which has an average diameter of about 1 μm. In this study, filtration efficiency was calculated following exposure of bare and salt-coated filters to influenza virus, which exhibits a smaller diameter than that of S. aureus by one order of magnitude. Additionally, whereas during BFE evaluation all three layers of surgical masks are used, in this work filtration efficiency refers to mask filters (middle layer). It is worth noting that the conditions for BFE standard evaluation (such as flow rate and time of application of flow) do not coincide with the experimental procedure we used for measurement of the filtration efficiency, which may further contribute to the different result. The enhanced filtration efficiency of salt-coated filters against influenza virus aerosols as compared to bare filters can be explained by the observed wetting of aerosols, favoring greater adhesion to salt-coated filters. Furthermore, the significant improvement in filtration efficiency resulted in complete protection of mice against lethal influenza aerosols, which demonstrates the high level of protection provided by salt-coated filters, outperforming currently used bare filters.

Rapid loss of HA activity and viral infectivity on salt-coated filters can be explained by physical destruction of virus during recrystallization of coated salts. When the salt-coated filter is exposed to virus aerosols, salt crystals below the aerosol droplet dissolve to increase osmotic pressure to virus. Due to evaporation, the salt concentration of the droplet significantly increases and reaches the solubility limit, leading to recrystallization of salt. As a consequence, virus particles are exposed to increasing osmotic pressure during the drying process and are physically damaged by crystallization. As shown in Fig. 3e ,f, the superior advantage of physically destroying the virus adsorbed to the salt-coated PP filters through natural salt crystallization process was further confirmed in vivo. According to previous reports, hyperosmotic stress (> 541 mOsm) and crystallization induce membrane perturbation with irreversible deformation of the viral envelope and structural virus damage, respectively, resulting in infectivity loss of virus 30, 31 . Therefore, our data support that the extensive level of infectivity loss associated with a salt recrystallization process caused by physical contact between virus aerosols and salt coating can be used in developing virus negation systems that are reusable without reprocessing.

Similarly to CA/09 H1N1 aerosols, increased protection in vivo due to higher filtration efficiency of salt-coated filters compared to bare filters and deactivation of virus on salt-coated filters were observed following exposure to PR/34 H1N1 and VN/04 H5N1 (Fig. 4a,b) . This suggests that salt-coated filters prevent virus penetration and destroy virus attached to the filter in a non-specific way. Furthermore, the performance of salt-coated filters was not degraded by storage at 37 °C and 70% RH, demonstrating that salt recrystallization-based filters can ensure protection even under harsh environmental conditions. Notably, for demonstration of the concept of salt-recrystallization based virus deactivation system, NaCl salt was used, which has a critical RH of 75% at 30 °C 35 . However, salts with higher critical RH can be easily used, such as ammonium sulfate, potassium chloride and potassium sulfate, which have critical RH of 80%, 84% and 96.3% at 30 °C, respectively 35 . This suggests that salt-coated filters may be developed for specific environmental conditions.

In conclusion, we demonstrated that the developed salt-recrystallization based filtration system provides high filtration efficiency and successfully deactivates multiple subtypes of adsorbed viruses. Moreover, we have shown that stability of the salt coating is not compromised by high temperature and humidity, which suggests safe use and long-term storage/reuse at such environmental conditions. Although our tests are based on exposure to different types of influenza virus, the significance of these results for personal and public protective measures may be generally extended to enveloped respiratory viruses where infection and transmission can occur by aerosol. Our salt-coated filter unit can promise the development of long-term stable, versatile airborne pathogen negation system, without safety concerns. In fact, the destruction mechanism of viruses solely depends on the simple, yet robust naturally occurring salt recrystallization process, combining the destabilizing effects of salt crystal growth and concentration increase during drying of aerosols. This idea can be easily applied to a wide range of existing technologies to obtain low-cost, universal personal and public means of protection against airborne pathogens, such as masks and air filters in hospitals. Therefore, we believe that salt-recrystallization based virus deactivation system can contribute to global health by providing a more reliable means of preventing transmission and infection of pandemic or epidemic diseases and bioterrorism.

Bare and salt-coated filter samples preparation. The commercial surgical masks had a three-ply structure. The middle layer is the filter media, whereas the inner and outer layers provide support and protect the filter against wear and tear. The metal nose clips and elastic ear loops were removed and circular samples (radius: 3 cm) were cut from the masks. The PP filters (middle layer) were isolated by removing the inner and outer protective layers (bare filters, Filter bare ). The coating solution was prepared by dissolving sodium chloride solution. Subsequently, the filters were deposited in the desired volume of coating solution (0, 100, 300, 600, 900 and 1200 μL, of which corresponding membranes are abbreviated as Filter wet , Filter wet+100μL , Filter wet+300μL , Filter wet+600μL , Filter wet+900μL , and Filter wet+1200μL , respectively) on petri dishes (60 × 15 mm; Fisher Scientific) to control the amount of NaCl per unit area and dried in an oven (Isotemp Incubator, Fisher Scientific) at 37 °C for 1 day.

(PR/34, H1N1) and A/Vietnam/1203/2004 (VN/04, H5N1) were grown in 10-day old embryonated hen eggs, in which H5N1 virus was derived by reverse genetics from HPAI A/Vietnam/1203/2004 36 . Influenza viruses were purified from allantoic fluid using discontinuous sucrose gradient (15%, 30% and 60%) layers following the previously reported procedure 37 .

Aerosols exposure to filters. For experiments involving aerosols exposure, an aerosol chamber (L × W × H = 145 × 145 × 150 mm; Emka Inc., Middletown, PA) was used (Fig. S11 ). It has a connection to the vacuum line and a circular aperture in the top wall (diameter: 22 mm) to exactly accommodate the cylindrical part (diameter: 20 mm, height; 20 mm) of the nebulizer unit that is below the aerosol generator (Aeroneb Lab Nebulizer System; Aerogen, Galway, Ireland). Bleach was used as trap between the chamber and the vacuum pump (Welch 2522C-10, 22 L/min; Niles, IL). The filters were placed on top of the chamber aperture and the nebulizer unit was inserted, ensuring the tight seal of the filters against the side of the aperture. 5 μ L of virus stock were added to the nebulizer unit, aerosols (VMD 2.5-4 μ m from manufacturer specifications) were generated for 30 sec and subsequently the desired vacuum level (3, 10 or 17 kPa) was applied, by manual control, three times in 1 sec cycles. Notably, in the case of bare filters, pressure was only applied for filtration efficiency tests.

For all assays and analysis, suspensions of the filters were prepared as follows, unless otherwise indicated. To reconstitute virus adsorbed onto filters, virus-laden filters were immersed in 400 μ L of sterilized DI water for about 5 min, and then removed after vortexing from the suspension. The virus suspension was centrifuged at 19,800 g and 4 °C for 10 min (Centrifuge 5810 R, Eppendorf, Hauppauge, NY), followed by resuspension of pellets in 70 μ L of DI water to eliminate any interference from materials in supernatant during assays.

Filtration efficiency tests. The filters were exposed to the virus aerosols at 3, 10 and 17 kPa and suspensions of the filters were obtained, as described above. The filtration efficiency was calculated as the ratio of the amount of virus (i.e., total proteins measured from the virus) reconstituted from the filter to that from the virus in the exposure aerosols. The concentration of virus in aerosols was determined by generating viral aerosols into a 15 mL centrifuge tube, containing 1 mL of DI water. After vortexing, virus concentrations (i.e., total protein concentration) were measured with bicinchoninic acid assay (BCA protein assay kit; Thermo Fischer scientific, Waltham, IL) with bovine serum albumin as a standard. In the case of virus reconstituted from salt-coated filters, virus-laden filter suspension was replaced with DI water prior to BCA assay.

In vivo infection tests. Lethal infectivity of influenza viruses (CA/09 H1N1) was examined in 8 week old female inbred BALB/c mice (Nara Biotech; Seoul, Korea) by using the intranasal route. For bare and salt-coated filters, 12 mice per group were infected with individual penetration dosage of influenza virus through each filter. The penetration dosage of the virus through the filters (Filter bare , Filter wet , Filter wet+600μL , and Filter wet+1200μL ) was calculated from the filtration efficiency at 10 kPa (near breathing pressure) using the relationship: penetration dosage = virus dosage in lethal aerosol × penetration efficiency (%)/100, where penetration efficiency (%) = 100 − filtration efficiency (%). To examine the effects of the aerosolization process on the viral infectivity change, two mice groups were infected with a lethal dose of virus before and after aerosol formation, which served as negative control groups. Body weight changes and survival rate of mice were monitored daily for 15 days. Mice with body weight loss greater than 25% were euthanized. All animal protocols were approved by the Kyung Hee University (KHU) Institutional Animal Care and Use Committee (IACUC). All animal experiments and husbandry involved in this work were conducted under the approved protocols and guidelines of KHU IACUC. KHU IACUC operates under National Veterinary Research and Quarantine Service (NVRQS), and animal welfare law and regulations of the WOAH-OIE (World organization for animal health).

To test strain-dependent lethal infection behavior, mice (12 per group) were infected with the penetrated dosage of viral aerosols (PR/34 H1N1 and VN/04 H5N1 viruses) through Filter wet+600μL at 10 kPa. Time-dependent body weight change was monitored in the same manner described above.

mice of each group were sacrificed for the collection of lung samples. Lung virus titers were measured on six-well plates containing confluent MDCK cell monolayers. Inflammatory cytokines (IFN-γ ) were determined using BD OptEIA mouse IFN-γ ELISA kit (BD Biosciences, San Jose, CA) following the manufacturer's procedure.

To investigate the effects of salt-coating on viral infectivity loss, lethal influenza aerosols were exposed to four different types of filters (Filter bare , Filter wet , Filter wet+600μL , and Filter wet+1200μL ). Since Filter bare exhibited almost complete penetration upon pressure application, aerosols were exposed to the bare filter in the absence of pressure and samples were carefully handled to prevent mechanical agitation. To measure time-dependent stability change of virus, virus-laden filters were incubated at ambient conditions for 0, 5, 15, and 60 min after aerosol exposure, and suspended in DI water to reconstitute virus at each time point. In vitro stability of virus was characterized by measuring hemagglutinin activity (HA) and virus titers at the same concentration as lethal dose 30 . The conformational stability of antigenic proteins was characterized by measuring intrinsic fluorescence using 0.1 mg/mL of virus suspension 38 stain, following manufacturer's protocol 39 . A decrease in fluorescence intensity can be used to examine the level of disintegration of the virus. Both intrinsic and nile red fluorescence were measured by using a fluorimeter (LB 50B; PerkinElmer, Waltham, MA). Intensity changes of fluorescent spectra were compared relative to those of a control from virus stock.

To test infectivity difference observed from in vitro findings, in vivo study was performed for the virus reconstituted from the filters (Filter bare , Filter wet , Filter wet+600μL , and Filter wet+1200μL ) after incubation for 60 min at RT (aerosol exposure at 10 kPa, except for Filter bare ). 12 mice per group were infected with a lethal dose of virus collected from each type of filter. Body weight change and lung virus titers were measured as described above.

Effects of environmental conditions on the performance of salt-coated filter. Salt-coated filters (Filter wet , Filter wet+600μL , and Filter wet+1200μL ) were stored at 37 °C, 70% RH in an incubator (Maru Max; Rcom, Gyeonggi-do, South Korea) for 15 days. Every day, the filters were collected and incubated at ambient conditions for 5 min. At 1-day incubation, filtration efficiency was measured at 10 kPa from Filter wet+600μL , followed by in vivo infection test. Lethal infectivity between two different filter groups (before and after incubation at 37 °C, 70% RH) was compared by measuring body weight change and survival rate of mice after exposure to lethal CA/09 H1N1 aerosols. XRD analysis was performed to salt-coated filters incubated for 1 and 15 days, and SEM/EDX mapping analysis for 15-day incubated samples.

Contact angle measurements and imaging of aerosols. The bare and salt-coated filters were fixed with carbon tape (Ted Pella, Inc., Redding, CA) to a metal, flat substrate and 3 μ L of DI water were added on the surface of the filters. The contact angles were measured from images collected with an optical microscope (10× lens, Motic SMZ-140; Motic, Richmond, Canada) at RT. Images of aerosols on filter fibers were obtained using a dispersive Raman microscope (Nicolet Almega XR; Fisher Scientific).

Aerosol drying time on filters. The bare and salt-coated filters were fixed with carbon tape to a metal, flat substrate and exposed to aerosols generated from 5 μ L of Sulforhodamine B Dye solution (1 mM, Sigma-Aldrich). Aerosol drying time was determined with timer by observation with optical microscope.

Electron microscopy analysis. For virus stability tests, bare and salt-coated filters were exposed to CA/09 H1N1 aerosols and, after 5 and 60 min incubation, virus was recovered by suspension of the filters, as described above. To study the effects of the coating formulation during aerosol drying independently from crystal growth, bare and salt-coated filters were immersed in DI water and removed after 60 min. Subsequently, virus was incubated in the obtained suspension for 60 min. Additionally, the virus suspension was centrifuged at 19,800 g and 4 °C for 10 min to collect the samples and suspend them in DI water. For TEM analysis (200 kV, JEOL JEM 2100; JEOL, Peabody, MA), samples were deposited on copper grid (Electron Microscopy Sciences, Hatfield, PA) and negatively stained with solution comprised of phosphotungstic acid hydrate (1.5 w/v%, pH = 7.0; Sigma-Aldrich, Oakville, Canada).

To identify the morphology of salt-coated filters and recrystallized salts, SEM/EDX analysis was performed for bare and salt-coated filters after coating with 10 nm thick gold layer. Scanning electron microscopy analysis (Hitachi S-3000N; Hitachi, Toronto, Canada) was operated in secondary electron mode at 20 kV and EDX analysis was obtained with EDX detector (Oxford Instruments, Concord, MA).

To confirm the formation of crystalline NaCl coating during drying process and its stability during storage at 37 °C and 70% RH, XRD analysis (BRU-1098; Bruker, Billerica, MA) was performed at different coating conditions. Filters (1 × 1 cm) were mounted on a slide glass for XRD analysis (θ -2θ mode) using a CuKα radiation.

",0.7346099062846785
Protecting health care workers from SARS and other respiratory pathogens: Organizational and individual factors that affect adherence to infection control guidelines,"Background: Traditional infection control policies have focused on engineering controls, specific protocols, and personal protective equipment (PPE). In light of the variable success in protecting health care workers (HCWs) from Severe Acute Respiratory Syndrome (SARS) in 2003, organizational and individual factors related to self-protective behavior in health care settings may also play an important role.","Severe Acute Respiratory Syndrome (SARS) emerged as a new cause of severe pneumonia in late 2002 and early 2003, which was quickly determined to be caused by a novel coronavirus. 1 The virus spread internationally along travel routes and caused the well-documented nosocomial outbreaks in Canada, China, Hong Kong, Vietnam, and Singapore. The Canadian outbreak resulted in 438 cases, with 51% of these being health care workers (HCWs), 2 3 of whom died from SARSrelated causes. 3 Traditional infection control practice has focussed on training individual HCWs to follow standard procedures and instruction in the use of personal protective equipment (PPE). Prior to SARS, it was already understood that the ability of HCWs to adhere to infection control guidelines varied substantially and was often less than ideal. For example, a recent study of 3 US hospitals over 3 years founds that HCWs wore appropriate respiratory protection with tuberculosis patients 44% to 97% of the time. 4 Similarly, compliance with universal precautions for blood and body fluids (BBF) has been shown to range from 16% to 44%. [5] [6] [7] During the SARS outbreaks of 2003, the implementation of basic infection control procedures appeared effective in controlling the outbreaks in most circumstances [8] [9] [10] ; however, in other situations, HCWs became infected despite apparent adherence to recommended guidelines. 11 Clearly, factors other than individual knowledge and motivation must be at work to give such variation in effectiveness.

A theoretic model that has been used to explain selfprotective behavior at work and could account for this variation derives from the PRECEDE (Predisposing, Reinforcing and Enabling Factors in Educational Diagnosis and Evaluation) model of health promotion, 12 as modified by DeJoy. 13 Predisposing factors can be seen as the characteristics of the individual (beliefs, attitudes, values) that facilitate self-protective behavior. Enabling factors can refer to the environmental factors that block or promote self-protective behavior, including skills, knowledge, and availability and accessibility of PPE and other resources. Reinforcing factors involve the organizational factors, such as communication, training, performance feedback, social approval or disapproval from coworkers or management, and other safety climate dimensions. This model has previously been used to explain the variation of compliance with universal precautions to prevent exposures to bloodborne pathogens by HCWs. 14 These factors can be seen to interact as shown in Fig 1. The goal of this project was to review the scientific evidence on what is already known about protecting HCWs from hospital-acquired infections, using this theoretic model as a guide. This paper will review the organizational and individual factors that have been shown to be important determinants of protecting health care workers from infectious hazards.

A 16-member research team in Vancouver, Canada, composed of experts in occupational medicine, occupational hygiene, infection control, public health, and epidemiology and clinicians and frontline care providers reviewed the current scientific knowledge on the efficacy of PPE in preventing the transmission of respiratory infections and the effectiveness of these protective measures when used in clinical practice under working conditions. Literature searches were conducted in 5 databases (Medline, EMBASE, CINAHL, Web of Science, and OSHROM) for articles published in English in the last 15 years that related to infection control practices, occupational health and safety issues, and environmental factors and other issues of importance in protecting workers against infections in health care settings. This produced an initial list of 841 publications. From the initial literature search results, a series of research topics were developed under 3 broad categories: (1) basic science and efficacy of facial protective equipment, (2) the effectiveness of specific infection control procedures, and (3) organizational and individual factors that influence infection control and occupational health in health care settings.

Titles and abstracts were screened to refine the citation list to include only those articles with direct application to these topics, and secondary sources were added from these primary references. The research topics were divided among the research committee members (subgroups) to summarize, using articles from the second iteration of the original citation list. Secondary reference materials, derived from these initial references, were added. Articles were critically evaluated based on the study design (descriptive, analytic, or intervention), the population under study, and the outcomes of interest. This resulted in 168 publications being used in the final report. Drafts from each subgroup were merged, and the compiled version was reviewed by the team as a whole. The results of the organizational and individual factors are presented here. The existing knowledge was then summarized, and recommendations for further research were developed through consensus by the research team.

Organizational factors, in this context, refer to determinants that range in scope from very broad issues such as workplace culture and safety climate to specific policies and procedures, such as policies that restrict individual nurses to working with either ill or well residents during an influenza outbreak. The majority of research conducted in this area has been exploring HCW compliance with universal precautions (UP). UP were introduced in the 1980s in response to the risk of transmission of bloodborne pathogens to HCWs from patients, in particular HIV, and now are more generally referred to standard precautions (in the United States) or routine practices (in Canada). Although the research does not directly examine the compliance of HCWs with protection from respiratory tract infections, the determinants of adherence to UP are likely applicable to many types of self-protective behavior.

The safety climate refers to the perceptions that workers share about safety in their organization and derives from a multidimensional, systems approach to worker health and safety. 15 It has generally been measured by asking workers how they rate their organization's commitment to safety and has been positively correlated to good safety performance in non-health care settings. [16] [17] [18] [19] In health care, it has been postulated as a determinant of improved worker safety, in general, 20 and the use of UP, in particular. 21 There is general agreement that the safety-related attitudes and actions of management play an important role in creating a good or bad safety climate. 22, 23 Studies in health care settings have shown that safety climate has an important influence on the transfer of training knowledge. 24, 25 Rivers et al in a survey of 742 nurses regarding predictors of nurses' acceptance of an intravenous catheter safety device 26 concluded that a positive institutional safety climate was more important than individual factors in predicting acceptance of these devices.

Gershon et al 27 found that, in 1716 hospital-based HCWs, respondents who perceived a strong commitment to safety at their institution were over 2.5 times more likely to be compliant with UP than those who did not. Similar results were found for a group of 216 HCWs from a state correctional facility. 28 A later study by this group 14 examined the relative importance of safety climate, the availability of PPE (an environmental factor), and individual worker characteristics (individual factors) in determining compliance with UP. They found that safety climate had the greatest association with compliance behavior of the 3 groups of variables. However, the amount of variation pre-dicted by the model was small, suggesting the existence of other important determinants of safetyrelated behavior that were not accounted for in the model.

Another study conducted with 482 nurses 29 found that the worker's perception that the use of UP interfered with their work (job hindrance) was the strongest predictor of failure to comply with UP. However, this study also found that perceived safety climate was the best predictor of this perceived job hindrances. Thus, it seems that safety climate underlies other important perceptions and reveals how some of these factors may interact. Other factors that seemed to predict worker perceptions of a strong safety climate included safety performance feedback and availability of PPE.

The most comprehensive attempt to describe the underlying components of the safety climate in health care institutions found 6 different components 23 : (1) senior management support for safety programs, (2) absence for workplace barriers to safe work practices, (3) cleanliness and orderliness of the worksite, (4) minimal conflict and good communications among staff, (5) frequent safety-related feedback and training by supervisors, and (6) availability of PPE and engineering controls. 23 In addition, 2 of these factors, senior management support for safety programs and frequent safety-related feedback and training, were significantly associated with lower rates of exposures to blood and body fluids. Although it seems that we have a good understanding of what specific elements contribute to the safety climate, no studies have attempted to implement measures to try to improve a safety climate where a poor climate exists. The study cited above recommended that safety climate surveys sponsored jointly by the infection control and occupational health and safety committees should be administered in hospitals using the safety climate scale. 23 The authors made several suggestions as to how they could be used. None of the recommendations, however, have been evaluated in terms of their ability to improve worker safety, once applied. Another challenge to improving safety climates in hospitals comes with the recent emphasis on downsizing organizations and outsourcing of the workforce. Studies in the United States have shown that hospital-based HCWs are having to work faster and harder than ever in an environment of higher patient acuity and increased patient turnover and with less time for training and education. [30] [31] [32] [33] [34] This is likely happening in Canada, and other countries, as well. How these larger organizational changes affect safety climate remains to be studied.

There is very little information regarding which formative training and continuing education strategies are most effective in implementing and maintaining good infection control practices or on which methods of feedback are best. In one study that examined the adherence to UP in 451 nurses employed in a large US hospital center, feedback on compliance was found to be one of the predictors of adherence, along with job hindrance and the availability and accessibility of PPE. 29 Again, the variance in adherence predicted by the model was modest. This study, however, did not look specifically at the type of feedback or communication used.

A study conducted in emergency room (ER) HCWs found that compliance with barrier precautions (use of cap, gown, mask, gloves, protective eyewear) improved when staff was notified of the arrival of patients by ambulance staff. 35 This prenotification resulted in 92% of ER staff using appropriate protection compared with 63% when patients arrived unannounced.

A study of Thai health care workers 36 demonstrated higher compliance with glove use and handwashing during a peer feedback intervention (83% compliance vs 49% compliance during baseline). However, compliance fell to 73% in the postintervention phase. The authors noted that other techniques, including inservice educational sessions, computer-assisted learning, and provision of education and group feedback by researchers also failed to show long-term effectiveness. The authors suggested that ongoing observation and feedback are likely needed because the effectiveness of programs diminishes over time.

Another study showed that an educational intervention consisting of lecture and practice sessions for operating room staff increased compliance with use of protective eyewear from 54% to 66% and double gloving from 28% to 55%. 37 It was unclear, however, how much of this effect was due to awareness by staff that they were being observed. Another study on UP found that, even when HCWs have adequate information and knowledge, they still need to enhance their skills by practicing how to use PPE. 14 The DeJoy study, which showed that safety climate was a strong predictor of perceived job hindrance, also offers some insight into what kind of training programs are needed. 29 If perceived job hindrance is an important predictor of compliance with UP, then training programs may need to focus less on knowledge-based training and more on helping workers overcome or reduce the barriers associated with compliance. There are no studies examining the effectiveness of measures that emerge from these suggestions.

In a recent review of the effectiveness of various interventions aimed at changing the clinical practice of physicians, 38 the authors reported that there was evidence that educational outreach visits, posted reminders, interactive educational meetings, and other multifaceted interventions were effective in improving the transfer of new information into clinical practice. Passive interventions, such as mailing out new recommendations, were generally not found to be effective, even though they are the methods most commonly applied. Interventions that relied on audits or other forms of feedback were found to have variable effectiveness. Grol et al 39 characterized the features that were more likely to be associated with a change in primary care practice by physicians. An important finding was that recommendations with a strong evidence base were more likely to be effective than consensus statements.

During the SARS outbreak in Hong Kong, Lau et al 40 showed that having received less than 2 hours of infection control training was strongly associated with developing SARS, in addition to the inconsistent use of PPE and perceiving the amount of available PPE to be inadequate. The latter factors may be concrete examples of poor safety climates. Of note, no studies were found that examined different communication strategies used in health care institutions to improve worker safety.

Individual factors in self-protective behavior at work Knowledge acquired through training and personal experience. Knowledge of the appropriate use of PPE is necessary but not sufficient for HCWs to adopt safe work practices. 41 The study by Gershon et al from 1995 27 found that most HCWs surveyed had high levels of knowledge regarding UP practices but that this knowledge did not lead to high levels of compliance. Repeated exposures without consequences may also decrease compliance. In a study examining this issue, HCWs who had repeated exposures to blood and body fluids and did not acquire infection perceived a decreased risk of acquiring infection than those who had not been exposed. This experience may lead to a false sense of invulnerability and therefore increased risk taking. 14 Another study found that HCWs who were younger than 40 years of age were more likely to comply with UP. 28 The authors suggested that this may reflect more recent training, rather than a direct effect of age. HCWs surveyed were found to have realistic risk perceptions about exposure to BBF: Few were fearful of contagion. The level of experience did not necessarily lead to a lack of understanding of risks involved. Nurses who were educated in a more disease-driven infection control model, in which precautions were used only when the patient was known to be infected by a given pathogen, appear to be less comfortable with the UP model, as compared with recent graduates. 42 Students and other HCWs may look to attending physicians as role models. However, younger physicians, house staff, and medical students have been found to be more complaint with UP than senior physicians. 37 The increased compliance again probably reflects more recent training. Another study found that compliance with methicillin-resistant Staphylococcus aureus (MRSA) precautions (which included use of gloves and gowns and handwashing) was related to the occupational group, with physicians showing the lowest compliance (22%) and physiotherapists and occupational therapists having the highest compliance (89%). 43 Compliance with gown and glove requirements was 65% and for hand hygiene, 35%. Angtuaco et al 44 found that fewer gastroenterologists than GI endoscopy nurses used face shields for all procedures (14% vs 21%). Gershon et al has observed that physicians are ''out of the loop'' with regard to safety climate within hospitals and that special efforts need to be made to involve them in training, safety programs, and safety committees. 28 Nurses have reported confusion at the ward level and uncertainty concerning the rationale for the uses of PPE recommended in infection control guidelines and perceive existing guidelines to lack specificity to their practice. 45 They also may doubt the effectiveness of isolation precautions to prevent disease transmission and report frustration with the lack of adherence by allied professionals. 45 Jeffe et al cited the need to teach medical students the importance of the use of PPE before they become set in their ways. 46 Teaching medical students early in their clinical training about the risk of exposure to BBF and specific prevention measures may be associated with more positive attitudes and better compliance with precautions. Attitudes and beliefs. Demographic factors such as gender, education levels, shift work, or occupation have not consistently found to be associated with compliance with infection control procedures. 27 Compliance is affected by attitudes and perception of risk; however, having a positive attitude toward the patients, lower risk-taking tendencies, and greater knowledge of modes of transmission have been shown to lead to greater compliance. 14 Use of PPE only when there is visible blood may demonstrate that HCWs make personal judgements concerning their own potential risk instead of following a consistent policy. 47 HCWs do not appear to dismiss or underestimate their personal risk of acquiring an occupational infectious disease [48] [49] [50] ; in fact, HCWs are more likely to overestimate their risk. However, several studies suggest that adherence may often be poorest when the risk of exposure is highest. 22 Perceived barriers may be one of the most important factors affecting compliance. Godin et al found that HCW perceptions of their ability to adopt the use of PPE into their practice affected their level of compliance. 51 If they believe that the barriers to their adherence to recommended use of PPE cannot be circumvented, they will not comply. Actual working conditions resulting in overwork, lack of time with patients, and having to deal with emergencies were reported to have significant negative affects on compliance. HCWs are influenced by the subjective norm, ie, the perception of social expectation to adopt a given behavior. 51 This suggests that, if HCW believe that key persons in their work and social environment expect them to be compliant with the use of PPE, they are more likely to do so.

Certainly, organizational issues impact individual attitudes considerably. For example, workload issues are thought to affect HCW willingness to comply with recommendations for PPE use. Workers who feel stressed and overloaded at work are much less likely to be attendant to safety needs and precautions. 23 Helfgott et al found that knowledge of how to prevent occupational exposure did not appear to correlate with compliance with UP. 41 The most common reasons why HCWs in this study did not comply were time constraints, interference with performing specific tasks, and lack of risk-based information to assist HCWs in identifying infectious patients. It was also noteworthy that this study also found that level of compliance was inversely proportional to level of experience of the HCW. Osborne determined that mean compliance rates among Australian operating room nurses were 55.6% with always double gloving during surgical procedures and 92% with always wearing adequate eye protection. 52 The variable that had the most influence on compliance was the perception of barriers to compliance, specifically, that adhering to UP interfered with duties. Nickell et al found in their study of 2001 HCWs during the SARS outbreak in Toronto that the most commonly cited difficulty with complying with precautionary measures, especially masks, was that wearing one for any extended period of time was very uncomfortable. 53 Dejoy et al, in their 2000 study, demonstrated the importance of easy access to the correct PPE when needed as an influence on compliance. 14 Presumably, the greater perceived availability of PPE may lead to stronger beliefs in their effectiveness for prevention among HCWs. It is interesting that the case-control study conducted by Lau et al during the SARS outbreak in Hong Kong also found that perceiving that adequate PPE was unavailable was associated with an increased risk of acquiring disease. 40 The perception that the use of PPE may lead to decreased quality in the therapeutic relationship between patients and HCWs has been shown to be a significant factor that influences HCW compliance. 5, 54, 55 Interference with the practitioner-patient relationship and decreased dexterity were the most frequently cited reasons for noncompliance in one study. 54 Nickell et al found that, during the Toronto SARS outbreak, HCWs found that wearing of masks made communication difficult and led to a sense of social isolation. 53 Others have found that the wearing of PPE places barriers between 2 people, negatively altering interpersonal dynamics and complicating the performance of tasks and treatment. 14 Respirators cover the face and mouth, hampering communication, especially for the elderly population and those with hearing loss. Use of respirators may lead to increased isolation and fear among patients. 56 Prieto and Clark also cited concerns among nurses that isolation of patients could lead to depression from lack of social contacts. 45 CONCLUSION SARS was a disease largely spread by respiratory droplets. The lack of spread within the community and the recent information on relatively low natural transmission rates for SARS coronavirus indicate that SARS is less contagious than influenza and other similar respiratory infections. 1 The consistent application of basic infection control precautions terminated outbreaks in Vietnam, 10 Taiwan, 57 Singapore, Hong Kong, 58 and, eventually, Toronto. 59 Large outbreaks occurred when the causative agent was not recognized, generally early in the course of the epidemic, and basic infection control procedures were not in place. As such, attention to understanding why there was a failure to implement appropriate precautions, and how best to promote compliance in future, is an important topic for study.

This literature review has shown that variations in organizational and individual factors can explain much of the variations in self-protective behavior in health care settings, especially with respect to applying universal precautions (now called standard precautions, or routine practices). It seems likely that these factors were also important safety determinants during the SARS outbreaks but that they have not been extensively studied. The priorities for further research, which have derived from this review, are presented in Table 1 . A qualitative study conducted in parallel with this review has found that organizational factors are considered to be important from the perspective of HCWs themselves. 60 These broader determinants of effective infection control practices have not traditionally been addressed when policies and procedures for protecting HCWs from nosocomial infections have been designed.

Safety climate is being increasingly recognized as one of the most important determinants of safe work practice in terms of preventing exposures to BBF but has been little studied in other types of nosocomial transmitted diseases. Respiratory tract diseases, in particular, have not been well studied in this regard, presumably because most HCWs do not develop severe or specific symptoms when infected (such as for most respiratory tract viruses) or because most HCWs are already immune to potential pathogens, either through vaccination (for influenza or measles) or through natural immunity (varicella). Other diseases, such as tuberculosis, are thought to be easily controlled through the use of specific environmental controls and PPE. 61 Improving the safety climate and creating a workplace culture in which workers and their health are valued has the added potential benefit of improving HCW outcomes for many different diseases and injuries, including emerging diseases of which preexisting immunity is not present. This has particular relevance to HCWs, who will likely be placed at great risk of acquiring novel strains of influenza during a pandemic. Clearly, HCWs do need to be trained in infection control procedures to apply them, but the available evidence indicates that knowledge deficit is not a major barrier to compliance. This suggests that a focus on training content or methods to increase knowledge may not yield much change in compliance. Feedback to workers on their adherence to precautions has been identified as an important factor in facilitating compliance with infection control practices. Unfortunately, most studies that have found positive effects on compliance levels through formal education sessions have found improvements to be short lived. The optimal type, timing, and frequency of feedback that is most effective in achieving compliance are not known. Most of the reviewed studies were observational in nature, whereas many of the research questions could be investigated using intervention-based study designs. It is particularly noteworthy that the communication strategies used by health care institutions to improve worker safety have not been researched at all.

Factors other than individual knowledge likely have more influence over worker behavior. Physicians, perhaps because they operate somewhat outside the established workplace health and safety system, are often the least compliant, despite having arguably the most knowledge. Individual attitudes and beliefs that affect adherence to infection control guidelines, such as having a positive attitude toward patients and the belief in the effectiveness of recommended guidelines, are largely influenced by organizational factors in the workplace. Even when workers have the attitudes and beliefs that facilitate adherence, workload issues and ease of incorporating infection control into usual work practices may run counter to these intentions. Time and equipment to permit compliance must be available. Reduction of job-related hindrance through analysis and modification of patient care tasks and development of skill-based training may result in better compliance.

Many authors have noted with concern that some HCWs acquired SARS when wearing what should have been adequate PPE 11 and have called for the use of PPE with better efficacy versus airborne particles. 62 However, in light of the wide variation in organizational factors that exist in health care settings, we feel that a closer examination of these factors is warranted before concluding that these breakthrough events were due to inadequate equipment. Some attitudes such as the use of PPE interfering with patient interactions and the discomfort associated with PPE use may not change until less obtrusive and more comfortable equipment is developed. In this regard, the use of PPE with higher protection factors, but which is less comfortable, may ultimately result in less protection for HCWs. Clearly, concerns regarding field effectiveness must be considered when recommendations are made for the use of specific PPE.

This review has also revealed the relative paucity of occupational health research conducted in health care facilities. This likely reflects the traditional lack of attention that HCWs have received in terms of protecting their own health and safety. The lessons learned from SARS should be used to improve occupational health and safety for health care workers for current nosocomially transmitted infections, as well as for future potential emerging diseases.

This project was funded by The Change Foundation as part of a project entitled ''Protecting the Faces of Healthcare Workers: Knowledge Gaps and Research Priorities for Effective Protection Against Occupationally-Acquired Respiratory Infectious Diseases.'' 60 

",0.7334534405325088
Personal Protective Equipment: Protecting Health Care Providers in an Ebola Outbreak,Purpose: The recent Ebola epidemic that devastated West Africa has infected and killed more health care providers than any other outbreak in the history of this virus. An improved understanding of pathogen transmission and the institution of strategies to protect health care providers against infection are needed in infectious disease outbreaks. This review connects what is known about Ebola virus transmission with personal protective equipment (PPE) designed to arrest nosocomial transmission.,"The recent Ebola epidemic that devastated West Africa evolved within months from a regional humanitarian crisis to a global public health emergency. As of May 27, 2015, 27 ,049 cases and 11,149 deaths from Ebola were reported by the World Health Organization (WHO), an underestimate that already eclipses the numbers of infections and deaths in all previous outbreaks combined. 1 With fewer than 0.1 physicians per 10,000 people in Liberia, Sierra Leone, and Guinea, the infection of 869 health care providers and the death of 507 in this epidemic alone has depleted an already precious resource. 2 Although the rate of confirmed cases has declined dramatically in West Africa, the loss of health care providers will continue to affect the people of this area for decades to come.

Despite major advances in the prevention and treatment of infectious diseases in general, there are currently no licensed vaccines, proven effective antiviral therapies, or proven postexposure prophylaxis strategies for Ebola virus disease (EVD). Personal protective equipment (PPE) plays a critical role in mitigating the risk of health care personnel (HCP) exposure to contaminated body fluids in the care of patients with communicable infectious diseases, including EVD. The importance of PPE was recognized during the outbreak of severe acute respiratory syndrome (SARS), in which HCP accounted for $ 20% of persons who were infected with SARS. 3 Evidence of continued SARS transmission despite the use of droplet, contact, and airborne precautions drew attention to the possibility of nosocomial transmission during PPE removal or doffing. 4, 5 In addition, recent studies suggest that viruses, including Ebola, have the potential to remain infectious on PPE for longer than it is typically worn, creating an opportunity for transmission during doffing. Historically, development of PPE strategies has been driven by the paradigm that infectious agents are transmitted by 1 of 3 routes: contact, droplet, or airborne. However, the consideration of self-inoculation in the removal of PPE is emerging as a major potential route of HCP infection. 6 To this end, we reviewed the major routes of Ebola virus transmission and the use of PPE to prevent HCP exposure and infection.

Once the Ebola virus enters the human population, outbreaks are sustained through human-to-human transmission, which is facilitated by the presence of the virus in every body fluid, including blood, diarrhea, vomit, sweat, breast milk, vaginal secretions, and semen. 7, 8 Ebola virus increases logarithmically in the blood during acute infection, and often the highest levels of viremia are achieved at the time of death. 9 In addition, patients in the later stages of disease have more severe symptoms, including diarrhea, vomiting, and bleeding complications, thus increasing the potential of spread via infectious body fluids. This coupled with limited health care infrastructure in the areas where most Ebola outbreaks occur contribute to the outbreak amplification that is often seen in health care settings. [10] [11] [12] Epidemiologic studies suggest that the virus is spread primarily through direct contact with the patient and virus-laden body fluids, especially late in the clinical course of disease. 11, 13, 14 Of 173 household contacts of 27 infected patients, 28 (16%) developed EVD. 13 All 28 cases reported direct physical contact with the index patient (risk ratio ¼ 3.6; 95% CI, 1.9-6.8). 13 Importantly, none of the 78 household members who reported no direct contact with the index patient developed EVD. In a separate study those family members who provided direct nursing care to the index patient had a 5.1-fold increased risk of infection, highlighting the importance of direct contact. 11 The risk of secondary transmission, in a separate study, increased with exposures that continued through the later states of illness (crude prevalence proportion ratio [ 15 Given the high levels of virus in body fluids and on the skin of patients at the time of death, postmortem contact is also associated with an increased risk of infection (adjusted risk ratio ¼ 2.1; 95% CI, 1.1-4.2). 13, 16 The increased potential for transmission during contact with a dead body, as occurs during traditional burial practices, can be partly attributed to the durability of virus in body fluids even after death. In a nonhuman primate study of viral persistence after death, replication competent virus was detectable in oral, nasal, and blood samples from dead animals. Blood contained the highest concentrations of viable virus (2 Â 10 5 median culture infectious dose/ mL) and remained positive for the longest duration, 7 days postmortem. 17 Viral RNA was detectible from oral nasal and blood swabs for up to 3 weeks postmortem. 17 Together, these data highlight close contact with a dead body, as is custom during preparing a body for funeral, is a potential route of transmission.

Of 316 people infected in the Kikwit outbreak (in 1995) only 5 reported no physical contact with a confirmed patient, suggesting that alternative routes of transmission, including droplet or fomite-mediated transmission, may be possible but are unlikely events. 18 Theoretically, fomite transmission is possible, but the conditions, including the environmental surface and ambient temperature, affect the viability of the virus. In 1 study, filoviruses, including Ebola, were found to remain infectious in liquid media at room temperature for at least 46 days, but infectious virus could not be isolated when allowed to dry on a plastic or glass substrate at room temperature. 19 Reports from the current outbreak indicate that multiple environmental samples obtained from an Ebola treatment unit were positive for polymerase chain reaction. 10 However, when sampling occurred after routine cleaning in a separate study, all 31 environmental samples were negative, suggesting that routine sanitation, as part of environmental control, can decrease the potential of fomite transmission. 20 Recently, the potential for airborne transmission has received considerable attention. 10, 21 Although animal studies suggest that this is possible when virus is experimentally aerosolized, epidemiologic studies of household contacts indicate that this is not a primary means of transmission. 11, 13, 14, [22] [23] [24] In addition, the institution of barrier protection with the use of surgical masks that do not protect against airborne transmission has historically been sufficient to eliminate nosocomial transmission and HCP infection. 25 Higher risks of airborne or droplet transmission is likely to occur in health care settings during aerosolgenerating procedures such as induced sputum procedures and/or intubation.

The combination of high viral loads, the ubiquitous presence of virus in all body fluids, and the low inoculum required for infection substantially increases the risk of HCP, family members, and loved ones who provide direct care to Ebola-infected patients. 26 In addition, patients infected with EVD often present with nonspecific symptoms that frequently mirror more common, but less contagious, infectious diseases. For this reason it is imperative that HCP implement the use of standard precautions consistently when providing care to all patients. 27, 28 The strict adherence to standard precautions before the identification of an Ebolainfected patient is paramount to preventing nosocomial transmission to HCP.

Key elements of standard precautions include the following 27,29,30 : (1) hand hygiene, (2) risk assessment for appropriate PPE, (3) respiratory hygiene, (4) prevention of needle-stick and injuries from other sharp instruments, (5) proper waste management, and (6) environmental cleaning and disinfection of patient care equipment and environmental surfaces.

Although a disproportionate amount of attention and debate have been directed to the components of PPE, the most effective means of reducing health care-associated infection include the implementation of environmental and administrative controls. 31 Environmental controls include not only the construction and maintenance of appropriate facilities for isolating potentially infected patients but also the establishment of clean water and sanitation and effective waste management that reduce environmental contamination and serve to limit HCP exposure at the source. Similarly, administrative controls alter the delivery of care to mitigate potential exposures such as implementation of infection control precautions, patient triage for rapid identification of suspect cases of EVD with immediate isolation of the patient in a single room, establishment of specific donning and doffing protocols, the presence of donning and doffing monitors, and policies on medical procedures. During the Ebola outbreak in Kikwit, Zaire, in 1995, 67 HCPs were infected while providing care in an isolation unit plagued by a lack of water and electricity, a shortage of PPE, and an absence of appropriate waste disposal. 25 After the implementation of environmental and administrative controls in the establishment of a properly functioning Ebola treatment unit the rate of HCP infections decreased dramatically. 25 Collectively, environmental and administrative controls are critical infection control measures that work to arrest potential chains of transmission in health care settings.

Despite the lethal nature of this virus and the potential ease of transmission, infection can be prevented. Although the most effective interventions to protect HCP are those that physically separate HCP from infectious patients and body fluids, mortality rates of Ebola-infected patients can be decreased with more aggressive care that requires close contact with these patients. 32 In this setting, PPE serves as the last physical barrier between a health care provider and infectious body fluids. In prior outbreaks, infection of HCP was substantially reduced with the institution of barrier precaution.

Although the actual PPE is the most visible aspect of infection control, it must be used as part of a larger infection prevention and control strategy that incorporates environmental and administrative controls, including the establishment of physically separate donning and doffing areas from the space in which actual clinical care is provided, training on the correct use of PPE, sufficient supply of all PPE components, and the use of a trained doffing instructor. Designated areas that allow for clear separation between donning and doffing is critical because doffing involves potential exposure to contaminated body fluids on the outside of used PPE. Moreover, clear delineation between high-and low-risk areas and when PPE is needed and not needed are paramount to ensuring that PPE is used appropriately to mitigate risks of exposure to sources of infection. Secondly, training in the use of PPE before providing care for suspect or confirmed patients is crucial because there is a learning associated with providing routine tasks in unfamiliar situations. In addition, the heat stress associated with the use of PPE in tropical climates is an occupational hazard that, in some instances, can increase the risk of accidents and thus exposure if not recognized early. Behavioral controls are also a fundamental aspect of infection control strategies. On average a person will touch his or her eyes, lips, and nostrils at a rate of 15.7 times per hour. 33 In Ebola endemic countries during this epidemic, there was a policy of no touch in which people do not hug, kiss, or shake hands to avoid potential transmission outside of Ebola treatment units. Refraining from touching one's face and frequent handwashing is encouraged to reduce the potential of self-inoculation. Collectively, the logistics of PPE are also necessary to protect health care providers.

Although there is no consensus on each of the specific components of PPE among the major organizations providing care to infected patients in the field, all agree that it should uniformly protect the major portals of virus entry, including mucous membranes and breaks in the skin. Centers for Disease Control and Prevention (CDC) guidelines, which are directed toward the use of PPE in US hospitals, recommend mucous membrane coverage with either an N-95 particulate respiratory or a powered air-purifying respirator (PAPR) that incorporates a full-face shield, helmet, or headpiece. 34 If an N-95 respiratory is used, it must be accompanied by a single-use surgical hood that extends to the shoulders and a full-face shield. Similarly, if a PAPR is used with a helmet or headpiece, it also must be used in combination with a disposable hood that extends to the shoulders and fully covers the neck. The WHO recommendations, which pertain to care of Ebola-infected patients regardless of location, include the use of a face shield or goggles to protect conjunctival membranes and either a fluid-resistant medical/surgical mask that does not collapse against the mouth (eg, duckbill or cup shape) or a fluid-resistant particulate respiratory if aerosol-generating procedures will be performed. 35 In both cases, the WHO offers a conditional recommendation that health care providers also wear a separate head cover that protects the head and neck. This recommendation is conditional because there is no evidence to support the use of a head cover or hair cap for preventing infection. 35 Although the use of a PAPR provides enclosed protection and full visualization of the provider's face, the logistical obstacles of disinfection after each use, need for reliable electricity to power the unit, and the cost limit these from being widely used in the field. Similarly, because Ebola does not appear to be efficiently transmitted via an aerosol route, a surgical mask can be used to protect against droplet transmission, although an N-95 if available provides better protection against airborne agents. However, given the length of time it takes to don and doff PPE and the inability to change components of PPE while inside a high-risk area, many in the field enter with a particulate respirator in case a patient is coughing, aggressively vomiting, or undergoing a procedure that could generate secondary aerosolization. No evidence is found of increased efficacy of either face shields or goggles in the prevention of Ebola virus transmission, but both have advantages and disadvantages. Goggles offer complete enclosure around the eyes, preventing inadvertent touching with potentially soiled gloves, but they provide a more limited range of view compared with face shields. However, face shields allow more of the HCP's face to be visible during patient care, which facilitates communication and potentially decreases patient anxiety. Although fogging affects both face shields and goggles, reducing visibility, it may affect face shields to a lesser degree.

Both the CDC and the WHO recommend the use of 2 pairs of gloves with at least the outer pair having an extended cuff that reaches beyond the wrist. 34, 35 The inner pair of gloves rests against the HCP's skin and underneath the gown/coverall (described in the Body and Skin Protection section), whereas the outer pair is worn on top of the gown/coverall to effectively protect the wrist from contamination. This also allows the outer glove to be changed between patients to mitigate risks of nosocomial transmission between patients.

The use of 2 pairs of gloves also protects against damage to the outer glove by disinfectants such as chlorine and may reduce the risk of parenteral exposure from sharp injuries while the loss of tactile sensation is minimal. As described in the next section, the use of double gloves has also been used to decrease the incidence of hand contamination particularly during PPE removal. No evidence suggests that 42 pairs of gloves allots additional protection but instead may increase risk as the doffing sequence becomes more complicated.

Given the high risk of transmission through direct patient contact, the CDC and the WHO recommend the use a single-use fluid-resistant gown or coverall to prevent contamination of underlying skin and surgical scrubs. Although it is not known if the Ebola virus can penetrate intact skin, the presence of virus on skin or clothing could be a source of self-inoculation. The resistance of commercially available gowns/coveralls is assessed by their ability to prevent passage of a nonenveloped DNA virus, phiX174, under different degrees of pressure. 36 Resistance, however, must be balanced by tolerance of use by health care providers who work in tropical conditions because increased resistance impairs evaporative cooling and may decrease the time HCP can provide care. If a fluidresistant gown is worn, it should extend beyond the top of the footwear or shoe covers (see Foot Protection). The integration of thumb loops may be beneficial in securing complete protection of the wrist area. The WHO guidelines recommend against the use of tape to attach gloves to gowns/coveralls because this may increase the risk of tearing the gown/coverall and complicate the doffing procedure at a time when health care providers are potentially most vulnerable. 35, 37 The use of a waterproof or impermeable apron worn over the gown/coverall is recommended to provide further protection against infectious body fluids. Both the CDC and the WHO recommend using a disposable apron if feasible because a reusable one will require decontamination after each use.

Given the high degree of environmental contamination due to substantial diarrhea and vomiting, HCP are advised to wear waterproof boots or shoe covers if used with a coverall that has integrated socks. 32 In addition to being easier to decontaminate, waterproof boots offer some protection against sharps injuries. 35 The feasibility of such an approach in the field must be considered however because the countries in which most Ebola outbreaks have occurred are among the poorest in the world with the least developed health care infrastructure available. In Sierra Leone, a country already among the countries with the lowest health care expenditures (ranked 141 of 192 nations) and devastated by the current epidemic, the use of full containment PPE as recommended by the CDC and WHO was deemed neither affordable nor practical in peripheral health care units that were visited initially by many patients infected with EVD. 38

Although the various forms of PPE recommended by the WHO, CDC, and Medecins Sans Frontiers (or Doctors Without Borders) all mitigate risks of exposure to infected body fluids while caring for Ebolainfected patients, the presence of PPE alone is not enough. PPE must be donned correctly before entry into a high-risk area, must remain in place while inside a high-risk area, and must be removed safely when leaving the high-risk area to be effective. PPE must not be adjusted during patient care because adjusting goggles or a face shield can lead to mucous membrane exposure and potential infection.

Risk of indirect exposure to infected bodily fluids is likely highest when removing PPE because, depending on the step, the major portals of entry may be exposed in close proximity to clothing contaminated with infected bodily fluids. These risks may be decreased by implementing a systematic process of instructed doffing in which safe removal of contaminated clothing is directed by a trained and rested doffing instructor. This is different than the buddy system of donning. When donning, it is sufficient to have the person you are entering with check to ensure that your PPE is intact and on correctly. However, given that doffing is the highest risk activity, it is critical that the person guiding you through the process of removal has not been inside the high-risk zone recently, is well rested, and is solely focused on getting you out of the high-risk area safely. The variability in recommended PPE by different organizations and hospitals necessitates variation in donning and doffing order because the order will change with each PPE item added or removed. It is imperative that this order is established, optimized, and taught before it is being used to ensure feasibility and success.

Although PPE in its various forms and designs cover the major portals of virus entry, the efficacy of actual protection is unknown and remains poorly studied. A nonpathogenic nonenveloped bacteriophage, MS2, has been used to assess safety of PPE and donning and doffing protocols in non-Ebola settings. 39 Although filovriuses are single-stranded enveloped RNA viruses, the use of MS2 is a conservative surrogate because the absence of an envelope likely improves the ability of this virus to maintain its infectiousness in the environment. In addition, the current CDC recommendations for environmental decontamination of an Ebola care area are consistent with those needed to decontaminate nonenveloped viruses.

The use of MS2 allows for the systematic evaluation of PPE and processes to ensure they have been optimized for health care provider safety. After the SARS outbreak the CDC sequence for removing PPE was evaluated with the use of a nonenveloped, nonpathogenic RNA virus and Glogerm (Glo Germ Company, Moab, Utah) fluorescent synthetic beads. 40 The fluorescent tracer was found not to be a reliable indicator of virus contamination because virus was recovered from both areas that fluoresced and areas that did not fluoresce. In this study, virus was recovered from the scrub shirt of 100% of participants, the nondominant hand in 80%, and scrub pants in 75%. 40 The highest virus titer was recovered from the scrub shirt. The use of fluorescent tracer provided false confidence because it was found on the shirt, nondominant hand, and scrub pants in 10%, 10%, and 0% of research participants, respectively. 40 The use of double gloving, however, significantly reduced not only the incidence of hand contamination with virus but also the quantity of virus that was transmitted to HCP hands, thus providing better protection against viral contamination during PPE removal.

A comparison of 2 personal protective systems found that the PAPR system that included a second outer layer was less likely to experience contamination than an enhanced respiratory and contact precautions system that lacked a second outer layer. 5 In the PAPR PPE set HCP wore a Tyvek (DuPont, Wilmington, Delaware) suit, shoe covers, a surgical gown, and a large hood, whereas the enhanced respiratory and contact precautions system included only a surgical gown, indicating that a second covering significantly reduced exposure to contaminated body fluids and provided evidence for the use of aprons on top of gowns or coveralls in the care of Ebola-infected patients. Areas that were more likely to be contaminated included the anterior neck, forearm, hands, and wrists. However, those persons donning the PAPR system were more likely to commit donning procedure violations, highlighting the increased difficulty of donning and doffing with more complex PPE. Fortunately, there were no significant differences in doffing procedure violations between the 2 groups. 5 Although PPE is often only worn for short periods of time, pathogenic viruses such as influenza, SARS, and Ebola can survive for extended periods of time on surfaces and be sources of transmission via surface-tohand and hand-to-face/mucous membrane contact. Despite 2 layers of protective clothing and 2 pairs of gloves, hand hygiene remains an essential aspect of PPE because previous studies have reported that organisms can spread from gloves to hands after glove removal. 41 

Outbreaks of EVD, with the exception of the Reston subtype, have occurred exclusively in central sub-Saharan Africa and more recently in West Africa where the climates are known for high ambient temperatures and humidity throughout the year. PPE worn in these settings significantly increase the risk of heat stress and pose yet another risk to the HCP. The risk of heat stress when wearing PPE depends on a number of factors, including length of work shift, ambient temperatures, hydration status, and preexisting medical conditions among others. Strategies to mitigate the risk of heat stress for HCP must be implemented such as the use of buddy systems to monitor the health of providers inside the high-risk area, hydration breaks in between shifts, and consideration of time limitations in staffing determinations. In addition, other strategies were used in the current outbreak, including the use of cooling vests and air conditioning, which have extended the time that providers can spend with patients. Ongoing studies by the National Institute for Occupational Safety and Health are evaluating the effect of different types of PPE on core body temperature. 42 Recommendations from the CDC for reducing heat stress-related complications include the following 43 : (1) educate HCP how PPE places them at a higher risk of heat-related illness, (2) acclimatize HCP to PPE conditions by gradually increasing their time working in PPE, (3) stay well hydrated, (4) watch for signs and symptoms of heat-related illness, and (5) ensure adequate breaks in between shifts to rest and cool down.

The devastation in West Africa exacted by Ebola will be felt for decades to come. In addition to the unprecedented numbers of infections and deaths, this epidemic has also decimated the HCP population that will leave an already susceptible region at risk well beyond the end of this epidemic. In this epidemic 869 HCP were infected and 507 died to date, more than any other Ebola outbreak and likely more than all previous outbreaks combined. Protection of HCP who bravely work on the front lines must be a priority. Although the use of PPE is an integral part of HCP safety, it must be used as part of a universal infection prevention and control strategy that incorporates environmental and administrative controls, sustained logistical support, and the use of scientific evidence to back current recommendations. There have been 25 outbreaks since the Ebola virus was discovered in 1976, and they are occurring with increased frequency. The question is not whether another outbreak will occur, but when. Improved PPE and evidencebased recommendations are a priority.

Drs. Fischer, Weber, and Wohl contributed equally to this work.

The study was supported by funds from the National Institutes of Aging R03AG045088 (WF), North Carolina Translational and Clinical Sciences Institute (NC TRACS) KL2TR001109 (WF), Infectious Disease Society of America Young Investigator Award in Geriatrics, and a National Institutes of Health K24 DA037101 (DW). The funders had no role in the design and conduct of the study; collection, management, analysis and interpretation of the data; and preparation, review or approval of the manuscript.

",0.7323498088823747
Physiologic and other effects and compliance with long-term respirator use among medical intensive care unit nurses,"Background: Long-term use of respiratory protection may be necessary, but compliance may be low, and physiologic effects have not been well evaluated. Methods: Ten nurses participated; physiologic effects, subjective symptoms, and compliance with wearing an N95 alone or with a surgical mask overlay were assessed. Longitudinal analysis based on multivariate linear regression models assessed changes in outcome variables (CO 2 , O 2 , heart rate, perceived comfort items, compliance measures, and others). Analyses compared changes over time, and compared wearing only an N95 to wearing an N95 with a surgical mask overlay. Results: Most nurses (90%, n ¼ 9) tolerated wearing respiratory protection for two 12-hour shifts. CO 2 levels increased significantly compared with baseline measures, especially when comparing an N95 with a surgical mask to only an N95, but changes were not clinically relevant. Perceived exertion; perceived shortness of air; and complaints of headache, lightheadedness, and difficulty communicating also increased over time. Almost one-quarter (22%) of respirator removals were due to reported discomfort. N95 adjustments increased over time, but other compliance measures did not vary by time. Compliance increased on day 2, except for adjustments, touching under the N95, and eye touches. Conclusion: Long-term use of respiratory protection did not result in any clinically relevant physiologic burden for health care personnel, although many subjective symptoms were reported. N95 compliance was fairly high.","Pandemics, outbreaks of emerging infectious diseases, and bioterrorism attacks may necessitate long-term filtering face piece respirator (N95) use for health care personnel. 1 However, researchers and experiences during the 2009 influenza A pandemic indicate that N95 supplies may be insufficient during a future event. 1, 2, 3 In response to this potential problem, the Centers for Disease Control and Prevention (CDC) 4 and the Occupational Safety and Health Administration 5 issued guidance regarding extending the use or reuse of N95s during a future influenza pandemic. In addition, the Institute of Medicine issued a report that proposed a strategy for prolonging the useful life of N95s through the use of a surgical mask overlay that is intended to provide barrier protection for the N95. 6 Research examining potential physiologic impacts of long-term N95 use has been limited. Most has been laboratory based, 7, 8 meaning that work conditions were approximated by walking on a treadmill and/or involved young, healthy subjects. 9,10 Only 1 study has examined long-term N95 use among health care personnel in an actual work setting, 11 and that study only assessed perceived intolerance. In addition to physiologic factors, researchers indicate that subjective symptoms/conditions, such as perceived comfort, headaches, or difficulty communicating with patients, may affect health care personnel's tolerance of long-term N95 use. In retrospective studies, researchers reported that long-term use of N95s during the severe acute respiratory syndrome outbreak was associated with an increased frequency of headaches 12 and physical discomfort. 13 In addition to examining tolerance, it is important to assess staff compliance. Noncompliance with N95 use can put staff at risk from infection, a factor believed to be associated with the high rate of severe acute respiratory syndrome among health care personnel. 14 A study using self-reported compliance found that less than half of all health care personnel reported being compliant when using an N95, and that study only examined the practice of touching the N95 when measuring compliance. 15 Other noncompliant behaviors, such as adjusting the N95 during use or touching under the N95, were not assessed. In addition, researchers indicate that N95 compliance may decrease over time; the longer N95s are worn, the less compliant staff become. 16 A prospective study examining tolerance and observed compliance with long-term N95 use among health care personnel providing routine patient care in an actual work environment has never been conducted.

The purpose of this study was to determine physiologic and subjective effects of long-term respiratory protection (ie, N95 and N95 with a surgical mask overlay) use among health care workers during routine patient care duties. Aims included the following: (1) determine changes to transcutaneous carbon dioxide (CO 2 ) and oxygen saturation (O 2 ) levels related to long-term N95 use;

(2) determine whether the addition of a surgical mask as an outer barrier over an N95 results in increased physiologic and subjective effects compared with the use of an N95 alone; (3) determine whether subjective symptoms, such as comfort and perceived exertion, increase during long-term N95 use; and (4) evaluate health care personnel N95 compliance during long-term use.

This study used a repeated-measures crossover design. All subjects were followed for two 12-hour shifts/days (intersession interval !1 day). After being evaluated for eligibility, participants were randomly assigned to wear only an N95 or an N95 with mask overlay for a single 12-hour shift. During the second shift, participants were crossed over to the other intervention.

Inclusion criteria included nurses working in the University of Louisville Hospital medical intensive care unit (MICU) who are nonsmokers (defined as having never smoked or not smoked in the last year), 20 to 50 years old, not pregnant, and able to pass quantitative fit testing. Exclusion criteria included any medical or physical symptom/condition that could potentially put subjects at risk from prolonged N95 use, including pregnancy, arrhythmias, hypertension, poorly controlled asthma, history of panic attacks or claustrophobia, and/or seizure disorder. Quantitative fit testing was conducted on all potential subjects prior to study enrollment; only those who passed fit testing were enrolled. Ten subjects were enrolled.

Physiologic and subjective symptoms were measured at baseline (ie, start of shift before putting on N95 or N95/mask), every 30 minutes throughout the shift, before N95 or N95 mask removal during shift, and at end of shift. Physiologic variables included blood pressure, heart rate, CO 2, and O 2 . CO 2 and O 2 were measured using a SenTec CO 2 and O 2 saturation sensor (SenTec AG, Therwil, Switzerland). Subjective symptoms measured include perceived exertion, perceived thermal comfort, perceived respirator comfort, and subjective symptoms related to wearing an N95. Perceived exertion was measured using the Borg Rating of Perceived Exertion Scale, 8 consisting of a Likert scale ranging from 6 to 20 points, with 6 ¼ no exertion at all to 20 ¼ maximal exertion. Perceived comfort was measured using a modified Frank Scale of Perceived Thermal Comfort Scale, 8 consisting of a Likert scale ranging from 0 to 10 points, with 0 ¼ coldest you've ever been to 10 ¼ hottest you've ever been. Perceived N95 comfort was measured using a modified Roberge Respirator Comfort Scale, 8 consisting of a Likert scale ranging from 1 to 5 points, with 1 ¼ most comfortable you've ever felt wearing an N95 respirator to 5 ¼ most uncomfortable you've ever felt wearing an N95. Subjective symptoms related to wearing an N95 included nausea, headache, light headedness, visual difficulties, shortness of breath, palpitations, confusion, and difficulty communicating; these variables were assessed using the Roberge Subjective Symptoms During Work Scale, 8 a Likert scale ranging from 1 to 5 points, with 1 ¼ not noticeable to 5 ¼ very noticeable. Study researchers collected the physiologic and subjective symptom data.

Respirator compliance was measured by direct observation of subjects throughout their work shift. Observations were conducted by student workers; inter-rater reliability was assessed prior to data collection. Compliance observations were obtained for a 10-minute interval during each hour of each shift (12 observations per subject per shift) by watching the nurse as he/she performed work duties. The following components of N95 compliance were collected: (1) number of N95 adjustments, (2) number of N95 touches, (3) number of face touches (ie, touching anywhere on the face, not counting the eye[s]), (4) number of under-the-N95 touches (ie, using a hand or finger[s] to reach under the N95), and (5) number of eye touches. Because of patient care priorities that required the nurses to be in a room with the blinds drawn for privacy, some compliance data collection points were late or missed altogether.

MICU temperature and relative humidity were measured and documented at the start and end of each shift during the study; readings were obtained at the nurses' station in the center of the unit. Subjects were provided Kimberly Clark N95s and Kimberly Clark Tecnol surgical masks for the study. These were chosen because they are one of the brands stockpiled by the CDC's Strategic National Stockpile and are likely to be the brands provided to hospitals during a pandemic. Subjects were instructed to follow their employer's extended use/reuse policy related to N95 use; this policy is based on published guidance outlining safe extended/ reuse of N95s. 1 Subjects could replace their N95 and/or N95/mask combination as needed because of discomfort, perceived loss of integrity, and others. The University of Louisville and Saint Louis University institutional review boards approved this study.

Longitudinal analysis based on multivariate linear regression models were used to assess changes in outcome variables (blood pressure, CO 2 , O 2 , heart rate, perceived comfort items, compliance measures, and others) over time. The advantage of using longitudinal study is that it provides information about individual change over time, separate from differences among subjects at baseline. Analyses were run comparing changes over time because of wearing only an N95 and comparing changes when wearing only an N95 to wearing an N95/mask combination. T tests were used to compare the average time nurses wore their assigned respiratory protection before first removal and the average time they wore the 2 types of respiratory protection. All analyses were conducted using SAS (SAS Institute Inc, Cary, NC).

Ten MICU nurses participated in the study on day 1; 9 completed both days. All participating nurses were white, and most (90%, n ¼ 9) were female, with an average age of 35 (range: 24-48) years. Most (60%, n ¼ 6) had a bachelor's degree and were not a charge nurse (80%, n ¼ 8). Participants had an average of 11 years of experience wearing an N95 and 9.5 years of nursing experience; 60% (n ¼ 6) worked day shift. All but 1 (90%) were overweight as determined by having a body mass index (BMI) equal to or greater than 25, and half (n ¼ 5) were obese (ie, BMI ! 30).

Most nurses (90%, n ¼ 9) tolerated the use of respiratory protection for 2 full 12-hour shifts. Only 1 (10%) withdrew because of unwillingness to continue wearing respiratory protection; this subject wore it for approximately 30 minutes before withdrawing from the study. Of the nurses who participated in the entire study, each used an average of 3 N95s for each 12-hour shift. Nurses wore the N95 alone or with a mask for 214 and 199 minutes on average, respectively, before the first removal for any reason (Table 1) ; this time difference was not significant. Daily average times wearing the N95 alone or with a surgical mask during each episode were 223.7 and 159.1, respectively (Table 1) ; this time difference was not significant. Each time a nurse removed his/her N95, the reason for removal was documented. In total, nurses removed their respirator 68 times during the study, either to eat or drink, because it was the end of his/her shift, or because the N95 was uncomfortable in some way. About half of the removals (55.9%, n ¼ 38) were reported to be because the nurse wanted to eat or get a drink. About one-quarter of the removals (22.1%, n ¼ 15) were because the shift ended, and the remaining one-quarter (22.1%, n ¼ 15) were due to reported discomfort. Qualitative statements made by nurses as reasons for removal included comments such as, ""It is getting hard to breathe,"" ""[the N95] is uncomfortable,"" and ""I can't breathe."" Five types of N95 noncompliance were assessed: (1) N95 adjustments, (2) N95 touches, (3) face touches, (4) under-the-N95 touches, and (5) eye touches. On average, each nurse was noncompliant with their respirator 25.7 times per shift. The most frequent types of noncompliance included touching the N95 and adjusting the N95 or N95/mask combination. There was no relationship between the amount of time an N95 or N95/mask combination was worn and compliance with wearing the N95 on 4 of the 5 compliance measures: face, eye, or N95 touches or touches under the N95 (Table 2) . Nurses wearing an N95 alone were less likely to adjust it toward the end of their shift compared with earlier in the shift; in contrast, when nurses were wearing the N95/mask combination, the number of N95 adjustments did not vary by time (Table 2 ). Compliance increased on day 2 in relation to the number of times a nurse touched the N95, regardless if he/she was wearing only an N95 or a N95/mask combination ( Table 2) .

Wearing an N95 for an entire 12-hour shift had statistically significant negative effects on some physiologic measures and subjective symptoms. Over time, nurses' CO 2 levels became significantly elevated, from a statistical standpoint, compared with beginning-of-shift baseline measures; perceived exertion; perceived shortness of air; and complaints of headache, lightheadedness, and difficulty communicating also increased over time (Tables 3  and 4 ). CO 2 levels increased from a baseline average of 32.4 at the beginning of the shift to 41.0 at the end of each shift. There were no changes in nurses' blood pressure, O 2 levels, perceived comfort, perceived thermal comfort, or complaints of visual difficulties compared with baseline levels.

Wearing an N95 with surgical mask overlay had statistically significant negative effects over and above those associated with wearing only an N95. CO 2 levels, nausea, and complaints of visual challenges increased significantly more when nurses were wearing the N95 and mask than when only wearing an N95 (see Table 5 ). Wearing an N95 with mask did not have a significant negative impact over and above wearing only an N95 in relation to blood pressure, O 2 levels, heart rate, headache, lightheadedness, perceived exertion, perceives shortness of breath, perceived comfort, perceived thermal comfort, or impeded communication.

Nurses having a higher BMI had statistically significant negative effects on some physiologic measures and subjective symptoms than nurses with lower BMIs, independent of time the N95 was worn or whether they wore an N95 alone or with a mask. Nurses with a higher BMI had lower O 2 levels and higher heart rates while wearing either type of respiratory protection (an N95 alone or with a mask) ( Tables 3 and 5 ). Heavier nurses also reported significantly more negative effects on subjective symptoms than nurses who weighed less. Nurses with higher BMIs reported higher perceived exertion, perceived shortness of breath, perceived discomfort, complaints of feeling warm while wearing the N95, headaches, lightheadedness, visual challenges, and impeded communication than nurses with lower BMIs, independent of time the N95 was worn or whether they wore an N95 alone or with a mask (Tables 3-5). Complaints of nausea also increased significantly more among nurses with a higher BMI when wearing an N95 plus a surgical mask than among nurses with a lower BMI (Table 5) . Nurses with higher BMIs also performed one of the most potentially high-risk noncompliant behaviors in terms of cross contamination than nurses with lower BMIs: touching the N95. Nurses with a higher BMI were significantly more likely than those with a lower BMI to touch their respirator when wearing an N95 (Table 2) .

From a physiologic standpoint, the nurses participating in this study tolerated long-term use of respiratory protection well, regardless of whether they wore an N95 alone or with a surgical mask overlay. The only negative physiologic change resulting from long-term respiratory protection use was elevated CO 2 levels, with CO 2 increasing over time when wearing an N95 alone, and increasing even more significantly, from a statistical standpoint, when wearing an N95 and mask compared with when they only wore an N95. However, although there were statistically significant negative physiologic changes over time associated with wearing respiratory protection (especially among those wearing an N95 with a mask overlay), these changes were not clinically relevant. For instance, the statistically significant rise in CO 2 levels over time from baseline to the end of the shift did not result in CO 2 levels that reached the clinical definition of hypercapnia (defined as an arterial CO 2 level ! 45). Therefore, from a physiologic perspective, long-term use of respiratory protection proved to not cause negative effects for the nurses in this study.

An interesting finding from this study is that, although the nurses did not experience any clinically significant negative physiologic effects from wearing respiratory protection, they reported many subjective symptoms. For example, perceived shortness of breath increased over time when nurses wore any type of respiratory protection. Although physiologic measures of heart rate, O 2 , and CO 2 did not reflect a difficulty with gas exchange, nurses reported feeling more short of breath the longer they wore respiratory protection. Other subjective symptoms also increased over time, including complaints of headache, lightheadedness, perceived exertion, and impeded communication. When wearing an N95 with mask overlay, nurses reported feeling more nausea and had more visual challenges than when they wore only an N95. Although these symptoms do not represent life-threatening conditions, they are unpleasant and may affect health care personnel's willingness or ability to tolerate long-term N95 usage that would be necessary during a disaster.

Contrary to prior research on health care personnel tolerance of long-term use of respirators that found that the average time health care personnel would tolerate N95 usage was less than 8 hours, 11 this study found that almost all nurses were willing to wear the assigned respiratory protection for the duration of two 12-hour shifts (ie, the entire length of the study). In this study, only 1 nurse had high intolerance to wearing an N95 (as evidence by withdrawing from the study because of discomfort after only half an hour). The reasons for the longer tolerance despite increasing complaints of discomfort seen in this study are not known. It is possible that the timing of the 2 studies played a role in the subjects' tolerance for wearing N95s. This study occurred after the 2009 H1N1 pandemic, an event that necessitated prolonged use of N95s for many health care personnel until the H1N1 vaccine was released, and one that involved a shortage of N95s among many health care agencies. 3 Study participants' recent experiences during the 2009 pandemic may have provided increased motivation to tolerate long-term use of N95s.

Although the majority of nurses in this study had a high tolerance for long-term respirator use, 1 of the 10 subjects withdrew very early on because of discomfort. In addition, some MICU nurses who worked at the hospital from which subjects were recruited refused to participate because of an unwillingness to wear an N95 for 2 entire shifts. It is likely that volunteer subjects tolerate wearing N95s better than those who refused to even be screened for the study. This has implications for future disasters during which health care personnel may be required to wear N95s for long periods of time. More frequent work breaks may need to be incorporated into work shifts when long-term N95 use is required. Future studies should also examine other factors that may help increase health care personnel tolerance of long-term N95 usage.

A unique finding from this study is the relationship between weight and N95 tolerance and compliance. Nurses with higher BMIs were less compliant when wearing an N95, in terms of being more likely to touch their respirator, than those with lower BMIs. This more frequent touching of the respirator may have been related to perceived discomfort because nurses with higher BMIs reported many more subjective symptoms (such as more perceived shortness of breath, discomfort, thermal discomfort, and headaches) related to wearing respiratory protection than nurses with lower BMIs. These findings have not been identified in previous research on N95 tolerance 8, 11 and have potential significant implications for future disaster response. In the US general population, 33% of people are overweight (but not obese), and another 36% are obese 17 ; data specific to nurses could not be found, but there is no reason to believe that a lower rate of obesity among health care personnel would exist compared with the United States as a whole. With such a high rate of overweight and/or obese health care personnel, and an associated lower tolerance for long-term N95 usage among these individuals, it may be difficult to safely implement extended use or reuse policies for N95s without building in additional break times for staff. Additional studies are needed to further examine the relationship between weight and N95 tolerance and compliance. The nurses in this study were fairly compliant with wearing respiratory protection, meaning that they wore it correctly and did not frequently engage in behaviors that might lead to potential auto-inoculation, even over long periods of time. Contrary to the authors' hypothesis, nurses did not become less compliant over the course of a shift and actually became more compliant the second day of wear than the first in terms of the number of times they adjusted their N95 or touched their face or the respirator. The reasons for this are unknown but may be because the nurses became accustomed to wearing the N95 over the course of the study. This finding is different from a previously published study that found that N95 compliance decreases over time. 16 This may be because the Seale et al study 16 occurred over 4 weeks versus only 2 shifts observed in this study or because this sample consisted of only intensive care nurses. Researchers have indicated that intensive care unit staff are often more compliant with N95s than health care personnel in other areas/units. 15 One somewhat troubling finding from this study is that the most frequently performed noncompliant behaviors involved 2 practices that may put health care personnel at risk of exposure to infectious particles when wearing N95s: touching the N95 and/or adjusting it during use. Better or more frequent education of health care personnel may be needed to reduce these potentially harmful behaviors and protect workers from exposure because knowledge has been found to be associated with better adherence to proper respirator practice. 15 Nurses in this study were asked to follow their hospital's extended use/reuse of N95 policy, which included instructions to replace their N95 whenever they believed the integrity was compromised, the N95 became soiled, or when they believed the N95 to be difficult through which to breathe. Sometimes the nurse participants reused an N95 (ie, redonned it after removal), and other times they chose to don a new N95. Each nurse used an average of 3 N95s per shift during the study, regardless of how often he/she chose to don and doff respiratory protection. This finding provides a general guideline for hospitals to use when estimating the number of N95s needed per staff member during a disaster if an extended-use/reuse policy is implemented by the agency and is different from previously published recommendations regarding how to estimate the number of N95s that may be needed during a disaster. 2 This is the first study to examine long-term use of respiratory protection in a health care setting in terms of compliance, tolerance, and physiologic effects of use. It is also the first study in a health care setting to compare the physiologic impact of wearing an N95 alone to the N95 with mask overlay combination recommended by the Institute of Medicine to be used during times of limited resources. This study also has a robust methodology because of the nature of the randomization of subjects and the repeated measures design. One potential limitation of this study is that volunteer subjects may tolerate N95s better than those who refused to be screened for the study, reducing the generalizability of the findings to all health care personnel. Another potential limitation is the use of transcutaneous measurement of CO 2 versus the more accurate method of arterial measurement; however, transcutaneous CO 2 measurement has been shown to have adequate accuracy, 18, 19 and it has been used in all previous studies examining the physiologic impact of N95 use because of the avoidance of potential complications related to arterial punctures. 1, 7 Last, because only intensive care unit nurses were recruited, the findings may not be generalizable to workers in other areas of the hospital or to non-nurse health care personnel.

Long-term use of N95s, when worn alone or with a mask overlay as an outer barrier, did not result in a significant physiologic burden for health care personnel over the course of 2 work shifts. Despite the fact that health care personnel reported subjective symptoms related to wearing N95s and that these complaints increased over time, worker tolerance for long-term N95 usage was high. Nurses' compliance with wearing N95s was also high, even after long-term use. Findings from this study indicate that many health care personnel can tolerate long-term use of N95s, alone or with an outer barrier. Additional studies are needed to further examine factors that influence intolerance of long-term use of N95s among some health care personnel and the relationship between weight and N95 tolerance and compliance to identify ways to maximize worker tolerance of N95s before another biologic disaster occurs.

",0.7321570192699022
Personal protection equipment for biological hazards: Does it affect tracheal intubation performance? ଝ,Biological hazard; Tracheal intubation; Intubating laryngeal mask; Flexible bronchoscopy; Personal protection equipment Summary,"Nosocomial transmission of severe acute respiratory syndrome-associated coronavirus (SARS-CoV) to health care workers (HCW) has been a notorious characteristic of this disease. During the 2003 outbreak, about 20-50% of all SARS-CoV cases in Hong Kong, Singapore and Canada occurred in HCW. 1, 2 Such viruses are a constant threat and recent reports of ''avian flu'' (in particular H5N1 virus) are now another cause for concern.

Pulmonary complications are a prominent feature of these diseases and patients frequently require intensive respiratory therapy and mechanical ventilation. Unfortunately airway management such as bag and mask ventilation, intubation, suctioning and mask based oxygen and drug delivery appear to have been important vectors of disease transmission. 3 Wearing a correctly fitted face mask (either surgical or particulate respirator type N95) while caring for SARS-CoV patients appears to be protective. [1] [2] [3] [4] [5] A variety of personal protection equipment (PPE) has also been suggested for use by HCW in all aspects of patient treatment during such outbreaks. 6 The level of PPE chosen for high-risk procedures such as tracheal intubation is extremely important for both the patient and the treating physician. Rigid prerequisites for the protective ability of such equipment are obviously essential but it is also important that the protective clothing does not impede HCW during clinical procedures, particularly crucial events such as airway management.

Previous studies have investigated the use of protective clothing for chemical hazards [7] [8] [9] [10] [11] [12] [13] and their impact on airway management. Though PPE for chemical and biological hazards may share some common characteristics (e.g. eye and face shields) chemical hazard PPE is often composed of different materials ranging from disposable Tyvek ® to polyvinylchloride ''splash suits''. [8] [9] [10] In contrast, water-resistant or water-proof gowns were the most frequently used clothing during the SARS-CoV outbreak in 2003. [14] [15] [16] [17] [18] [19] [20] [21] During outbreaks of these diseases, anaesthetists are frequently involved in patient airway management, resuscitation and intensive care. This is not because these patients are particularly difficult to intubate, but because the World Health Organization (WHO) guidelines 6 stipulate that the most experienced operator should secure the airway in order to minimise delay and secretion dissemination. At such times, tracheal intubation is often necessary and, although other airway devices such as the laryngeal mask may facilitate some temporary ventilation and oxygenation, a properly sealed tracheal tube is often mandatory in the care of these patients. At this stage the optimal level of protection for the HCW performing such high-risk procedures has yet to be found, and in the past the Centre of Disease Control and Prevention (CDC) 22 have suggested a number of combinations of PPE. The PPE recommended during the 2003 SARS-CoV outbreak included eye and facial protection, [14] [15] [16] [17] [18] [19] and powered air purifying respirators (PAPR). 14, 15, [17] [18] [19] [20] [21] Recently the WHO has proposed its recommendations for avian flu 6 which includes goggles or eye shields for eye protection. We have, therefore, taken these recommendations as well as reviewed the most commonly used PPE employed during the SARS outbreak in China, Hong Kong and Canada and have adopted this as our ''control PPE''. This control group has then been compared with two other types of PPE to investigate if they had an impact on the ability or time taken to perform tracheal intubation and the comfort of the individual.

The objective of this study was to examine the impact of three types of PPE on the ability of anaesthetists and anaesthesia trainees to intubate manikins using four different intubation techniques.

Approval for the study was granted by the local institutional review board. Four consultant anaesthetists and 14 anaesthetic trainees participated in this prospective comparative study after giving informed consent. All subjects were staff members of the same large teaching hospital and were selected based on their availability to participate in the study. The presence of learning curves for practical skills in anaesthesia is well recognised and a 90% success rate after 57 attempts has been suggested in a study of anaesthesiologists. 23 Using a mono-exponential model, Smith et al.'s learning curve indicated that after 45 intubations (five halflives) the trainee anaesthesiologist draws close to their 'expert' fibreoptic intubation time. 24 All participants in this study had at least this level of experience. Subjects who had previous experience wearing PPE prior to the commencement of this study or those who had previous opportunities to intubate patients while wearing PPE were excluded from the study. Three weeks before the study, all subjects underwent qualitative fit testing of the N95 face mask. This was performed well before the study to parallel the clinical situation during outbreaks when there is often insufficient time for testing prior to tracheal intubation.

For anaesthetists the length of time since obtaining the fellowship was recorded, and for anaesthetic trainees, their level of training was noted. The subjects practised on the manikin using all the airway devices for 30 min immediately prior to their participation in the study to familiarise themselves with the equipment. This aimed to eliminate ''learning phenomena'' during the study because the times for the various procedures might change as a result of familiarity with the equipment.

Since the use of PPE during tracheal intubation of patients with infectious respiratory illness is mandatory, the control group wore the basic level of PPE for use in this situation. 2 We had the eye shield group as our control and compared this with the two other types of PPE as described. Subjects applied the PPE in the order control PPE, PPE 1 and then PPE 2 (see Table 1 ). An observer with wide experience in the use of infection control measures and in particular PPE, performed a final inspection after the PPE was applied to ensure that the subjects were dressed in compliance with the above recommendations (Plate 1).

Tracheal intubation of a Laerdal Airway Management Trainer (Laerdal Medical Corp., Oakleigh, Vic., Australia) was performed using the following methods.

A standard Macintosh size 3 blade was used for direct laryngoscopy. The time measured was from the moment the anaesthetist grasped the laryngoscope until the tracheal tube was placed in the trachea, the cuff inflated and ventilation via the tracheal tube was successful.

A size 4 iLMA was used for intubation along with the corresponding 7.5 mm internal diameter (I.D.) cuffed tracheal tube. After the device was placed correctly in the manikin's airway, the cuff of the laryngeal mask airway was inflated with 20 ml of air. Ventilation through the iLMA was tested with a self-inflating bag. The first split time was taken from picking up the iLMA to the first inflation of the manikin's lungs. The bag was then disconnected and the tracheal tube was inserted. The second split time was recorded as the cumulative time to ventilation via the tracheal tube. The third split time was recorded following removal of the laryngeal mask and successful ventilation via the tracheal tube.

A lubricated size 9 cm Berman Intubating Airway (Vital Signs, Totowa, NJ, USA) was inserted into the mouth of the manikin to assist oral fibreoptic intubation and to parallel the clinical situation of using fibreoptic bronchoscopic intubation in anaesthetised patients. An intubating fibreoptic bronchoscope (Olympus LF-GP, Olympus America Inc., USA) was used for all cases and the tracheal tube was passed over the bronchoscope and into the trachea of the manikin. The first split time recorded was from picking up and inserting the Berman airway until the carina was first visible through the bronchoscope. The second split time was cumulative and recorded as successful ventilation via the tracheal tube.

A lubricated size 9 cm Berman Intubating Airway was inserted into the mouth of the manikin. A fibreoptic bronchoscope with an attached camera (Olympus OTV-S4, Olympus America Inc., USA) mounted on the eyepiece and video screen attached to the eyepiece was used to visualise the manikin's airway on a video screen during the intubation. Split times were taken in a similar method to fibreoptic intubation using the eyepiece alone. Successful intubation was confirmed by observation from the bottom of the manikin of the inflated tracheal tube cuff in the trachea in addition to successful inflation of the lungs. Failure was defined by the occurrence of oesophageal intubation. Any instance of endobronchial intubation was also recorded.

At the completion of the study, subjects were given the following questions to answer: Q1. Which PPE provided the best conditions for all methods of tracheal intubation? Q2. Which PPE provided the worst conditions for all methods of tracheal intubation? Q3. Do you have any general comments about any of the PPE used?

All the intubation times were analysed by repeated measures of analysis of variance (ANOVA). When the normality assumption on the residuals was violated, log transformation was applied to the intubation times before performing repeated measures ANOVA. Since this is a prospective observational study examining the impact of various types of PPE on tracheal intubation techniques, power calculations were based partly on previous work focussing on the impact of chemical protective equipment on tracheal intubation. [7] [8] [9] [10] [11] [12] [13] However, patients with infectious respiratory illnesses requiring tracheal intubation will have significant degrees of respiratory failure and are often intolerant to prolonged intubation attempts. Based on a pilot study we aimed to detect not less than a 5 s difference between the times for direct laryngoscopy and intubation with an estimated standard deviation of 7 s. The required sample size was 17 participants with an 80% power of the test at the 0.05 level of significance.

Experience of the consultant anaesthetists ranged from 1 year post fellowship to 20 years. The level of training of the trainees ranged from first year to final year in the Australian and New Zealand College of Anaesthetists training system. Table 2 shows that none of the three types of PPE had a significant effect on the ability to perform tracheal intubation in the manikin with the different intubation techniques. The intubating laryngeal mask airway and fibreoptic intubation using the eyepiece both provided the longest intubation times. These times are significantly longer than direct laryngoscopy and fibreoptic intubation using the video screen.

There were no oesophageal intubations; however, there were four endobronchial intubations. One was associated with direct laryngoscopy while wearing the control PPE. The other three cases occurred with control PPE, PPE 1 and PPE 2, respectively, using the intubating laryngeal mask. The study size was insufficient to show any statistical difference in the incidence of endobronchial intubation. Table 3 shows the results to the questionnaire at the completion of the study. Sixty-seven percent of subjects recorded that PPE 2 generally provided the most comfort for all types of intubation, while the same percentage of subjects rated PPE 1 as having the worst. Numerous comments from the subjects highlighted the uncomfortable environment that PPE 1 produced, with most subjects sweating while wearing the water-resistant surgical gown and face shield despite the air-conditioned environment (23 • C and 55% relative humidity) in which the study took place. The face shield in PPE 1 often became fogged especially during longer intubation techniques. Subjects frequently needed to adjust their head into different positions to maintain visibility. The positive pressure produced by the Dustmaster TM device in PPE 2 appeared to protect against fogging. Other issues apart from the level of comfort using PPE included the following:

1. All PPE devices produced problems when using the bronchoscopic eyepiece. The distance between the eyes of the subject and the bronchoscopic eyepiece meant that the participants needed to move their head across the eyepiece to view the entire image. 2. One subject found that the combination of bifocal eyeglasses, PPE 1 and the bronchoscopic eyepiece produced difficult conditions for intubation. Frequent adjustment of the visual axis was necessary to obtain the optimal image. 3. Another subject wearing glasses for myopia found PPE 1 and the bronchoscopic eyepiece difficult for intubation, finding the visual image poorly focused. 4. Reflections from the back of the face shield proved to be troublesome with PPE 1 by two subjects. 5. Two subjects noted that the noise from the battery-powered pump in the Dustmaster TM in PPE 2 made it difficult to hear instructions from personnel directing them to the various intubation stations.

This study examined the impact of selected PPE on the ability to perform tracheal intubation using a standard airway manikin. The use of a manikin does not equate to an actual intensive care patient and their environment. However, this study does allow an important practical comparison of three types of PPE while undertaking a variety of different intubation techniques. If PPE impedes the ability to perform tracheal intubation, then its use during high-risk procedures on patients with infec-tious respiratory disease could be impractical and possibly dangerous. Furthermore, its role as an infection control barrier could also be compromised if problems during tracheal intubation necessitated adjustment of the PPE thereby increasing the infection risk of the user. We have included a wide range of tracheal intubation experience in the selected participants as would mirror the actual clinical situation during respiratory illness outbreaks closely where both qualified anaesthetists as well as anaesthetic trainees would be required to perform this task.

Suggestions have been made that a minimal amount of PPE (consisting of surgical mask/N95, surgical gown and gloves) can provide adequate protection for HCW 2 and that more complicated protection may increase the risk of contamination during the de-gowning process (Dr. WH Seto; Department of Microbiology, Queen Mary Hospital, Hong Kong, personal communication). We have examined several types of PPE so that a more informed decision may be made when choosing the appropriate type of PPE for tracheal intubation.

After each type of PPE was applied, the subjects performed the different methods of tracheal intubation randomly in four separate rooms to avoid subjects assisting each other during the study. Times were compared to define the optimal method for intubation. Cumulative split times were taken for the iLMA to differentiate possible variations in times during the intubation that may be associated with the type of PPE worn. Similarly during the two bronchoscopic methods, the time until the carina was first visualised was distinguished from the time to pass the tracheal tube over the bronchoscope and ventilate the lungs to highlight possible effects by the PPE.

We found that the type of PPE does not influence the time taken to intubate a manikin with any particular method. We did not perform a comparison with no PPE (i.e. no mask, gloves, surgical gown or eye protection) because HCWs are required to wear some level of PPE while intubating patients with infectious respiratory diseases and, in fact, it is prudent to do so even in asymptomatic patients.

The fact that the PPE did not prove to affect the intubation times may be related to the fact that the tracheal intubations were carried out on manikins and that difficult airway management conditions were not examined. Certainly further research examining various intubating conditions should be performed to the detail the effects of this equipment.

All the subjects felt that PPE 1 made them uncomfortably hot, that fogging of the face shield frequently occurred and that they would prefer to avoid this particular type of PPE. The proposal that patients with highly infectious respiratory illness should be placed in negative pressure isolation rooms, which frequently produces a drop in the number of air changes, 17 may compound this temperature problem. Reflections from the back of the face shield in PPE 1 were a problem for two subjects and may be detrimental during tracheal intubation, especially if fogging occurs as well. The use of prescription glasses by subjects wearing PPE 1 while performing fibreoptic intubation with the eyepiece also appears to be troublesome. Two subjects found this combination made the procedure very difficult but not impossible. We suggest that if contact lenses are available, then these should be worn prior to applying the PPE.

In contrast, the control PPE and PPE 2 produced favourable conditions for tracheal intubation, particularly PPE 2. All subjects felt that the air powered respirator of PPE 2 countered the insulating and subsequent heating effect from the waterresistant surgical gown. However, the Dustmaster TM produced a low-level background noise that made hearing difficult. Although assistants were able to overcome this by raising their voices, the possibility that this may contribute to difficulties in communication during the intubation and subsequent management of a patient with a respiratory illness should be considered.

Direct laryngoscopy was the fastest method of tracheal intubation followed by fibreoptic intubation with camera/video screen with fibreoptic intubation using the eyepiece and iLMA together as the slowest (see Table 2 ). Frequently direct laryngoscopy may require closer proximity of the subject to the manikin's airway than the other intubation techniques. This is of concern when performing tracheal intubation on patients with diseases spread by droplet or contact transmission.

It should be noted that the laryngeal mask airway intubation method used in this study provided three occasions where the manikin was ventilated during the procedure. This initial ventilation (mean values for PPE groups: 14.0-14.7 s) was in fact faster than the time for ventilation following direct laryngoscopy (mean values for PPE groups: 21.7-24.2 s). Although there is concern that ventilation other than through a tracheal tube may lead to dissemination of secretions, we felt that initial ventilation via the laryngeal mask would be of lesser risk than for face mask ventilation. On the other hand the average time with no ventilation using the bronchoscopic eyepiece method ranged from 61.9 to 70.2 s for all types of PPE. This may impact on the main-tenance of oxygenation in patients with respiratory illness when the fibreoptic bronchoscope using the eyepiece is used.

The use of the eyepiece of a fibreoptic bronchoscope is difficult when any protective eyewear is worn. This occurred with all three types of PPE but the distance from the subjects' eye and the protective shield and, therefore, bronchoscopic eyepiece was greatest for PPE 2 and least for the control PPE. This resulted in all subjects expressing concern if this type of technique was to be used while wearing PPE. We suggest the use of a video screen, if available, with fibreoptic intubation as this avoids the problems that eye protection creates and allows the physician to avoid placing their hands in close proximity to their face.

The occurrence of three endobronchial intubations is a concern, although the study was not designed to indicate if this is a higher risk while wearing PPE. The possibility that PPE may potentiate endobronchial intubation should be investigated further. In particular, PPE 2 may interfere with the detection of endobronchial intubation as the use of a stethoscope to check for the presence of bilateral chest sounds is impossible due to the head being covered and with the background noise level.

This study has several limitations. The principle limitation was the use of a manikin. Apart from the anatomical differences between manikins and patients, there is the failure of manikins to respond physiologically to tracheal intubation. The study took place in controlled conditions without the extra stress created by performing life-saving procedures on patients with respiratory failure. In addition the possibility of the participants contracting the respiratory illness during the procedure could not be simulated. All intubations were of the same grading and further work needs to be performed focusing on more difficult airway management.

In summary we have assessed different types of PPE and their influence on four common intubation techniques. We found that, although none of the types of PPE had a measurable effect on intubation times, the practical problems of excessive heating and fogging while wearing a transparent face shield device may be problematic during tracheal intubation of patients with respiratory distress. There were also difficulties in viewing the fibreoptic bronchoscopic eyepiece through the face shields of PPE 1 and PPE 2. The study showed that using bronchoscopic methods was inferior to iLMA, which allowed significantly earlier ventilation of the lungs. This suggests that the iLMA should be used in preference to the fibreoptic bronchoscope when difficulties in viewing the larynx are experienced during direct laryngoscopy.

Background noise produced from the Dustmaster TM was undesirable but the device was otherwise comfortable. In this laboratory environment we were not able to study or properly simulate situations such as unexpectedly difficult intubation, but we believe this could be a concern in such circumstances.

The use of personal protection equipment during tracheal intubation of patients with infectious respiratory illnesses is essential for the safety of health care workers. While its use in chemical hazards and its effect on airway management has been examined previously its effect on intubation techniques in the setting of a biological hazard has not been assessed before and this study will appraise this aspect critically.

",0.7314638939349103
Nosocomial Transmission of Emerging Viruses via Aerosol-Generating Medical Procedures,"Recent nosocomial transmission events of emerging and re-emerging viruses, including Ebola virus, Middle East respiratory syndrome coronavirus, Nipah virus, and Crimean-Congo hemorrhagic fever orthonairovirus, have highlighted the risk of nosocomial transmission of emerging viruses in health-care settings. In particular, concerns and precautions have increased regarding the use of aerosol-generating medical procedures when treating patients with such viral infections. In spite of increasing associations between aerosol-generating medical procedures and the nosocomial transmission of viruses, we still have a poor understanding of the risks of specific procedures and viruses. In order to identify which aerosol-generating medical procedures and emerging viruses pose a high risk to health-care workers, we explore the mechanisms of aerosol-generating medical procedures, as well as the transmission pathways and characteristics of highly pathogenic viruses associated with nosocomial transmission. We then propose how research, both in clinical and experimental settings, could advance current infection control guidelines.","Aerosol-generating medical procedures (AGMPs) are increasingly being recognized as important sources for nosocomial transmission of emerging viruses. Intubation was investigated as a possible cause of Ebola virus (EBOV) transmission among health-care workers (HCWs) in the United States [1] . Additionally, the high rate of nosocomial transmission of Middle East respiratory syndrome coronavirus (MERS-CoV) and Severe Acute Respiratory Syndrome coronavirus (SARS-CoV) caused speculation about the role of AGMPs [2] [3] [4] [5] . Crimean-Congo hemorrhagic fever orthonairovirus (CCHFV), was also associated with nosocomial infection secondary to AGMPs [6] . While guidelines were developed for performing AGMPs on patients with certain viral infections, assessing and understanding the risk that specific viruses and AGMPs pose for nosocomial transmission could improve infection control practices, as well as reveal relationships in virus transmission.

Despite the perceived importance of AGMPs in nosocomial transmission of viruses and other infectious agents, scarce empirical or quantitative evidence exists [7] . In order to assess the risk that certain viruses and AGMPs create for nosocomial transmission, we first need to identify potential AGMPs and viruses. The second step is then to determine the risk associated with these viruses and procedures, either through retrospective analysis, investigating the circumstances of nosocomial transmission, or through experiments, such as using air sampling during AGMPs to determine the risk of generating infectious virus-laden aerosols. Lastly, we can use this knowledge to transmission [11] . Lasers can create plumes of debris that contain infectious aerosolized virus, as well [15] . It is important to recognize the range of AGMPs and the circumstances under which they might be performed on infected patients. In order to associate certain AGMPs with nosocomial virus transmission, researchers need to test whether certain procedures generate aerosols with infectious virus, either through hospital sampling or laboratory procedures. Figure 1 . Potential types of aerosol-generating medical procedures (AGMPs). AGMPs can be divided into procedures that induce the patient to produce aerosols and procedures that mechanically generate aerosols themselves. 

Knowing the mechanisms behind different AGMPs allows us to narrow our focus of emerging viruses that could cause nosocomial transmission via AGMPs. These viruses must be able to Figure 1 . Potential types of aerosol-generating medical procedures (AGMPs). AGMPs can be divided into procedures that induce the patient to produce aerosols and procedures that mechanically generate aerosols themselves. [11] [12] [13] .

In contrast to causing a patient to produce aerosols, AGMPs can also mechanically create and disperse respiratory aerosols through procedures such as ventilation, suctioning of the airway, or nebulizer treatment. Both manual ventilation, using a bag-valve-mask, and other forms of noninvasive ventilation (NIV), such as continuous positive airway pressure (CPAP), bilevel positive airway pressure (BiPAP), and high-frequency oscillatory ventilation (HFOV) are associated with SARS-CoV nosocomial transmission [11] . Although the exact mechanisms of how these procedures create virus-laden aerosols in the respiratory tract remain unknown, it is possible that forcing or removing air from the respiratory tract could generate aerosols.

While AGMPs are traditionally thought of in regard to the generation of respiratory aerosols, AGMPs can also aerosolize infected fluids in other regions of the human body. Surgical techniques can aerosolize blood and possibly viruses. For example, infectious HIV-1 was found in the aerosols generated by surgical power tools [14] , and a tracheotomy was associated with SARS-CoV transmission [11] . Lasers can create plumes of debris that contain infectious aerosolized virus, as well [15] . It is important to recognize the range of AGMPs and the circumstances under which they might be performed on infected patients. In order to associate certain AGMPs with nosocomial virus transmission, researchers need to test whether certain procedures generate aerosols with infectious virus, either through hospital sampling or laboratory procedures.

Knowing the mechanisms behind different AGMPs allows us to narrow our focus of emerging viruses that could cause nosocomial transmission via AGMPs. These viruses must be able to opportunistically infect via the aerosol route and must be present in the patient where the AGMP is taking place. These two conditions fit a wide spectrum of viruses, and therefore we focus on those that are emerging and pose a high risk to HCWs performing AGMPs. Here we define high risk as both a high likelihood of infection if an aerosol is inhaled or comes into contact with a mucous membrane and a high case-fatality rate for the viral disease. Such viruses are those that are highly infectious and pathogenic and for which limited prophylactic or therapeutic countermeasures are available. This includes most biosafety level 3 and 4 viruses, while it excludes viruses such as the measles, mumps, and rubella, which can infect via the aerosol route and be spread by AGMPs, but a common vaccine protects HCWs against them. Viruses such as Norwalk virus, enteroviruses, or human respiratory syncytial virus (RSV), which either cause self-limiting diseases or are primarily pathogenic in pediatric, pregnant, or immunocompromised patients, are also included. Infection control measures must be performed on these and other viruses, for other patients and hospital visitors are also at risk of nosocomial virus transmission [16] . However, here we focus on novel, high-risk viruses for HCWs performing AGMPs.

When considering emerging highly pathogenic viruses, we used the following criteria to assess which viruses are high risk for HCWs performing AGMPs. (1) The virus is infectious via small or large droplet aerosols in humans or non-human primates (NHPs). Although some virus-laden aerosols, specifically large droplets, could land on surfaces and cause subsequent fomite transmission, those that can infect via inhalation of aerosols or aerosol contact with the eyes or mucous membranes may have the most potential to cause nosocomial transmission through AGMPs. (2) The virus is found in the human respiratory tract or in the respiratory tract of NHPs. Most AGMPs occur in the upper or lower human respiratory tract, and, therefore, if the virus is present in these locations, we expect that it has a higher likelihood of becoming aerosolized. (3) There is previous evidence of nosocomial transmission or association with AGMPs. This third criteria identifies viruses that were associated with this type of transmission in the past; although, it may miss viruses that are emerging or do not frequently infect humans.

The viruses that pose the highest risk to HCWs performing AGMPs may be some of the viruses that we know the least about. This is because many of these viruses may be emerging zoonotic viruses that rarely infect humans compared to human-adapted viruses. Therefore, we relied on knowledge from both human and animal viral infections to create a list of potential viruses (Table 2 ). We included viruses that fit at least two of the three previously mentioned classifications. Many of these viruses are also on the World Health Organization's list of priority pathogens for research and development preparedness [17] .

The viruses that we identify as high risk come from eight families and have diverse characteristics. However, they also have much in common. All of these viruses are emerging or re-emerging zoonotic RNA viruses. Initially spilling over from animal hosts into humans, these viruses can undergo subsequent human-to-human and nosocomial transmission to cause epidemics. However, unlike viruses that have evolved with human hosts, none of these viruses are endemic in human populations. Some of these viruses may cause stuttering chains of transmission before disappearing from human populations, while others, like Ebola virus or pandemic influenza A virus, may cause large outbreaks before being contained or establish themselves as endemic pathogens in the human population [18] . Viruses evolve within their hosts to maintain an optimum balance between transmission (consequently virulence) and persistence [19] . Because humans are not the reservoir hosts for these viruses, this equilibrium was not established. Most of these high-risk viruses are highly infectious and virulent, but are not as efficient at transmitting and persisting as true human respiratory viruses. Of the high-risk viruses, those belonging to the families of coronaviruses, orthomyxoviruses, and paramyxoviruses come closest to the equilibrium of persistence and transmissibility in humans. Uncoincidentally, these viral families also contain viruses that have become endemic in human populations. [20] [21] [22] ii. Laboratory workers infected by inhaling aerosols [23] Upper respiratory: i. Viral RNA in NHP oral and nasal swabs [24] ii. Virus isolated from human throat swabs [25] ii, iii. Nosocomial transmission [26, 27] Lower respiratory: ii. Virus isolated from human lung [28] Hantaviridae, Nairoviridae, Phenuiviridae i. CCHF virus ii. Hantaviruses iii. Rift valley fever virus i, ii, iii. Laboratory workers infected by inhaling aerosols [23, 29] Upper respiratory: i, iii. Viral RNA in NHP nasal swabs [24] iii. Viral RNA in NHP oral swabs [24] ii. Viral RNA in human saliva [30] Lower respiratory:

i, ii. Nosocomial transmission [6, 31] i. Likely association with AGMPs [6] ii. Causes human respiratory disease. Viral antigen in human lung [32] Coronaviridae i. MERS-CoV ii. SARS-CoV ii. Laboratory and health-care workers infected by inhaling aerosols [23] i, ii. Known human-to-human aerosol transmission Upper respiratory:

ii. Viral RNA in nasal/throat swabs [33] i, ii. Nosocomial transmission [2, 11, 12] ii. Significant association with AGMPs [11] [12] [13] Lower respiratory: i, ii. Causes human respiratory disease. Virus isolated from lung and sputum [33, 34] Filoviridae i. Ebolaviruses ii. Marburg virus i, ii. NHPs infected by aerosol administration [35] Upper respiratory: i. Isolated from human saliva [36] ii. Isolated from NHP saliva [37] i. [40] Upper respiratory: ii. Isolated from human nasal and throat secretions [41] ii. Nosocomial transmission [42] Lower respiratory: i, ii Causes human respiratory disease.i. Viral antigen in human lung [43] Considering these eight viral families, we can begin to assess the risk of particular viruses. To make a conclusive risk assessment, we need further experimental and epidemiological evidence. We can inform these future studies by first looking at what is currently known about the viruses in each of these families in regard to AGMPs.

The family Arenaviridae, in the order Bunyavirales, contains multiple viruses that have the potential for nosocomial transmission due to AGMPs. Arenaviruses spill over when humans inhale the aerosolized excreta of the rodent hosts for these viruses. Additionally, laboratory workers and NHPs were also infected by aerosolized arenaviruses, specifically Junin virus, Lassa virus, and Machupo virus [23] . Arenavirus infections can cause viral hemorrhagic fevers (VHFs) in humans. Known nosocomial transmission has occurred from patients infected with Lassa virus and Machupo virus [26, 27] . Less clinical or experimental data exist for other arenaviruses, but these may have similar characteristics. Although arenaviruses are found in the respiratory tracts of humans or animal models [24, 25, 28] , there is no evidence for human-to-human airborne transmission of arenaviruses. However, arenavirus aerosol transmission could theoretically occur when aerosols are mechanically generated through AGMPs.

Like arenaviruses, multiple other viruses within the order Bunyavirales are zoonotic and can cause VHFs. Both Crimean-Congo hemorrhagic fever (CCHF) orthonairovirus and Andes hantavirus were associated with nosocomial transmission, with CCHF transmission occurring after AGMPs were performed without eye or respiratory protection [6, 31] . Interestingly, other hantaviruses were aerosol transmitted to humans, either through accidentally aerosolizing the virus or through inhaling aerosolized rodent excreta [23] , but only Andes hantavirus was confirmed to transmit from person to person [31] . Although hantaviruses can cause respiratory disease in humans, as in hantavirus pulmonary syndrome (HPS), and were found in the respiratory tract [30] , they do not seem to efficiently transmit between humans like typical respiratory viruses. However, similar to arenaviruses, certain bunyaviruses found in human-or animal-model respiratory tracts, including CCHF virus, hantaviruses, and Rift valley fever virus, could possibly gain the route of aerosol transmission if an AGMP is performed.

The family of Coronaviridae contains viruses that are known to transmit routinely between humans through the aerosol route. Both MERS-CoV and SARS-CoV cause respiratory disease in humans and transmit via aerosols, but it is unknown whether small-droplet or large-droplet aerosols are the modes of transmission for these viruses. Significant nosocomial transmission of SARS-CoV has incited the most research regarding the role of AGMPs in nosocomial virus transmission [11] [12] [13] , while recent nosocomial transmission events of MERS-CoV warrant further research [2] [3] [4] [5] . Therefore, AGMPs could possibly amplify an already established route of infection for these viruses.

Filoviruses also cause VHFs and could potentially become transmissible through AGMPs. During outbreaks of Ebola virus disease (EVD), concerns were raised regarding airborne transmission of EBOV because of nosocomial transmission events and the discovery of the virus in the human respiratory tract [36, 38] . Given what we know from experimental and epidemiological evidence, airborne transmission is unlikely, yet it is possible that AGMPs could create infectious EBOV-laden aerosols that could lead to nosocomial transmission [8, 44] . Likewise, viruses belonging to the other species of ebolaviruses that are pathogenic in humans, as well as another filovirus, Marburg virus, could share similar transmission properties.

The family of viruses Orthomyxoviridae contains both human and zoonotic viruses, of which the most well-known are influenza viruses. While seasonal flu vaccines protect HCWs against influenza [10] . However, there is variation in the efficiency of human-to-human aerosol transmission of different influenza A viruses. For instance, to date, there were few instances of nosocomial transmission of H7N9 or H5N1, even when protective measures were not used, while there were multiple nosocomial transmission events of pandemic H1N1 and other influenza A virus subtypes [39, [45] [46] [47] [48] [49] . This could be due to variation in infectivity of the virus and tissue tropism, with the pandemic H1N1 preferentially replicating in the human upper respiratory tract and the avian influenza A viruses preferentially replicating in the lower respiratory tract [50, 51] . Therefore, AGMPs have the potential to amplify or open up the route of aerosol transmission for influenza A viruses. Understanding the characteristics of the aerosol transmission of different influenza A viruses and subtypes could help us determine the risk of influenza A viruses for nosocomial transmission due to AGMPs.

Of the viruses in the family Paramyxoviridae, the recently emerged Nipah and Hendra viruses pose a high risk to HCWs performing AGMPs. Both viruses are known to cause respiratory disease in humans, and nosocomial transmission was documented for Nipah virus [42] . Aerosol transmission is one of the suspected routes of transmission for Nipah virus because of evidence from contact tracing and finding the virus in human respiratory secretions [41] . Hendra virus spilled over from horses to humans, and no human-to-human transmission was documented, but the virus was detected in human lungs [43] . Although henipaviruses do not seem to be as contagious through the aerosol route between people as other viruses in their family, such as measles virus, it is possible that AGMPs could contribute to the formation of infectious Nipah-and Hendra-laden aerosols that could cause nosocomial infection.

Given the lack of experimental or epidemiological data on nosocomial virus transmission and AGMPs, current guidelines for infection control are based on the precautionary principle. In order to have a more nuanced understanding of the risks associated with difference AGMPs and viruses, we need more research in both clinical and experimental settings. This type of research could take two different forms, retrospective epidemiological studies or on-site sampling and experimental tests. The former was used to assess the risk of AGMPs and SARS-CoV transmission [11] . However, the quality of retrospective data limits these kinds of studies. Control cases are necessary to rule out other sources of nosocomial transmission besides AGMPs, such as direct patient contact and fomite transmission. Moreover, these studies rely on reporting that may be infrequent and/or unreliable.

Air sampling for viruses during AGMPs performed on patients would provide the most clinically relevant data. Multiple air-sampling techniques for viruses now exist. Researchers can use both solid and liquid impactors to sample and recover aerosolized viruses [52] . Personally worn bioaerosal samplers and stationary room samplers were used to detect influenza A virus RNA in an emergency department [53] . Researchers also used aerosol samplers to determine the amount of influenza A (H1N1) RNA in aerosols in the vicinity of patients while AGMPs were being performed [54] . This allowed the authors to determine which procedures were associated with a higher concentration of viral RNA [54] . In order to determine whether viable virus is present in aerosols, virus isolation could be performed from air samples, and further quantification could occur through titrations or plaque assays [52] . One group used a simulated aerosol chamber to demonstrate that viable influenza virus A could be extracted from surgical masks and N95 respirators [55] . Particle sizers may also be used in experimental settings to characterize the size and dispersal of aerosols. One group used particle sizers to measure the size and travel distance of aerosols from patients who underwent AGMPs, such as nebulizer treatment and NIV [56] . Determining the quantity of viable virus expelled from certain patients during AGMPs could help determine phenomena like super-spreading events, while understanding aerosol characteristics such as particle size could elucidate mechanisms of transmission.

While on-site sampling works for current nosocomial transmission events, we can design experiments to gain prospective knowledge. Procedures such as bronchoscopy and intubation are performed on animal models of the high-risk viral diseases we identified, and air sampling during these procedures could determine whether they are aerosol-generating. Experimentally generating virus-laden aerosols of different sizes and under different environmental conditions could also help determine the risks of different viruses based on their stability in aerosols [57, 58] . Researchers could then create risk models for different viruses based on aersol stability, as well as data on the quantity, concentration, travel distance, and size of aerosols formed during AGMPs.

Multiple environmental factors influence the viability of aerosolized viruses, including relative humidity, temperature, UV radiation, and gas composition of the air [52] . These factors affect viruses differently, and so it is important to consider the environments where emerging viruses exist and where AGMPs are being performed. The aforementioned AGMPs include those that are both ubiquitous, such as CPR or manual ventilation, as well as those that are limited to advanced health-care settings, such as bronchoscopy. The risk of transmission from AGMPs may be very different in a field-based treatment unit than from a tertiary care hospital. Additionally, some health-care settings, such as hospitals with biocontainment units, include additional air-handling systems that can limit aerosol exposure to HCWs [59] . Therefore, the risk of nosocomial transmission via AGMPs varies greatly based on the environment, and this must be considered when designing experiments.

During the 2013-2016 outbreak of EVD, the Centers for Disease Control and Prevention (CDC) updated its guidelines regarding precautions to prevent the transmission of EBOV in health-care settings [60] . The updated guidelines further emphasized proper personal protective equipment (PPE) and isolation when performing AGMPs on EVD patients. Currently, in addition to standard PPE, the CDC recommends the use of eye protection, airborne infection isolation rooms, and N95 or higher respirators when performing AGMPs on patients with VHFs, SARS-CoV, and avian or pandemic influenza A viruses [61] . The CDC made similar recommendations as an interim guidance for MERS-CoV [62] , and we were unable to find additional CDC AGMP guidelines for Nipah virus, Hendra virus, or hantaviruses. More evidence of nosocomial transmission events of these and other viruses due to AGMPs is likely to prompt future guidelines. Therefore, our understanding of the risks associated with AGMPs and nosocomial virus transmission is not static, and we must continue to improve our knowledge to develop appropriate precautions.

The ambiguity of which procedures and viruses require additional protective measures during AGMPs may lead to breaches in protocol. During many of the cited nosocomial transmission events, HCWs did not use proper eye or respiratory protection. Even when aware of the need for respiratory protection, HCWs may mistakenly wear surgical masks or unfitted N95 respirators, which do not provide proper protection. Additionally, HCWs may not have access to approprtiate PPE depending on the health-care environment. Therefore, while determining the risks of certain viruses and procedures is essential, communicating their respective precautions and providing resources is equally important. Likewise, proper patient triage and diagnosis are the first steps to ensuring that precautions are undertaken when performing AGMPs.

Overall, more research and communication about the risks of certain viruses and AGMPs are necessary to resolve the uncertainty surrounding their role in nosocomial virus transmission. Although we identified certain viruses and procedures that could be high risk and should be experimentally or clinically tested, emerging viruses or novel procedures may also play significant roles. If we are to design proactive infection control guidelines and understand the underlying biology of viral transmission, we must conduct collaborative clinical and scientific research on nosocomial virus transmission and AGMPs. 

",0.7311836207916707
Public Understanding of Medical Countermeasures,"Medical countermeasures, including new drugs and vaccines, are necessary to protect the public's health from novel diseases and terrorist threats. Experience with the 2001 anthrax attack and the 2009 H1N1 pandemic suggest that there is limited willingness to accept such drugs and that minority groups may respond differently from others. We conducted 148 intercept interviews in the metropolitan Washington, DC, area, examining 2 hypothetical scenarios: a new respiratory virus and public exposure to high levels of radiation. Findings provide insights into key factors that affect whether diverse members of the public comply with recommended protective actions like taking emergency authorized vaccines. These insights can help improve how public health practitioners communicate during uncertain times.","S ince the 2001 anthrax attacks, federal government agencies, particularly those in the Department of Health and Human Services (HHS), have placed significant emphasis on evaluating and, as needed, producing new drugs, vaccines, and devices that can protect the US public from chemical, biological, radiological, and nuclear (CBRN) threats. Those efforts have included policy changes that enable the Food and Drug Administration (FDA) to quickly evaluate and authorize such medical countermeasures in a declared public health emergency and to communicate this approval, along with partner public health agencies like the Centers for Disease Control and Prevention (CDC). However, there is relatively little literature that explores public perceptions about such medical countermeasures and the mechanism through which they would be distributed.

The Emergency Use Authorization (EUA) authority is a legal mechanism that allows the FDA commissioner to authorize use of medical countermeasures, including unapproved medical products (eg, drug, vaccine, diagnostic device) or unapproved uses of approved medical products, to diagnose, prevent, or treat conditions associated with the emergency. 1, 2 Ongoing research is developing medical countermeasures deployable in public health emergencies, enabling the best emergency medicines and tools to be available when disaster strikes. 3 According to the FDA, 1 about 26 different EUAs were in use to address public health emergencies at the time the study was conducted: Zika virus (6), enterovirus D68 (1), Ebola virus (12) , H7N9 influenza (3), Middle East respiratory syndrome coronavirus (2) , and anthrax (2) . These numbers do not include the archived EUAs for Ebola virus (6) , Middle East respiratory syndrome coronavirus (1) , H1N1 influenza (4) , and anthrax (1) , in addition to past public health disasters without authorized or available EUAs such as the Fukushima nuclear disaster. 4, 5 The use of EUAs does not require informed consent by the consumer but instead relies on a fact sheet that should be highly accessible and must highlight the product's potential risks and benefits.

As a foundation for these actions, the FDA has reasonably good credibility with the US public. In a nationwide Harris Poll of 2,232 US adults surveyed between January 14 and 20, 2015, 92% understood the FDA's roles and responsibilities. 6 Of that 92%, 57% of adults rated the FDA as doing an ''excellent/pretty good'' job, while the remaining 43% rated the FDA as doing an ''only fair/poor'' job. According to the Harris Poll, the trend in the FDA's positive ratings decreased by 5% since the first year of the study in 2000, but an overall 3% increase occurred between 2009 and 2015. This overall increase in positive FDA ratings is supported by other similar surveys. 7 Additionally, critics disagree about whether the FDA is too risky or too risk-averse when making drug approval decisions. 8 In a more recent poll that specifically measured public opinions on the FDA's role in the safe and timely approval of new medical treatments, nearly 6 out of 10 Americans opposed changing safety standards to allow for faster approval of new prescription drugs and medical devices, while roughly 40% favored speedier FDA action. 9 These results provide information on how the public balances their priorities between speed and safety in the approval of new medical treatments. In the context of an emergency, it may suggest greater public concern about EUAs and medical countermeasures. Therefore, in an emergency, in which the FDA would work closely with the CDC and other agencies on decisions and communications about necessary countermeasures, communication with the public will need to clearly articulate the risks and benefits associated with proposed EUAs and medical countermeasures.

Little research has examined public reactions to the use of products available under EUAs and medical countermeasures. Focusing on the 2009 H1N1 influenza pandemic, Quinn and colleagues were the first to examine public acceptance of taking a vaccine or drug under an EUA. 10 Results showed that 63.5% of 1,469 respondents would not accept a new vaccine that had not been approved through the standard process. There was greater willingness to accept Tamiflu, which was an approved drug authorized under EUA for unapproved uses, with 54% indicating willingness to take the drug. In both cases, African Americans were least likely to accept the medical countermeasure. Quinn et al also examined public acceptance of an unapproved EUA drug, Peramivir, an antiviral drug used to treat influenza, in a hypothetical medical crisis situation, finding that 48% of 2,042 respondents indicated that they would probably or definitely take the drug. 11 Needing more information and the use of the term experimental were impediments to acceptance for all groups. An important conclusion from these 2 studies is that trust in the FDA is important for EUA acceptance and that particular care must be taken to ensure that patients and their families receive adequate and understandable information about the medical countermeasure.

The quality of communication and trust in government actions and spokespersons contributes to public acceptance. Strong communication between the FDA and the public and between providers and patients is critical to ensuring that the benefits of EUA products are realized in a time of crisis. 11 To do so requires effective crisis and emergency risk communication.

why the event happened; promote action steps to reduce the threat; express empathy about the threat to human health; express accountability; and express commitment. 18 Other key elements for effective crisis and emergency risk communication include enhancing trust through education efforts with community-based organizations and including targeted risk communication materials that are culturally relevant and appropriate, while paying specific attention to literacy levels. 10 

Based on previous research, trust, uncertainty, and risk perception are critical determinants of public reactions in emergencies. We describe these determinants and explore what we currently know about their impact on the public.

Although trust is known to play an important role in public adherence during a public health emergency, there is substantial interest in more nuanced studies of trust, its components, and its impact on behaviors during one specific emergency, a pandemic. 16, [19] [20] [21] Wray and colleagues determined that trust is an important factor in effectively communicating risk. 21 Furthermore, the public's general lack of trust and confidence in the government's ability to effectively respond in an emergency may be due to the public's perception that the government has not done enough to prepare for an attack and the belief that government officials withhold important information and are sometimes dishonest. 21 Communication during an emergency takes place in the larger context of current trust in government more generally. The Pew Research Center released a comprehensive report in 2015 stating that fewer than 3 in 10 Americans have expressed trust in the federal government in every major national poll conducted since July 2007-the longest period of low trust in government in more than 50 years. 22 In a crisis, the degree to which one trusts the source of an emergency recommendation significantly affects compliance. 23 For example, trust in government agencies was found to be a powerful predictor of vaccine intention and compliance, which could be translated to the context of EUA acceptance in a crisis situation. 16, 24, 25 Additionally, uncertainty, concerns about equity, agency disagreements, and mixed messaging can diminish trust in public health agencies. 26 The more that people trust their government or the communicating official, the better they are able to handle fear in uncertain situations. 27 Most important, the willingness of a member of the public to engage in preventive or emergency behaviors depends on the risk communicator's preexisting organizational reputation, people's past and present relationship experience with the communicating organization, and the credibility of the organization's advice. 25 Without trust, communicating uncertainty in a crisis situation becomes almost impossible.

The best practices in risk and crisis communication acknowledge uncertainty, but empirical research on the intersection between uncertainty, crisis, and communication is limited. This may be because the uncertainty communication literature in relation to crises is sparse. Lachlan and colleagues define uncertainty as ''an inherently uncomfortable state, and information seeking is a common cognitive strategy when that uncertainty is directly related to a perceived threat.'' 27(p39) Uncertainty arises throughout public health emergencies including: who or what caused the emergency; how many lives have been lost and the extent of infrastructure damage; what members of the public can do to protect themselves; and when the emergency will be over. 28 Available research has identified a relationship between public trust levels in emergency information sources and the level of crisis uncertainty experienced, but with so much variation existing among crises, it is difficult to know how to effectively communicate crisisrelated uncertainties to the public. 6, 27, 29 When public health agencies disagree on recommendations, as was the case in the 2001 anthrax attacks, uncertainty and conflicting opinions can create even more confusion. To mitigate this uncertainty about conflicting government guidance, having an open forum can foster trust and enhance people's abilities to make informed decisions, ultimately reducing uncertainty. 17 Additionally, by directly addressing uncertainty early in a crisis, the government may be able to influence the public's acceptance of future changes in understanding and behavioral recommendations. 16 These kinds of situational updates can help ensure effective communication-all while maintaining credibility in public health agencies. 30 

Psychological, social, and cultural processes often affect how the public perceives risk, including heightening or attenuating public perceptions, which can further be affected by the source of the science, media, risk management institution, social organizations, and personal networks. 31 Covello and colleagues described outrage factors, which relate to public reactions to the risk, rather than the technical aspects of a given risk. 30 In addition to trust in institutions and uncertainty, they identified additional outrage factors: controllability, voluntariness, dread, effects on children, media attention, benefits, familiarity, catastrophic potential, human versus natural origin, understanding, and reversibility, among others-all of which can affect how we perceive risk. 6, 17, 30 In the case of the 2001 anthrax attacks, Quinn and colleagues determined that PUBLIC UNDERSTANDING OF MEDICAL COUNTERMEASURES postal workers experienced heightened perceived risk in the beginning of the attacks due to outrage factors, including perceived inequity, lack of control, and other factors in their workplace. 17 Although strong emotions can create substantial barriers to effective communication during a crisis, several studies find that increased perceived risk correlates with greater public adherence to public health recommendations. [31] [32] [33] Communicating effectively with the public about specific threats is the key to successful emergency management and public health, which ultimately helps to mitigate risks, support the implementation of protective actions, and contribute to minimizing negative mental health impacts seen in public health emergencies. 34 

This study provides a critical look at these foundational determinants and the public understanding of medical countermeasures in 2 hypothetical scenarios, described in detail below. Recognizing the lack of familiarity and the novelty of a threat during an emergency, and the complex terminology used by the FDA and the CDC, our first research question is: To what extent are there differences across US racial/ethnic groups and their subpopulations in their understanding of medical countermeasure messages, including FDA regulatory terms relevant to medical countermeasures used in public health emergencies (eg, IND, shelf life, EUA, adjuvants, compassionate use, animal rule, stages of drug or vaccine development)? Our second question examines to what extent did respondents understand and indicate willingness to comply with the recommended countermeasures. Finally, our third question explores what factors influence diverse audiences' informed decision making (eg, risk perception, uncertainty, trust, emotions) and to what extent are there racial and ethnic differences in such decision making?

The research team conducted 148 intercept interviews from December 2015 through June 2016 across the Washington, DC, region at metro stops and in barbershops. Central intercept interviews are ideal for understanding how people immediately process and react to information and why. 35 The team selected metro stops that were located in diverse areas of the Washington, DC, region or that served as hubs connecting multiple metro lines.

The sample included 53 African Americans, 50 Caucasians, and 33 English-speaking Hispanic/Latino Americans. The average participant age was 32 years, ranging from 18 to 83 years old (SD = 15.47) and 35% self-identified as female. * Teams of trained undergraduate and graduate students, under the supervision of a postdoctoral fellow, conducted the interviews. The face-to-face interviews generally lasted 15 to 20 minutes, with interviewers transcribing all comments from subjects by hand, verbatim. Interviews were not recorded because of the sensitivity of the topic and the high level of background noise in the interview locations. Because the interview questions required short answers (ie, a few words to a few sentences), it was possible for interviewers to accurately capture participants' responses.

Interviewers were trained in interview techniques following guidance provided by Lindlof and Taylor. 35 The interview began with a brief verbal consent form explaining the study purpose and the compensation for participants' time, followed by general screening questions. Interviewers were sent to locations based on US 2010 census data indicating racial and ethnic clusters in close proximity to the businesses and metro stations used. Additionally, one location, a local barbershop, is a community partner of the Maryland Center for Health Equity. This shop primarily serves African American and Latino clients. This sampling approach helped prevent bias of interviewers attempting to use mental heuristics to identify what they thought a person from ''X background'' should look like. Interviews were generally conducted in the afternoons and early evenings after work hours, in the hope that participants would be more willing to engage with the research team after work than while they were commuting to work.

After consent and screening questions, participants were read a brief message that informed them about a new treatment they may be recommended to take by the FDA during a public health emergency. One of 2 scenarios was then presented to each participant. One scenario focused on a radiological threat and the other a biological threat. Both scenarios were presented as a 3-page document, mirroring existing FDA content. Page 1 showed a Facebook post from the FDA with a color graphic about the hazard; page 2 gave a brief scenario describing exposure to the hazard; and the final page was a mock-up of an FDA fact sheet about the treatment. When participants were ready, interviewers asked a series of openended and closed-ended questions about the documents. (See supplemental material at www.liebertpub.com/hs.)

The research team developed the interview instrument from literature and previous experience. Demographic * The remaining 12 subjects either provided too little or suspect data for analysis, were of an ethnic or racial background of a sufficiently small group that meaningful comparisons could not be made, or had no dominant racial identity, preferring to identify only as mixed race.

Volume 15, Number 2, 2017 information collected included self-identified gender, race and ethnicity, and age. Other questions focused on understanding what was being asked of participants; the clarity and persuasiveness of the information; the relevance of the information and its importance to self, friends, and family; the likelihood of taking the medication; trust in the government and federal agencies; and emotional response items, modified from prior research. 6, 11, 15, 16 All measures were administered in an oral interview in which researchers recorded responses from a scripted survey. As a result of the nature of the interaction, many measures were single-item in nature, generally measured on 10-point Likert-type scales. A sample item would read, ''On a scale of 1 to 10, where 1 is not at all important and 10 is extremely important, if your family or friends were affected, how important would it be for them to read this information?'' As single-item measures do not lend themselves to traditional reliability measures, the instrument was evaluated by several public health experts external to the project's data collection for face validity. Other items were assessed with open-ended responses in which interviewers recorded verbatim responses from subjects. A sample openended question reads, ''What remaining questions do you have regarding this information?'' We also included items to explore the impact of uncertainty on participants. 36 Participants were asked to identify other information they needed and were asked to define some common words used by the FDA, like experimental, accelerated approval, or adjuvant.

A mixed methods approach was used to evaluate the data collected. Qualitative analysis methods were employed in line with Corbin and Strauss's recommendations for data analysis. 37 Additionally, a computer-assisted semantic analysis assessed the tone of participants' open-ended responses, which interviewers transcribed verbatim during the interviews. Quantitative methodologies like ANOVA, linear regression, and multivariate GLM were used to analyze the closed-ended responses. Where relevant, Variable Inflation Indexes (VIF) were calculated and assessed to ensure multicollinearity was not present. No values above 1.262 or below 1.108 were noted.

The majority of participants reported that they understand that the FDA was asking them to immediately take the recommended vaccine or medication (111 of the 145 completed responses for this question). Comparing those who would take the medication to those who would not (used as an indicator for inadequate comprehension) independent samples t-test indicated that those who would not take the drug (M = 5.13, SD = 3.30) were significantly less confident in their ability to identify the causes of the ailment than those who would take the medication (M = 6.88, SD = 2.54; t(unequal variance) = -2.885, DF = 44.44, p < .006). There were no significant differences between Hispanics and African Americans in certainty, prevention, emotional responses, or likelihood to take the countermeasure. On aggregate, the radiation-based scenario was reported as being significantly easier to understand as to the causes of the illness than the biological threat (F(134,1) = 5.009, p = 0.027, Z 2 = .11). There were no significant differences between groups on understanding of the scenarios (see Table 1 ).

To explore to what extent participants understand language commonly used to communicate about medical countermeasures, we asked participants to listen to a series of words and then tell us immediately what comes to mind. Table 2 displays exemplar responses. Overall, the language seemed challenging to participants. On average, respondents did not know the meaning of a word { more than a tenth of the time (M = 13.63, SD = 12.19). Removal of the word adjuvant, which was an outlier, did not reverse the trend. Respondents still were unable to respond with any definition of a word more than one-tenth of the time (M = 10.56, SD = 6.30). Participants predominantly responded negatively to the words (see Table 2 ). Some participants also expressed confusion about the meaning of the words.

Given the findings about the overall challenging language, we further probed understanding of regulatory terms through affective responses. While participants may not be able to define terms, whether they respond positively or negatively provides insights into their risk information processing.

Linguistic Inquiry and Word Count (LIWC) reads a text-based dataset and compares the individual modules of that text to established categories of words, punctuation, and other components of the documents. The sum of these categories is the LIWC dictionary, which has a tone composite category constructed from subcategories focused on the emotionality of words. This category drills into the positivity and negativity of expression. To understand the positivity or negativity of people's responses to medical countermeasures, the following procedure was undertaken. LIWC reports various standards for different types of text to give a rubric that can be used to compare evaluated data to different types of information. 38 

uniqueness is outside what is normally found in a variety of common information exchange formats-including emotionally charged writings.

The tone value for open-ended responses in this study was a 36.50 mean with a standard deviation of 40. However, when we removed single-word responses, the new value had a mean of 25.20 and a standard deviation of 33.70. LIWC reports that values under 50 are ''generally negative,'' 38 making the discussion of medical countermeasures here strongly negative. To determine just how negative the data collected here are, a series of t-tests were conducted. When one considers that the category for comparison most appropriate for this data is natural speech, as the surveys here were collected in face-to-face interviews, it becomes evident that even with the higher value including single-word responses (2-tailed t-test, t = 11.32, DF = 6327, p < .001), or without the single-word responses (2-tailed t-test, t = 16.18, DF = 6327, p < .001), there is a significant difference between the data here and other forms of expression and a strong negative skew such that people are generally quite negative about emergency medical countermeasures. In other words, people in general are quite negative about the idea of emergency medical countermeasures, significantly beyond what people normally encounter in their daily, nonemergency activities, such as conversations with friends and family and news consumption.

Participants were asked how likely they were to take the medication or vaccine after reading the provided information. On a scale of 1 to 10, where 1 is ''will not take the medication'' and 10 is ''will absolutely take the medication,'' participants on average reported being slightly likely to take the medication or vaccine (M = 5.57; SD = 3.17). Compliance was distributed Of those who indicated that the FDA was asking them to do something else (participants were asked, ''What is the FDA asking you to do?''; responses were categorized as ''take the medication'' or ''other''), most responses reflected comprehension of the FDA's message. For example, par-ticipants stated that the FDA was asking them to ''watch out for the disease,'' ''tell you about a vaccine,'' ''decide whether to take it,'' and ''research more.'' However, a few respondents completely misinterpreted the message. Reasons for complying focused on avoiding negative health outcomes (eg, ''don't want radiation poison,'' ''high cost of not taking it,'' and ''because I don't want to die'').

Another common theme related to complying was trust in the CDC and/or the countermeasure (eg, ''FDA approved,'' ''because I trust vaccines''). Reasons for hesitating to comply When asked what remaining questions participants had about the information provided, answers emphasized a need for more information about the countermeasure. For example, participants asked: ''Why hasn't a definitive list of side effects been found?'' ''How is the medicine tested? Sample size of the trial?'' ''How do they know the medicine works?'' ''Why hasn't it been approved by the FDA?'' Participants also wanted to know more about the emergency. For example, participants asked: ''Where did they first find out someone had radiation poisoning?'' ''Is this a real thing?'' ''What was the cause of the radiation outbreak?'' ''When did this happen?'' Furthermore, some participants had questions about disease transmission, such as ''How do you get a virus?'' and ''Is radiation poisoning contagious?'' Finally, some participants had questions about how the emergency information was disseminated: ''Why didn't they send information over the TV screens or metro?''

A multivariate general linear model was conducted to predict trust in government, the CDC, and the FDA based on racial identity, gender, and type of hazard presented # while allowing for the following covariates: information clarity, likelihood of taking the emergency medication, certainty of disease recognition, disease prevention, self-reported fear, sense of relief, sense of being pleased, and sense of confidence. The analysis indicated significant differences for willingness to take the medication (F(3,109) = 4.391, p = .006, Wilks l À = .892), disease prevention (F(3,109) = 5.567, p = .001, Wilks l À = .867), and racial identity (F(6, 218) = 3.682, p = .002, Wilks l À = .824). Betweensubjects testing confirmed the above relationships (see Table 3 ) and demonstrated good explanatory power for trust in the government (adj. R 2 = .300) and the CDC (adj. R 2 = .371). However, after applying the Bonferroni adjustment, trust in the FDA was not significant. What is interesting is that when treating trust as a dependent variable, we see that racial/ethnic identity is critical for predicting trust in the government overall as well as trust at the organizational level, such as for the CDC (Table 3) . Later, we treat trust as an independent variable to better explore the nature of its role in decision making. When viewing Table 3 , attention should be paid to larger F values and smaller p values, especially the p*.

One-way ANOVAs and Bonferroni tests were conducted to evaluate what, if any, differences existed between racial and ethnic groups. Hispanics and African Americans self-reported higher levels of certainty and prevention, more positive emotional responses for a sense of being pleased, relieved, and confidence about the information, but they were no more likely to take the medication or vaccine than were their Caucasian counterparts (F(133,2) = .251, p = 0.778, Z 2 = <.01). In general, results indicated that Caucasians differed from African Americans and Hispanics. Specifically, Caucasians were the least certain about their ability to recognize an illness and their ability to prevent the illness, and were less pleased, relieved, and confident after being presented with the information. Caucasians had higher trust in the government and the CDC compared to African Americans .000 * P* = Bonferroni adjusted significance level determined by a/n, where N is the number of planned comparisons. 3 The critical value becomes .017.

*indicates a still significant value. # Socioeconomic status was not assessed because of the high proportion of participants who declared they were, or who appeared to be, homeless. Researchers were concerned about negative impacts on response rates regarding questions of household income to participants who were homeless. As such, household income was not included in the instrument or subsequent analyses. Education was measured, but was not included in the final models as the focus of the article was on race/ethnicity. Finally and notably, education was a negative predictor that lowered the explanatory capacity of all models when tested per reviewer suggestion. Table 1 , focus on p values, means, and Z values describe the relative relationship across groups and variables.) A series of linear regressions indicated differences between racial/ethnic groups in vaccine and medicine compliance (DV) as predicted by information clarity (IV), persuasiveness (IV), fear from reading the information (IV), and trust in government (IV). Specifically, decisions made by Caucasians were better explained than for other groups. { To test the difference between regression models, a series of F-ratio tests were conducted (Test F statistic = 2.44, 3.09 > 2.44; therefore, difference is significant). { Findings indicated significant differences between Caucasians and African Americans (Test F statistic = 2.44, 3.09 > 2.44; therefore, difference is significant). The difference between Caucasians and Hispanics was not significant (Test F statistic = 1.83, 1.37 < 1.83; therefore, difference is not significant) ( Table 4) .

When viewing Table 4 , focus on p values and standardized b values is important for understanding the relationship between variables for decision making across groups. Importantly, persuasiveness was the only consistent motivating factor across groups, with the second most common factor, fear, having inconsistent directional implications on different demographics.

Our first research question focused on public understanding of medical countermeasure messages. The majority of participants reported that they understood that the government was asking them to immediately take the recommended vaccine or medication. Results further indicated that those who would not take the drug were significantly less confident in their ability to identify the causes of the ailment than those who would take the medication. On aggregate, the causes of the illness in the radiation-based scenario were reported as being significantly easier to understand than the biological threat. There were no significant differences in self-reported understanding of the scenarios, despite Caucasians' self-reported higher levels of certainty and prevention, more positive emotional responses for a sense of being pleased, relieved, and confident about the information received (see Table 1 ).

While respondents reported they understood the FDA messages, they demonstrated poor understanding of the terminology in the messages. This suggests that future research will need to attend more carefully to examining the contribution of message components to any desired behavioral or attitudinal outcomes rather than a more standard approach of examining the effect of the overall message. It also suggests that the FDA should anticipate that any messages aimed at the general populationand specifically at lower income, immigrant, or minority groups-will require careful attention to literacy levels and English as a second language. Finally, these 

Our second question focused on the extent to which respondents understood and were willing to comply with the recommended countermeasures. Participants on average reported being slightly likely to take the medication or vaccine, but compliance was distributed multi-modally, with the 2 largest clusters of individuals grouping at noncompliance and complete compliance. Prior research also found that participants were somewhat likely to accept a vaccine or drug under EUA. 6 However, findings here about a multi-modal distribution indicate that additional persuasive communication likely is needed during an emergency beyond the initial factsheet to those who are completely noncompliant. Future research is needed to determine what factors may motivate people from noncompliance to compliance. It may be possible to encourage compliance through ensuring that messages cover topics of most interest to members of the public. 13 This study found that those topics include more information about the countermeasures (eg, side effects, medicine testing, approval process) and the emergency itself (eg, cause of the outbreak, when did the emergency begin, is the emergency real). Some participants also wanted more information about disease transmission. Others wanted more information about how emergency information is transmitted. We were surprised that we found no significant difference in perceived risk of the 2 hazards-an infectious disease and a radiation exposure. Typically, risk perception literature might point to a higher perceived risk for the radiation scenario. 39 However, these were hypothetical scenarios, which could differ from real world reactions.

Although the LIWC is less commonly used in public health research, it is a valuable tool for understanding emotional reaction to a medical countermeasure. Our results identified strong negativity toward medical countermeasures, even more than expressive writing about tragic personal events, and a substantial undertone of concern about the use of medical countermeasures. Prior research linked high public anxiety to crisis and emergency risk communication. 15, 16 This study emphasizes just how strong the public's negative emotions are when it comes to risk communication about medical countermeasures. However, it is unclear whether the negativity found in this study is about the countermeasure itself, the public health emergency, the underlying risks the countermeasure seeks to address, or the government itself. This high negativity presents significant challenges for FDA communication about medical countermeasures, suggesting that any campaign will need to be more extensive and require more exposures in order to foster positive attitudes toward the medical counter-measure and its adoption. Although negativity is not unexpected nor necessarily problematic in crisis situations, future research will need to explore where counterproductive negativity resides and the most effective strategies for increasing compliance.

The final research question explored the factors that influence diverse audiences' informed decision making and whether there are racial and ethnic differences in such decision making. In an analysis on compliance as predicted by information clarity, persuasiveness, fear from reading the information, and trust in government, there were significant differences between Caucasians and African Americans. Indeed, decisions made by Caucasians were better explained than for the other groups.

Importantly, persuasiveness was the only consistent motivating factor across groups, with the second most common factor, fear, having inconsistent directional implications on different racial/ethnic groups. From this finding several conclusions can be drawn. First, if a single untailored message is used to communicate about medical countermeasures, messages likely should avoid fear appeals. Second, future research could identify what makes medical countermeasure messages persuasive to different target audiences. Here we found that the 2 least persuasive factors, and thus the worst predictors of compliance, were government trust and information clarity. Recall that trust, when treated as a dependent variable, was predicted by racial/ethnic identity. However, when trust is an independent predictor of positive behavioral outcomes, the relationship becomes even more complex. From this finding we can deduce that medical countermeasure messages cannot rely on government agencies' credibility or public trust, as extensively argued in prior research. 13, 14, 16, 17, 24, 25 These messages also are unlikely to be persuasive if they rely on a clear argument that the medical countermeasure is necessary for public health to motivate compliance. Additional research is needed to identify what discrete message characteristics are most persuasive for motivating public compliance for medical countermeasures. Here we only tested persuasiveness as a global construct and found it was the strongest predictor of compliance.

Furthermore, important racial/ethnic group differences emerged in participants' informed decision making. First, compared to other groups, Caucasians were least certain about their ability to recognize an illness and their ability to prevent an illness. They also were less pleased, relieved, and confident. Second, compared to African Americans, Caucasians had higher trust in the government in general and higher trust in the CDC in particular. It is possible that these findings are related to a socially desirable response effect. People in relatively powerless positions, like minorities or economically repressed individuals, learn and use an adaptive strategy of agreeing with statements in order to maintain a ''good face'' and avoid psychological distress. 40 Socially desirable responses have been long investigated, 41 with recent work noting the common nature of the effect in various powerless groups. 42 Further research is needed to explore whether the differences found here are real differences or differences caused by a socially desirable response effect. Furthermore, future research should explore what other factors might affect how diverse audiences respond to medical countermeasure communication, including economic status and employment.

These findings once again support the limited prior research on racial and ethnic group differences in responding to medical countermeasures 6, 11 and call for additional research and consideration as to how best to tailor communication for different groups while maintaining consistency in government communications about medical countermeasures. This may also suggest that the FDA, CDC, and their partners should continue to work with other national partners whose credibility with diverse communities may help the agencies disseminate messages that can be more trusted. 26 Finally, the findings suggest that a single factsheet for all groups may not be effective and that agencies communicating about medical countermeasures may wish to develop tailored factsheets for different groups.

Like all research, this study has limitations. First, participants were recruited from select metro stops and barbershops in the Washington, DC, metropolitan area, and thus the findings are not generalizable to other areas within or outside of the United States. The high proportion of homeless people who participated in this study further limits the study's transferability to dissimilar contexts. Second, the study examined 2 public health emergencies, and the findings are not generalizable to other public health emergencies. Third, the interviews were conducted only in English. Future research should examine how non-English-speaking members of racial/ ethnic groups respond to medical countermeasures, along with other potential within-group differences such as acculturation level and immigration status. Finally, the study examined 2 hypothetical public health emergencies, and the findings may not apply to real public health emergencies.

In sum, this study adds to the extremely limited body of knowledge on how diverse members of the public respond to medical countermeasures issued during public health emergencies. Key and novel findings include: (1) participants demonstrated poor understanding of terminology commonly used by the FDA and other government agencies to communicate about medical countermeasures;

(2) participants generally were likely to take the recommended drug or vaccine, but compliance was distributed multi-modally, indicating a wide divide among likely compliant and noncompliant publics; (3) source credibility and government trust are less persuasive in motivating public compliance with medical countermeasures than has been found in previous research; (4) message persuasiveness is the strongest motivator for message compliance; (5) racial/ethnic differences emerged in certainty about abilities to recognize an illness, abilities to prevent an illness, and feeling pleased, relieved, and confident; and (6) members of the public have a lot of unanswered questions not typically covered in government factsheets about medical countermeasures.

In terms of risk communication policy, these findings point to a need for more pre-emergency education about medical countermeasures, disease transmission, how to best obtain information during a public health emergency, and the government's role in public health emergencies. The findings also point to a need for more research testing discrete message components to design medical countermeasure messages that are even more persuasive. While much is known about effective emergency risk and crisis communication, we cannot continue to assume that this knowledge base transfers to the specific context of medical countermeasures without additional research.

",0.7311701572703958
Self-contamination during doffing of personal protective equipment by healthcare workers to prevent Ebola transmission,"Background: Healthcare workers (HCWs) use personal protective equipment (PPE) in Ebola virus disease (EVD) situations. However, preventing the contamination of HCWs and the environment during PPE removal crucially requires improved strategies. This study aimed to compare the efficacy of three PPE ensembles, namely, Hospital Authority (HA) Standard Ebola PPE set (PPE1), Dupont Tyvek Model, style 1422A (PPE2), and HA isolation gown for routine patient care and performing aerosol-generating procedures (PPE3) to prevent EVD transmission by measuring the degree of contamination of HCWs and the environment.","Ebola virus disease (EVD) is a severe infectious disease with a high fatality rate of approximately 50% [1] . The virus in the blood and body fluids of a patient can enter another person's body through skin lesions or mucous membranes of the eyes, nose or mouth. Therefore, health care workers (HCWs) should wear protective gear and adopt strict infection control measures when caring for suspected patients [2, 3] .

The EVD outbreak has recently prompted interest in personal protective equipment (PPE) apparel and their use [4] . PPE comprise gowns, gloves, hood, face shield, boots, masks or respirators, which are used to protect HCWs from contact with infectious agents. However, although equipped with protective clothing, HCWs can be contaminated if the PPE apparel is improperly removed [3] . PPE must be removed slowly, deliberately and in the correct sequence to reduce the possibility of self-contamination or exposure to EVD [5] .

Several healthcare organisations developed PPE protocols based on the best locally available components. However, HCWs may be hesitant to use a PPE with no empirical validation [4] . Thus, crucial precautions during PPE removal must be determined to effectively protect HCWs [6] .

The Hospital Authority (HA) of Hong Kong is a statutory body that manages Hong Kong's public hospital services [7] . The HA recommends a PPE ensemble with a neck-to-ankle overall without skin exposure to meet the current recommendations of the Centers for Diseases Control and Prevention (CDC) on the PPE to be used by HCWs during management of patients with confirmed EVD [5] . A waterproof hood and a water-resistant gown were designed to cover the head, neck and body of HCWs. Previous studies [8, 9] reported that a water-resistant gown can provide a good physical barrier via preventing the absorption of liquid contaminants, and thus, conferring protection to HCWs who come in contact with body fluids and secretions of patients with EVD. Our previous study has shown that the barrier protection performance and usability of PPEs are affected by the covered area and ergonomic features [8] . However, systematic data on the risk of self-contamination of different PPE types for Ebola prevention remain lacking. In the present study, three types of PPEs, namely, Hospital Authority Standard Ebola PPE set (PPE1), Dupont Tyvek Model, style 1422A (PPE2) and HA isolation gown for routine patient care and performing aerosol-generating procedures (PPE3), were tested. We compared the PPE ensembles used to prevent EVD transmission in terms of protocol deviations during usage and the degree of contamination during doffing.

This research was an experimental study of one group using multiple comparisons.

A total of 59 HCWs were recruited for this study. The sample size was determined as previously described by Guo et al. [8] , who have examined body-contamination rates and environmental-contamination levels during doffing of different PPE types in accordance with the protocol recommended by the HA. Pregnant females and participants suffering from upper respiratory tract infection and respiratory diseases requiring treatment were excluded.

Among the participants, 57.60% (n = 34) were female with an age range of 21-60 years old. The participants were either registered nurses (n = 50, 84.80%), advanced practicing nurses (n = 4, 6.80%), nursing officers (n = 3, 5.10%) or nurse educators (n = 2, 3.40%). The participants worked in units with high infection risk, including the intensive care unit, emergency department, infection control units and respiratory wards, accounting for 47.50% (n = 28), whilst the rest worked in units with relatively low infection risk (i.e., other clinical units apart from the units mentioned above [n = 31, 52.50%]). All the participants have not yet worn PPE2 because this ensemble is generally not adopted in local hospitals for HCWs. Participants who are currently working in high-infection -risk units have more opportunities to wear PPE1 and PPE3 in daily practice.

Three PPE ensembles were tested (Additional file 1: Figure S1 , Additional file 2: Figure S2 , Additional file 3: Figure S3 , Additional file 4: Figure S4 , Additional file 5: Figure S5 , Additional file 6: Figure S6 ). (1) HA standard Ebola PPE set (PPE1) is a neck-to-ankle overall with an overlying water-resistant gown (Halyard, AAMI Level 4 Liquid Barrier Standard), double and long nitrate gloves, boots, hood, disposable face shield and N95 respirator. A bow was tied at the lateral of the waist to minimise the risk of front contamination. (2) DuPont™ Tyvek®, Model 1422A (PPE2) is commonly adopted in clinical settings to prevent Ebola transmission in countries, such as the US [10, 11] and South Korea [3] . Its protective clothing is also fluid resistant, but the design is a one-piece head-to-ankle overall with a zipper on the front. The whole outfit includes double gloves, boots, disposable face shield and an N95 respirator. A plastic apron was used to cover up the front zipper before use.

(3) PPE3 is a HA isolation gown (Medicom®) for routine patient care and performing aerosol-generating procedures. PPE3 was selected as the reference PPE in the present study. A commercially available pure cotton surgical scrub suit (upper and lower working clothes) was worn inside the individual PPE ensembles during testing. Participants were free to select the appropriate size of gowns and gloves and the known best-fitted respirator model (3 M 1860, 1860s and 1870). Table 1 shows the comparison of the three PPE ensembles.

Data collection was performed in an air-conditioned room with an average temperature of 23°C ± 2°C and a relative humidity of 60% ± 3%. Information about the purpose and procedures of the study was provided to the participants, and written consent was obtained prior to the study.

The participants' socio-demographic data, including gender, age, educational background, specialty, working units and clinical experience, were collected. Each subject received a 30 min briefing from a trained research personnel. The donning and doffing procedures for PPE1 and PPE3 were designed based on the recommendations by the HA, whilst the World Health Organisation (WHO) protocol was followed for PPE2 doffing [12] . On the testing day, the participants watched a video about donning and doffing of the PPE ensembles to familiarise themselves with the procedures. The total duration for donning and doffing of PPEs in the videos was 8.74, 10.68 and 4.59 min for PPE1, PPE2 and PPE3, respectively. Posters related to donning and doffing procedures were pinned up in the venue. Participants with long hair were asked to tie up their mane. Watch and jewellery were removed to minimise the risk of exposure during the procedures. Afterwards, the participants donned and doffed the three PPEs in a random order as decided by a computer-generated randomised table.

The experiment was sequentially conducted in three areas. Area A was the 'clean zone' , where the participants donned the working clothes and clean PPE ensemble in front of a mirror. Area B was the 'preparation zone' , where the PPE of the participants was contaminated with a fluorescent solution (UV GERM Hygiene Spray, Glow Tec Ltd., London, England) that mimics contaminated bodily fluids or secretions spread via contact route. Fluorescent solution was sprayed onto the face shield, two upper limb/ gloves and anterior surfaces of the gown at a distance of 60 cm from the participants, which represents the length of a stethoscope, simulating the usual working distance between a patient and an HCW [8] , with an average of 1.99 g fluorescent solution/per stroke [9] . This value was determined using an electronic analytical balance with a precision of 0.1 g (NJW-3000, Xiangxin, Taipei, Taiwan) via obtaining the average of 20 trial cases. A standard of three strokes was sprayed on each body part with a total of 12 strokes made for each case. The weight of the splash in 1 stroke was 1.99 g in this study when the density of the solution was assumed as 1. Area C is the 'degown and test zone' , wherein the participants were required to doff the PPE. A video camera with a high-density capability was set up for subsequent evaluation of protocol deviations during donning and doffing. Protocol deviations are defined as accidental or noncompliance with the donning and doffing procedures of the PPEs under testing. The performance of the participants was monitored using a checklist. The participants were notified immediately of any deviation being committed. For evaluation, all protocol deviations were recorded. The participants were timed and videotaped whilst donning and doffing the PPE. The timer was stopped when the participants removed the final item of the protective clothing.

During the procedures, hand washing with liquid soap and water was performed according to the procedures of individual PPEs. Immediately after doffing, the participants were scanned for the presence of fluorescent solution. The participants' body (hair and head, face, anterior/ posterior neck, left/right arms, hands or wrists, upper/ lower working clothes and clogs) and the surrounding environment (rubbish bin cover, chair, faucet and sink) were examined using an ultraviolet lamp (CheckPoint, 220-240 V/50 Hz; Glow Tec Ltd., London, England) under dim light. Areas of contamination were counted and measured in square centimetres, and the fluorescent patches of different sizes were counted. Contaminated stains were defined as either small-(≤1cm 2 ), medium-(1cm 2 to <3cm 2 ), large-(≥3cm 2 to 5cm 2 ) or extra-large patch (≥5cm 2 ) [8, 13, 14] . The number of contaminated patches and the time consumed by the participants during donning and doffing were recorded. The environment was thoroughly cleaned, and the areas were rechecked for any contamination with the ultraviolet lamp before the next trial. A 15 min break was given, and water was provided to the participants before testing the next PPE to prevent fatigue, which may affect performance.

All data were analysed with IBM SPSS Statistics 23. Descriptive statistics were used for all independent Tyvek, a brand of flash spun high-density polyethylene fibers, a synthetic material. Apparel with elasticated wrists and ankles.

Water resistant isolation gown (Medicom®)

No zipper; the bow of the water-resistant gown is tied at the lateral side of the waist.

Zipper along the center front of the coverall, covered by a plastic apron. (Table 4 ).

Our study demonstrated considerable self-contamination during doffing. This result raised concerns on pathogen contamination of the skin or clothes of HCWs during PPE removal, which may result in self-inoculation and spread of the virus to patients and other HCWs through contaminated body fluids, including blood, urine, vomitus and stool. Gastrointestinal fluid losses of patients with EVD can be massive (5-10 L/day), droplet dispersion can be greater than 10 ft. and serum viral loads of dying patients with EVD can reach 10 billion copies/mL [15] . Given that no licensed vaccines nor proven effective antiviral therapies for EVD are currently available, PPE plays a crucial role in mitigating the risk of HCW exposure to contaminated body fluids in the care of patients with EVD [16] . The frequent occurrence of self-contamination during PPE doffing is also consistent with the findings of previous studies [6] [7] [8] [13] [14] [15] [16] [17] [18] [19] [20] [21] . The most likely contaminated areas include the neck, hands and fingers, arms and wrists and face [14, 17] . A study conducted in South Korea that estimated the degree of contamination during PPE doffing of HCWs reported that the most vulnerable processes comprise the removal of the respirator, shoe cover and hood [3] .

The current study indicated that contamination of the working clothes occurred less frequently during PPE1 removal than during the removal of PPE2 and PPE3, which may be due to the ergonomic features of individual PPEs under testing. PPE1 consists of a neck-to-ankle outfit and includes a hood covering the neck. PPE2 is a head-to-ankle overall, and is a PPE ensemble frequently used in overseas settings to prevent Ebola transmission [3, 10, 11] . However, PPE removal is complicated because of the head-to-ankle, one-piece design and the elastication in the facial opening, wrists and ankles. HCWs have to take off the hood, unzip the front zipper, remove the overall and outer gloves together and place the trousers on the chair, thereby resulting in easy contamination of the hair and head, hands, working clothes, clogs and chair [17] . The elasticated one-piece coverall hood creates a potential contamination risk because the elastic contracts and pulls the outer part of the hood inwards and towards the participants' hair and neck during removal [22] . The zipper and its flap are also placed along the PPE2 centre front. Therefore, a plastic apron is worn to minimise the risk of body fluids being trapped in the zipper region. Herlihey et al. [22] also reported that when the subjects unzip the coverall, the zipper is stuck in the surrounding fabric or the gloves are stuck to the adhesive of the PPE, while unsealing the flaps covering the zipper results in ripping [22] .

The WHO protocol requires the overall to be removed from top to bottom, followed by the removal of outer gloves whilst pulling the arms out of the sleeves of the overall. Special caution is needed to prevent self-contamination. PPE3 is recommended by HA for routine patient care, in which the neck, lower part of the legs and shoes are incompletely covered. Compared with PPE 1, additional sites, including the neck, arms, working clothes and clogs, were heavily contaminated when wearing PPE3 because it cannot provide adequate protection for HCWs caring for patients with EVD. These contaminated regions may be caused by self-contamination during doffing and contamination when the fluorescent solution was sprayed. Considering the possible underclothing contamination during doffing, the working clothes worn under the PPE ensembles should be frequently changed, especially when contamination is suspected.

During PPE1 or PPE2 doffing, the participants have to wear the clean clogs after removing their boots. However, the clogs may be possibly contaminated by the gowns or the environment in some cases. Hence, using footwear covers is an unideal option. During boot cover removal, HCWs struggle to balance their legs in the air [20] . Shoe covers are also difficult to doff, thereby often requiring assistance and increasing the risk of cross-contamination among workers [22] .

The CDC and WHO recommend the use of double gloving with at least the outer pair possessing an extended cuff that reaches beyond the wrist [6] to decrease the incidence of hand contamination and provide improved protection for HCWs during PPE removal [16, 23] . Although double gloving is incorporated into the protocols for PPE use, the removal of the outer and inner gloves should be done with caution, followed by proper hand hygiene.

Previous studies defined contamination as small fluorescent stains (<1cm 2 ) and large patches (>1cm 2 ) [8, 13, 14] and revealed that fluorescent stain sizes are affected during gown removal [8] . In the present study, a precise estimation of the contaminated regions was performed in terms of the size of patches, that is, small (≤1cm 2 ), medium (1cm 2 to <3cm 2 ), large (≥1cm 2 to 5cm 2 ), or extra large (≥5cm 2 ). The stain sizes can be associated with either inadequate PPE coverage or because of self-contamination during PPE removal. For example, PPE3 cannot fully cover the neck of the participants, which resulted in many small or extra-large patches in the anterior and posterior neck region after spraying of the fluorescent solution onto the face shield and anterior surfaces of the gown. Meanwhile, PPE2 offers a high coverage area during fluorescent solution spraying. However, the hair/head, hands or wrists of the participants were heavily In this study, the older staff showed significantly less small-sized contaminated patches on their working clothes than the younger staff. This result may be due to the additional cautiousness of the older staff, whilst working than the younger staff. However, this finding cannot be generalised because of the low number of older staff (n = 4) who participated in this study.

In addition to self-contamination of HCWs during PPE doffing, environmental contaminations, such as those in the lid of the rubbish bin, chair, faucet and sink, were observed. Human-to-human transmission of EVD is also possible via indirect contact with the environment contaminated with such fluids [24] . The virus can survive for several hours on dry surfaces, such as doorknobs and countertops, to several days at room temperature in body fluids, such as blood [25] ; virus-positive samples were still observed 7 days post-mortem [16] .

Considering that hand hygiene methods using alcohol hand sanitiser fail to remove the fluorescent solution, handwashing with soap and water was performed by the participants. Thus, the sink may be contaminated because of handwashing, and the working clothes that came in contact with the sink may be contaminated because of the repeated handwashing. These results suggested that the height and width of the sink must be at a good working level of HCWs to prevent self-contamination during handwashing. Although alcohol gel is commonly used nowadays during PPE donning/doffing, hand cleansing with soap and water is recommended in cases of visible contamination in various situations, such as when areas are contaminated by vomitus, respiratory secretions, or fecal matter. Discarding used PPEs should be given much attention because of frequent contamination of rubbish bin covers [13] .

Deviations of the donning procedure may increase the risk of self-contamination whilst doffing [20] . Although the participants watched a video on PPE donning and doffing to familiarise themselves with the steps on the day of testing, they can also refer to the posters related to the procedures available in the venue. PPE1 exhibited the lowest overall deviation rate among the three PPE ensembles during doffing (2.95, 9. 48 and 3.52% for PPE1, PPE2 and PPE3, respectively). This finding was expected because of the complexity of PPE2, as described above. The highest deviation rate (58.33%) was observed during the simultaneous removal of the overall and outer gloves in PPE2. As mentioned above, this result agrees with the WHO protocol for doffing overall [12] . This protocol requires the participants to remove the inner gloves, which were covered by the coverall. This procedure is difficult for many participants because they can only 'feel' the inner gloves during removal and cannot see them. Therefore, several participants cannot remove the overall and outer gloves together, or in certain situations, they removed both the inner and outer gloves simultaneously. Apart from the emphasis on regular training for HCWs to perform the procedure smoothly, the doffing procedure should be evaluated to increase its practicability for the users.

Being an international aviation hub, Hong Kong is frequently visited by travellers from all around the world. Moreover, contacts between Mainland China and African [3, 17, 26, 27] . On the average, participants used the longest time for donning and doffing PPE2, followed by PPE1 and PPE3. A study reported that HCWs may show poor compliance with proper PPE removal protocol because of time constraints [28] . The most time-consuming processes include removing the shoe covers, putting on gloves and removing the outer gloves [3] . Thus, a short duration of doffing PPE is important for the faultless completion of removal protocol. Familiarisation of the HCWs with the procedures via frequent training and improved ergonomic features is necessary for the PPE design not only to prevent HCWs from self-contamination but also to shorten PPE donning and doffing time.

This study has several limitations. Results showed the possibility of Hawthorne effect because the participants knew that they were being observed during the study. Therefore, compared with previous findings, real-life contamination rates or protocol deviations can be poorer than the findings presented in this study. Result generalisation is limited given the small number of participants, most of which are relatively young staff. A larger sample size with a better balance of staff seniority than that of the present study should be considered in future trials to evaluate whether clinical experiences influence the PPE performance.

The fluorescent solution used in this study was intended to mimic the mechanical effects of body fluids or secretions of patients with EVD. Although this method can provide a visualisation of contamination, it cannot provide information about viral load and shows no response to alcohol-based hand sanitiser, similar to EVD. Future studies may consider using surrogate viruses, such as MS2 (a surrogate for non-enveloped human viruses) and bacteriophage ϕ6 (a surrogate for enveloped viruses such as Ebola) to allow researchers to obtain quantitative data on virus transfer events and risks to HCWs without exposing participants to the risk of infection [16, 19, 23] .

The ethical approval was obtained from the human subject ethics subcommittee of the university [HSEARS20160605001]. All participants provided written informed consent prior to participation in the study.

Were taken from each person in the photos.

",0.7301365701276776
Clinical Data on Hospital Environmental Hygiene Monitoring and Medical Staff Protection during the Coronavirus Disease 2019 2 Outbreak,46,"The outbreak of COVID-19 in Wuhan in December 2019 has led to a serious public 69 health event [1] [2] [3] . Meanwhile, the outbreak of this novel virus has placed 70 unprecedented challenges on hospital environmental hygiene. The occurrence of 71 medical staff-associated infections is closely related to long-lived pathogens in the 72 hospital environment [4, 5] . Thus, it is crucial to assess hospital environmental hygiene 73 to understand the most important environmental issues for controlling the spread of 74 COVID-19 in hospitals. The Chinese government quickly adopted quarantine 75 measures for confirmed and suspected patients to restrain the spread of the 76 pandemic [6] . Comprehensive monitoring of hospital environmental hygiene during the 77 outbreak of the pandemic is conducive to the refinement of hospital infection control 78 [5, 7] . It also increases understanding of the environmental challenges corresponding to 79 the reemergence of COVID-19 or similar viruses. Therefore, it is of great significance 80 to ensure the safety of medical treatment and the quality of hospital infection control 81 through the monitoring of environmental hygiene. According to a report from the The environmental monitoring methods referenced the hospital sanitation standards 106 (GB15982-2012). All air was collected by two methods: natural sedimentation [9] and 107 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint . https://doi.org/10.1101/2020.02.25.20028043 doi: medRxiv preprint a microbial air sampler (MAS-100 ECO), for which the stream of air was set to 108 exactly 100 liters/minute (Merck, Germany) [10] . Environmental surfaces were 109 sampled using swabs. is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint . https://doi.org/10.1101/2020.02.25.20028043 doi: medRxiv preprint were centrifuged at 12000 g for 10 min and incubated for 30 min, the supernatant was 130 discarded, 50 µL of RNA release agent was added to the tube, and the sample was 131 mixed and incubated for 10 min. (Tables 2 and 3 ). We found that the virus was present both on surfaces and in the air. 148 The total positive rate was 1.26% (2/158). The positive rates of the air and surface 149 samples were 3.57% (1/28) and 0.77% (1/130), respectively. 150 Table 2 : Air monitoring results for the different risk areas 151 . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint . CC-BY-NC-ND 4.0 International license It is made available under a is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

(which was not peer-reviewed) The copyright holder for this preprint . https://doi.org/10.1101/2020.02.25.20028043 doi: medRxiv preprint

",0.7285231629675637
Evaluation of the survivability of MS2 viral aerosols deposited on filtering face piece respirator samples incorporating antimicrobial technologies,"Background: Respiratory protective devices exposed to pathogenic microorganisms present a potential source of transmission of infection during handling. In this study, the efficacy of 4 antimicrobial respirators to decontaminate MS2, a surrogate for pathogenic viruses, was evaluated and compared with control N95 filtering face piece respirators, which did not contain any known antimicrobial components. Methods: MS2 containing droplet nuclei were generated using a Collison nebulizer and loaded onto respirator coupons at a face velocity of 13.2 cm/seconds for 30 minutes. The coupons were incubated at 2 different temperature and relative humidity (RH) conditions and analyzed for viable MS2 at different time intervals. Results: Results showed that log 10 reduction of MS2 was not statistically significant (P . .05) between the control and antimicrobial respirator coupons, when stored at 228C and 30% RH up to 20 hours. Coupons from 1 of the 4 antimicrobial respirators showed an average MS2 log 10 reduction of 3.7 at 378C and 80% RH for 4 hours, which was statistically significant (P # .05) compared with coupons from the control respirators. Conclusion: Results from this study suggest that MS2 virus decontamination efficacy of antimicrobial respirators is dependent on the antimicrobial agent and storage conditions.","Experts predict that an influenza pandemic is likely to occur, and, as a result, the federal government has instituted a number of initiatives to enhance pandemic influenza planning efforts. To minimize and delay the spread of an influenza pandemic, a number of nonpharmaceutical interventions that would be readily available at the onset of a pandemic are recommended by government agencies and nongovernment organizations. The use of respiratory protective devices is one intervention designed to reduce exposure to infectious influenza aerosols. National Institute for Occupational Safety and Health (NIOSH)-approved respirators are also recommended for protection of health care workers against several other pathogenic microorganisms including Mycobacterium tuberculosis, severe acute respiratory syndrome, Bacillus anthracis, and others. 1, 2 Respirators contaminated by influenza or other infectious aerosol can become a potential source of transmission. Fomites are inanimate objects capable of aiding the dissemination of infectious organisms. Viruses can contaminate and survive in the inanimate environment, persist after drying, and become reaerosolized. [3] [4] [5] Use of respirators in infected environments can potentially result in the deposition of infectious agents on the surface as well as inner layers of the respirator that may cause its conversion to a fomite, thereby becoming a vehicle for direct or indirect transmission. Prior studies have demonstrated the survival of various infectious microorganisms (eg, bacteria [6] [7] [8] and fungi 9 ) on respirators, but little work has been done with respect to contamination of respirators by viruses. 10 These prior studies indicate that some bacteria and fungi can survive on respirator filters, but their survivability is dependent on the specific organism, filter material, and storage conditions.

Other studies have focused on handling contaminated devices. For example, a recent study addressed the issue of virus transmission among health care workers handling contaminated personal protective equipment (PPE). 11 In that study, respirators and other PPE including goggles, gowns, and gloves donned by volunteers were intentionally contaminated with MS2. Participants performed tasks such as measuring blood pressure on a mannequin and then removed PPE according to standard protocol. One-handed removal of respirator and goggle resulted in approximately 1-to 2-log 10 of MS2 (most probable number) transfer to hands. Removal of other PPE including gowns and gloves showed higher levels of contamination. Similarly, cross contamination of viruses by surface to hand 12 and hand to hand 13 have been reported. Handling rhinovirus-contaminated coffee cups and plastic tiles caused transmission of virus in some test subjects. 12 Similarly, hand-to-hand contact was shown to transfer rhinovirus infection more effectively than aerosols produced by cough, sneeze, and loud talk or prolonged exposure. 13 In another study, influenza A and B viruses survived for 24 to 48 hours on hard, nonporous surfaces such as stainless steel and plastics but only survived for ,8 to 12 hours on cloth, paper, and tissues. 14 The study also demonstrated that influenza A could be transferred from the environmental surfaces to the hands and survives long enough for self-inoculation to occur.

Recent reports from the Institute of Medicine related to the reusability of face masks and PPE for health care workers have recommended research on ''alternative materials, including bioactive fibers'' 15 and ''chemical treatments to impart biocidal properties to PPE to enhance their protection capability and extend their useful life.'' 16 It is speculated that a respirator or surgical mask incorporating a proven antimicrobial substance (hereafter referred to as an ''antimicrobial respirator'') could potentially kill or prevent the growth of microorganisms such as bacteria, fungi, or viruses that have been deposited on the respirator surface or trapped in the filter media. 17 With increasing media reports on influenza pandemic planning issues, there is a growing interest in the area of antimicrobial respirators. Several manufacturers have produced prototype and commercially available filtering face piece respirators (FFRs) and other types of face masks claiming antimicrobial efficacy for a wide range of microorganisms.

However, there is limited knowledge on the efficacy of antimicrobial respirators to reduce fomite potential. Among the studies reported in the literature, many employed iodine-treated filters to investigate microorganism viable removal efficiency using different techniques. [18] [19] [20] [21] [22] These studies investigated whether antimicrobial filter media was able to reduce the viable virus particles passing through the filter media by inactivation in addition to particle capture. This was done by comparing the number of viable virus particles that pass through the control and antimicrobial filters. The conclusion from these studies 18, 20, 21 was that viruses and bacteria were inactivated by iodine at the filter level. Interestingly, a recent study indicated that iodine released from the filter and dissolved in the virus extraction medium may also contribute to virus inactivation. 23 The authors also showed that the filter materials contained many MS2 particles after extraction, indicating the possibility for a fomite. Thus, it is of great scientific interest to focus on the question of whether the potential for the respirators to act as a fomite was reduced or not. Some limited studies have been reported on the survivability of spores, bacteria, and fungi on antimicrobial air filter media, 18 electrospun nanofiber webs, 24 activated carbon fibers, 25 military fabrics, 26 and surgical masks 17 after storage. These studies found that the storage conditions (time, temperature, humidity) played an important role in the efficacy of the antimicrobial agent. However, it is difficult to make generalizations across studies because they all used different test methods and each study evaluated only a single antimicrobial agent. Furthermore, none of these studies reported data on the viability of viral aerosols applied to the devices. Manufacturers often provide unpublished antimicrobial efficacy data obtained from third-party test laboratories using different test protocols for their products. For example, in some testing, a small volume of the microorganism suspension is applied on to filter swatches, whereas other tests use the whole respirator/ mask to load bioaerosol particles. There is a general need for a standardized protocol based on realistic test conditions for assessing the efficacy of antimicrobial respirators.

In this study, coupons from antimicrobial respirators from 4 manufacturers representing 4 different antimicrobial agents were loaded with aerosolized MS2 virus containing droplet nuclei, incubated for different time periods, and, then, viable virus particles were recovered and enumerated. The Bio-Aerosol Respirator Test System used in this study was designed to deliver a representative challenge mimicking the airborne transmission of virus containing droplet nuclei. 27 After coupon loading, the antimicrobial effect of the test samples was evaluated at 2 different storage conditions, namely 228C and 30% relative humidity (RH) and 378C and 80% RH and, then, assaying the viable viruses trapped on respirators at different time points. It was hypothesized that relatively fewer viable MS2 would be recovered from the coupons obtained from the antimicrobial respirators compared with the control N95 FFR coupons containing no known antimicrobial components. Furthermore, it was hypothesized that storage conditions would affect the ability of the antimicrobial respirator to render the virus inactive.

Antimicrobial FFRs (respirators) from 4 manufacturers were obtained ( Table 1 ). One of them was a NIOSH-approved P95 particulate respirator. The other 3 were not NIOSH-approved respirators. All manufacturers claimed incorporating antimicrobial treatments in their respirators, but none of them were approved by any US regulatory agencies for their antimicrobial efficacy. One manufacturer embedded silver-copper based antimicrobial technology throughout the fiber on the outer layer of the mask. Similarly, EnvizO 3 -Shield technology (oxygen species) was incorporated on the outer layer of the mask by another manufacturer. In other cases, TiO 2 coated filtering layers were placed beneath the outer layer of the mask or iodine-activated resin incorporated filtering layer was positioned within the respirator. The presence of antimicrobial agents on the straps and sealing surfaces is not known. NIOSH-approved FFRs, containing no known antimicrobial components, from a single manufacturer were used as the control.

Circular coupons (5 cm 2 ) were cut from NIOSH-approved N95 FFRs (control) and 4 antimicrobial respirators as described previously. 27 The coupons were not sterilized prior to loading but were handled with sterile forceps to minimize chemical and biologic contamination. Two N95 FFR and 4 antimicrobial FFR coupons (excised from at least 2 different FFRs) were placed into separate test specimen holders and attached to the sample ports of the Bio-Aerosol Respirator Test System (BARTS) for MS2 loading. 27 For controls, N95 FFR coupons were used instead of soluble gelatin filters used in some studies to enumerate viable microorganisms.

Coliphage MS2 virus was selected as a surrogate virus for this study because it is nonpathogenic and easy to handle in a biosafety level 1 laboratory. MS2 is a nonenveloped virus and less sensitive to decontamination agents. 28 Many researchers have used MS2 as a stringent test case to assess the antimicrobial efficacy of respiratory materials. 21, 22 Previous studies also showed that MS2 survival was better at low RH conditions than at high RH. 29, 30 Escherichia coli and MS2 cultures

The bacterium Escherichia coli was used as a host for the virus MS2. E coli 15597 and MS2 virus (ATCC 15597-B1) were obtained from American Type Culture Collection (ATCC). E coli was replicated in ATCC medium 271 (www.atcc.org) as described previously. 27 Briefly, 20 mL E coli stock was inoculated in 10 mL medium 271 and incubated overnight at 378C in an incubator. An aliquot (1 mL) of overnight culture of E coli was added to 100 mL medium 271 and incubated at 378C with shaking at 100 rpm for 5 hours.

MS2 virus was replicated using E coli (ATCC 15597) as the host bacterium. An aliquot (1 mL) of the 5-hour culture of E coli was used to inoculate 30 mL of ATCC medium 271 in a conical flask. After 2.5 hours, 1.5 mL of MS2 stock was added to the conical flask containing E coli and incubated overnight at 378C. The medium 271 containing replicated MS2 was centrifuged at 7100g for 30 minutes at 48C (IEC Multi RF, Thermo Electron Corporation, Waltham, MA). The supernatant containing MS2 was filtered through a 0.22-micron millipore filter (Fisherbrand, Fisher Scientific Company, Pittsburgh, PA). The virus suspension (approximately 10 11 plaque-forming units (pfu)/mL) was stored in a 50-mL plastic conical tube (Falcon; Becton Dickinson. Franklin Lakes, NJ) at 48C.

Droplet nuclei containing MS2 virus were generated using a Collison nebulizer (BGI Inc., Waltham, MA) and loaded onto 6 respirator coupons using the Bio-Aerosol Respirator Test System. 27 The count median diameter of the particles loaded onto coupons was measured using a scanning mobility particle sizer (SMPS, Model 3080; TSI, Inc., Shoreview, MN) and found to be 32 nm with a corresponding mass median diameter of 141 nm. 27 Briefly, 23 mL of MS2 (approximately 10 5 -10 8 pfu/mL) suspension in 1% ATCC medium 271 was added to a Collison nebulizer glass jar. Compressed filtered air was passed into the nebulizer (20 psi, 10 L/ min) to aerosolize MS2 along with the other constituents of the media. The proteins and other components of the aerosolization fluid serve as a protective factor, which has been shown to neutralize or serve a physical barrier to reduce the effectiveness of some antimicrobial agents. 27 The aerosol was diluted with high-efficiency particulate air filtered air (13 psi, 50 L/min) downstream of the nebulizer outlet. The diluted aerosol entered the aerosol chamber and was allowed to equilibrate. After 5 minutes, MS2 aerosol was passed in parallel through 6 specimen holders, each containing a test coupon fixed in the sample port at 4 L/min flow rate (face velocity: 13.2 cm/seconds [s]) regulated by vacuum lines. MS2 droplet nuclei were allowed to deposit throughout the 6 respirator coupons for 30 minutes. Coupons from the controls and the antimicrobial respirator being tested were randomly assigned to a particular sample port (holder) to avoid any bias caused by port location within the Bio-Aerosol Respirator Test System chamber.

In each experiment, 4 coupons from the N95 FFR control and 2 coupons from one of the antimicrobial respirators were loaded with MS2. Of the 4 control coupons, 2 were used to determine MS2 loading levels. The remaining 2 control and 2 antimicrobial coupons were stored under controlled environmental conditions.

MS2 loaded respirator coupons were stored at 2 different environmental conditions in a Caron 6010 Environmental Test Chamber (Caron Products & Services Inc; Marietta, OH) for different time intervals. In the first set of experiments, MS2 loaded coupons were stored at 228C and 30% RH, and virus particles recovered at 0, 8, and 20 hours were enumerated. A second set of coupons were loaded with MS2 and stored at 378C and 80% RH for 0, 2, and 4 hours, and viable MS2 from coupons were enumerated. The experiment was repeated 3 times for each storage time point for each environmental condition. MS2 recovery from coupons and enumeration of viable virus particles were accomplished by the methods described below.

Following storage or in the case of the loading level control coupons immediately following loading, each respirator coupon was resuspended in 10 mL ATCC medium 271 in a 50 mL conical tube and vortexed at the highest setting for 2 minutes. The coupons were removed and discarded. The supernatant containing virus was enumerated for viable MS2 by a plaque assay as described below.

MS2 virus was enumerated using a single agar layer method as described previously. 26 Each MS2 virus suspension was serially diluted. Briefly, 8 mL of medium 271 with 0.5% agar was placed into each glass culture tube and incubated at 478C in a water bath. E coli (0.5 mL) at log phase, and 100 mL or 1 mL of the MS2 suspension was added to the culture tubes. The soft agar containing E coli and MS2 was poured into an empty Petri plate and mixed by swirling. The plates were allowed to harden at room temperature and placed in an incubator at 378C and 30% RH overnight. MS2 plaques were counted manually, and those containing 30 to 300 pfu were recorded.

Experiments were conducted to determine the toxicity of iodine species released in to the recovery medium. Three coupons from both the N95 control and antimicrobial respirator C were stored at 378C and 80% RH. After 4 hours, each coupon was placed in a separate 50-mL conical tube containing 10 mL of 271B medium and approximately 10 6 MS2 pfu. Each sample containing a coupon, 271B medium, and virus was vortexed for 1 minute at the highest setting. The coupon was removed, and the recovery medium was allowed to stand for 3 hours at room temperature before a plaque assay was performed.

Log reduction of MS2 (ie, decontamination efficacy) for each antimicrobial respirator coupon and the control N95 FFR respirator coupon was calculated by dividing the average number of viable MS2 virus recovered from the loading level coupons by the number of viable MS2 virus recovered from each control N95 FFR respirator or each antimicrobial respirator coupon. These values were then converted to log 10 units, and the average and the standard deviations of the 6 replicates reported. Statistical analysis comparing the average log 10 values for the coupons from 4 antimicrobial respirators and the coupons from the control N95 FFR respirator was done with a series of t tests for each of the 4 antimicrobial respirator models, time points, and storage conditions using Sigma Stat (Jandel Corporation, Systat Software Inc., San Jose, CA). Table 2 shows that MS2 loading levels for the coupons from the N95 FFR controls and the 4 antimicrobial respirators were consistent. The relative standard deviations for the loading levels of the N95 control and antimicrobial respirators were within reasonable limits.

The first set of MS2 loaded coupons was stored at 228C and 30% RH. MS2 survival was measured at 0, 8, and 20 hours. Figure 1 shows that the log 10 reduction of MS2 increased with time up to 20 hours for all respirator coupons except antimicrobial respirator D. All respirator coupons showed ,1-log 10 reduction even at 20 hours storage time. There was no significant difference (P . .05) in the log 10 reduction of MS2 between the control N95 FFR and the antimicrobial respirator coupons (A, B, C, and D) at 8 or at 20 hours.

In the second set of experiments, MS2 loaded coupons were stored at 378C and 80% RH, and the log 10 reduction was measured at 0, 2, and 4 hours. Figure 2 shows that the log 10 reduction of MS2 increased with time for all the antimicrobial respirators and N95 FFR controls tested. MS2 reductions for coupons from antimicrobial respirators A and B were approximately 2log 10 units and were not significantly (P . .05) different from the control N95 FFR. At the same time, coupons from antimicrobial respirator C showed 3.7-log 10 reduction of MS2 at 4 hours of storage, which was significantly (P # .05) different from the N95 FFR control coupons. Coupons from antimicrobial respirator D were unable to be tested at the high RH conditions.

Coupons from antimicrobial respirator C were compared with N95 control respirators for MS2 reduction at the 2 different storage conditions (Figs 1 and 2) . MS2 reduction was approximately 2-log 10 and 3.7-log 10 units (4 hours) at 378C and 80% RH for coupons from the control and antimicrobial respirator C, respectively. However, coupons from both the N95 FFR control and the antimicrobial respirators showed approximately ,1-log 10 MS2 reduction (8 hours) at 228C and 30% RH. To determine whether MS2 inactivation of respirator C was due to iodine released from respirator coupon, a control toxicity assay was performed. MS2 survival was found to be 6.27 6 0.03 and 6.23 6 0.10 log 10 units for the N95 control and respirator C, respectively, with no significant difference between them.

The respirators employed in the study were manufactured with different antimicrobial technologies and tested at 2 different storage conditions. Other studies on the effectiveness of antimicrobial devices 18,26 have used similar storage conditions. Furthermore, the low temperature, low RH setting (228C and 30% RH) can be considered based loosely on room temperature conditions found in health care facilities. Some anecdotal evidence suggests that health care facilities in North America maintain RH below 40%. 31 The high temperature, high RH setting (378C and 80%) can be considered similar to the warm and moist conditions found in the breathing zone of a respirator user.

In general, the results from this study (Figs 1 and 2 ) showed that the MS2 decontamination efficacy of the antimicrobial respirator coupons was dependent on the storage conditions and the type of antimicrobial agent. MS2 loaded antimicrobial respirator coupons at 378C and 80% RH showed significantly higher log 10 reductions for only 1 antimicrobial respirator (respirator C) compared with control N95 FFR coupons. At the same time, coupons from all 4 antimicrobial respirators tested in the study showed no significant difference in MS2 reduction compared with the coupons from the control N95 FFRs at 228C and 30% RH for up to 20 hours.

As expected, high temperature and RH were found to decrease MS2 survival in the N95 FFR control coupons. Log 10 reduction of MS2 was ,1 at 228C and 30% RH (20 hours) compared with ;2 or more at 378C and 80% RH (4 hours) for all the respirators tested in the study. The effect of RH and temperature on viable MS2 loaded onto respirator coupons is consistent with previous studies that showed MS2 aerosol survival was higher at 20% RH than at 80% RH. 29, 30 In addition, MS2 is less sensitive to commonly used antimicrobial agents compared with enveloped viruses. 30 This is partly because MS2 is a nonenveloped virus, which lacks a lipid bilayer envelope. In general, nonenveloped viruses are hardier and able to survive longer than enveloped viruses 32 such as influenza.

Coupons from respirator C containing iodinated fibers tested in this study showed a significant increase in the log 10 reduction of MS2 at 378C and 80% RH, but not at 228C and 30% RH, suggesting that the storage condition is a critical factor for the survival of MS2 and activity of this antimicrobial agent. MS2 virus reduction of the iodinated respirator coupon increased significantly at 378C and 80% RH (4 hours, Fig 2) as did the control N95 respirator coupons, consistent with previous studies that showed MS2 inactivation was maximal at 75% RH and less at 20% and 30% RH. 29, 30 However, coupons from antimicrobial respirator C were significantly different from the control N95 respirator coupons only for the tests done at 378C and 80% RH, suggesting that the MS2 decontamination effect of the coupons from the iodinated respirator may be increased due to the high RH and high temperature employed in our study. Previous studies suggested that MS2 remained in the solid particle state at low RH, and inactivation of MS2 in the solid particle state was less compared with the levels in the fluid conditions. 29, 30 This may be a reason why many types of viruses including influenza virus are maximally stable at a low RH environment. 33, 34 High temperature and RH also increased MS2 log 10 reduction compared with the low temperature and RH condition regardless of the respirator type. Taken together, the results suggest that iodine and high temperature and RH synergistically inactivated MS2 because this effect was not found for coupons from any of the antimicrobial respirators. Only coupons from antimicrobial respirator C showed a significant reduction of MS2 compared with the control coupons at 378C and 80% RH. The results are in agreement with a previous study that investigated the decontamination efficacy of iodine-treated filter media against bacterial spores. 18 Furthermore, comparing the results for respirator C to the controls for both storage conditions lends support to inactivation occurring on the respirator filter sample as opposed to in the extraction medium. This conclusion is further supported by the results from the toxicity assay showing that iodine released into the recovery medium was not directly interfering with the survival of MS2. This indicates that MS2 inactivation had occurred prior to the recovery of virus from coupons. However, one recent study reported that MS2 inactivation can occur in the extraction medium after removal of the virus from an iodinecoated filter. 23 Further studies in this area are needed. Iodine inactivation of microorganisms appears to involve different mechanisms. In one study, iodine inactivation of poliovirus was mediated by disruption of the capsid protein coat. 35 Results from a recent study employing isoelectric focusing of iodinated MS2 proteins suggested that iodine inactivation involved conformational changes to the protein coat. 36 Some studies showed that iodine reaction with sulfhydryl groups caused inactivation of enzymes. 37 Iodine also appears to cause nucleic acids damage in bacterial species previously. 38 One of the antimicrobial respirators (D) employed an ultraviolet (UV)-A (310 nm -400 nm), lamp (4W; emission maximum, 380 nm) to activate TiO 2 on the respirator placed approximately 15 cm distance. Coupons from this antimicrobial respirator showed no ability to render MS2 inactive more than the control at either storage condition. However, bacterial culture on Petri dish coated with TiO 2 when exposed to a UV-A light showed a significant increase in inactivation compared with the controls. 39, 40 This may be partly explained by the difference in the intensity of the UV-A on the target organism and other exposure conditions. In our study, access for UV-A light to the TiO 2 layer as well as free radicals to MS2 deposited in different layers 26 are limiting factors unlike the direct UV-A exposure to bacterial cultures in other studies. 39, 40 Alternately, the hydroxyl and oxygen radicals produced in the experimental setup were not sufficient enough to inactivate MS2. On the other hand, MS2 was shown to be highly sensitive to direct UV-C light (254 nm) compared with other virus types. 41, 42 This may be attributed to the difference in the wavelengths of the UV light used in those experiments. It is well-known that free radicals damage cells through mechanisms involving oxidative stress and damage of DNA 40 as well as RNA. 43 The absence of a significant inactivation of MS2 by UV-A and TiO 2 obtained in our study suggests the production of insufficient levels of free radicals to cause significant RNA damage.

Other reactive oxygen molecules such as ozone are also excellent antimicrobial agents. Results for MS2 loaded antimicrobial respirator test coupons with incorporated EnvizO 3 -Shield technology (B) did not show any statistically significant inactivation compared with the controls at either storage condition. However, in other studies, ozone gas was found to inactivate aerosolized bacteriophages including MS2, phi 6, and T7. 44 Tseng et al introduced bacteriophage aerosols generated by a Collison nebulizer and ozone produced from a generator into a chamber in a parallel manner. 44 Samples were removed from the chamber before and after ozone treatment, and viable bacteriophages were enumerated using a 1-stage Anderson sampler. Ozone at concentrations ,10 ppm showed a significant inactivation in 15 seconds. In general, higher inactivation levels were obtained for the bacteriophages at 85% RH compared with the levels at 50% RH. The effect of ozone was attributed to its interaction with capsid protein of the virus. 44 The difference in the sensitivity of MS2 to ozone between the 2 studies may partly be attributed to the different forms of oxygen species in the experimental procedures. The failure to obtain inactivation of MS2 using EnvizO 3 -Shield technology engineered respirators in our study may be explained by the different form of oxygen species as well as to the insufficient levels of oxygen species available for MS2 inactivation throughout the layers of the respirator coupon under the exposure conditions.

Heavy metals including copper, silver, and mercury have been also used for antimicrobial applications.

Results from this study showed that coupons from respirators engineered with silver-copper based antimicrobial technology (A) did not increase the log 10 reduction of MS2 virus significantly at either storage condition. Other studies on antimicrobial surgical masks coated with a mixture of silver nitrate and titanium dioxide nanoparticles 17 and silver particle coated activated carbon fibers 24 demonstrated good antimicrobial properties against E coli and other bacteria, with complete inactivation occurring after 24 hours and 10 minutes of storage, respectively. In a previous report, MS2 virus resuspended in phosphate-buffered saline showed a slight (0.28 log 10 ) reduction upon exposure to silver (0.1 mg/L) for 130 minutes. 45 Silver also enhanced the effect of UV light-induced inactivation in a synergistic manner. Silver ion generated reactive oxygen species was found to inactivate microorganisms. 46 Similarly, silver nitrate inactivation of herpes simplex virus types 1 and 2 at concentrations 30 mmol/L was reported. 47 Another mechanism of heavy metals including silver is believed to be mediated by their ability to bind sulfhydryl groups of capsid proteins of viruses. 47 In this study, coupons from the respirator containing silver-copper based antimicrobial technology failed to show a statistically significant decontamination of MS2 compared with the controls. This may be partly explained by the difference in the test methodologies. In our study, MS2 was resuspended in 1% ATCC medium 271 for aerosolization and then in 100% medium 271 for subsequent procedures. The aerosol particles undergo desiccation to become droplet nuclei. The protein contained in the aerosol medium is concentrated through a reduction in volume of the aerosolized particles. 27 The high concentration of protein in the droplet nuclei can diminish the decontamination effect of silver-copper based antimicrobial technology on MS2 by competing/interfering with potential binding to sites including the capsid protein sulfhydryl groups of the virus. High concentration of many proteins is also known to inhibit the effect of antimicrobial agents including bleach 27 and other agents. 30 Contaminated respirators may act as fomites during handling (eg, donning or doffing the respirator) or reuse. In this study, a viral challenge was loaded by passing MS2 containing droplet nuclei with a mass median diameter of 141 nm through the respirator coupons. Under the conditions used in this study and a previous study, varying levels of MS2 virus may be deposited in different layers of the respirator. 27 However, significant amounts of virus containing droplet nuclei remain on the surface for cross contamination. MS2 virus loaded as droplet nuclei were found to survive for an extended period of time (.20 hours)-even for the antimicrobial respirators-at room temperature and low RH, consistent with other studies investigating the survivability of viruses on other porous substrates. 5 In practice, other studies have shown that MS2 can readily transfer from respirator to hand. 11 Because viruses can generally survive for extended periods of time and the time between respirator donning/doffing events can be short, the antimicrobial agent needs to be able to reduce viability within hours and preferably within minutes. If an effective antimicrobial respirator could be developed and validated, it may be possible to reduce the risks of handling of contaminated respirators because the likelihood of transferring active virus particles to the hand would be greatly diminished.

This study has some limitations such as the selection of surrogate virus, procedure for loading respirator coupons with the aerosolized MS2 containing droplet nuclei, and storage conditions. The antimicrobial respirators tested in the study were all previously evaluated by their respective manufacturers using different microorganisms and test protocols. MS2 virus selected for this study is a nonenveloped virus resistant to many antimicrobial agents. Thus, it is not surprising that only 1 antimicrobial respirator was somewhat effective at reducing MS2 viability at 1 storage condition. The decontamination efficacy of antimicrobial respirators is likely to be different for enveloped viruses such as influenza, which are more likely to be rendered inactive by many antimicrobial agents. In this study, MS2 resuspended in 1% ATCC medium 271 was aerosolized and loaded onto coupons. Different results could be obtained using a medium containing different concentration of proteins, leading to higher or lower levels of protective factor. In this study, respirator coupons with MS2 were stored at only 2 different storage conditions. The antimicrobial effect of respirator coupons at additional storage conditions may be necessary to confirm the results.

Coupons from the 4 antimicrobial respirators tested in the study showed consistent MS2 loading levels similar to coupons from the N95 FFR controls. Coupons from all 4 antimicrobial respirators showed ,1-log reduction of MS2 at 228C and 30% RH storage condition up to 20 hours, which was not significantly different from the N95 control FFR coupons. At 378C and 80% RH, the iodinated antimicrobial respirator coupons showed 3.7-log 10 reduction of MS2 at 4 hours, which was significantly higher than the control. The viability of MS2 from the coupons from the other antimicrobial respirators was not significantly different from the controls. In general, high temperature and RH decreased MS2 log 10 survivability of control and antimicrobial respirators. The decontamination effect seen with the coupons excised from the iodinated respirators suggests that iodine and high temperature and RH synergistically inactivated MS2. The results suggest that the ability for antimicrobial respirators to reduce the amount of viable MS2 is dependent on the storage conditions and the antimicrobial agent used. Further improvements in antimicrobial respirators are necessary to assure that they reduce the risks of handling after contamination.

",0.7278273310895917
Occupational exposure to infection risk and use of personal protective equipment by emergency medical personnel in the Republic of Korea,"Background: Few studies of occupational exposure (OE) to infectious risk among emergency medical personnel (EMP) or their use of personal protective equipment (PPE) have been conducted in the Republic of Korea. Objective: To determine the status of OE to infectious risks and use of PPE. Methods: A convenience sample of 907 questionnaires (response rate, 88.5%) was collected from September 1, 2014, to January 31, 2015, in 5 metropolitan Korean cities. Results: Respiratory diseases were significantly prevalent (44.5%) and influenza (29.5%) was the most frequently reported illness. An exposure report was only made in 19.5% of cases. The primary reason for OE report noncompletion was the complexity of the reporting process (23.9%). A total of 365 participants reported OE to body fluids and blood (40.2%) with needlestick injury being the most frequent OE type (17.6%). More than 5 years of job experience (47.8%) (P < .001) and region (city) (P = .003) significantly increased OE to body fluids and blood. Puncture-resistant containers (71.9%) and disposable gloves (68.9%) were used. Job training and education on infection risks and use of PPE were not uniformly conducted (77.5%). Anxiety about OE to risk of infection from patients was common among EMP (63.2%). Conclusions: EMP experienced significant OE to infectious risk and use PPE inadequately. Surveillance and education programs regarding OE should be developed.","Prehospital health care providers, particularly emergency medical personnel (EMP), including emergency medical technicians (EMTs) and nurses, are exposed through their occupation to bloodborne pathogens, including hepatitis B virus, hepatitis C virus, HIV, and various other infectious hazards. 1, 2 Unlike the characteristics of occupational exposure among other hospital health care workers (HCWs), 3, 4 EMP are exposed more frequently to respiratory diseases 2 and blood via skin exposure rather than percutaneous exposure such as needlestick injury. [5] [6] [7] Thus, standard precautions, including the adequate use of personal protective equipment (PPE), are strongly recommended for EMP. 8, 9 Blood exposure risks are more than doubled (odds ratio, 2.4) when not using appropriate PPE. 5 In the Republic of Korea (hereafter Korea), prehospital health care providers as EMPs were mainly EMTs and nurses. As providers of prehospital emergency medical services (EMS), EMTs have 2 levels of certification: basic emergency medical technician (EMT-B) and paramedic (EMT-P). There are college-or university-based education systems for EMT-P and special authorized training organizations for EMT-B accredited by the Ministry of Health and Welfare, in which individuals are required to pass both written and practical examinations for the national EMS certification. Most EMTs are stationed at fire stations as prehospital EMS providers, whereas others are often positioned in the emergency department of hospitals. The duties of EMT-P include invasive medical treatments (including endotracheal intubation, initiating intravenous access, and injecting intravenous glucose for hypoglycemic shock), administering medication (sublingual nitroglycerin and bronchodilator for asthma attack), and performing cardiopulmonary resuscitation and ventilator support. The duties of EMT-B are limited to noninvasive procedures and basic life support. 10 Few studies of occupational exposure to infectious risk among EMP and prehospital HCWs providing EMS and their adherence to the use of PPE in prehospital environments have been conducted in Korea. Moreover, during the Middle East respiratory syndrome outbreak from May 20-July 28, 2015, it was reported that 2 Middle East respiratory syndrome cases were caused by occupational exposure among EMP. 11 EMP should be included in occupational exposure prevention systems and systematically protected from occupational infectious risks as are other HCWs. 3 To achieve this, the status of their occupational exposure to infectious risk and infection prevention measures should be investigated and quantified, providing basic information of the status of occupational exposures to develop effective occupational exposure prevention systems for EMP. Therefore, this study was conducted to determine the current status of occupational exposures among EMP to infectious risks and their use of PPE in prehospital environments, and to provide basic information about the occupational exposures of EMPs for the development of occupational exposure prevention programs.

A survey was conducted in the 5 largest and most representative metropolitan cities in Korea (referred to as locations A-E). A selfreport, anonymous questionnaire about occupational exposure to infectious risks, use of PPE, and job training was administered to EMPs. The questionnaire took approximately 15 minutes to complete. The study was approved by the Institutional Review Board at Daejeon University.

The 2-part questionnaire was developed based on literature reviews. 4, 6, 12, 13 Part I consisted of 12 questions assessing participants' demographic characteristics and the general characteristics of their workplaces, a majority of which were emergency fire stations. Part II included 18 questions measuring the extent of occupational exposure to infectious risks, job training and education, the use of PPE, and their concerns and suggestions. Detailed follow-up questions were used in several categories. Specific occupational exposure information included exposure experiences, types of occupational exposure, types of infectious diseases to which they were exposed, and previous reports of occupational exposure (if occupational exposure was not reported, the reasons for this were also collected). Specific PPE use information included use of PPE as a standard precaution (ie, wearing gloves and other PPE), manipulation of needles, use of sharps containers, types of PPE used during the transfer of patients with respiratory symptoms, and types of PPE used during transfer of patients with bleeding. Specific information about job training and educational experiences within the past year was collected, including the status of their training in occupational exposure to infection risks, use of PPE, and postexposure management (PEM). Information about participants' major concerns and suggestions about occupational exposure and prevention was also collected. The questionnaire was revised to increase validity following a pilot study of expert EMPs. The final questionnaire included 30 questions.

The Cronbach's alpha value of the final questionnaire was 0.788 (Cronbach's alpha based on standardized items, 0.782), indicating a good internal consistency.

The sample size required for a statistical power of 0.80, an effect size of 0.15, and an α < 0.05 was N = 277. A total of 1,025 questionnaires were mailed to prehospital EMPs working at fire stations (questionnaire packages with cover letters were distributed with a return envelope). Participation was both voluntary and anonymous. Between the study period September 1, 2014-January 31, 2015, a total of 907 questionnaires (response rate, 88.5%) were collected via mail. Only EMPs indicating that they provide EMS as prehospital workers were enrolled in the study, excluding EMP working in hospital emergency departments.

The Kolmogorov-Smirnov test was used to analyze data distribution and normality. Descriptive statistics and multiple response analysis were used. Categorical variables were compared using the χ 2 test. Statistical analyses were performed using SPSS version 20.0 for windows (IBM-SPSS Inc, Armonk, NY). P < .05 was considered statistically significant.

The average age of EMPs was 34.8 ± 15.0 years. Men (n = 795; 87.7%) were dominant in this sample. The job categories of the study population included EMTs (n = 646; 71.3%), nurses (n = 60; 6.6%), and nonspecified EMPs (n = 201; 22.1%). The educational attainment among the study population was college (or university) education (n = 808; 89.1%), followed by high school diploma (n = 87; 9.6%) and master's degree (n = 12; 1.3%). The median years at current workplace was ≤5 years (n = 551; 60.7%), followed by 6-10 years (n = 211; 23.3%) and ≥11 years (n = 145; 16.0%). Participation according to national representation was 181 from location A (20.0%), 241 from location B (26.6%), 134 from location C (14.8%), 108 from location D (11.9%), and 243 from location E (26.8%).

Types of occupational exposure to infectious risks and management of sharps are listed in Table 1 . Respiratory diseases were the most common occupational exposure (44.5%); influenza (29.5%), specifically, was the illness to which participants were most frequently exposed, followed by diarrhea, hepatitis, and HIV/AIDS. An exposure report was completed in only 19.5% of occupational exposure cases. The reasons for unreported exposure were the complexity of the process (23.9%), followed by being too busy, finding report completion annoying, and concerns regarding promotion and salary consequences.

A total of 365 participants reported occupational exposure to body fluids and blood (40.2%). Percutaneous exposures (ie, needlestick injury) were the most frequent route of exposure (17.6%), followed by mucocutaneous exposure and nonspecified. Needle and sharps manipulation were practiced by 34.9% of subjects. In particular, recapping (22.6%) and needle manipulation (10.9%) were the most frequently used procedures. Puncture-resistant containers for the disposal of needles and sharps were used by 71.9% (Table 1) .

Length of experience on the job and city of employment had a statistically significant association with occupational exposure to body fluids and blood. Those with more than 5 years of job experience (170 out of 356; 47.8%) had significantly higher (P < .001) occupational exposure to body fluids and blood than those with 5 years or less (195 out of 551; 35.4%) experience. The rate of occupational exposures to body fluids and blood were 39.8% at location A (72 out of 181), 32.8% at location B (79 out of 241), 53.7% at location C (72 out of 134), 41.7% at location D (45 out of 108), and 39.9% at location E (97 out of 243). The differences among the cities were statistically significant (P < .003).

The most commonly used PPE item was disposable gloves (68.9%), followed by masks, face protectors, eye protectors, gowns, and caps. The proportion of participants who reported always using PPE when making contact with patients was 83.9%. The reasons for not always using PPE were no need to wear (16.4%), followed by annoying, insufficient supply, busy, and worry about making patients uncomfortable.

When transferring patients with respiratory symptoms, the most commonly used PPE was a mask (93.8%). When transferring trauma patients with bleeding, the most commonly used PPE was a mask (86.0%), followed by gloves, goggles, gowns, face shields, caps, and shoe covers ( Table 2) .

Among the participants, 703 (77.5%) had received on-the-job training and education about occupational exposure to infectious risks, use of PPE, and PEM within the past 12 months. Topics on bloodborne and infection-risk pathogens included the transmission route of bloodborne pathogens (n = 596; 65.7%), occupational blood exposures and other potential exposure pathogens (n = 573; 65.3%), infectious diseases and bloodborne diseases (n = 443; 47.7%), and the effects, safety, benefits, and cost of hepatitis B vaccine (390; 43.0%). Topics on PPE included how to select PPE (n = 623; 68.7%), how to use, operate, wear, and remove PPE as well as disinfection and disposal of PPE (n = 593; 65.4%). Topics on PEM included PEM of blood or other potential pathogen exposures (n = 532; 58.5%), process of report and postexposure treatments (n = 522; 57.6%), and information about evaluating the risk of exposure and PEM (n = 423; 46.6%). Training on topics of disinfection included ambulances and other materials (n = 662; 73.0%) and infection prevention planning for fire stations (n = 574; 63.3%).

Regarding the question, ""What most concerns you related to occupational exposure to infection risks?"" participants showed highest concern about infection from patient exposure (63.2%), followed by contamination of uniforms (11.0%), and other concerns. Regarding the question, ""What are your comments or suggestions to prevent occupational exposures?"" the majority of participants suggested a need for greater support for employee health (36.5%), followed by educational support that provides information on decontamination processes (27.8%) and other (Table 3) .

The majority of participants (EMPs as prehospital EMS providers) were men, as in a previous study. 6 Respiratory diseases were a major occupational exposure infectious risk, with influenza being the disease to which EMPs were most frequently exposed. This finding corresponds with previous study results. El Sayed et al 2 reported that EMPs were exposed most frequently to respiratory diseases such as possible meningitis (32.9%) followed by tuberculosis (17.1%) and viral respiratory infections (15.4%). An occupational exposure report was completed by a small proportion of participants and the proportion of unreported cases of exposure was easily correctable with adequate education and information about occupational exposure infection reporting systems.

Datta et al 1 reported that first responders have high rates of exposure to blood via skin contact (174 per 100 person-years) but few via mucosal or needlestick exposures (1 and 0 per 100 personyears, respectively). Marcus et al 6 reported that individual EMS workers have a mean of 1.25 blood contacts, including 0.02 percutaneous exposures, per 100 patients attended. Unlike the previous studies, 1,6 our study revealed that EMP percutaneous exposure in Korea (ie, needlestick injury) was the most frequent route of occupational exposure to body fluids and blood. This result was likely related to the high rate of recapping and manipulation of needles, and to participants' dissatisfaction with their use of punctureresistant containers for disposal of needles and sharps (shown in Table 1 ). Therefore, job training and education about blood and body fluid exposure prevention should be encouraged. In addition, supplies of sharps containers should be increased in all areas of the work environment.

In this study, the magnitude and the types of occupational exposure could be measured only in an approximate manner. The first step toward establishing effective programs for occupational exposure prevention is accurately and practically quantifying the size and characteristics of occupational exposure, which should include measuring the incidence density. This will be valuable for determining the effects of subsequent occupational exposure prevention programs. Next, an occupational exposure infectious risk surveillance system should be developed.

Occupational exposure to body fluids and blood was higher among EMP with more than 5 years of job experience and in specific regions. Exposure prevention education and training should be targeted toward senior EMP, with regular support and ongoing training throughout their careers. Furthermore, national occupational exposure prevention programs should be developed to address regional disparities.

Adherence to the use of PPE as a standard precaution was low. Among the types of PPE, gloves were used most frequently. However, percentage of EMPs wearing gloves was lower than in previous studies (where 2.4% 12 and 17% 13 did not wear gloves). Our participants' use of PPE did not satisfy the standards. 9,14 Therefore, additional efforts should be made to improve adherence to routine PPE use. When EMPs transfer patients with respiratory symptoms and open trauma with bleeding, the most commonly used PPE was a mask; however, the use of other PPE was very low. Therefore, job training and education about PPE use according to transmission-based and exposure types should be included to decrease exposure risk. Leiss 5 reported that the risk of nonintact skin blood exposure and not being provided with appropriate PPE increased the risk of occupational exposure (odds ratio, 2.4; 95% confidence interval, 1.6-3.3).

In this study, on-the-job education and training status did not satisfy the recommendations. 9,14 Therefore, job training and education should be developed to improve the use of PPE and prevent occupational exposure more effectively. Moreover, because EMP reported being preoccupied with worry about infection transmission risk, adequate information about occupational exposure and prevention should be delivered.

This study had some limitations inherent to self-report studies; for example, recall bias of occupational blood exposures, using a gross measurement of occupational exposure, and a lack of incidence density assessment.

However, this study measured the status of occupational infection control programs among EMP in terms of types of occupational exposure to infectious risks and use of PPE among a nationally representative sample working in 5 large cities in Korea.

Significant occupational exposure risks, the lack of adherence to PPE protocols among EMPs, and on-the-job training was reported. Therefore, the following should be developed: surveillance programs for occupational exposure, employee health programs for occupational exposure prevention and PEM, and effective job training and education programs for PPE use and occupational exposure prevention. 

",0.7274190310888031
Assessment of healthcare worker protocol deviations and self-contamination during personal protective equipment donning and doffing Recommended Citation,objective. To evaluate healthcare worker (HCW) risk of self-contamination when donning and doffing personal protective equipment (PPE) using fluorescence and MS2 bacteriophage.,"Personal protective equipment (PPE) is used in healthcare settings to protect healthcare workers (HCWs) from exposure to pathogens and to prevent the spread of pathogens to other patients. Proper use of PPE is crucial when HCWs care for patients with highly pathogenic organisms, such as the Ebola virus. To date, studies on PPE effectiveness are uncommon, small, and potentially out of date, and many evaluate PPE types no longer in use. 1 The 2014-2016 Ebola virus disease (EVD) outbreak revealed the need for better empirical data regarding best practices to safely don and doff PPE. [1] [2] [3] [4] [5] Although EVD is a high-visibility, high-impact disease, HCWS are much more likely to encounter pathogens on a daily basis, including methicillin-resistant Staphylococcus aureus (MRSA), vancomycin-resistant Enterococcus, Clostridium difficile, and carbapenem-resistant Enterobacteriaceae. The primary forms of PPE used to protect HCWs and other patients against these important hospital-associated pathogens are associated with contact precautions (CP), which includes gown and gloves. Few data exist regarding whether HCWs follow guidelines for donning and doffing CP PPE and their risk of self-contamination. 6, 7 One of the primary challenges when designing studies to evaluate PPE or donning/doffing procedures is determining how to model pathogen transmission. The most commonly used surrogate marker for the presence of pathogens is fluorescence, and it can be delivered in a variety of forms: powder, liquid, lotion, etc. [7] [8] [9] [10] [11] [12] [13] [14] Fluorescent markers are inexpensive, easy to use, and because the read out is visual, they can provide immediate feedback to HCWs; however, fluorescence may not be an appropriate surrogate for contamination with infectious viral particles. 10 An alternate marker for viral infection is the MS2 bacteriophage, a single-strand RNA bacteriophage that is a biosafety level 1 agent and nonpathogenic to humans. MS2 has been used previously in several studies of PPE transmission and/or disinfection, 10, 11, 15, 16 in a long-term-care facility, 17 a hotel, 18 and an office. 19 Commercial preparations of MS2 are expensive and require significant laboratory expertise to use, but they may provide a more accurate surrogate marker for how pathogens spread in the environment than fluorescence. 3, 10 The purpose of this study was to evaluate HCW risk of selfcontamination when donning and doffing EVD PPE and CP PPE using MS2 bacteriophage and a fluorescent marker as surrogates for pathogen transmission. The frequencies and types of protocol deviations that occurred were documented, and associations between HCW self-contamination after doffing and particular doffing protocol deviations or HCW characteristics were determined. 

Two sets of HCWs were enrolled in this study. EVD PPE HCWs were enrolled during EVD PPE practice sessions and included respiratory therapists, nurses, infection control preventionists, and critical care physicians. CP PPE HCWs were recruited from BJH hospital wards during their normal shifts and included nurses, patient care technicians, and physicians. HCWs were interviewed regarding demographics and years of service, previous PPE training; HCW height and weight were measured and body mass index (BMI) was calculated.

During EVD PPE training sessions, the donning and doffing processes were aided by a donning/doffing assistant and a trained observer who instructed HCWs step-by-step as per CDC guidelines. 20 HCWs using CP PPE were not given donning or doffing instructions; they were encouraged to proceed according to their usual practices.

After consent, participants were scanned for baseline fluorescence using an UV-A light. Any areas of fluorescence detected were cleaned and noted. Next, HCWs were instructed to don the PPE. Upon completion, HCWs were instructed to close their eyes, and the MS2 bacteriophage and fluorescent marker were applied to HCW palms, abdomens, and ankles (for EVD PPE HCWs) or palms and abdomens (for CP PPE HCWs). Dummy applications of molecular grade water were applied to HCW shoulders. After donning, EVD PPE HCWs practiced various EVD patient care activities before doffing. CP PPE HCWs proceeded directly to doffing. The order and technique used to don and doff the PPE were videotaped and recorded. Immediately after doffing, the participant was scanned for fluorescence. Any areas of fluorescence detected were photographed and sampled utilizing a flocked swab in universal transport medium (Quidel, San Diego, CA). HCW hands (1 swab for both hands), coat sleeves or wrist, and peri-orbital/nasal/oral areas were swabbed regardless of fluorescence.

Donning and doffing videos were reviewed and protocol deviations were recorded. A second reviewer randomly reviewed selected videos to ensure accuracy. Protocol deviations were grouped into categories based on site and the donning/doffing procedural step during which they occurred (ie, glove removal and hand hygiene; PAPR and hood removal). Proper CP PPE and EVD PPE removal sequence were based on recommendations from the CDC 6,20 and on written protocols used by the BJH infection prevention team.

A commercially available preparation of MS2 (Zeptometrix, Buffalo, NY), supplied as a stock solution of 1.0 × 10 9 PFU/mL, was utilized as a surrogate for viral transmission. This substance was diluted to a 1:10 solution in viral transport medium for a working solution of 1.0 × 10 8 PFU/mL. GloGerm Mist liquid was selected as the fluorescent marker (GloGerm, Moab, UT). A mixture of 100 µL GloGerm Mist liquid with 0.5 mL working solution MS2 was applied to each contamination site. This combination was tested, and there was no negative effect on MS2 recovery and detection. The mixture of GloGerm liquid and MS2 was drawn into a 3-mL syringe with a needleless, Luer-lock tip (Becton Dickinson, Franklin Lakes, NJ). The syringe was attached to a pediatric intranasal laryngeal mask airway mucosal atomization device (LMA MAD Nasal, Teleflex, Westmeath, Ireland). Syringes were not reused.

MS2 RNA was extracted utilizing a QIAamp viral RNA mini kit (Qiagen, Valencia, CA). MS2 detection was performed using reverse-transcriptase polymerase chain reaction (PCR) using previously described primers 21 and the Cepheid Smart Cycler with QuantiTect Probe RT-PCR Kit (Qiagen, Valencia, CA). A positive control with MS2 RNA, and a negative control of PCR water was included in each run. The cycle threshold for all positive results was recorded.

The primary outcomes of interest were the presence and frequency of MS2 and/or fluorescent contamination on the HCW after removal of PPE. The secondary endpoints were the correlations of the presence of contamination with the number of lapses in PPE doffing techniques, years of experience, type of PPE, and BMI. Univariate analyses were performed, and P ≤ .05 was considered significant. We used χ 2 or univariate logistic regression for categorical variables, and we used the Mann-Whitney test for continuous variables. Analyses were performed with SPSS version 24 (IBM, Armonk, NY).

In total, 36 HCWs were enrolled in the study: 18 with EVD PPE and 18 with CP PPE. Most HCWs were nurses: 78% of EVD PPE HCWs and 61% of CP PPE HCWs (Table 1) . EVD PPE HCWs were significantly older than CP PPE HCWs (median age, 38 vs 28.5 years; P = .02), and there was a trend toward greater years of service among the EVD PPE HCWs (median years of service, 8.5 vs 5.25; P = .10).

Donning videos were available for review for 15 EVD PPE HCWs (Table 2 ). Donning videos for the remaining 3 HCWs were unavailable because the HCW was donning simultaneously while another HCW was being recorded. Overall, 27% of EVD PPE HCWs made at least 1 donning protocol deviation, compared with 50% of CP PPE HCWs (P = .28). Protocol deviations occurred most often in the gloves and hand-hygiene steps (20% of EVD PPE HCWs and 33% of CP PPE HCWs).

All EVD PPE HCWs had at least 1 doffing protocol deviation, versus 67% of CP PPE HCWs (P = .02) ( Table 2 ).

The median number of doffing protocol deviations was greater among EVD PPE HCWs (median, 4 vs 1 among CP PPE HCWs). Moreover, 15 protocol deviations during EVD PPE doffing were committed by the doffing assistant or trained observer: 6 during gown or apron removal, 2 involving hand hygiene, 2 during hood removal, 2 during boot-cover removal, 1 during PAPR removal, and 2 miscellaneous deviations. Among EVD PPE HCWs, the unique doffing step with the greatest number of protocol deviations was boot-cover removal: 78% of HCWs made at least 1 protocol deviation doffing boot covers. The doffing step category with the greatest number of HCWs that committed at least 1 protocol deviation (in both PPE types) was gown/apron removal (83% of EVD PPE HCWs; 50% of CP PPE HCWs), followed by glove removal/hand hygiene (67% of EVD PPE HCWs; 39% of CP PPE HCWs).

Overall, fluorescence was detected on 8 EVD PPE HCWs (44%) and 5 CP PPE HCWs (28%) (P = .49), and 21 unique HCW sites fluoresced. The most common site of fluorescence was HCW hands: 6 among EVD PPE HCWs and 5 among CP PPE HCWs (Table 3) . Of the 125 samples tested for MS2, 5 were positive (4%). MS2 was recovered from 2 EVD PPE HCWs (11%) and 3 CP PPE HCWs (17%). The 2 EVD PPE HCW sites from which MS2 was recovered were from an alcohol foam pump in the doffing area and an HCW's hands ( Table 3) . The 3 CP PPE HCW sites from which MS2 was recovered were from the face of 1 HCW and from the sleeves/ wrist of 2 HCWs. Among the 5 sites positive for MS2, 2 (40%) also fluoresced. The association between fluorescence and doffing protocol deviations is given in Table 4 . There were no significant differences in detection of any fluorescence by protocol deviation type, although there was a trend toward significance with boot-cover removal (100% of EVD PPE HCWs with fluorescence detected had a boot cover protocol deviation, versus 60% of EVD PPE HCWs without fluorescence; P = .09).

Among EVD PPE HCWs, there was no significant difference in the median number of donning or doffing protocol deviations by years of service (data not shown). There were no significant differences in fluorescence and/or MS2 detection between BMI categories (ie, normal, overweight, or obese; data not shown). There also were no significant differences in the frequencies of types of donning or doffing protocol deviations by BMI (data not shown).

Proper use of PPE is essential to protecting patients and HCWs from infectious diseases. However, our results indicate that protocol deviations were common in both donning and doffing. Notably, we found that 100% of EVD PPE HCWs committed at least 1 protocol deviation during doffing, and 27% while donning. This finding is not surprising, given the complexity of EVD PPE, and it is consistent with previous studies. 8, 14, 22 In a study involving 120 students, Casalino et al 22 found that EVD PPE doffing errors occurred even after a 3-phase training program. While protocol deviations while doffing are a major focus for HCW self-contamination, donning deviations, such as an improperly tied gown (a deviation we observed) may increase the future risk of selfcontamination while doffing. Furthermore, we demonstrated that not all protocol deviations were committed by the donning and doffing HCW. For example, several doffing assistants touched the inside of HCW gowns when undoing the neck Velcro, and trained observers occasionally failed to instruct HCWs to perform hand hygiene. While previous studies have evaluated HCW protocol deviations while doffing PPE, few have evaluated the role of other HCWs in the doffing process. This is an important area for future investigation. Boot-cover removal was particularly problematic. HCWs received varied instructions on the specifics of the boot-cover removal process. HCWs struggled to balance their legs in the air or rest their legs on their scrubs without contaminating themselves, and left-handed HCWs struggled to use righthanded scissors. All 3 left-handed EVD PPE HCWs made ≥1 protocol deviation during boot-cover removal. Many HCWs touched their scrubs with their shoes or gown, both potentially contaminated, during boot-cover removal and shoe disinfection. Herlihey et al 23 also reported difficulties with shoe-cover removal. HCWs caring for EVD patients may be exposed to large amounts of environmental contamination; 3 thus, this component of EVD PPE removal may benefit from process improvement. Notably, the recommendations for boot-cover removal have changed since this study was performed. At BJH, the revised process doffs gowns before boot covers, eliminates the use of scissors, and allows HCWs to keep their feet on the ground. We hypothesize that these changes will decrease protocol deviations, but more studies are needed to confirm this. Hand hygiene and glove removal protocol deviations were common during doffing of both EVD and CP PPE (67% and 39% of HCWs made ≥1 error, respectively). During EVD PPE doffing, common protocol deviations included touching outer gloves with inner gloved hands and touching the outside of gloves with bare hands. Herlihey et al 23 reported similar challenges doffing multiple pairs of gloves. Casanova et al 15 compared HCW self-contamination after doffing PPE with single gloves versus double gloves, using MS2 as a marker, and found that although double gloves reduced viral transfer, MS2 was still recovered from the hands of 23% of HCWs after doffing. These results may not be directly comparable to our study because it is unclear whether those HCWs performed hand hygiene after doffing. Regardless, hand hygiene and glove removal are high-risk opportunities for HCW self-contamination. For both the EVD and CP groups, we found fluorescence on HCW hands more often than any other site. HCWs may benefit from targeted training in the correct method for glove removal during EVD PPE doffing, and training should reinforce the fact that gloves are not a substitute for proper hand hygiene.

Measures to reduce HCW self-contamination rates include training and maintenance of training. Several previous studies have suggested that, regardless of PPE type, increased training and access to published donning/doffing guidelines improves HCWs' ability to don and doff PPE without protocol deviation. 7, 12, 22, 24, 25 All EVD PPE HCWs in our study previously had received formal EVD PPE training. By contrast, although 72% of CP PPE HCWs reported having previous training in PPE donning/doffing, this training was often informal, ""on the job"" training from other HCWs. Similarly, Turnberg et al 26 reported that 15%-40% of HCWs had not received PPE training during the previous 12 months, and John et al 27 found that ""on the job"" training was the most common method of PPE training for HCWs. Despite the comparative simplicity of the CP PPE donning/doffing process, only half of the HCWs were able to don PPE without protocol deviation, and only approximately onethird were able to doff PPE without protocol deviation. Common CP PPE doffing protocol deviations included touching the front of the gown with bare hands or allowing the contaminated gown to brush against scrubs while disposing. Possibly, HCWs may be unaware that specific guidelines exist for donning/doffing CP precautions. 6 Beam et al 8 demonstrated that simple exposure to a poster showing the correct donning/doffing sequence may not be enough to improve HCW practices. Tomas et al 7 found that a training session on CP PPE doffing techniques led to a significant decrease in HCW self-contamination. Formal, targeted interventions or education programs may be needed to improve CP PPE donning/doffing practices.

We were unable to demonstrate clear superiority of either surrogate marker. Fluorescence was detected more frequently than MS2. MS2 was not detected from most sites with fluorescence, and MS2 was detected from 3 sites without fluorescence. Commercial preparations of MS2 are expensive; thus, fluorescent markers, which are inexpensive, may be preferable. Conversely, Casanova et al 10 found considerable MS2 transfer to HCW hands and scrubs in the absence of fluorescence; thus, fluorescence may not accurately mimic transmission of viral particles. MS2 is not visible to the naked eye, and it is possible in our study that additional areas of MS2 contamination were not detected because, outside of HCW hands, face, and arms, we sampled only those areas that fluoresced. Additional data are needed on the relative benefits and limitations of these surrogate markers.

This study has several limitations. It was a relatively small pilot study and as such was underpowered. The small number of HCWs may not be reflective of HCW populations at large. The methods need replication in larger studies, and our methods and results may be useful in designing these. The end of the 2014-2015 EVD outbreak may remove the impetus for healthcare facilities to continue EVD PPE training programs, potentially making future studies of HCWs using EVD PPE more challenging. Some EVD PPE doffing recommendations have been revised since this study was performed. CP PPE, however, are routinely used in healthcare facilities, and larger studies may be possible. We used PCR for MS2 detection; therefore, MS2 detection may not be reflective of viable MS2.

In conclusion, PPE are critical for protecting both HCWs and patients from pathogens, regardless of whether the pathogen in question is high impact like EVD or commonly encountered like C. difficile. Previously published data on donning and doffing EVD PPE are limited, both by the number of studies available and the types of data and analyses. 1, 4 There are even fewer data on donning and doffing CP PPE. Our study highlights some potential areas for future research, including an improved bootcover removal process, improved HCW education in the correct processes for glove removal, and an overall need for better training in the use of CP PPE. Both fluorescent markers and MS2 can be used safely as surrogates for pathogen transmission, although the relative strengths of each need further evaluation. Overall, improved processes for donning/doffing PPE and improved methods for evaluated these processes will help to protect both HCWs and patients from exposure to pathogens.

The authors would like to thank the Barnes-Jewish Hospital Infection Prevention and Interventional Epidemiology Team for their support and assistance with this study.

Financial support: This study was supported by the Centers for Disease Control and Prevention (CDC) Prevention Epi-Center (grant no. 3U54CK000162-05S1). J.H.K. was supported by the Washington University Institute of Clinical and Translational Sciences and a grant (grant no. UL1TR000448, subaward KL2TR000450) from the National Center for Advancing Translational Sciences of the National Institutes of Health (NIH). The content is solely the responsibility of the authors and does not necessarily represent the official view of the NIH. S.Y.L. was supported by the KM1 Comparative Effectiveness Research Career Development Award (grant no. KM1CA156708-01), the Clinical and Translational Science Award program (grant no. UL1RR024992) of the National Center for Advancing Translational Sciences, and the Barnes-Jewish Patient Safety and Quality Career Development Program, which is funded by the Foundation for Barnes-Jewish Hospital.

Potential conflicts of interest: S.Y.L. serves as a subinvestigator for institutional research studies supported by Cepheid. V.J.F. reports that her spouse is Senior Vice President and Chief Medical Officer for Express Scripts; she has current funding from the NIH, the CDC, the Doris Duke Charitable Foundation, and the Foundation for Barnes-Jewish Hospital. She has past funding from the NIH, the CDC, and the AHRQ. All other authors report no conflicts of interest relevant to this article.

",0.7271354677261223
PROTECTION PERFORMANCE OF BIOLOGICAL PPE 521 Performance of materials used for biological personal protective equipment against blood splash penetration,"For occupational safety, healthcare workers must select and wear appropriate personal protective equipment (PPE), protective clothing, and masks as countermeasures against exposure to infectious body fluids and blood splash. It is important for healthcare workers to ensure the protective performance of each PPE against penetration of pathogens. The International Standards Organization (ISO) 22609 test evaluates the effectiveness of medical facemasks to protect against penetration of splashed synthetic blood. However, in this method, the protective performance is determined only visually, without quantification of leaked liquid volume. Therefore, in this study, we modified the ISO 22609 test method to quantify the volume of leaked liquid and obtain a more accurate assessment of the protection performance. We tested non-woven and woven materials used for masks or protective clothing, and the performance of each material was classified using this new method. We found that the quantity of leaked synthetic blood was dependent on the structural characteristics of each material. These findings will allow healthcare workers to select the most appropriate PPE for a given situation or task.","Accidental occupational infections occur in laboratories, hospitals, and animal handling facilities as well as in some industries, pharmaceutical and food production, and agriculture 1) .

In the case of accidental infection, the most common routes of pathogen entry are aerosol inhalation, percutaneous inoculation through needles or broken glass, animal bites or scratches, direct contact with contaminated surfaces, and accidental ingestion through a pipette 2, 3) .

The most common hospital-acquired infections are those associated with surgery; in the gastrointestinal tract, bloodstream, or urinary tract via a catheter; and ventilator-associated pneumonia 4, 5) . Ebola virus, Middle East respiratory syndrome coronavirus, hepatitis B virus (HBV), and norovirus are pathogens that have been linked to occupational infection 6 -9) .

To mitigate the risks of accidental infection, healthcare workers (HCWs) must wear appropriate personal protective equipment (PPE) in environments where they are exposed to pathogens. However, HCWs should be aware of the performance and suitability of different types of PPE in specific situations. For example, during an Ebola virus outbreak in western African in 2014, secondary accidental infections occurred in hospitals outside the affected Industrial Health 2017, 55, 521-528 countries 10, 11) . In response to this crisis, the World Health Organization and U.S. Center for Disease Control and Prevention published guidelines for HCWs treating Ebola patients 12, 13) that included wearing PPE covering the entire body -i.e., masks, personal protective clothing (PPC), head covers, gloves, goggles, and boots. The guidelines also stipulate the selection and use of PPE with high performance in terms of protection from sprayed liquids, such as contaminated body fluids.

There are various tests for evaluating PPE performance. The International Organization for Standardization (ISO) 22609 test measures the protection performance of medical face masks with respect to penetration of splashed synthetic blood (SB) 14) . In this test, the protective performance is determined by visual inspection. However, a more accurate mode of evaluation based on the quantification of leakage liquid volume is desired, given that our previous study found a positive correlation between volume of leaked SB and the number of microbes that penetrated PPC 15) .

In this study, we modified the ISO 22609 test method, using absorption paper to measure leaked liquid volume through woven and non-woven materials used for PPC or masks, to evaluate their protection performance more accurately.

Eleven fabrics used in commercially available PPC or masks at hospitals were tested in this study (Table 1) . These fabrics were previously tested for penetration resistance to SB according to the pressurized cell test (JIS T 8060, Fig. 1 ) 16) and grouped into specific classes according to the response to applied pressure 17) . In JIS T 8060, the loaded pressure level is divided into six stages, and the pressure is increased step-by-step at 5-min intervals. Higher-class fabrics were more resistant to pressure -i.e., of those that were woven, samples 1, 2, and 4 were in class < 1, whereas samples 3 and 5 were in class 1; and of those that were non-woven, sample 6 was in class < 1; samples 7, 8, and 9 were in class 1; sample 11 was in class 2; and sample 10 was in class 3 18) . Samples were cut into squares measuring 13 × 13 cm for testing. Testing apparatus and procedure The experimental setup of the testing apparatus based on ISO 22609 is shown in Fig. 2a . The apparatus consisted of a testing booth equipped with a splash gun, sample holder, and a splash pressure control unit. We tested woven and non-woven materials used for PPC or masks at impact pressures of 16.0 and 21.3 kPa, which were the same as those for SB in ISO 22609. We used Kimtowel paper (Nippon Paper Crecia Co., Tokyo, Japan) to absorb and easily visualize the leaked liquid. The fabric sample was placed in the sample holder along with a sheet of the absorbent paper with a diameter of 8 cm. The distance between the splash gun and sample holder was 30 cm. A 2-ml volume of SB (Synthetic Blood Reagent Mix: ISO 16603; Johnson, Moen & Co., Rochester, MN, USA) was ejected from the splash gun onto the sample, which was then removed from the holder along with the paper. The back of the sample was checked for leaked SB and the area was measured to determine leakage volume (Fig. 2b) . The test was repeated five times for each sample.

The area of leakage (length and breadth of the ellipse) on the absorption paper was measured using a ruler. The SB penetration volume was estimated from the measured area based on a linear standard curve obtained before the test by analyzing the correlation between the dispensed volume of SB and detected area, using the following equation: detected area (mm 2 ) = 3.7844 × dispensed volume of SB (μl); R 2 = 0.9987.

We tested and estimated leaked SB volume on absorption paper for five woven samples (Fig. 3) . The volume was correlated with splash gun pressure for all samples except 2 and 3, which had twill weave structures (Katsuragi) ( Table 1 ). Samples 2 and 3 had similar leakage volumes at 21.3 and 16.0 kPa. The volume varied by more than 100fold between samples 1 and 2 and sample 5. Accordingly, the five woven samples were classified into two groups by this test method: samples for which leakage volumes at 21.3 kPa were > 100 and < 50 μl were grouped as low and high-performance groups, respectively.

We tested six non-woven samples and estimated the volume of SB that leaked onto absorption paper for each sample (Fig. 4) . Leakage volume was correlated with splash gun pressure for all samples except 10 and 11, which had flashspun fabric structures (Table 1 ). Samples 10 and 11 The pressure is increased step-by-step at 5-minute intervals. For example, if it was observed visually that the SB did not leak through a protective clothing sample at 3.5 kPa but did leak at 7 kPa after more than 15 minutes, the sample was classified into Class 3. The pressure is increased step-by-step at 5-minute intervals. For example, if it was observed visually that the SB did not leak through a protective clothing sample at 3.5 kPa but did leak at 7 kPa after more than 15 minutes, the sample was classified into Class 3. and samples 10 and 11. Based on these observations, the six non-woven samples were classified into low-, moderate-, and high-performance groups (i.e., samples for which leakage volumes at 21.3 kPa were > 100 μl, between 100 and 50 μl, and < 50 μl, respectively). The above findings indicate that quantitative differences in protection performance among samples were distinguishable by our modified test method.

The SB detection sensitivity of our test at an impact pressure of 21.3 kPa was carried out by visual inspection of leaked SB on the back surface of the sample and on the absorption paper. The sample fabric was considered as having failed the splash test if SB leakage was detected (upper two rows of Table 2 ). For woven sample 3, the fail rate was 5/5 based on the absorption paper and 0/5 by visual inspection; for samples 4 and 5, the rates were 5/5 and 3/5, respectively. For non-woven sample 10, the fail rate was 2/5 based on the absorption paper and 1/5 by visual inspection; for sample 11, the rates were 4/5 and 3/5, respectively. Therefore, leakage could be detected with greater sensitivity using absorption paper than by visual inspection (i.e., the ISO 22609 test). The testing apparatus consisted of a test booth equipped with a splash gun, sample holder, and a splash pressure control unit. Samples were placed on a sheet of absorption paper in the holder, which had a diameter of 8 cm. The distance between the splash gun and sample holder was 30 cm. A 2-ml volume of SB was ejected by the splash gun at the sample. 

In this study, we evaluated the protection performance of woven and non-woven materials used in commercially available PPC or masks at hospitals to protect against leakage of splashed blood, using a modified version of the ISO 22609 test. The results are summarized in Table 2 . We found that the volume of leaked liquid was dependent on the structural characteristics of each material; samples 3, 4, 5, 10, and 11 had low leakage volumes. Detection sensitivity was improved by using absorption paper rather than by relying on simple visual inspection. In this study, an SB volume as low as 0.05 μl that penetrated sample 5 was detected using absorption paper (Fig. 3) . Our previous study demonstrated a positive correlation between leaked SB volume and number of penetrated microbes 15) . Therefore, quantifying the volume of leaked liquid is a more effective approach for evaluating the protection performance of materials used to manufacture PPC and masks against pathogens than the current method based on visual observation. For instance, HBV DNA concentration in the whole blood of infected patients was found to be 7.5 × 10 5 − 4.3 × 10 8 copies/ml; 19) HBV-infected patient blood contains 37.5 − 2.15 × 10 4 copies HBV DNA/0.05 μl. Thus, HCWs are at high risk of HBV infection, given that a previous study reported that the minimum amount required for transmission of HBV is approximately 30 copies in the case of chimpanzees 20) .

The protection performance of each sample material against SB splashes was not correlated with that of each material against SB impact pressure ( Table 2 and Fig. 1 ). This implies that protection performance is dependent on multiple factors -i.e., mainly material structure, but also load condition (splash impact and continuous pressure). Therefore, it is necessary to test materials under various conditions to determine their protective capacity. It is important for HCWs to select suitable PPC and masks certified by testing. Identifying differences in protection performance by various test methods can facilitate PPE selection based on risk assessment so that accidental exposure to infectious agents can be avoided. However, there are few methods currently available for testing the performance of protective materials against hazardous biological agents (Table 3) . These tests typically measure the Clothing for protection against contact with blood and body fluids -Determination of the resistance of protective clothing materials to penetration by blood and body fluids -Test method using synthetic blood Clothing for protection agains tinfectious agents -Medicalfacemasks-Test method for resistance against penetration by syntheticblood (fixedvolume, horizontallyprojected)

Surgical drapes, gowns, and clean air suits, used as medical devices, for patients, clinical staff and equipment -Test method to determine the resisitance to wet bacterial penetration ISO 22612:2005 Clothing for protection agains tinfectious agents -Test method for resistance to dry microbia lpenetration penetration of a liquid/particle or the permeation of molecules through PPE materials or membranes 21) . For handling hazardous biological agents such as microorganisms, PPE that protects against microparticles with a size of ~20 nm is required. Therefore, materials with high protective performance against penetration or permeation of liquid or small particles are equally suitable for protection against hazardous biological agents.

In conclusion, the results of this study provide a basis for evaluating and selecting materials for PPC or masks based on their capacity for protection against splashed blood, which can be quantitatively analyzed using our modified method. The performance information of PPE can help HCWs select PPE suited to biological hazards based on the risk of infection.

",0.7268174793252242
Challenge of N95 Filtering Facepiece Respirators with Viable H1N1 Influenza Aerosols HHS Public Access,"OBJECTIVE-Specification of appropriate personal protective equipment for respiratory protection against influenza is somewhat controversial. In a clinical environment, N95 filtering facepiece respirators (FFRs) are often recommended for respiratory protection against infectious aerosols. This study evaluates the ability of N95 FFRs to capture viable H1N1 influenza aerosols.","airborne influenza virus. This study also provides evidence that filtration efficiency is based primarily on particle size rather than the nature of the particle's origin.

Pandemic influenza poses a significant health threat to the international community as novel strains emerge that vary widely in virulence and infectivity. 1, 2 Which of the primary modes of human transmission of influenza 3-6 -direct contact, inspiration, inhalation, and direct spray-are responsible for spreading influenza is a subject of active debate. As a consequence, specification of the appropriate personal protective equipment (PPE) for respiratory protection against influenza is likewise controversial. For direct-spray transmission, a surgical mask may be appropriate for reducing the risk of infection, but it is not recommended for protection against aerosol transmission via inhalation or inspiration. In accordance with guidance provided by the Centers for Disease Control and Prevention, the Occupational Safety and Health Administration (OSHA) mandates that healthcare workers wear PPE at least as protective as a properly fitted National Institute for Occupational Safety and Health (NIOSH)-certified N95 filtering facepiece respirator (FFR) when exposed to some inhalable or inspirable infectious aerosols (eg, severe acute respiratory syndrome, tuberculosis, and 2009 H1N1 pandemic influenza). 7, 8 For use in clinical settings, N95 FFRs are sometimes also cleared for sale by the Food and Drug Administration as a medical device having fluid-resistant properties and certified by NIOSH. Devices carrying a NIOSH certification have shown the ability to remove 95% or more of particles of the conventional most-penetrating particle size (MPPS), 0.3 µm (with larger or smaller particles being removed more efficiently). 9 However, the MPPS for FFRs employing electret media (media possessing an electrical charge) is smaller. 10 The mechanisms used by FFRs to remove particles from the air are well understood. 11 It is also well accepted that the composition of particles of similar density does not affect particle capture efficiency. Thus, viable and inert particles of equivalent size and mass should be removed with the same filtration efficiency. Many studies have been performed to evaluate the filtration efficiency of viable microorganisms. [12] [13] [14] [15] [16] Without exception, they all show that viable microorganisms are removed at similar or slightly greater rates than inert particles of the same size, supporting the idea that FFR effectiveness against aerosol transmission does not need to be reevaluated for every new disease-causing agent. However, even with this consistent knowledge base, end users of FFRs still want confirmation that the device is capable of removing actual infective agents of interest. We found limited studies evaluating FFR performance when challenged with viable influenza aerosols. Zuo et al 17 challenged N95 FFRs with viable aerosols of human adenovirus serotype 1 and swine influenza H3N2 but were able to obtain viable data for the adenovirus only upstream of the FFR. Borkow et al 18 evaluated the antimicrobial efficacy of copper-impregnated N95 FFRs by challenging with viable H1N1 aerosols. Their results showed greater than 99% viable filtration efficiency (VFE), but they did not correlate their data to inert particles. Our study challenged 5 FFR models (Table 1) with viable H1N1 influenza aerosols representative of human respiratory secretions and compares the VFE to the inert particle filtration efficiency (PFE) at 2 flow rates.

Influenza A/PR/8/34 VR-1469 (ATCC VR-95) was propagated in embryonic chicken eggs by means of standard World Health Organization protocols. 19 Virus titers were determined by a median tissue culture infectious dose (TCID 50 ) assay using Madin-Darby canine kidney cells (ATCC CCL-34) and cell culture techniques approved by the World Health Organization. 19 For aerosolization studies, the H1N1 influenza virus was diluted to a concentration of 1 × 10 8 TCID 50 /mL in an artificial saliva buffer. 20 The count median diameter (CMD) of the particle size distribution (PSD) of the influenza aerosol in the artificial saliva buffer was 0.83 µm, as previously determined using an Aerodynamic Particle Sizer (APS) 3321 (TSI). 21

Five models of NIOSH-approved N95 FFRs, of which 2 models contained antimicrobial components (GlaxoSmithKline [GSK] Actiprotect and SafeLife T5000), were used for this study ( Table 1 ). The 3 nonantimicrobial models were chosen for their common use in the healthcare workplace. The 2 antimicrobial models were selected because they were the only 2 such models that were commercially available and NIOSH approved. All models were tested in triplicate under 2 conditions: (1) an aerosol challenge at the NIOSH-specified standard flow rate of 85 liters per minute (LPM) and (2) a morestrenuous aerosol challenge of 170 LPM to evaluate FFR performance under extreme conditions. A laboratory-scale aerosol tunnel (LSAT; Figure 1 ) was used to challenge the FFRs with viable influenza and inert beads. A complete description of the LSAT has been reported elsewhere. [20] [21] [22] Prior to each test, the LSAT was flushed with purified air for 30 minutes at a flow rate of 50 LPM. For each independent test (1 FFR at 1 condition), a FFR was glue-sealed into a 6inchdiameter sample holder as described elsewhere 21 and then secured into the LSAT via stainless steel sanitary fittings. Each FFR was first challenged with 0.8-µm polystyrene latex beads (Thermo Scientific). The beads were suspended in sterile water and then placed in a 6jet Collison nebulizer (BGI), operating at 20 psi to generate the aerosol. Following a 10minute equilibration period, 3 alternating upstream and downstream samples were collected using the APS. The air flow was then redirected to a high-efficiency particulate air (HEPA) filter, while the Collison nebulizer was replaced with another Collison nebulizer containing 30 mL of H1N1 influenza diluted to a concentration of 1 × 10 8 TCID 50 /mL in artificial saliva.

Following a 10-minute equilibration period, alternating viable samples were collected through the upstream and downstream ports. All-glass impingers (AGI-30; Ace Glass) containing 20 mL of serum-free Eagle's minimum essential medium (Hyclone Laboratories) supplemented with 1% 100× penicillin-streptomycin and 1% 200 mM L-glutamine (Sigma-Aldrich) were used for collection. To minimize particle loss, the AGI-30s were directly attached to the isokinetic sampling ports on the LSAT. Sampling was initiated by opening the valve on the port and then applying a vacuum source to the AGI-30, which sampled at approximately 12.5 LPM. After 5 minutes, the sampling port was closed, the vacuum was turned off, and the AGI-30 was placed on ice until viable plating was performed. A total of 6 samples (3 upstream and 3 downstream, alternately sampled) were collected for each FFR. Following each run, the FFR was removed and HEPA filters were connected to the sampling ports. The LSAT was subsequently flushed with purified air at 60 ± 10 LPM for 3 hours. A manometer was used to monitor the pressure drop across the filter during each run.

Upstream and downstream measurements for the 0.8-µm bead study were collected using data from the 0.723-0.925-µm size bins of the APS. The concentration of viable virus (log TCID 50 per milliliter of extract) collected in the upstream and downstream AGI-30s was determined using the Spearman-Kärber formula. 23 Equation (1) was used to determine the total amount of virus recovered from each sample (20-mL impinger volume). For samples with no detectable downstream viable data, half the detection limit (2.5 TCID 50 infectious dose units) of the viable assay was used to calculate the reduction. 24 The VFE of the FFRs was determined using equation (2) , and the PFE was determined using equation (3). A 2tailed paired t test was used to compare the inert (0.8-µm bead) and viable (H1N1 influenza) filtration data for each N95 FFR model. The average PFE and VFE values for the 2 flow rates were compared using a 2-tailed unpaired t test. A 1-way analysis of variance (ANOVA) test with a Bonferroni posttest was used to compare data obtained from the antimicrobial and nonantimicrobial FFR models.

Equation (1) is as follows: (1) where L is viable H1N1 expressed in units of log 10 TCID 50 per milliliter and V is sample volume. If no viable viruses are present (L = −∞), then L S will be half the detection limit. Equation (2) is (2) where DL S is downstream log 10 TCID 50 , UL S is upstream log 10 TCID 50 , and n is the number of determinations, and equation (3) is (3) where U is the upstream particle concentration and D is the downstream particle concentration.

The average upstream challenge for all FFR replicates was 1.8 × 10 3 TCID 50 per liter of air. Under standard flow (85 LPM) parameters, the mean PFE for all FFR models ranged from 99.72% to 99.999%, and the mean VFE ranged from 98.93% to 99.996% (Table 2) . A statistical comparison of the 2 data sets demonstrated that there is a significant difference (P < .05) between inert and viable particle filtration for only the Kimberly-Clark model (P = . 02). The SafeLife T5000 provided 1-2 orders of magnitude higher filtration performance, exceeding the NIOSH standard for an N100 FFR. Four of the 6 SafeLife T5000 replicates produced no detectable virus downstream.

Under high flow (170 LPM) parameters, the mean PFE for all FFR models ranged from 98.37% to 99.994%, and the mean VFE ranged from 96.29% to 99.995% (Table 3 ). The SafeLife T5000 again provided 1-2 orders of magnitude higher filtration performance. A statistical comparison of the 2 data sets demonstrated a significant difference between inert and viable particle filtration for only the Kimberly-Clark FFR (P = .02).

A comparison of performances at 85 and 170 LPM was conducted. The Kimberly-Clark model demonstrated statistically significant different filtration efficiencies for both inert and viable aerosol challenges (P = .003 and .002, respectively). The GSK Actiprotect model was found to demonstrate a significant difference only for the inert particles (P = .0006). A 1way ANOVA test demonstrated a statistically significant difference between the nonantimicrobial FFR models and both the Safelife T5000 and GSK Actiprotect for VFE at the 170-LPM condition (P = .0001 and .05, respectively). A significant difference was also observed for PFE (P = .0002 and .0003, respectively). No significant difference was found between the nonantimicrobial and antimicrobial FFRs at the 85-LPM condition.

Previous experimental studies, supported by filtration theory, demonstrate that PFE increases with particle size above the MPPS. While it is possible in a laboratory setting to artificially generate an influenza aerosol near the MPPS of most FFRs, particles in this size range (approximately 0.1 µm) are relatively unstable and are unlikely to exist in practice. In actual workplace settings, influenza expelled from humans via respiratory sections is typically much larger (approximately 0.8 µm) than the bare virus. We acknowledge the existence of divergent reports pertaining to the assessment of particles/droplets derived from human respiratory secretions, 25-28 but we maintain that use of a 0.8-µm particle is justified on the basis of the literature. 20 Each N95 FFR model tested as part of this study yielded equivalent VFE and PFE values that exceeded 95% (Tables 2 and 3 ). As NIOSH certification is based on removal of 0.3-µm particles, these higher removals are to be expected for the larger particles studied here. Although determined to be statistically significant, the differences between PFE and VFE at 85 LPM for the Kimberly-Clark model (less than 2.6%) are not considered to be meaningful because the 95% NIOSH benchmark was met and actual protection is driven more by differences in fit (leakage) than filtration performance. Thus, the statistical analysis in this case is not instructive and indicates only that the low variability among replicate measurements obtained by the particle sizer allows discrimination of the slightly higher filtration efficiencies of inert particles from the generally greater variability associated with capturing and assaying viable biological particles.

A possible bias introduced in this study is that the methods of analysis for inert and viable challenges are different, which may influence the comparison of the VFE and PFE. The PFE is determined using the APS and accounts only for particles whose aerodynamic particle size ranges from 0.723 to 0.925 µm. In contrast, the VFE accounts for all particles in the PSD. Another bias may be present in the sampling procedure because AGI-30 impingers collect larger particles more efficiently, 29 as do FFRs. The particles most likely to penetrate the FFR fall into a smaller size range, in which capture efficiency by the impinger is lower. Another factor that must be considered is the distribution of viable particles within the overall PSD, which is not known and may introduce another bias that cannot be accounted for. Our data are consistent with values reported by Borkow et al, 18 who demonstrated more than 95% reduction of VFE in an aerosol (approximately 3.0-µm CMD) containing viable influenza, although they sampled by means of impaction rather than impingers and performed their testing at a lower flow rate, 28 LPM. Zuo et al 17 also provided data showing that viable influenza can be removed from the airstream but provided particle-count data derived only from a viable challenge of much smaller particles (CMD of less than 0.1 µm), which behave much differently. 20 The effect of flow rate on N95 FFR performance was assessed by incorporating 2 flow conditions into the experimental design. According to 42 CFR 84 subpart K, section 84.181, the 85-LPM flow rate is the condition specified by NIOSH for evaluating the performance of FFRs. This flow rate was selected to represent a worker's inhalation at a high work rate. However, peak inhalation flow during breathing may be greater than 85 LPM for brief periods of time 30 and exacerbated further as work intensity is increased. For these reasons, we also tested at 170 LPM to provide an extreme challenge to the filter. The overall filtration numbers were slightly lower in the higher flow rate (Tables 2 and 3 ), as would be expected for particles smaller than 1 µm. Critical inspection of the data shows that the actual difference in filtration performance between the 85-and 170-LPM conditions for the particle size studied is negligible (1%-2%). Although statistically significant, these differences are merely an indicator of low variability in the data sets and not a physically meaningful distinction.

Although the antimicrobial FFR models (SafeLife T5000 and GSK Actiprotect) demonstrated considerably higher filtration efficiencies than the nonantimicrobial models, they did not provide a significantly greater reduction in viable penetration compared with inert particles, and we attribute the increased filtration efficiency to physical means rather than antimicrobial properties. These results are in line with what was observed by Borkow et al, 18 who found no improvement in VFE for FFRs impregnated with copper oxide. The SafeLife T5000's filtration performance actually exceeds the rating for a N100, observed for both the inert and the viable H1N1 particles. For the GSK FFR, the lack of reduction in VFE due to the antimicrobial was expected, as the manufacturer claims only that the antimicrobial is a surface decontaminant. It is of interest to note that the GSK FFR had the highest variability for VFE (σ = ±2.5%) among all FFRs tested (Tables 2 and 3 ). The reason for this is unclear; it is possible that the citric acid present on the FFR interferes with the viable assay, but as the VFE is lower than the PFE, it might suggest that citrate is protective, acting to shield the virus downstream of the FFR. Additional research is necessary to isolate the mechanism causing the variability.

The significance of these findings to healthcare workers is that the data provide a basis to estimate the level of protection that a healthcare worker can expect from a respirator during exposure to infectious aerosols. Inhalation exposures received by a respirator wearer come from a combination of leakage around the face seal, direct penetration through the filter, and leakage through other apertures (eg, holes in filters from staples used to secure FFR straps). Numerous workplace studies have shown that a properly fitted NIOSH-certified N95 FFR will reduce toxic inhalation exposures by a factor of 10 or more. 31, 32 Controlled leak studies conducted using manikin headforms have shown that leak size is the dominant factor affecting respirator inward leakage. 33 In the workplace, an OSHA-mandated fit test is required to ensure that the respirator is capable of fitting the healthcare worker (ie, seals tightly to the face to minimize leakage in the face seal area). Because the FFR was sealed (ie, a perfect fit) in our experiments, capture efficiencies for viable H1N1 influenza exceeding 98.9% at the lowest flow rate represent a best-case scenario in terms of fit. However, when some inward leakage during routine respirator wear is factored in, these data, combined with the workplace studies cited above, suggest that an N95 FFR is capable of reducing inhalational exposure to H1N1 influenza or other infectious aerosols by a factor of 10 or greater if properly fitted and used as expected, similar to the attenuation of other workplace aerosols.

In conclusion, this study empirically demonstrates that a NIOSH-approved N95 FFR captures viable H1N1 influenza aerosols with an efficiency equal to or greater than its N95 rating, suggesting that a properly fitted FFR reduces inhalation exposure to airborne influenza virus. Only 5 FFR models were tested as part of this study, but the findings have broad applicability to all properly fitted NIOSH-approved N95 FFRs. This study also demonstrates that the N95 FFR models tested remove particles from the airstream, indiscriminate of viability. Particles that contain H1N1 influenza are equally affected by filtration mechanisms as inert particles of the same size. Although the antimicrobial FFRs demonstrated significantly higher VFE, they also showed significantly higher PFE; thus, their enhanced performance must be attributed to physical means rather than antimicrobial activity.

Financial support. This research was funded by the Biomedical Advanced Research and Development Authority, Office of the Assistant Secretary for Preparedness and Response, US Department of Health and Human Services, through an interagency agreement with the Air Force Research Laboratory (AFRL). This work was also partly funded by the National Institute for Occupational Safety and Health through an interagency agreement with the AFRL. Representatives of both funding agencies were involved in the development of the experimental design, data interpretation, and manuscript preparation. Laboratory-scale aerosol tunnel. FFR, filtering facepiece respirator; HEPA, high-efficiency particulate air. a The data for all 3 filtering facepiece respirator (FFR) replicates were below the detection limit.

Infect Control Hosp Epidemiol. Author manuscript; available in PMC 2015 November 16.

",0.7257185117772792
Stockpile of personal protective equipment in hospital settings: Preparedness for influenza pandemics,"Background: Personal protective equipment (PPE) is known to be a crucial means of preventing influenza pandemics; however, the amount of PPE that should be stored in hospital settings has been unclear. Objectives: The purpose of this paper is to propose a PPE calculation system to help hospitals to decide their PPE stockpile. Methods: We searched influenza guidelines from a number of countries and research papers on protective devices and infectious diseases. The PPE calculation system included factors such as the influenza pandemic period, risk classification by health care workers (HCW) type, and the type and number of PPE for a HCW per day. Results: We concluded that 4 sets of PPE (N95 respirators, double gloves, gowns, and goggles) per day should be prepared for HCWs in a high-risk group. Similarly, 2 sets of appropriate PPE, depending on the risk level, are required for medium-and low-risk groups. In addition, 2 surgical masks are required for every worker and inpatient and 1 for each outpatient. The PPE stockpile should be prepared to cover at least an 8-week pandemic. Conclusion: Purchasing a PPE stockpile requires a sizable budget. The PPE calculation system in this paper will hopefully support hospitals in deciding their PPE stockpile.","Human life has often been threatened by influenza pandemics, such as the ''Spanish flu'' in 1918, ''Asian flu'' in 1957, and ''Hong Kong flu'' in 1968. Above all, the Spanish flu, which suddenly broke out in Western Europe during World War I, caused the worst damage: 40 million deaths and 600 million infected people all over the world and 380 thousand deaths and 23 million infected people in Japan. 1 No major influenza pandemic has occurred since the beginning of the 21st Century; however, a pandemic might be imminent because it is known that influenza pandemics usually repeat within 10 to 40 years, and 40 years have already passed since the last pandemic: ''Hong Kong flu.'' In addition, development of transportation such as commercial flights in recent years makes it easy for infections to spread over seas. Severe acute respiratory syndrome (SARS) in 2003 was a good example of this.

During the SARS period, another key factor occurred: many health care workers (HCWs) who cared for SARS patients in hospital settings became infected. For instance, the rate of infected HCWs of all patients was 19% in China, 22% in Hong Kong, 20% in Taiwan, 43% in Canada, and 41% in Singapore, respectively. 2 On the other hand, there were rare cases, such as a hospital in Vietnam, which succeeded in treating patients without infecting HCWs, even though Vietnam's national rate of infected HCWs was extremely high (58%). 3 According to a study of this hospital, one of the factors that contributed to protecting HCWs from secondary infection was the use of personal protective equipment (PPE), such as N95 respirators, surgical masks, and gloves.

Given the lessons from SARS, PPE is considered essential as an infection control measure. It should also be noted that a large number of PPE will be required in the short-term because it is estimated that the rate of infected people would be 25% of the total population during an influenza pandemic. 4 The key question is how many PPE each hospital setting actually needs to purchase. The purpose of this paper is to establish a calculation system to decide the appropriate PPE stockpile in each hospital setting based on factors such as the influenza pandemic period, risk classification by the HCW type, and the type and number of PPE required for HCWs per day. In addition, we investigated the average number for each HCW in hospital settings in Japan classified by the location and scale of hospitals so that PPE can be calculated from only the location and scale of hospitals. Finally, as an example, the stockpile of PPE needed for a sample hospital with 300 beds in Tokyo is shown using this system. 

Based on the above data, we extracted various factors, such as the influenza pandemic period, the risk classification by the HCW type, and the type and number of PPE required for HCWs per day to calculate the stockpile of PPE in hospital settings.

We first obtained the average number of HCWs in hospital settings from the database of the Ministry of Health, Labor, and Welfare of Japan. We then developed a PPE calculation system, which can calculate the number of PPE from only the location and scale of the hospital. In this system, the stockpile of PPE is calculated by multiplying (1) the average number of HCWs determined automatically by the location and scale of the hospital, (2) the number of PPE sets required for HCWs per day, and (3) the length of the pandemic period.

As an example, the stockpile of PPE required for a sample hospital with 300 beds in Tokyo is shown using this PPE calculation system. The expenditure for PPE was calculated by multiplying the total stockpile of PPE by the average cost of PPE. 

Based on the data obtained during the SARS epidemic in 2003, we calculated the pandemic period, assuming that it started from the day that the first patient was detected to the last day when a SARS-free declaration was issued by the country. As a result, the average duration was 122 days. The average was taken from the countries shown in Table 1 , which included more than 100 patients. China was excluded because of the unhelpful actions of the government, such as concealment at the beginning of the SARS pandemic. 6-8 The Netherlands 10 3 mo (90 days) New Zealand 11 8 Norway 12 6 mo Republic of Korea 13 8 South Africa 14 8-12 Sweden 15 6-8 United States 16 6-8

However, the pandemic periods in each region may be shorter than 122 days, which is the national average. According to the US Department of Labor, 5 the pandemic period in each region is considered to be 12 weeks at maximum. In addition, the majority of guidelines of the countries that are introduced on WHO Web site 6 assume that the pandemic lasts 6 to 8 weeks ( Table 2 ). The Ministry of Health, Labor, and Welfare of Japan also supposes that a pandemic will last 8 weeks 4 ; therefore, a stockpile of PPE should be prepared to cover at least 8 weeks, although influenza pandemics could last longer with 2 or more waves.

The type of appropriate PPE for each HCW differs depending on the risk level. In this research, HCWs are classified into 3 groups: high risk, medium risk, and low risk (Table 3) . Type and number of PPE required for each HCW per day

The type of PPE needed for each risk group is shown in Table 4 . According to the US Department of Labor, 5 the number of PPE required for HCWs in a high-risk group is 4 sets per day. It is also considered that 2 sets of PPE are required for HCWs in medium-and low-risk groups because HCWs work around 12 hours a day and are required to change PPE every 6 hours during pandemics. 20 The number of gloves depends on how many patients HCWs can treat because gloves should be changed for each patient. We suppose that 20 pairs of gloves/doctor (high risk)/day will be required because 1 SARS report showed that 1 doctor can treat 5 to 10 patients per day from the view of infection control. 21 Furthermore, the use of masks by patients is also important to block virus transmission. The US Department of Labor indicates that 1 surgical mask per day is necessary for outpatients and 2 for inpatients. 5 All medical and nonmedical workers in the hospital, such as doctors, nurses, medical technologists, pharmacists, caregivers who provide critical care or spiritual care, respiratory therapists, reprocessors of reusable medical devices, and cafeteria workers, in addition to the family members and visitors, also require at least 2 surgical masks per day. The type and number of PPE required for each HCW per day are summarized in Table 5 .

We developed a PPE calculation system based on the following factors: influenza pandemic period of 8 weeks, risk classification by the HCW type, and type and number of PPE required for HCW per day. This system made it possible to demonstrate (1) the average number for each HCW, (2) the required PPE stockpile, and (3) associated expenses from only the location and scale of each hospital. The allocation of doctors and nurses to each risk group is illustrated in Table 3 . In this study, we allocated 1/16 of all doctors and nurses to the high-risk group, 3/16 to the medium-risk group, and remaining 3/4 to the low-risk group.

Finally, to give an example, we show the stockpile of PPE required for a sample hospital with 300 beds in Tokyo (Table 6 ). According to this system, the total number of PPE is 10,528 N95 respirators (with exhalation valve), 8848 N95 respirators, 122,192 surgical masks, 21,280 goggles and gowns, 34,832 aprons, and 172,480 pairs of gloves. The total expense for this hospital came to 55,342,000 yen (US $553, 420.00; $15100 yen). 

In recent years, the government of Japan has appropriated an enormous budget for preventive measures against influenza pandemics, but the major part of this budget is used to stockpile Tamiflu and Relenza and to develop a vaccine. 22 Considering that $1 million worth of PPE was required in the first week alone at the beginning of the SARS outbreak in Toronto, 23 PPE is as important as infection control measures. It also should be noted that stockpiling a sufficient number of PPE could be a large financial burden on each hospital; however, this must occur before pandemics break out, which will result in a massive shortage of PPE.

Stockpiling PPE at each hospital is a matter of great urgency. The PPE calculation system in this paper will hopefully help to estimate the stockpile of PPE for each hospital. After all, appropriate use of PPE is an essential factor to prevent the transmission of virus. Therefore, the education to HCW should be properly conducted in addition to stockpiling PPE before the pandemic occurs.

",0.7255279959041594
Nosocomial infection control in healthcare settings: Protection against emerging infectious diseases,"The Middle East respiratory syndrome (MERS) outbreak in Korea in 2015 may be attributable to poor nosocomial infection control procedures implemented. Strict infection control measures were taken in the hospital where an imported case with MERS was treated in southern China and 53 health care workers were confirmed to be MERS-CoV negative. Infection control in healthcare settings, in which patients with emerging infectious diseases such as MERS, Ebola virus disease, and the severe acute respiratory syndrome (SARS) are diagnosed and treated, are often imperfect. When it comes to emerging or unknown infectious diseases, before the imported case was finally identified or community transmission was reported, cases have often occurred in clusters in healthcare settings. Nosocomial infection control measures should be further strengthened among the workers and inpatients in designated healthcare settings that accommodate suspected cases suffering from emerging or unknown infectious diseases.","Which intervention and control measures should be immediately taken when suspected Middle East respiratory syndrome (MERS) case(s) are imported from abroad? High priority should be given to the prevention of nosocomial infections among the workers and inpatients in the healthcare settings. Since the first human case of MERS coronavirus (MERS-CoV) was reported in Saudi Arabia in 2012, 1684 laboratory-confirmed cases and 600 related deaths have been recorded (as of January, 2016) [1] . As a result, great concerns about a potential pandemic arose [2, 3] . Although the majority of cases occurred in countries in the Arabian Peninsula, international spread of MERS due to travel has been reported in at least 20 other countries, with many cases emerging in the healthcare settings [4] .

On May 27, 2015, a suspected human case of MERS with a fever of 39.7°C, who had travelled from South Korea to Huizhou city, Southern China, was notified by the World Health Organization (WHO). This suspected case was then quarantined in a negatively pressurized room and confirmed to be infected with MERS on May 29. Strict infection control measures were taken in the hospital where the case was treated to reduce the risk of further transmission. On June 10, serum samples were collected from 53 healthcare workers who used personal protective equipment when treating this patient, and all were confirmed to be MERS-CoV negative [5] .

Poor nosocomial infection control may play an important role in emerging infectious disease outbreaks, including MERS

The first imported case of MERS in Korea was reported on May 20, 2015. Over the following weeks, the number of secondary and subsequent cases from this patient increased, leading it to become the largest case cluster of MERS outside the Middle East. All cases (excluding the index case) have been linked to a single chain of transmission and were associated with healthcare facilities [6] . Of these, 30 were secondary cases, 124 were third generation cases, 24 were fourth generation cases, and 0 were fifth generation case. The index patient of the MERS outbreak in South Korea was diagnosed nine days after the onset of symptoms, and was responsible for generating the secondary cases [7] . Nearly two-thirds of the cases have been reported from St. Mary's Hospital, Seoul, Korea, where the air-conditioning system's lack of ventilators resulted in MERS-CoV being detected in bathrooms and on doorknobs [4] . The ineffective infection control procedures implemented during this MERS outbreak may be attributable to poor nosocomial infection control.

When it comes to emerging infectious diseases such as the severe acute respiratory syndrome (SARS), Ebola virus disease, and MERS, before the imported case was finally identified or community transmission was reported, cases have often occurred in clusters in healthcare settings. In March 2003, for example, 19 medical staff members, one inpatient, and one family number were infected with SARS-CoV by the same index SARS patient in a hospital in Guangdong [8] . In a Beijing hospital in 2003, 23 first and secondary cases were infected, of which 16 were healthcare workers, two were inpatients, and five were family numbers [9] . In the US, two nurses were infected with the Ebola virus when treating an Ebola patient [10] . A comparative study on the transmission of emerging infectious diseases in the healthcare setting showed that both SARS and MERS were found to be nosocomial super-spread at the early stage, and the reproduction number dropped below 1 within 3 to 5 generations. More SARS cases were found among healthcare workers during the outbreak, while MERS cases occurred among the patients who sought care in the same healthcare settings as the index case [7] . Infection control measures are critical in preventing the spread of infectious diseases in healthcare facilities among, for instance, medical personnel who have direct contact with patients, patients sharing an intensive care unit (ICU) room with the case patient, as well as family members visiting inpatients.

Nosocomial infection control measures should be further strengthened in designated healthcare settings that accommodate suspected cases suffering from emerging infectious diseases In many countries including China, nosocomial infection regulations have been established nationally, in order to ensure routine infection control operation in healthcare settings. However, in healthcare settings where patients with emerging or unknown infectious diseases are diagnosed and treated, especially those operated by local governments, infection control methods against severe infectious diseases such as MERS are often imperfect. For example, a survey of device-associated healthcare-associated infection (DA-HAI) rates in 398 ICUs in Shanghai, China, reported a high number of DA-HAIs, which posed a major threat to patient safety [11] . Therefore, great efforts are needed to strengthen and enhance the capacity of infectious disease control in local healthcare units. Equipment, facilities, supplies, and standards of operations need to be improved. More importantly, all personnel in healthcare settings, such as doctors, nurses, and administrative and other staff, have to develop their own awareness, essential knowledge, and skills in order to protect themselves against emerging infectious diseases.

Proper control measures should be taken to ensure that nosocomial infections do not occur in designated healthcare settings that accommodate suspected cases suffering from emerging infectious diseases. To this end, a comprehensive and detailed evaluation of nosocomial infection control should be conducted in each designated healthcare setting. Negative-pressure quarantine ICUs and wards should be built in accordance with the demand in the area. Regulations, standards, procedures, and operational instructions on protection against infections from emerging respiratory, gastrointestinal, body fluid, and insect-borne infectious diseases should be established. Periodical regular trainings for the knowledge of prevention and control emerging or unknown infectious diseases, and emergency exercises regarding nosocomial infection events among medics can also help to strengthen the infection control system. 

",0.7245564793662248
A cluster randomized clinical trial comparing fit-tested and non-fit-tested N95 respirators to medical masks to prevent respiratory virus infection in health care workers,"Background We compared the efficacy of medical masks, N95 respirators (fit tested and non fit tested), in health care workers (HCWs).","Background We compared the efficacy of medical masks, N95 respirators (fit tested and non fit tested), in health care workers (HCWs).

Methods A cluster randomized clinical trial (RCT) of 1441 HCWs in 15 Beijing hospitals was performed during the 2008 ⁄ 2009 winter. Participants wore masks or respirators during the entire work shift for 4 weeks. Outcomes included clinical respiratory illness (CRI), influenza-like illness (ILI), laboratoryconfirmed respiratory virus infection and influenza. A convenience no-mask ⁄ respirator group of 481 health workers from nine hospitals was compared.

Findings The rates of CRI (3AE9% versus 6AE7%), ILI (0AE3% versus 0AE6%), laboratory-confirmed respiratory virus (1AE4% versus 2AE6%) and influenza (0AE3% versus 1%) infection were consistently lower for the N95 group compared to medical masks. By intentionto-treat analysis, when P values were adjusted for clustering, nonfit-tested N95 respirators were significantly more protective than medical masks against CRI, but no other outcomes were significant. The rates of all outcomes were higher in the convenience no-mask group compared to the intervention arms. There was no significant difference in outcomes between the N95 arms with and without fit testing. Rates of fit test failure were low. In a post hoc analysis adjusted for potential confounders, N95 masks and hospital level were significant, but medical masks, vaccination, handwashing and high-risk procedures were not.

Interpretation Rates of infection in the medical mask group were double that in the N95 group. A benefit of respirators is suggested but would need to be confirmed by a larger trial, as this study may have been underpowered. The finding on fit testing is specific to the type of respirator used in the study and cannot be generalized to other respirators.

The current influenza A H1N1 2009 virus pandemic, 1 the ongoing zoonotic transmission of influenza A H5N1 and the emergence of oseltamivir-resistant seasonal influenza A H1N1 are threats to human health. Hospital health care workers (HCWs) are key to effective pandemic response and the capacity of health care systems. Respiratory protec-tion is one of the key non-pharmaceutical interventions for protection of HCWs.

Nosocomial influenza and other outbreaks result in significant morbidity and costs 2,3 and can occur in the absence of community epidemics. 4 During outbreaks of infectious diseases, hospitals may amplify virus transmission, as demonstrated during severe acute respiratory syndrome (SARS). 5 Furthermore, anticipated antiviral shortages and Original Article delays in vaccine development make non-pharmaceutical interventions crucial. There are gaps in knowledge about prevention of influenza by medical masks and respirators. There are several prospective, randomized controlled trials on the use of handwashing, [6] [7] [8] but only two trials on the use of medical masks ⁄ respirators in households. 9, 10 In one of these studies, we showed that medical masks ⁄ respirators in compliant users in the household setting were associated with reductions in the risk of influenza-like illness (ILI)associated infection. 10 To date, there is one small randomized controlled trial (RCT) of medical masks compared to respirators in HCWs 11 which found no difference, but lacked a control arm. Medical masks are not designed to provide respiratory protection. 12 They have consistently lower filtration efficiency when compared to respirators, which are designed specifically for respiratory protection. [13] [14] [15] Medical masks were designed to prevent wound contamination when worn by the surgeon; however, three RCTs failed to show efficacy against their intended design. [16] [17] [18] The aim of this study was to determine the efficacy of medical masks compared to fit-tested and non-fit-tested N95 respirators in HCWs in the prevention of disease because of influenza and other respiratory viruses.

A prospective, cluster randomized trial of medical mask and respirator use in frontline HCWs was conducted from December 2008 to January 2009 in Beijing, China. We initially aimed to determine the efficacy of two different kinds of respiratory protection (N95 respirators and medical masks) during the influenza season compared to each other and compared to a no-mask group. However, although we intended to have a randomized control group, this was not acceptable to the Chinese IRB, who felt it would be unethical to assign HCWs randomly to not wear a mask, given mask use was widespread in Chinese hospitals that were included in the randomization. As such, we studied a convenience-selected no-mask group of HCWs who did not wear a mask. These HCWs were selected from other hospitals where mask wearing was not routine during the study period. Absence of randomization in the no-mask group meant that we eventually had to restrict the primary analysis of the trial to the comparison of the efficacy of N95 respirators and medical masks with each other.

Participants were hospital HCWs aged ‡18 years from the emergency departments and respiratory wards of 15 hospitals. These wards were selected as high-risk settings in which repeated and multiple exposures to respiratory infections are expected. We also monitored all participating wards by active surveillance for clinically compatible illness, including in the no-mask group, for outbreaks of respiratory infection in patients during the study period, and none was detected. All hospitals were large, tertiary hospitals in urban Beijing, and there was no variation in the start of the influenza season within this geographic area.

Recruitment commenced on the 1 December 2008 and final follow-up was completed on 15 January 2009. The study protocol was approved by the Institutional Review Board and Human Research Ethics Committee of the Beijing Ministry for Health. Verbal informed consent was provided by participants, and they were provided written information about the study.

The nine hospitals in the convenience no-arm group were not part of the randomization, but HCWs in those hospitals were selected from the same type of wards as the intervention arms (emergency departments and respiratory wards). They were followed up in the same way as the trial participants for development of infections.

The unit of randomization was hospitals. Hospitals were randomized to one of three intervention arms: (i) Medical masks (3MÔ medical mask, catalogue number 1820, St Paul, MN, USA); (ii) N95 fit-tested mask (3MÔ flat-fold N95 respirator, catalogue number 9132) and (iii) N95 nonfit-tested mask (3MÔ flat-fold N95 respirator, catalogue number 9132). Figure 1 outlines the recruitment and randomization (using a secure computerized randomization program) process. A pre-study assessment of hospital infection control levels determined that the hospitals had sufficient diversity to warrant stratified randomization by size of hospital and level of infection control. This assessment measured ventilation, spatial dimensions, bedding configuration, handwashing facilities and personal protective equipment use. The Ministry of Health in 1989 categorizes hospitals in China into three levels (Level 3 is the highest) depending on their level of sophistication, equipment and staff ⁄ bed numbers. Fifteen hospitals were randomized -five level 2 and ten level 3.

(i) Clinical respiratory illness (CRI), 19 defined as two or more respiratory or one respiratory symptom and a systemic symptom; (ii) ILI, defined as fever ‡38°C plus one respiratory symptom (i.e. cough, runny nose, etc.); (iii) laboratory-confirmed viral respiratory infection (detection of adenoviruses, human metapneumovirus, coronavirus 229E ⁄ NL63, parainfluenza viruses 1, 2 and 3, influenza viruses A and B, respiratory syncytial virus A and B, rhinovirus A ⁄ B and coronavirus OC43 ⁄ HKU1 by multiplex PCR); (iv) laboratory-confirmed influenza A or B and (v) adherence with mask ⁄ respirator use.

The choice of a relatively broad CRI definition was dictated by our interest in interrupting transmission of a wide range of respiratory viruses, which in adults may or may not be accompanied by fever. Also, all respiratory pathogens share a similar transmission mechanism namely aerosol, droplet and fomite spread, although the relative role of these factors may vary between different viruses and in different clinical situations. Other endpoints included adverse effects, measured using a semi-structured questionnaire and adherence.

Any nurse, doctor or ward clerk who worked full time in the emergency or respiratory wards at the hospital were eligible. HCWs were excluded if they: (i) were unable or refused to consent; (ii) had beards, long moustaches or long facial hair stubble; (iii) had a current respiratory illness, rhinitis and ⁄ or allergy and (iv) worked part-time or did not work in the aforementioned wards ⁄ departments. In all participating wards, 100% of eligible health workers participated.

Participants wore the mask or respirator on every shift for 4 consecutive weeks after being shown when to wear it and how to fit it correctly. Participants were supplied daily with either three masks for the medical mask group or two N95 respirators. Participants were asked to store the mask in a paper bag every time they removed it (for toilet breaks, tea ⁄ lunch breaks and at the end of every shift) and place the bagged mask or respirator in their locker. All participants were instructed on the importance of hand hygiene prior to ⁄ after the removal of medical masks and respirators. Participants in arm two underwent a fit-testing proce-dure using a 3MÔ FT-30 Bitrex Fit Test kit according to the manufacturers' instructions (3MÔ, St Paul, MN, USA).

Detailed demographic and clinical details of all participants were collected. This included age, sex, smoking history, comorbidities, seasonal influenza vaccination status, medications, conduct of high-risk procedures (defined as suctioning, intubation, nebulized medications, chest physiotherapy and other aerosol generating procedures), handwashing practices, use of other personal protective equipment (gowns, gloves, eye shields and hair ⁄ foot covers) and results of laboratory tests. Use of specific interventions for influenza such as antivirals was also measured.

Participants were followed for 4 weeks of wearing the masks or respirators and an extra week of non-wearing for development of respiratory symptoms.

All participants received a mercury thermometer to measure their temperature at the beginning of each day and at the onset of any symptoms. Diary cards were provided for the duration to record daily the (i) number of hours worked; (ii) mask ⁄ respirator usage and (iii) recognized CRI encounters.

Participants were contacted daily by phone or face-to-face contact to actively identify incident cases of respiratory infection. At each ward, the head nurse actively followed up all participants and identified incident illness. Staff members from the District CDC also undertook daily monitoring of the sites. If participants were symptomatic, swabs of both tonsils and the posterior pharyngeal wall were collected.

We also monitored adherence with mask or respirator use over the 4-week time course by: (i) observation: the head ward nurse observed compliance on the ward on a daily basis and recorded the information on a structured form, (ii) self-report: a diary card with tick boxes was given to each subject, to be carried during the day. Adherence to wearing the masks or respirators was monitored by these diary cards and returned to researchers on a weekly basis. Exit interviews with participants were conducted after the 4 weeks to gain further insights into adherence and other issues around the use of masks ⁄ respirators including adverse effects.

Participants with symptoms had two pharyngeal swabs collected by a trained nurse or doctor. Double rayon-tipped, plastic-shafted swabs were used to scratch both tonsilar areas and the posterior pharyngeal wall. These were transported immediately after collection to the laboratory, or at 4°C within 48 hours if transport was delayed. Pharyngeal swabs were tested with at the Laboratories of the Beijing Centers for Disease Control and Prevention. Viral DNA ⁄ RNA was extracted from 300 ll of each respiratory specimen using the Viral Gene-spin TM kit (iNtRON Biotechnology, Inc., Seoul, Korea) according to the manufacturer's instructions. Reverse transcription was performed on 8 ll of RNA in a final reaction volume of 20 ll for 1AE5 hours at 37°C, using the RevertAid TM First Strand cDNA Synthesis kit (Fermentas, Burlington, ON, Canada) to synthesize cDNA. Multiplex polymerase chain reaction (PCR) was carried out using the Seeplex Ò RV12 Detection kit (Seegen, Inc., Seoul, Korea) to detect adenoviruses, human metapneumovirus, coronavirus 229E ⁄ NL63, parainfluenza viruses 1, 2 or 3, influenza viruses A or B, respiratory syncytial virus A or B, rhinovirus A ⁄ B and coronavirus OC43 ⁄ HKU1. Three microlitres of synthesized first-strand cDNA, 4 ll of multiplex primers, 10 ll master mix (hot start Taq DNA polymerase and dNTP are included in the reaction buffer) and 3 ll of 8-methoxypsoralen (8-MOP) were added (8-MOP, accompanied by UV irradiation for 20 minutes, prevents amplification of contaminated DNA). A mixture of 12 viral clones was used as a positive control template, and sterile deionized water was used as a negative control. After preheating at 95°C for 15 minutes, 40 amplification cycles were carried out under the following conditions in a thermal cycler (GeneAmp PCR system 9700, Foster City, CA, USA): 94°C for 30 seconds, 60°C for 1AE5 minutes and 72°C for 1AE5 minutes. Amplification was completed at the final extension step at 72°C for 10 minutes. The multiplex PCR products were visualized by electrophoresis on an ethidium bromidestained 2% agarose gel. Viral isolation by MDCK cell culture was undertaken for some of the influenza samples which were positive by nuclei acid detection. Specimen processing, DNA ⁄ RNA extraction, PCR amplification and PCR product analyses were conducted in different rooms to avoid cross-contamination.

The primary endpoints of interest as described above were analysed by intention-to-treat analysis. The two N95 arms were also combined and compared to the medical mask arm, given that there was no significant difference between them and rates of fit test failure were extremely low in the fit-tested arm (5 ⁄ 461 fit test failures). Differences in proportions between the trial arms were tested by calculation of Pearson's chi-square using SAS 9.2 software (Cary, NC, USA). The distribution of key potentially confounding variables between study arms was compared. To estimate the odds ratio while adjusting for the clustering effects, we used a random effect logistic regression model. In the model, we added a hospital-specific random intercept in the linear predictors, and maximum likelihood was estimated using adaptive quadrature. 20 The model was fitted using 'xtlogit' command in STATA (College Station, TX, USA). 21 We also conducted multivariable analysis to adjust for the potential confounders. In the initial model, we included all the variables along with the main exposure variable those were significant (P < 0AE05) in the univariate analysis. We then used a backward elimination method to remove the variables that did not have any confounding effect, that is, could not make meaningful (roughly 10%) change in the effect measure with the main exposure variable. 22 In case of high multi-collinearity because of strong correlation among the potential confounders, we chose the more relevant ones having the highest confounding effect on the association of interest.

We analysed compliance as wearing the mask for >80% of the shift.

To obtain 80% power at 2-sided 5% significant level for detecting a significant difference of attack rate between the intervention arms, and for an assumed 5% attack rate in the N95 arm and 12% in the medical mask arm, a sample size of 488 participants or five clusters (hospitals) per arm was required for cluster size (m) 100 and intra-cluster correlation coefficient (ICC) 0AE01. 23 The design effect (deff) for this cluster randomization trial was 2 (deff = 1 + (m)1) · ICC = 1 + (100)1) · 0AE01 = 2). As such, we aimed to recruit a sample size of 500 per arm.

A total of 1441 nurses and doctors in 15 Beijing hospitals were recruited into the randomized arms and 481 nurses and doctors in nine hospitals were recruited into the convenience no-mask group. Figure 1 shows the recruitment process. The distribution of demographic variables was generally similar between arms (Table 1) , but was significantly different for anyone smoking in the family, four or more people in family, four or more adults in family, influenza vaccination in 2008 and 2007, public transport, handwashing, hospital level and high-risk procedures. In regards to hand hygiene, 83% (382 ⁄ 461), 87AE8% (428 ⁄ 488) and 88AE6% (435 ⁄ 492) of participants from the N95 fit test arm, N95 non-fit test arm and medical mask arm stated that they washed their hands between patients, respectively.

For all outcomes, non-fit-tested N95 respirators had lower rates of infections compared to fit-tested N95s (for all N95 versus medical masks, the rates were 3AE9% versus 6AE7% for CRI, 0AE3% versus 0AE6% for ILI, 1AE4% versus 2AE6% for laboratory-confirmed virus and 0AE3% versus 1% for influenza) but these differences were not significant. All infection outcomes were consistently higher (approximately double) in the medical mask group compared to the N95 group ( Figure 2 ). There were no cases of influenza in the non-fit-tested N95 arm, three in the fit-tested N95 arm and five in the medical mask arm. After adjustment for clustering, non-fit-tested N95 masks were significantly protective compared to medical masks against CRI, but other outcomes were not significant between N95 and medical masks ( Table 2) . When compared to the convenience no-mask group and adjusted for clustering, N95 non-fit-tested was significantly protective against CRI, and all N95 was protective against laboratory-confirmed virus and laboratoryconfirmed influenza (Table 3 ). In a post hoc analysis carried out to adjust for potential confounders which were unevenly distributed between arms, all N95 and hospital level remained significant for CRI and laboratory-confirmed viral infection, but handwashing, vaccination and high-risk procedures were not significant (Table 4) .

Fit-testing failure rate was very low (5 ⁄ 461, 1AE08%). Rates of adherence in all arms of the study were high (Figure 3 ). Table 5 shows adverse events associated with medical mask or N95 use, and that N95 respirators were associated with higher rates of adverse events. Adherence with mask or respirator wearing was high and not significantly different in all arms, with 74% adherence (95% CI 70-78%) in the N95 fit-tested arm, 68% in the N95 nonfit-tested arm (95% CI 64-73%) and 76% in the medical mask arm (95% CI 72-79%). The duration of mask wearing in these arms, respectively, was 5AE2 hours (95% CI 5AE1-5AE4 hours), 4AE9 hours (95% CI 4AE8-5AE1 hours) and 5 hours (95% CI 4AE9-5AE2 hours; Figure 3 ).

We found that rates of respiratory tract infection were approximately double in the medical mask group compared to the N95 group in health workers who wore masks throughout their shift. However, only the N95 non-fittested arm was significantly protective against CRI, and there were no other significant differences between N95 respirators and medical masks for the four primary outcomes in the adjusted analysis. However, it should be noted that under the null hypothesis where there is no difference between groups, the probability that we wrongly find at least one significant difference given the 12 tests undertaken is 46%. The trial may also be underpowered because observed attack rates were lower than expected.

The rates of all outcomes were higher in the convenience no-mask group than in the masks groups. *ILI definition using fever >38 -note, this is less sensitive than laboratory-confirmed infection. **Any respiratory virus. ***Odds Ratio -Medical group as reference. A random effect logistic model accounting for clustering was used to compute odd ratios. P m : P value adjusted for clustering of hospitals using random effect logistic regression model. 29 CRI, Clinical respiratory illness; ILI, influenza-like illness. intention-to-treat analysis, N95 respirators but not medical masks had significantly lower rates of infection compared to no masks. However, the convenience no-mask group was not a randomized control arm and hospitals in this group were actually selected on the basis that most of their staff did not wear masks (which is not the norm in hospitals in Beijing), suggesting that conditions in those hospitals were different than those in hospitals from the masks groups. As a consequence, it is not possible to make any definitive judgement on the efficacy of masks on this basis. One possible bias would be if those hospitals had differentially higher risk of infection compared to the intervention hospitals, for example because of the occurrence of outbreaks. However, we monitored all hospitals involved in the study for outbreaks which may have increased apparent attack rates, and none were documented. Other than that, possible sources of bias that could have plausibly increased the infection rate in the control arm (namely vaccination, handwashing, hospital level and high-risk procedures) were measured. In a post hoc adjusted analysis, only hospital level and the N95 arm were significant against CRI and laboratory-confirmed viral infection. Respiratory protection is a key strategy for pandemic control and key to sustaining the health care workforce. The fact that rates of all outcomes were consistently lower in the N95 group suggest that N95 respirators might offer better protection for HCWs; but a larger trial is needed to make a definitive judgment about the relative efficacy of respirators and medical masks. A recent, smaller trial found no difference between N95 and medical masks, but was 

*ILI definition using fever >38 -note, this is less sensitive than laboratory-confirmed infection. **Any respiratory virus. ***Odds Ratio -No-mask convenience group as reference. A random effect logistic model accounting for clustering was used to compute odd ratios. CRI, clinical respiratory illness; ILI, influenza-like illness. Bold text signifies statistical significance. probably underpowered to detect any differences. 11 Further, the intervention in that study was use of respiratory protection only during care of identified febrile patients with ILI or high-risk procedures. This is different from the intervention in our study, which comprised wearing the mask for the entire shift. In addition, that study measured serological evidence of influenza as an outcome, which comprised the majority of outcomes, but did not exclude influenza-vaccinated participants, a flaw that would have resulted in falsepositive cases of 'influenza'. The finding that fit testing did not improve the efficacy of N95 respirators is important, although it could be explained by a lack of power. The value of fit testing varies with the quality of the respirator, and our study used a high-quality respirator. These results would not be generalizable to other respirators, where fit testing may be more important. As such, we still recommend that fit testing be part of the process of using respirators.

The small number of randomization units along with the small numbers of cases means that estimation of multivariate models would not necessarily converge. In the post hoc multivariable analysis, we could not adjust for all of the factors because of high correlation among some of them.

Other limitations of the study include the generalizability of our results to other types of respirators and to other HCW populations in other countries. Scoping work with Australian HCWs showed compliance of 10% with continual mask wearing during a severe influenza season. 24 Beijing was selected to maximize the power of the study because of the strong culture of mask wearing among HCWs. Another limitation of the study is that cluster RCTs can be impacted by heterogeneity of behaviours, meaning that we cannot exclude such effects caused by behaviours we did not measure. The cluster design is also strength, as interventions against infectious diseases can have herd effects. In infectious diseases which can spread from person to person, the 'herd effect' is a real and documented phenomenon where protecting some individuals with an intervention (most commonly vaccination, but also applicable to other interventions) can also protect individuals who were not protected by the intervention. Therefore, if some individuals are randomized to masks on a ward, the individuals who do not wear masks may also be protected because of the effect the masks have on interrupting the transmission of disease from person to person. This is why it is preferable to use cluster design, where everyone in the cluster gets the same intervention. In our study, masks or respirators were worn during the entire shift. Some policies recommend mask ⁄ respirator use only when HCWs are conducting high-risk procedures or entering an isolation room. Whether masks ⁄ respirators will be protective when used only when an identified episode of exposure occurs depends on whether HCWs accurately identify all episodes of risk, whether most transmission occurs after clearly identified exposures and whether there is transmission from asymptomatic or pre-symptomatic infections. There is currently no evidence on how much of a HCWs' risk is unidentified or unrecognized. In our study, HCWs who conducted high-risk procedures had higher rates of CRI, but not of laboratory-confirmed pathogens or influenza. Further clinical research is required to determine the efficacy of continuous versus targeted mask use.

Until now, public health policy for dealing with pandemics has relied heavily on data from a modest number of often old and inadequate studies. Data from the SARS outbreak showed that masks reduced transmission of SARS and other viral respiratory infections. 25, 26 During SARS, the use of N95 respirators and medical masks was the major protective infection control measure. 27 However, the relative contribution of each type or the difference between N95 respirators and medical masks cannot clearly be determined from observational data.

Problems with adherence to mask ⁄ respirator use are also a potential problem. We showed that in Australia, less than half of parents who were randomized to wear a medical mask or respirator while their child was ill adhered with mask wearing. 10 There may be adverse effects of wearing masks, which can reduce adherence. [28] [29] [30] Our study showed significantly higher reported adverse effects of N95 respirators compared to medical masks, consistent with other studies. 28 Interestingly, this population of Chinese HCWs reported overall similar rates of discomfort with masks as parents in our household study, 10 with higher rates in the N95 group, but it did not affect their adherence with mask ⁄ respirator wearing. This suggests that discomfort is not the primary driver of adherence, and rather, cultural acceptability and other behavioural factors may be the main reason for non-adherence. The past experience of Beijing health workers with SARS may also be a factor in the high adherence. This level of adherence may not translate to Western cultural contexts in a normal winter season, especially for N95 respirators; however, adherence can change with perception of risk. During a pandemic, we would expect HCWs to have higher adherence to infection control measures. In summary, our study adds evidence on the use of respiratory protection for HCWs, but highlights the need for larger trials and comparison of different policy options.

Sanofi-Pasteur MSD on the modelling of varicella zoster virus. The remaining author(s) declare that they have no competing interests. The corresponding author had full access to all the data in the study and had final responsibility for the decision to submit for publication. Prior to the start of this study, NMF acted as a consultant for Roche, Novartis and GSK Biologicals (ceasing in 2007).

",0.7231550101595146
Low usage of government healthcare facilities for acute respiratory infections in Guatemala: implications for influenza surveillance,"Background: Sentinel surveillance for severe acute respiratory infections in hospitals and influenza-like illness in ambulatory clinics is recommended to assist in global pandemic influenza preparedness. Healthcare utilization patterns will affect the generalizability of data from sentinel sites and the potential to use them to estimate burden of disease. The objective of this study was to measure healthcare utilization patterns in Guatemala to inform the establishment of a sentinel surveillance system for influenza and other respiratory infections, and allow estimation of disease burden. Methods: We used a stratified, two-stage cluster survey sample to select 1200 households from the Department of Santa Rosa. Trained interviewers screened household residents for self-reported pneumonia in the last year and influenza-like illness (ILI) in the last month and asked about healthcare utilization for each illness episode. Results: We surveyed 1131 (94%) households and 5449 residents between October and December 2006 and identified 323 (6%) cases of pneumonia and 628 (13%) cases of ILI. Treatment for pneumonia outside the home was sought by 92% of the children <5 years old and 73% of the persons aged five years and older. For both children <5 years old (53%) and persons aged five years and older (31%) who reported pneumonia, private clinics were the most frequently reported source of care. For ILI, treatment was sought outside the home by 81% of children <5 years old and 65% of persons aged five years and older. Government ambulatory clinics were the most frequently sought source of care for ILI both for children <5 years old (41%) and persons aged five years and older (36%). Conclusions: Sentinel surveillance for influenza and other respiratory infections based in government health facilities in Guatemala will significantly underestimate the burden of disease. Adjustment for healthcare utilization practices will permit more accurate estimation of the incidence of influenza and other respiratory pathogens in the community.","As the 2009 influenza A (H1N1) pandemic highlighted, surveillance for influenza is now a worldwide priority. [1, 2] At the 58 th World Assembly in 2005, The World Health Organization adopted a resolution calling for Member States to fortify and coordinate national strategies to prepare for an influenza pandemic, including establishment of surveillance systems for human influenza. [3] To assist with the development of standardized influenza surveillance systems in the Americas, the Pan American Health Organization (PAHO) and the United States Centers for Disease Control and Prevention (CDC) developed a generic protocol for influenza surveillance incorporating two sentinel surveillance systems, one hospital-based system for severe acute respiratory infections (SARI) and SARI-related mortality and another for influenza-like illness (ILI) based in ambulatory clinics. [4] Sentinel surveillance for influenza can provide information on trends in viral circulation patterns and seasonality, along with virus characteristics to help guide decisions on vaccine composition. However, healthcare seeking behaviors can affect who accesses care at the sentinel site, limiting the ability to gather information to guide public health policies. Without understanding patterns of healthcare seeking behavior, it is not possible to calculate the burden of disease, generalize findings to a larger population or identify risk groups.

Healthcare utilization surveys (HUS), one method of determining the healthcare utilization practices for specific diseases in defined populations, have been conducted in several countries. [5] [6] [7] [8] [9] [10] [11] [12] In HUS, random samples of the catchment population are interviewed with respect to their healthcare seeking and treatment behaviors during recent episodes of disease. These data can be used in a number of ways to support the interpretation of information from sentinel surveillance sites: first, to establish correction factors for estimates of incidence in the community based on numbers of cases presenting at the sentinel surveillance site, including the incidence in particular population sub-groups; second, to describe the actual catchment population accessing healthcare at the sentinel site to determine generalizability; and third, to identify other healthcare providers who may be recruited to participate in the surveillance system.

To inform the establishment of a surveillance system for influenza and other respiratory infections, and the implementation of the PAHO/CDC standard protocol for influenza surveillance in Guatemala, we conducted a HUS among residents of the Department of Santa Rosa, Guatemala to describe the healthcare seeking behavior for acute respiratory illnesses.

Guatemala, with a population of 12,755,366 in 2008, had a gross national income per capita of $2680 and is considered a middle-income country by the World Bank (http://data.worldbank.org/indicator/NY.GNP.PCAP.CD, accessed on 1 September 2010). Guatemala is divided into 22 departments, which are further subdivided into 10-29 municipios (similar to counties), made up of multiple communities. The Guatemalan Ministry of Public Health and Social Welfare (MSPAS) provides free healthcare in several different settings, including hospitals, health centers, health posts, and outreach centers. Hospitals and health centers are staffed by physicians and nurses, whereas health posts are staffed by nurses. Outreach centers provide preventive and primary healthcare but are only visited by trained medical staff a few days each month. In addition to the MSPAS facilities, formally-employed workers who contribute to the Guatemalan Institute of Social Security (IGSS) can receive healthcare from IGSS hospitals and health centers, which are concentrated in Guatemala City. Other non-governmental locations where people may seek healthcare are private hospitals and clinics, pharmacies, drug shops, and traditional healers and midwives. Communities in Guatemala vary in their access to healthcare depending on their size and location (e.g., urban vs. rural).

Santa Rosa is a mostly agrarian department located in the southeastern part of the country approximately 80 km from Guatemala City. The population in 2006 was 308,522 residing in 14 municipios with an estimated 768 communities. Cuilapa is the department's capital city. In contrast to the country as a whole, which is almost half Amerindian indigenous, only 3% of Santa Rosa's residents are Mayan or Xinca, and Spanish is spoken by approximately 91% of the inhabitants. The mortality rate of children <5 years of age for Santa Rosa is 58 per 1000 live births, significantly higher than the average for the country (45 per 1000 live births). [13] Government-run healthcare facilities within the department include one hospital (the National Hospital of Cuilapa, 176 beds), 14 health centers (one in each municipio) and 56 health posts in the outlying communities. There is one IGGS facility that treats only patients involved in motor vehicle accidents. Two small private hospitals as well as approximately 133 private ambulatory clinics are available for those who choose to pay for healthcare. Additionally, healthcare services can be sought from more than 114 pharmacies or drug shops, and an unknown number of traditional healers, midwives and community healthcare workers. Healthcare may also be accessed in Guatemala City and neighboring departments.

We conducted a cross-sectional survey to determine healthcare utilization patterns for acute respiratory, diarrhea, neurologic and febrile illnesses: we report here only the results for acute respiratory infections. We used a stratified, two-stage cluster sampling procedure. Communities in the 2002 Guatemalan census were stratified as to whether or not they had a hospital or health center located in their community. As the first stage of sampling, 30 communities were selected within each stratum, using probability proportional to the population of each community, for a total of 60 clusters. Maps detailing household locations were obtained from the Guatemalan Census Bureau for these communities and 20 houses were randomly selected for a total of 1200 houses.

Interviews were conducted in person from October 1 through December 13, 2006. All persons who had lived in the house for at least six of the preceding 12 months were considered members of the household and eligible for inclusion, including persons deceased at the time of the survey if they had been resident during the reference period. Infants <6 months of age were included if they had lived in the household since birth. Households were excluded if a head of household or consenting adult was unavailable after visiting the house on three separate occasions over at least two days, or if the household head declined to participate. Excluded households were not replaced. If a house was abandoned or no longer existed, another house was randomly chosen for inclusion.

The adult respondents from each household were read a consent statement and asked to give verbal consent for their household's participation. The protocol for this study was reviewed and approved by the institutional review boards of the Centers for Disease Control and Prevention (Atlanta, GA) and the Universidad del Valle de Guatemala (Guatemala City, Guatemala) and approved by the MSPAS (Guatemala City, Guatemala).

The sample size of 600 households per strata (1200 total) was based on calculations for diarrhea, a more common syndrome, rather than for pneumonia as information was not available on the expected incidence of pneumonia. However, assuming a 10% household nonresponse rate, and 4.8 persons per household, a sample of 600 households per stratum should yield between 39 and 156 persons with pneumonia, assuming an annual incidence of between 1.5% and 6.0%, respectively. Given a design effect of two due to the clustering of pneumonia cases by community and household, this sample would be large enough to estimate the proportion of the population seeking healthcare outside of the house for pneumonia with a precision of 10%, assuming 70% of persons with pneumonia seek care for their illness.

A structured survey was completed for each participating household with information on both household-and individual-level characteristics. All household members were enumerated and an adult proxy was interviewed for children <15 years old or older residents not present at the time of the interview to determine whether any household member met any of the case definitions (mild or severe respiratory, diarrhea, acute febrile and acute neurologic illness) during the prescribed time period. A clinical history was obtained for each illness episode (if more than two episodes of the same illness were reported, the most recent illness episode was used as the reference) along with a history of healthcare treatment seeking. Proxies of household residents who died but met the case definition for one of the illnesses in the relevant time period before death were also administered the illness-specific forms.

A case of severe respiratory illness, referred to as pneumonia, was defined as self-reported cough and difficulty breathing for two or more days, or a physician-diagnosis of pneumonia; the reference period was the 12 months prior to the interview. This case definition has been used in several studies of self-reported pneumonia in the community [12, 14] and is based on questions that were moderately sensitive and specific for pneumonia from a World Health Organization verbal autopsy questionnaire. [15] Additionally, severe pneumonia was defined for children <3 years old who met the pneumonia case definition as any of the following: blue lips and/ or nails, inability to breastfeed or drink, convulsions, unconsciousness or decreased activity. For those ≥3 years old who met the pneumonia case definition, severe pneumonia was defined as fast breathing with confusion.

A case of mild respiratory illness, referred to as ILI, was defined as subjective fever with either cough or sore throat in the 30 days prior to the interview. If a respondent reported both an ILI and pneumonia for the same month, the ILI data were excluded.

Outpatient providers were defined as all sources of healthcare that did not admit patients for overnight stays, and included government and private ambulatory clinics, pharmacies, drug shops, the IGSS and traditional healers. Inpatient providers included government and private hospitals.

Survey forms were received at the offices of the CDC-UVG Collaboration at the Universidad del Valle de Guatemala for optical scanning into a database using the Cardiff Teleform system (Vista, CA). Each Teleform entry was checked manually with the original forms to ensure accurate scanning and coding. Socioeconomic status (SES) was estimated using a wealth index generated using the factor effects derived from the first principle component of a principle component analysis of household goods, house construction material, source of water supply, source of cooking fuel and sanitation facility; the wealth index was categorized into quintiles with households weighted by number of residents and sample weights. [16, 17] To account for the complex survey design, sample weights were applied in all analyses. We used the Wald Chi-square statistic to test for differences between proportions and logistic regression to test for trends related to age and SES. Analyses were conducted with SAS version 9.1 (SAS Institute, Cary, NC) using PROC SURVEYFREQ or PROC SURVEYLOGISTIC.

We approached 1200 households but residents could not be reached at 33 (3%) locations after three visits, and in 36 (3%), the household head declined to participate. We interviewed residents from 1131 (94%) households and gathered information on a total of 5449 persons of which 2806 (52%) were female and 586 (12%) were children <5 years old (Table 1) .

We found 323 persons (6%, 95% confidence interval [CI] 6-7%) who met the pneumonia case definition in the previous year. Almost all (87%) met the case definition with self-reported cough and difficulty breathing for at least two days; 2% reported only a physician's diagnosis of pneumonia; and 12% reported both. There were 60 cases (11%, 95% CI 9-13%) of pneumonia reported among children <5 years old, and 263 cases (6%, 95% CI 5-6%) among persons aged five years or older. Among the children <5 years old, 31 (6%, 95% CI 5-7%) met the case definition for severe pneumonia.

The proportion of pneumonia cases reported by month increased from October 2005 through September 2006 (Figure 1 .) More than half of the pneumonia cases were reported from the last five months prior to the survey.

There were 628 (13%, 95% CI 12-14%) persons who reported ILI in the previous month. A case of ILI was reported by 106 (19%, 95% CI 17-20%) children <5 years old and 522 (12%, 95 CI 11-13%) persons aged five years or older.

The most common symptoms reported by persons with pneumonia were difficult breathing (100%), cough (99%), and feverishness (88%) ( Table 2 ). The mean duration of illness of all persons with pneumonia was 13 days (range 2-120); more than one-quarter had symptoms for seven days or more.

Among persons who reported ILI, the most common symptom besides feverishness (100%) was sore throat (97%), headache (89%) and cough (88%). Signs of lower respiratory tract infection, such as difficult or fast breathing and wheezing, were less common among person who reported ILI than those with pneumonia. The mean duration of illness among persons with ILI was seven days (range 1-90); more than half of person who reported an ILI had symptoms for seven days or more.

The age distribution of persons with pneumonia was significantly different from the surveyed population without pneumonia (P<0.0001), with more children <5 years and adults ≥60 years old among the persons reporting pneumonia than among the surveyed population without pneumonia (Table 1) . Similarly, the age distribution of those with ILI was younger than the surveyed population without ILI (P = 0.001). The distribution of the person who reported ILI by household wealth index was significantly different from those without ILI (P<0.0001) with more cases among persons in the lowest wealth category and fewer in the wealthiest category. There was no difference in household wealth between persons with and without pneumonia (P = 0.14). 

Among the 60 children <5 years old reporting pneumonia in the last year, 55 (92%) sought care outside the home. All subsequent analyses of healthcare-seeking behavior are based on those who sought care outside the home. Sixteen (27%) children sought care from more than one source. Hospitals were consulted by 17 (25%) children <5 years old with pneumonia, and most were government hospitals (Table 3) . Nine (12%) children <5 years old with pneumonia were admitted for at least one night in a hospital. Outpatient care providers were visited by 38 (75%) children <5 years old with reported pneumonia. Overall, the most frequently reported source of healthcare for children <5 years old with pneumonia were private ambulatory clinics, which attended to more than half the reported cases. More than half (55%) of the children <5 years old with reported pneumonia received care at least once during their illness from government facilities, either government hospitals or ambulatory clinics. Among the 263 persons five years or older who reported pneumonia in the last year, 199 (73%) sought healthcare outside their home, with 21 (8%) seeking care from more than one source. Among persons in this age group who sought care outside the home, 28 (12%) sought care at hospitals (Table 3) , and 8 (4%) were admitted for at least one night. Government hospitals provided most of the hospitalized care. Among outpatient care providers, the most frequently sought source of care were private clinics, which provided care to 65 (31%) persons with pneumonia aged five years or older, along with government ambulatory clinics (46, 27%). A considerable proportion (16%) of persons with pneumonia aged five years or older sought care at pharmacies. Care for ILI was sought outside the home by 87 (81%) children <5 years old, and 6 (6%) sought care from multiple sources (Table 3) . Government clinics were the source of healthcare most often consulted by children <5 years old for ILI; 34 (41%) children <5 years old reported seeking care at a government clinic, whereas 20 (20%) reported consulting a private clinic. Hospitals were consulted by 6 (5%) children <5 years old for ILI, and 4 (5%) were hospitalized for one night or more. Care was sought at pharmacies and drug shops for nearly one-third of children <5 years old with ILI.

Care for ILI was sought outside the home by 337 (65%) persons aged five years or older, and 13 (3%) consulted multiple sources. Government clinics were consulted for ILI by 111 (36%) persons aged five years or older. Pharmacies were consulted for ILI by 110 (29%) persons aged five years or older. One (0.1%) ILI patient five years or older was hospitalized for more than one night.

Among the respondents with pneumonia who did not seek healthcare for their illness, the perception that their illness was not severe enough to warrant treatment (28/69, 42%) and the cost of treatment (13/69, 20%) were the major reasons cited for not seeking care. Among persons with ILI who did not seek healthcare for their illness, insufficient severity of illness (68/204, 31%), cost of treatment (37, 18%), lack of medical services (13, 9%) and spontaneous improvement (19, 7%) were the major reasons cited.

Sociodemographic and illness characteristics associated with seeking treatment at government facilities There was no significant association between sex of the respondent and whether care was sought for pneumonia (P = 0.34) or ILI (P = 0.15) at a government hospital or clinic (Table 4 ). Children <5 years old were more likely to receive healthcare for pneumonia and ILI at government facilities than persons aged five years or older, but this difference was statistically significant only for Numbers will not necessarily add up to 100% because more than one healthcare provider can be consulted in the course of an illness. Percentages are calculated using sample weights.

pneumonia (P = 0.03). There was a significant inverse trend across SES status with persons of higher socioeconomic status less likely to seek care for pneumonia and ILI at government facilities (P = 0.005 and P = 0.001, respectively). The duration of illness was not associated with consultation at a government facility for either pneumonia (P = 0.37) or ILI (P = 0.25). Severity of pneumonia was not associated with seeking care from a government facility (P = 0.13).

We conducted a HUS to help inform establishment of a sentinel surveillance system for pneumonia and influenza-like illness in Santa Rosa, Guatemala, and found that private clinics are the single most important source of healthcare for pneumonia both in children <5 years old and older persons. For more mild ILI, both children <5 years old and persons aged five years or older are more likely to consult government clinics than other sources of health care. These findings suggest that in Santa Rosa, sentinel surveillance for pneumonia in government hospitals will significantly underestimate the burden of disease, by up to 75% for children <5 years old and 88% for persons aged five years and older. Government healthcare clinics will underestimate the number of cases of ILI by about 59% for children <5 years old and 64% for persons five years and older.

Our study is consistent with other studies of healthcare-seeking behavior in Guatemala and Central America that have found private clinics to be common sources of healthcare. Van der Stufyt et al. reported that more than 40% of Guatemalan families sought healthcare for their children <5 years old from private physicians, compared with 26% consulting a governmental health center.

[18] Focus group interviews from three countries in Central America found that persons considered the healthcare obtained through private physicians and clinics preferable to public options because of prompt attention and a perception that healthcare is better. [19] Another study evaluating healthcare utilization among children in rural Guatemala who reported a diarrheal or respiratory illness found private physicians were more likely to be consulted by households with higher income. [20] The population that uses government health clinics and hospitals for respiratory illnesses in Santa Rosa is younger and poorer than the general population. We found a trend for decreasing use of government facilities with increasing age and household wealth. These findings should be taken into account to improve the generalizability of burden of disease estimates made from sentinel surveillance data.

The results of this study are subject to several important limitations. We used a case definition that required self-report or report by a proxy of an illness that occurred up to one year prior to interview. It is well known that such self-reports are limited by recall decay, and recent episodes are more likely to be recalled than earlier episodes. [21] This could be noted in our data that demonstrated a decreasing report of pneumonia with increasing time before the survey. As long as recent illness episodes do not differ from prior episodes with regard to patterns of healthcare-seeking behaviors, there is no reason to believe that recall decay causes bias with regard to these variables. Because our case definition is based on self-report, there is substantial potential for misclassification, especially between mild and severe acute respiratory illness, and this can be seen in the report of some lower respiratory tract symptoms among respondents with ILI. However, the behaviors associated with episodes of ILI compared to pneumonia (lower probability of seeking care outside the home, less likely to seek treatment at a hospital) are suggestive of a more mild illness and we are reasonably confident that we have described the healthcare seeking behaviors that are broadly associated with both pneumonia and ILI. An additional limitation is our sample size, which is too small to permit age to be stratified into more than two groups, restricting our ability to model healthcare-seeking behaviors more precisely by smaller age groups. Finally, it is not clear whether results from one area of Guatemala with a significantly lower indigenous population than the rest of the country can be generalized to the nation as a whole.

Despite the limitations of this and similar surveys, our findings indicate that Guatemala and other countries in the region can improve the estimation of the burden of influenza and other respiratory pathogens from sentinel surveillance by taking healthcare utilization into account. As a large proportion of the population with respiratory disease in Guatemala does not attend government health facilities for treatment, this approach could help correct government surveillance data for missing cases and facilitate comparison of the burden of influenza with other countries.

",0.7223891526445425
Aerosol Generating Procedures and Risk of Transmission of Acute Respiratory Infections to Healthcare Workers: A Systematic Review,"Aerosol generating procedures (AGPs) may expose health care workers (HCWs) to pathogens causing acute respiratory infections (ARIs), but the risk of transmission of ARIs from AGPs is not fully known. We sought to determine the clinical evidence for the risk of transmission of ARIs to HCWs caring for patients undergoing AGPs compared with the risk of transmission to HCWs caring for patients not undergoing AGPs. We searched PubMed, EMBASE, MEDLINE, CINAHL, the Cochrane Library, University of York CRD databases, EuroScan, LILACS, Indian Medlars, Index Medicus for SE Asia, international health technology agencies and the Internet in all languages for articles from 01/01/1990 to 22/10/2010. Independent reviewers screened abstracts using pre-defined criteria, obtained full-text articles, selected relevant studies, and abstracted data. Disagreements were resolved by consensus. The outcome of interest was risk of ARI transmission. The quality of evidence was rated using the GRADE system. We identified 5 case-control and 5 retrospective cohort studies which evaluated transmission of SARS to HCWs. Procedures reported to present an increased risk of transmission included [n; pooled OR(95%CI)] tracheal intubation [n = 4 cohort; 6.6 (2.3, 18.9), and n = 4 case-control; 6.6 (4.1, 10.6)], non-invasive ventilation [n = 2 cohort; OR 3.1(1.4, 6.8)], tracheotomy [n = 1 case-control; 4.2 (1.5, 11.5)] and manual ventilation before intubation [n = 1 cohort; OR 2.8 (1.3, 6.4)]. Other intubation associated procedures, endotracheal aspiration, suction of body fluids, bronchoscopy, nebulizer treatment, administration of O2, high flow O2, manipulation of O2 mask or BiPAP mask, defibrillation, chest compressions, insertion of nasogastric tube, and collection of sputum were not significant. Our findings suggest that some procedures potentially capable of generating aerosols have been associated with increased risk of SARS transmission to HCWs or were a risk factor for transmission, with the most consistent association across multiple studies identified with tracheal intubation.","Heath care workers (HCWs) are at constant occupational risk for many infectious diseases transmitted from ill patients, despite existing safety protocols [1] . During the severe acute respiratory syndrome (SARS) outbreaks, many frontline HCWs had a significantly increased risk of contracting the SARS-coronavirus (SARS-CoV) that resulted in severe illness and death [2] . Although clinical guidelines and protective measures for the management of patients with acute respiratory diseases exist, the magnitude of the risk of acquiring an infectious disease through some patient care procedures is not clearly understood [3, 4] .

Procedures that are believed to generate aerosols and droplets as a source of respiratory pathogens include positive pressure ventilation (BiPAP and CPAP), endotracheal intubation, airway suction, high frequency oscillatory ventilation, tracheostomy, chest physiotherapy, nebulizer treatment, sputum induction, and bronchoscopy [5] [6] [7] . Although those procedures are known to stimulate coughing and to promote the generation of aerosols, their risk of transmission of infection is not known with certainty. It is worth emphasizing that the scientific evidence for the creation of aerosols associated with these procedures, the burden of potential viable microbes within the created aerosols, and the mechanism of transmission to the host have not been well studied. It is unclear whether these procedures pose a higher risk of transmission and whether HCWs caring for patients undergoing the aerosol generating procedures are at higher risk of contracting the diseases compared to HCWs caring for patients not undergoing these procedures.

Prolonged exposure and poor infection control compliance, such as poor hand-washing, may be associated with an increased risk of occupationally acquired infection [8, 9] . Inadequate spacing, and the ineffectiveness of personal protective equipment may also contribute to nosocomial transmission [4] . There is some evidence that training programs and the use of personal protective equipment are associated with a decreased risk of transmission of SARS [10] . For instance, with proper control measures in three key areas (including staff personal protection, categorization of patients to stratify risk of SARS transmission, and reorganization of the operating room), high risk aerosol generating procedures (surgical tracheostomy) performed on SARS patients appeared to be associated with a low risk to HCWs who were in direct contact with the patients in the operating room [11] .

While there appears to be a lack of high quality evidence regarding the risk of transmission of acute respiratory infections from aerosol generating procedures, the current evidence-based guidelines [5] [6] [7] [12] [13] [14] [15] [16] [17] recommend additional infection control measures be taken for specified aerosol generating procedures performed on patients with suspected respiratory infection. These additional infection control measures include performing aerosol generating procedures in a single room with a minimal number of personnel present; using the most qualified personnel to perform the aerosol generating procedures; and requiring the use of personal protective equipment, specifically facial mask, full waterproof gown, face shield or goggles, and gloves. Many of these guidelines provide recommendations based on expert opinion and little understanding of the actual risk of transmission associated with the aerosol generating procedures.

We therefore sought to systematically review the literature on the risk of transmission of acute respiratory infections to HCWs exposed to patients undergoing aerosol generating procedures compared with the risk of transmission to HCWs caring for patients not undergoing aerosol generating procedures, as specified in the existing literature [5] [6] [7] . The review did not address the generation of aerosols from specific procedures, the presence of viable microbes responsible for acute respiratory diseases within aerosols which may have been created by specific procedures, and the risk of transmission of Mycobacterium tuberculosis.

A protocol for the systematic review was written a priori.

Peer reviewed literature searches were conducted to obtain published literature for this review. All search strategies and search terms were developed by an information specialist with input from the authors. The following bibliographic databases were searched through the Ovid interface: MEDLINE, MEDLINE In-Process & Other Non-Indexed Citations, EMBASE, CINAHL. Parallel searches were run in PubMed, Cochrane Library (Issue 10, 2010), LILACS, Indian Medlars and Index Medicus for South East Asia. The search strategy was comprised of both controlled vocabulary, such as the National Library of Medicine's MeSH (Medical Subject Headings) and keywords. Methodological filters were applied to limit the retrieval to health technology assessments, systematic reviews, meta-analyses, randomized controlled trials, non-randomized studies, and guidelines. Detailed search strategies are available from the CADTH website (http:// www.cadth.ca/media/pdf/ M0023__Aerosol_Generating_Procedures_e.pdf). Accessed 2012 Mar 30.

The search included all languages and was limited to articles published between Jan 1, 1990 and Oct 22, 2010. Conference abstracts were excluded from the search results. Regular alerts were established on EMBASE, MEDLINE, CINAHL and PubMed, and information retrieved via alerts was current to Jan 15, 2011.

Grey literature (literature that is not commercially published) was identified by searching the websites of health technology assessment and related agencies, professional associations, and other specialized databases. Google and other Internet search engines were used to search for additional information. These searches were supplemented by hand searching the bibliographies and abstracts of key papers, and through contacts with appropriate experts and agencies.

Eligible studies included health technology assessments (HTAs), systematic reviews, meta-analyses, randomized controlled trials, and non-randomized studies. The study population involved HCWs caring for patients with acute respiratory infections. The intervention was the provision of care to patients undergoing aerosol generating procedures (exposed to the procedures). The comparator was the provision of care to patients not undergoing aerosol generating procedures (unexposed to the procedures). The outcome of interest was the risk of transmission of acute respiratory infections from patients to HCWs. Procedures that might promote the generation of droplets or aerosols (nonexhaustive list) included non-invasive ventilation (CPAP and BiPAP), endotracheal intubation, airway suctioning, high frequency oscillatory ventilation, bag-valve mask ventilation, chest physiotherapy, nebulizer therapies, aerosol humidification, bronchoscopy or other upper airway endoscopy, tracheotomy, and open thoracotomy.

Two reviewers (KT and KC) independently applied the selection criteria and screened all citation titles and abstracts that were retrieved from the literature search. The full texts of articles selected by either reviewer were obtained. The reviewers then independently reviewed the full text articles and selected studies for inclusion. The included and excluded studies were compared and any differences between reviewers were resolved by consensus. An independent third reviewer was available to determine final study selection in instances where consensus could not be reached. However, there were no studies that required consultation with a third reviewer to determine whether they fit the inclusion criteria.

Relevant data from each of the individual studies were extracted by one reviewer (KT) and verified by a second reviewer (KC) using the predesigned data extraction form to capture the study characteristics and the outcome of interest. The study characteristics included information about the origin of the study, the period of evaluation, the population, types of laboratory tests to confirm the diseases, and assessment of training and protection equipment use. The outcome of interest was the risk of transmission of acute respiratory infections from patients to HCWs. Any disagreements between reviewers were resolved by consensus. An independent third reviewer was available to determine final data extraction in instances where consensus could not be reached. However, there were no data elements extracted that required consultation with a third reviewer to determine accuracy. Where appropriate, study results were pooled in a meta-analysis. The appropriateness of pooling of data was determined based upon the degree of clinical and statistical heterogeneity between trials. Where statistical heterogeneity was found, sensitivity analysis on treatment effect was conducted. The majority of aerosol generating procedures were evaluated in one study, which precluded the need for pooling. Data analysis was performed using Review Manager Software using a random effects model [18] . Effect sizes were reported as odds ratio (OR) and its 95% confidence interval (CI). A GRADE evaluation of the quality of evidence was performed [19] .

The literature search identified a total of 1,862 publications. Of those citations, 1,776 were excluded after screening of titles and abstracts, and 86 were retrieved for full-text screening. Ten publications were included in this report, and the remaining 76 articles were excluded ( Figure S1 ). The reasons for exclusion were an inappropriate study design, intervention, comparator, or outcome, and inappropriate patient population.

Ten non-randomized studies were identified, including five relevant case-control studies [20] [21] [22] [23] [24] and five retrospective cohort studies [25] [26] [27] [28] [29] . One study [22] was published in Chinese language and was translated by a CADTH researcher. No relevant systematic reviews, meta-analyses, or randomized controlled trials were identified.

The study characteristics (risks of transmission of an acute respiratory infection) and assessment of quality according to GRADE are shown in Table 1 . All 10 studies investigated the protective measures or the risk factors for transmission of SARS-CoV from patients to HCWs in hospital or intensive care unit settings during the 2002-2003 SARS outbreaks. Four studies were carried out in Canada, [25] [26] [27] 29] one in Singapore, [23] and five in China [20] [21] [22] 24, 28] . Six studies [20] [21] [22] [24] [25] [26] included more than 100 HCWs (ranging from 122 to 758), and four studies [23, [27] [28] [29] included less than 100 HCWs (ranging from 43 to 86). Doctors, nurses, residents, therapists, technologists, housekeepers, and others were among HCWs in eight studies, [20] [21] [22] [23] [24] [25] [26] 29] while one study included only nurses [27] and the other included only medical students [28] . Most studies assessed whether HCWs had proper infection control training or wore personal protective equipment while caring for patients with SARS. The SARS cases were confirmed by various laboratory tests for the presence of antibodies against SARS-CoV.

The results of GRADE (Grading of Recommendations Assessment, Development and Evaluation) categorized all ten studies [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] as providing very low quality evidence (http:// www.cadth.ca/media/pdf/ M0023__Aerosol_Generating_Procedures_e.pdf). Accessed 2012 Mar 30. Table 2 shows the risks of SARS transmission to HCWs exposed and not exposed to AGPs, and AGPs as risk factors for SARS transmission.

Four cohort studies [25] [26] [27] 29] showed that HCWs performing or being exposed to a tracheal intubation procedure had a higher risk of disease transmission compared with unexposed HCWs (Table 2) . A summary estimate (using a random effects model) for the cohort studies yielded an OR of 6.6 (95% CI 2.3, 18.9) with moderate statistical heterogeneity (I 2 = 39.6%) (Figure 1 ). Four case-control studies [20, 21, 23, 24] identified that tracheal intubation was a significant risk factor for transmission of SARS to HCWs (Table 2) . A summary estimate (using a random effects model) for the case-control studies yielded an OR of 6.6 (95% CI 4.1, 10.6) with high statistical heterogeneity (I 2 = 61.4%) (Figure 2) . Exclusion of an outlier study (Teleman [23] ) from the summary estimate yielded an OR of 8.8 (95% CI 5.3, 14.4) with no statistical heterogeneity (I 2 = 0%). In three of the case control studies, [20, 21, 24] the authors reported tracheal intubation as an independent risk factor for acquisition of SARS based on results obtained using multivariate analysis.

One case-control study [22] reported that the combination of four procedures which were evaluated together (intubation, tracheotomy, airway care, and cardiac resuscitation) was a risk factor with an OR of 6.2 (95% CI 2.2, 18.1) estimated from multivariate analysis. This combined analysis was derived from the same data set as that of Liu et al., 2009, [24] but was based on a clinical diagnosis of SARS. Other aerosol-generating procedures either reported as a risk factor or with an increased risk of transmission for SARS among HCWs included non-invasive ventilation from two cohort studies (OR 3.1; 95% CI 1.4, 6.8), [25, 26] tracheotomy in one case-control study (OR 4.2; 95% CI 1.5, 11.5), [20] and manual ventilation before intubation from one cohort study (OR 2.8; 95% CI 1.3, 6.4) [25] . These two latter procedures were not found to be independently associated with an increased risk of SARS transmission in the two studies that performed multivariate analysis.

Two cohort studies [25, 27] reported some risks associated with nebulizer treatment exposure, while another cohort study [28] showed otherwise. The latter study by Wong et al. (2004) [28] showed that medical students performing bedside clinical assessment had an increased risk of SARS infection even before nebulizer therapy was used. This study did not assess the training for infection control measures among medical students, which may be a source of bias and thus the study may yield a different result compared to the cohort studies by Loeb et al.(2004) [27] and Raboud et al. (2010) [25] . A summary estimate of those three studies yielded an OR of 0.9 (95% CI 0.1, 13.6) with high statistical heterogeneity (I 2 = 73.1%). In a sensitivity analysis, exclusion of the data of Wong et al. (2004) [28] from meta-analysis yielded an OR of 3.7 (95% CI 0.7, 19.5) with no statistical heterogeneity (I 2 = 0%).

Pooled estimates suggest that activities such as chest compressions (cardiopulmonary resuscitation), [25, 27] suction before intubation, [25, 27] suction after intubation, [25, 27] manipulation of oxygen mask, [25, 27] bronchoscopy, [25, 27] insertion of nasogastric tube, [25, 27] and defibrillation [25, 27] might be associated with an increased risk of transmission, but the odds ratios were not statistically significant. Chest compressions from one case control study [24] were found to be a risk factor for transmission, but this finding was in contradistinction to the findings from the pooled estimate from two cohort studies, which did not find a significantly increased risk of transmission [25, 27] . For procedures such as manipulation of BiPAP mask, [27] endotracheal aspiration, [27] suction of body fluids, [23] mechanical ventilation, [25] manual ventilation, [27] manual ventilation after intubation, [25] high-frequency oscillatory ventilation, [26] administration of oxygen, [23] high-flow oxygen, [25] chest physiotherapy, [25, 27] and collection of sputum sample, [25] the point estimates showed no significant difference.

Our findings suggest that some procedures potentially capable of generating aerosols have been associated with increased risk of SARS transmission to HCWs, with the most consistent association across multiple studies identified with tracheal intubation. Tracheal intubation may require HCWs to be in close proximity to a patient's airway for prolonged periods of time and the association of transmission of SARS-CoV in this setting would be biologically plausible. The strength of the association is supported by the observation that 7 of the 8 studies revealed that HCWs performing or being exposed to a tracheal intubation had a higher risk of SARS-CoV transmission compared to unexposed HCWs. In addition, the one study in which this observation was not consistent was considered as an outlier and, when removed from the random effects model for transmission, the degree of heterogeneity, as measured by the between-studies variance, dropped from 49.1% to 15.9%. In a random-effects model, the between-studies variance or I 2 , reflects how much the true population effect sizes differ from single studies of a meta-analysis [30] . The finding of relatively low heterogeneity with removal of the one outlier study provides a certain degree of confidence in the observation, given the consistency of the finding.

Other associations observed from the systematic review included non-invasive ventilation (two studies) and manual ventilation before intubation and tracheotomy, each from single studies. These findings were identified from a very limited number of studies and the data from these studies were not considered sufficiently robust to establish the risk of transmission with any certainty, in contrast to the consistent findings from multiple studies associated with tracheal intubation. Among 20 other potential aerosol generating procedures identified, none were found to be significantly associated with a risk of SARS transmission.

We acknowledge there were a number of limitations within the study. Although the methodologies and results of the included studies differed, overall the evidence from the 10 included studies was of very low quality according to GRADE. In general, limitations in design and imprecision are issues in all studies that led to the very low rating. Furthermore, all of the included studies evaluated the risk of transmission of SARS-CoV and may not be generalizable to other acute respiratory pathogens, including influenza virus. As well, with the exception of tracheal intubation, there were a limited number of studies identified for each procedure, which limits the confidence for an individual observation. In addition, there is difficulty in identifying the specific part of a given procedure, which may be complex and involve several manoeuvres that impart the greatest risk of transmission. There are likely differences which exist related to the degree of infectious aerosol generation associated with various procedures and the actual risk of transmission. We also acknowledge that the findings presented may have been influenced by direct and indirect contact transmission even though this route of transmission should have been minimized with the use of personal protective equipment. We were unable to exclude noncompliance with the use masks, gloves, and gowns during the procedures which were performed, but consider it unlikely that health care workers would use no precautions. Seven out of 10 studies conducted the investigation at only one hospital, which could increase the risk of selection bias and limit the generalizability of the results. Four studies included less than 100 patients. The number of HCWs included in the studies, who were exposed to the aerosol generating procedures, was small, ranging from 2 to 120. The sample size of the studies could potentially bias estimates of effects and limit statistical power. Related to this, the number of events was small in a number of studies. As noted in the results, for a number of potentially aerosol generating procedures (bronchoscopy, [27] non-invasive positive pressure ventilation, [26] manipulation of BiPAP mask, [27] and insertion of nasogastric tube [27] ) point estimates suggested an increased risk, but confidence intervals were wide and were not statistically significant. Not all HCWs caring for SARS patients were included in the studies, since there were some HCWs who refused to participate in the interview process as outlined in the individual studies. HCWs' recall might be imperfect, thus generating recall bias if some were more complete or more accurate than others. Since the source of transmission (i.e., primary, secondary, or tertiary cases) was sometimes unclear, it is difficult to accurately determine if HCWs were infected directly or indirectly from the index patients.

The estimated risk of transmission of infection through aerosol generating procedures in the included studies could have been confounded by the medical characteristics of the patients, the level of infection control training, and compliance with the use of effective personal protection methods among HCWs. Among the included studies, five [20] [21] [22] 24, 25] reported that infection control training and personal protective measures are effective against the nosocomial spread of SARS. These factors might also contribute to the spread of the viral pathogens, in addition to the aerosol generating procedures themselves.

Any conclusions drawn from this systematic review must be interpreted with caution, given the number and quality of the identified studies. However, the evidence included in this review, considered to be of very low quality based on GRADE, does suggest that some procedures potentially capable of generating aerosols have been associated with an increased risk of SARS transmission from SARS-CoV infected patients to HCWs. Of the procedures that were assessed, performing or being exposed to a tracheal intubation appeared to be most consistently associated with transmission of SARS Co-V. While other procedures, including tracheotomy, non-invasive ventilation, and manual ventilation before intubation were associated with an increased risk of SARS infection, given the paucity of studies and lack of robustness, these findings were considered difficult to interpret with respect to drawing firm conclusions. There were no other procedures which were found to be significantly associated with a risk of SARS transmission.

Despite the comprehensive nature of the search, the limitations of the included studies serve to emphasize the lack of high quality studies which have examined the risk of transmission of microbes responsible for acute respiratory infections to HCWs caring for patients undergoing aerosol generating procedures. In addition, the findings serve to highlight the lack of precision in the definition for aerosol generating procedures. Further, the results of this report should not be generalized to all acute respiratory infections because the evidence available is strictly limited to SARS. A significant research gap exists in the epidemiology of the risk of transmission of acute respiratory infections from patients undergoing aerosol generating procedures to HCWs, and clinical studies should be carefully planned to address specific questions around the risks of transmission in these settings. Given the importance to policymakers with respect to guidelines and barrier precautions for the protection of HCWs who are providing care for patients who are undergoing aerosol generating procedures, a priority should be established by funding agencies, health care organizations, and governments to foster high quality research in this area. Figure S1 Selection of Included Studies. (TIF)

",0.7200995777225758
"Applications of ultraviolet germicidal irradiation disinfection in health care facilities: Effective adjunct, but not stand-alone technology","This review evaluates the applicability and relative contribution of ultraviolet germicidal irradiation (UVGI) to disinfection of air in health care facilities. A section addressing the use of UVGI for environmental surfaces is also included. The germicidal susceptibility of biologic agents is addressed, but with emphasis on application in health care facilities. The balance of scientific evidence indicates that UVGI should be considered as a disinfection application in a health care setting only in conjunction with other well-established elements, such as appropriate heating, ventilating, and air-conditioning (HVAC) systems; dynamic removal of contaminants from the air; and preventive maintenance in combination with through cleaning of the care environment. We conclude that although UVGI is microbiocidal, it is not ''ready for prime time'' as a primary intervention to kill or inactivate infectious microorganisms; rather, it should be considered an adjunct. Other factors, such as careful design of the built environment, installation and effective operation of the HVAC system, and a high level of attention to traditional cleaning and disinfection, must be assessed before a health care facility can decide to rely solely on UVGI to meet indoor air quality requirements for health care facilities. More targeted and multiparameter studies are needed to evaluate the efficacy, safety, and incremental benefit of UVGI for mitigating reservoirs of microorganisms and ultimately preventing cross-transmission of pathogens that lead to health care-associated infections.","Ultraviolet germicidal irradiation (UVGI) has been used to ''scrub'' the air in health care facilities and laboratories for many decades. UVGI is known to be efficacious to varying degrees in controlling the circulation of airborne infectious particles. Approximately 60% of all UVGI air disinfection systems are installed in health care facilities. According to Kowalski and Bahnfleth, 1 this equates to 41% in hospitals and 19% in clinics. Until recently, most of the experimental data that led to the development of UVGI systems were decades old. Aside from anecdotal observations, little information about the actual performance of these systems in hospital rooms was available. Although UV light is known to inactivate microorganisms, limiting their ability to grow and multiply when inhaled or picked up on surfaces, there is insufficient evidence on which to base a decision to rely solely on UVGI as an engineering control for preventing health care-associated tuberculosis (TB) transmission. 2 Numerous laboratory studies, dating back to the 1930s, have been conducted to analyze the efficacy of UVGI for various microorganisms in a range of temperature and humidity conditions; few studies have evaluated the practical application of UVGI in health care buildings, however. 3 Most of the existing evidence comes from laboratory investigations conducted under simulated conditions. Our search revealed only one study that has been conducted in a physically realistic setting under controlled conditions. 4 That study served as the basis for the 2009 National Institute for Occupational Safety and Health (NIOSH) technical guidance document on the use of UVGI systems to protect health care providers from occupational TB infection. 5 This review examines the gaps in existing evidence and highlights design and operational factors that can significantly impact the efficacy of UVGI systems.

Myocobacterium tuberculosis, an obligate inhalational airborne pathogen, is inactivated by UVGI systems, which are most often are installed in the upper portion of rooms to disinfect air. Today UVGI is receiving renewed interest, given the emergence of new infectious diseases such as pandemic strains of influenza, the ongoing threat of bioterrorism, and increased controls for aerosol-generating procedures. 6 In addition, highly drug-resistant strains of M tuberculosis have been reported in several countries. 7 Others have also highlighted problems from pathogens known to survive in the environment, such as multidrugresistant Acinobacter baumannii, Clostridium difficile, and others, which are increasingly the cause of invasive infections and outbreaks in a various settings. [8] [9] [10] [11] [12] Four technological methods can be used to reduce the risk of airborne transmission: pressurization, dilution, filtration, and purification.

Pressure. Differential pressurization refers to measurable differences in air pressure that creates a directional airflow between adjacent spaces. For example, airflow into airborne infection isolation rooms (AIIRs) ensures that the rooms are negative with respect to adjacent spaces, such as corridors. Positive pressure, or airflow out of a defined space, is also common in facilities, used to mitigate the entrance of contaminants from adjacent areas into spaces in which invasive procedures are performed, such as an operating and procedure rooms.

Dilution. High ventilation rates, in terms of high values of air changes/hour (ACH), control particles by removal through ventilation. Current guidelines suggest a value of 12 ACH for new facilities when designing an AIIR, with 6 ACH the absolute minimum value. The trade-off with this means of control is that increasing the ventilation rate results in diminishing returns in terms of removal; that is, there is increased removal of particulates with ACH .12, but at a cost of greater energy consumption. Thus, the incremental benefit to prevent cross-transmission is much more difficult to demonstrate beyond 12 ACH. For other spaces, such as operating rooms, national guidelines recommend 20 ACH.

Filtration. Filters are a key element of air-handling units (AHUs) that supply air to occupied spaces. There are two banks of filters: a prefilter of approximately 30% particle removal efficiency (defined in terms of a minimum efficiency reporting value [MERV] as MERV 7), followed by a final filter of 90%-95% efficiency (MERV 14) . High-efficiency particulate air (HEPA) filtration can be used to supplement other recommended ventilation measures by providing a minimum removal efficiency of 99.97% of 0.3-mm particles. HEPA filters are typically used in ventilation systems that recirculate the air from an AIIR or from a portable device. HEPA filters also are used to filter special care areas for highly immunocompromised patients, such as a protective environment room as part of a bone marrow transplantation unit. Proper installation, maintenance, and monitoring of the HEPA filters is essential.

Purification. Purifying the air through UVGI destroys the infectious agents in the air through exposure to ultraviolet (UV) radiation, which damages the nucleic acid of bacteria and viruses, including M tuberculosis, preventing replication. 13 For spores, UV-C exposure is postulated to result in the formation of lethal photoactive products.

Airborne transmission of infectious agents involves droplets that are expelled by sneezing or coughing or are otherwise distributed into the air. Although the liquid/vapor around the infectious agent evaporates, the residue (or droplet nuclei) may remain in the air for long periods, depending on such factors as particle size, velocity, force of expulsion, particle density, infectivity (ie, viability of the microorganism when exposed to the environment and its ability to cause infection when a susceptible host is subsequently exposed), humidity, and rate of air flow.

Roy and Milton 14 suggested that transmission of infectious agents does not correlate solely with the size of the microbes in droplet nuclei or larger droplets. The size can range from obligate inhalational airborne pathogens, such as M tuberculosis, to preferential inhalational transmission, such as measles virus or varicella-zoster (VZV) (based on the ability to cause infection in distal airways), to opportunistic pathogens like SARS-CoV that take advantage of unique environmental and clinical circumstances that permit dissemination over several meters. For M tuberculosis, the prototype obligate inhalational pathogen, airborne droplet nuclei containing this agent can travel via air currents, aided by the ventilation system, and be spread over a wide area. The disease-causing organisms then are inhaled and cause infection. induction of cough by chest physiotherapy. There is theoretical chance that pathogen-laden droplets expelled during these procedures might travel further distances and reach deeper into the respiratory tract of susceptible persons. Concerns over the protection of health care personnel performing these types of procedures on patients with H1N1 2009 infection led to recommendations for higher facepiece filtering devices, such as N95 respirators. The latter have traditionally been required only to protect health care personnel against occupational exposure to M tuberculosis.

Droplet transmission involves relatively short-range movement of the infectious agent, over a distance of 1-2 m. Some of these agents (eg, influenza virus) also can be transmitted by direct and indirect contact. With droplet transmission, respiratory droplets containing infectious pathogens travel directly from the respiratory tract of the infectious individual to another susceptible person through deposition on mucosal surfaces of the recipient. The distance that droplets travel depends on the velocity and mechanism by which respiratory droplets are propelled from the source, the density of respiratory secretions, environmental factors such as temperature and humidity, and the ability of the pathogen to maintain infectivity over that distance. Droplets in dry air evaporate quickly, shrink in size, and fall to the ground more slowly. The changing size of a droplet affects how it responds to airflow patterns and how quickly it settles.

Small pressure differences, induced by natural forces such as thermal buoyancy due to air temperature differences, the wind, or mechanical fans, can generate air flows that move air from one room to another. Air filtration aims to reduce airborne concentrations to well below infectious doses. In a hospital setting, patients lie in bed much of the time. The direction of an exhalation jet from a standing or seated person and that from a lying person can be different (eg, the latter may face up). The upward thermal plume generated by a standing or seated person is much stronger than that generated by a lying person. Thus, some differences between the behaviors of breathing flows in hospital and other indoor environments are expected. The exhalation jet from a lying patient can behave differently in different ventilation systems, and also can be affected by other factors, such as the mode of contaminant release and the thermal plume generated by the human body or other heat sources. Understanding breathing flows from a patient lying supine with different ventilation systems is useful for developing an effective ventilation method for minimizing the risk of cross-infection via airborne transmission. Droplet nuclei ,5 mm in diameter exhibit a settling velocity of ,1 m/h (88 feet per minute in still air, and can follow the exhalation flows as well as the ambient air flows in a hospital ward. Clinically applicable distinctions are made between short-range airborne infection routes (between individuals, generally ,1 m apart) and long-range routes (within a room, between rooms, or between distant locations, generally distances .1 m). Fennelly et al 15 Small droplets also may participate in short-range transmission, but they are more likely than larger droplets to evaporate to become droplet nuclei and then be considered to have the potential for long-range airborne transmission.

True long-range aerosol transmission becomes possible when the droplets of infectious material are sufficiently small to remain airborne almost indefinitely and to be transmitted over long distances. Pathogens that are not transmitted routinely by the droplet route can be dispersed into the air over short distances. For example, as reported by Bassetti et al, 17 although Staphylococcus aureus is most commonly transmitted by the contact route, viral upper respiratory tract infection has been associated with increased dispersal of S aureus from the nose into the air over a distance of 4 feet under both outbreak and experimental conditions, known as the ''cloud baby'' and ''cloud adult'' phenomena.

Once infectious droplets are released, the main factors that determine how they move are their size and the airflow patterns that carry them around. Droplet size changes with time, depending on the environmental conditions. Droplets in dry air evaporate quickly, shrink in size, and fall to the ground more slowly. The changing size of a droplet affects how it responds to airflow patterns and how quickly it settles. Movement of people in a room plays a significant part in disturbing airflow and also in transporting infected air from one place to another. Thus, room airflow is governed primarily, but not solely, by mechanical ventilation. Other influences include temperature, humidity, movement of personnel and patients, and equipment. The varying combinations of these factors make the route and suspension time of an infectious particle very difficult to predict in a dynamic, real-world environment of a health care facility.

Measles and chickenpox (VZV) are both lipidenveloped and sensitive to changes in temperature, relative humidity (RH), and UV radiation. According to Cox, 18 Stephenson et al, 19 and Ijaz et al, 20 viruses without a lipid envelope (eg, poliovirus) generally survive longer at high RH (.50%), but lipid-enveloped viruses (eg, influenza, Lassa fever virus, human coronavirus [hCV] 229E) survive longer in low RH (,50%). [18] [19] [20] Data on hCV 229E indicate that when airborne, this virus has a survival half-life of about 3 hours at an RH of 80%, 67 hours at an RH of 50%, and 27 hours at an RH of 30% at 20 8C, suggesting that high RH (.80%) is most detrimental to the survival of this coronavirus. Bean et al 21 reported that influenza can survive for 24-48 hours on hard, nonporous surfaces such as stainless steel and plastic, but for less than 8-12 hours on cloth, paper, and tissues. In addition, influenza virus can survive for up to 5 minutes on hands, and can be transferred to hands from these nonporous surfaces for 24 hours and from tissues for 15 minutes. 21 More recently, Lai et al 22 demonstrated that SARS CoV can survive in alkaline diarrhea stools for up to 4 days and can remain infectious in respiratory specimens for more than 7 days at room temperature. Similarities with other viruses of nosocomial importance (eg, other RNA lipid-enveloped respiratory viruses, such as influenza) suggest that such organisms can survive long enough in aerosols to cause disease, especially when associated with biological fluids such as mucus, feces, and blood. This sensitivity to environmental conditions also might help explain the seasonality of some viral infections.

Regarding influenza transmission, Brankston et al 23 concluded that natural influenza transmission in humans occurs via droplets and contact over short distances as opposed to long distances. Although none of the studies that they reviewed could specifically rule out airborne transmission, the authors believed that the airborne route is neither the predominant mode of transmission nor a frequent enough occurrence to be of significant concern when considering control measures for most clinical settings. 23 A recent epidemiologic investigation confirmed their conclusions. 24 

A recent systematic review by Li et al 25 demonstrated that adequate or inadequate ventilation has an effect on the risk of infection via infectious aerosols. An inefficient ventilation system causes the spread of airborne disease, whereas an efficient ventilation system can help mitigate the spread of infectious particles and thereby reduce transmission of disease. 25 Even before the 2003 SARS epidemic, there was strong evidence that ventilation and building finishes are important determinants of the nosocomial transmission of tuberculosis. According to the Centers for Disease Control and Prevention's (CDC) Guidelines for Environmental Infection Control in Health-Care Facilities, only TB, measles (rubeola virus), and chickenpox (VZV) should be considered ''true'' airborne infectious diseases. 26 However, other infectious agents, such as SARS CoV, are sometimes called ''opportunistic,'' because they might be transmissible over short distances (eg, 1-2 m), given a favorable environment. 14 

All viruses and almost all bacteria (excluding spores) are vulnerable to moderate levels of UVGI exposure, but the magnitude of the effect is extremely species-dependent. 27 Spores, which are larger and more resistant to UVGI than most bacteria, can be effectively removed through high-efficiency air filtration without UVGI. Some UGVI systems are installed in conjunction with high-efficiency filtration. This combination design can be very effective against biological agents in certain situations. Smaller microbes that are difficult to 38 Reprinted with permission. 5 filter out tend to be more susceptible to UVGI, whereas larger microbes, such as spores, which are more resistant to UVGI, tend to be easier to filter out (Fig 1) . 29 A recent Taiwanese study found that the effectiveness of UVGI depends strongly on the type of virus nucleic acid, and that viruses with dsRNA or dsDNA are significantly less susceptible to UV inactivation. 30 For 90% airborne virus inactivation, the UVGI dose was approximately 2-fold higher for dsRNA and dsDNA viruses than for ssRNA and ssDNA viruses. The microorganism susceptibility factor was the highest for the viruses, similar to that for fragile bacteria, but 13-20 times higher than that for endospore bacteria or fungal spores. The susceptibility factor for the viruses was higher at 55% RH than that at 85% RH, possibly because under high RH, water adsorption onto the virus surface might provide protection against UV-induced DNA or RNA damage. 30 

Supplemental control UVGI has been used as a supplement to mechanical ventilation to inactivate airborne infectious agents to protect the health of building occupants. Upper-room UVGI installations are frequently used to provide ACH equivalent or effective (e-ACH) to that recommended by the CDC for AIIRs. However e-ACH is not acceptable for meeting CDC recommendations as a primary environmental control against M tuberculosis.

UVGI generally refers to a UV wavelength of 253.7 nm (UV-C). Exposure to UV light at this wavelength is a practical and cost-effective method of inactivating airborne viruses, mycoplasma, bacteria, and fungi on clean surfaces. 31

The most widely used application of UVGI is in the form of passive upper-room fixtures containing UVGI lamps that provide a horizontal layer of UV energy field above the occupied zone. These fixtures are designed to inactivate bacteria that enter the upper irradiated zone, and their efficacy is highly reliant on, among other factors, the airflow field conditions in the room. The survival probability of bacteria exposed to UV irradiance depends on the susceptibility of the target microorganism and the dose and duration of UV-C to which it is exposed. 32 Lamps used to produce UV-C are located relatively high up in the room (8 ft), to prevent exposure to occupants by a specially designed fixture. There are two basic designs: a ''pan'' fixture with UVGI unshielded above the unit to direct the irradiation upward, and a fixture with a series of parallel plates that direct the irradiation outward while preventing the light from reaching the eyes or unprotected skin of the room's occupants. Germicidal activity is dependent on air mixing via convection between the room's irradiated upper zone and the lower patient care zones. 32 This was confirmed in an investigation by Miller et al 4 that involved installation of upper-room UVGI units and evaluation of these units' impact on culturable airborne bacteria. More than 90% of the bacteria detected were inactivated; however, the rate was lower for more-resistant bacteria and fungal spores. That investigation also clearly demonstrated that room air must be mixed for UVGI to effectively inactivate microorganisms. When warm air entered the room via a duct close to the ceiling (which can occur in the winter when the heating system is turned on), the warm air simply ''rested'' on the much cooler air below, and the efficacy of the UVGI system was dramatically diminished because the microbes did not move up for exposure to the UV-C irradiation. No mixing fans were turned on during the experiment, but moderate ventilation was present.

The cleanliness of UV light bulbs and age of UV lamps should be checked periodically (approximately every 6 months) to ensure sufficient UV light intensity for germicidal activity (UV-C). The intensity of germicidal wavelength light decreases with age, and bulb ratings (hours of use) may vary by manufacturer. 13 Upper-room UVGI is often seen as a cost-effective measure to supplement the general ventilation system in a room; however, the combination of the general ventilation system and UV lamps might not necessarily be implemented correctly within a room. For example, if the ventilation rate is too high, the particles may not be sufficiently exposed to the UV-C irradiation to ensure complete inactivation, or if the ventilation system does not provide good mixing within the room, airborne particles containing microbes might not even be exposed to the UV-C irradiation. 13 A well-designed upper-room UVGI system may effectively kill or inactivate most airborne droplet nuclei containing Mycobacterium spp if designed to provide an average UV fluence rate (ie, irradiance from all angles that is incident on a small region of space; a more accurate term than ''UV dose'') in the upper room in the range of 30-50 mW/cm 2 , provided that the other criteria stipulated in the CDC's TB guidelines are met. 2 The fixtures should be installed to provide as uniform a UVGI distribution as possible in the upper room. 5 Schafer et al 33 developed a method to measure fluence rate and used it to verify that this rate varied as much as 3-fold in a typical room, depending on proximity to the lamp, and found that lamp failure was common. This reinforces the need to monitor the efficacy of the lamps used in UVGI fixtures. Under experimental laboratory conditions with mechanical ventilation rates of up to 6 ACH, the rate at which microorganisms are killed or inactivated by UVGI systems appears to be additive with mechanical ventilation systems in well-mixed rooms. 2 For other infectious agents, such as SARS-CoV and influenza, the mode of transmission is by droplets, which do not remain suspended in air for long periods of time, but fall out within a 2-m radius from a coughing/sneezing person. Even the most robust HVAC system is unlikely to achieve sufficient air mixing to provide efficient kill of microbes transmitted by droplets. These particles never reach the upper-room UV zone; thus, an alternate method of disinfection is needed. 34 Escombe et al 35 recently investigated impact of upward-facing UV light fixtures installed in ceilings of a negative-pressure TB isolation ward and ceilingmounted air ionization fixtures in an animal enclosure chamber, using a guinea pig air sampling model that involved exposure of the animals to exhaust air from the isolation ward. With this animal model, 35% of controls exposed to untreated exhaust air from the TB ward developed TB infection, whereas frequency was reduced to 14% and 9.5% with use of an ionizer and UVGI, respectively. They concluded that ''provided there is adequate mixing of room air, an upper-room UVGI fixture is an effective, low-cost intervention for use in TB infection control in high-risk clinical settings.'' 35

Critical factors that affect the efficacy of UVGI include temperature, RH, and lamp output. A number of studies have indicated that the effectiveness of upper-room UVGI systems decreases as humidity increases. For optimal efficiency, RH should be controlled to 60% or less when upper-room UVGI systems are installed. Temperature should be kept between 688F and 75 8F (20 8C-24 8C). Both of these suggestions are consistent with 2010 Facility Guidelines Institute (FGI) and the American Society of Heating, Refrigerating, and Air-Conditioning Engineers (ASHRAE) recommendations in ASHRAE Standard 170 (now part of the FGI Guidelines Standards). 36 The ASHRAE Handbook also provides comprehensive recommendations for installation and operation of UVGI systems. 37 Experimental upper-room UVGI systems used in rooms with aerosolized bacteria (including surrogates of M tuberculosis) have shown that the higher the UV fluence rate produced in the upper air of a room, the greater the effectiveness of the system. 4, 38, 39 Based on the results of experiments with upper-room UVGI systems and aerosolized bacteria in bench-scale reactors, it is apparent that the greater the UV fluence rate in the irradiated zone, the more effective the system. 40, 41 However, there appears to be an upper threshold after which an increase in UVGI does not directly correspond to an increase in the system's ability to kill or inactivate microorganisms. 4, 13, 42, 43 Miller et al 4 reported decreased effectiveness of the UVGI system when the UV fixtures were placed on only one side of the room. This is consistent with the findings of Riley and Permutt, 44 who reported that a wider distribution of low-irradiance UV lamps was more efficient compared with the use of one centrally located high-irradiance UV lamp. This suggests that upperroom UVGI systems should be installed to provide the most uniform UVGI distribution in the upper air possible.

In most of the studies that form the basis of the irradiance guidelines, the bacteria studied were primarily single cells aerosolized in deionized water. This lack of a mucus coating could possibly make these bacteria more sensitive to UVGI compared with bacteria in droplet nuclei from an infected host. 45 The killing or deactivation of 63% of droplet nuclei in a room by UVGI is equivalent to 1 ACH in terms of reduced total droplet nuclei concentration in the room. 3 This reduction of droplet nuclei by a method other than mechanical ventilation is termed eACH.

UVGI lamps can be installed in a various locations in a HVAC system. One possible location is inside the AHU, typically in front of the cooling coils and drip pan. There are anecdotal reports that this configuration results in energy conservation and maintenance cost savings, but more rigorous study is needed to reproduce and validate these claims. Some manufacturers of these systems have also made claims of reduced incidence of health care-associated infections (HAIs) with the use of UVGI in AHUs. To date, however, there is little, if any, supportive evidence in the peer-reviewed scientific literature. Many of the published investigations rely on environmental surface or air sampling cultures or laboratory-based animal studies for inferential support. Our assessment of the available literature indicates claims of reduced HAIs from AHU-installed UVGI in health care facilities remain unfounded. There is some evidence of fewer complaints related to indoor air quality in buildings with systems containing UVGI inside the AHU. 46 Levetin et al 47 provided some evidence for this by demonstrating a significantly lower concentration of fungal spores on a floor of a building with an in-duct UVGI system compared with a floor in the same building without such a system. The spores recovered in the building were the same as from insulation material in the ventilation ducts, however. The authors concluded that few spores from the outdoors passed through filters in the AHUs, but that the spores developed when the HVAC system was turned on and off. Notably, they noted that ''as a result, we cannot say that the UV-C radiation had a direct effect on spores in the air stream. The effectiveness of UV-C lamps seemed to be localized, because visual inspection indicated there was conspicuous fungal growth in the downstream duct insulation lining.'' 47 UV lamps also can be placed inside supply or return air ducts to disinfect the air before it is supplied to an occupied space or when recirculated.

UV irradiation by itself does not clean air. The microorganisms are still there, and in the case of some microorganisms, might still contain the ability to cause noninfectious (eg, allergenic) disease. Although UV potentially can destroy allergenic sites on the surface of a bioaerosol, this ability has yet not been documented or quantified. 47 Bacterial inactivation studies using Bacillus Calmette-Guérin (BCG; a strain of Mycobacterium bovis) and Serratia marcescens have estimated the effect of UVGI as equivalent to 10-39 ACH. 34 However, another study suggested that UVGI may result in fewer equivalent ACH in the patient-care zone, especially if the mixing of air between zones is insufficient. 48 The use of fans or HVAC systems to generate air movement and good mixing might increase the effectiveness of UVGI by ensuring exposure of airborne microorganisms to the light energy for a sufficient length of time. 35 

UVGI has been used for disinfection of water, but that application is not addressed in this review. It has also been used to disinfect surfaces. One study found that the effectiveness of this application is limited by the low penetrating power of UVGI, and thus it is currently limited to decontaminating surfaces when conventional methods, such as the use of liquid chemical disinfectants, are not feasible. 31 Some studies also have explored disinfection of medical devices and other high-frequency touch surfaces. Sweeney and Dancer 49 found that UVGI disinfection of computer keyboards without mechanical friction from cleaning had no impact on bioburden for 72% of the 68 keyboards in their study, and concluded that physical cleaning is of greatest importance before the use of UVGI. Kac et al 50 found that UVGI effectively disinfected endocavitary ultrasound probes, but only if used in combination with a surface disinfectant applied with a cloth and with mechanical friction. Interestingly, both of these investigations highlight the adjunctive impact of UVGI following traditional cleaning and disinfection for medical devices and other surfaces, whivch is consistent with use of UVGI for disinfection of air. More recently Rutala et al 51 presented unpublished results of their study of ''no-touch'' full room disinfection with an automated, portable UV-C device that uses mirrors to ''bounce'' UVGI around a room to reach all surfaces, including those not directly exposed to fluence. They reported substantial log reductions in vegetative bacteria (3) (4) within 15 minutes of exposure and in spore-forming bacteria, such as C difficile (2-3), after 50 minutes of exposure.

An analytical model for evaluating the UV dose in steady-state conditions using the Eulerian system was proposed by Memarzadeh et al. 48 Computational fluid dynamics (CFD) was used to study the efficacy of inactivation of airborne bacteria by upper-room UVGI in a test room. Several UV lamp configurations were used in the model. Compared with available experimental data, the proposed model closely predicts the percentage of particles inactivated by UVGI. The proposed model was used to study the effects of ventilation flow rate and UV fixture configuration on inactivation of airborne bacteria in a test chamber. The Lagrangian system model was also applied in the same test chamber for a similar scenario. This CFD model demonstrates that the percentage of UVGI inactivation is higher when the ventilation flow rate is lower. Increasing the ventilation flow rate from 2 to 6 ACH reduces the residence time of a pass through the UV zone from 24.7 to 8.3 seconds. In the latter case, the dosage is then only˜35% of the total dose received in the former case. For upper-room UVGI to be effective, the aerosolized infectious particles must be moved from the lower part of the room, where they are produced by a person coughing or sneezing, to the germicidal zone in the upper room. Practical considerations prohibit the ideal situation of UVGI cleansing of all infectious particles in a single pass when they move through the upper-room UVGI zone. Another consideration is how rapidly microorganisms proceed through the UVGI zone. A higher frequency of ACH limits the exposure time of the infectious particles to the UVGI and thus is likely to have less effective antimicrobial activity. In practice, the effectiveness of a UVGI installation is determined by the following factors: d Fixture used to house the UV-C lamp. This determines how much of the radiation discharged from the UV lamp is actually emitted from the fixture and how it is distributed. d Environmental sustainability issues. Most UV-C lamps use low-pressure mercury, have a limited life span, and require environmental precautions for disposal. d Distance from the UV-C lamp. The distance of airborne infectious agents from the fixture will determine the irradiance level and thus the germicidal efficacy. d Airflow pattern. This affects how long the bacteria and viruses are exposed to the UV radiation. d Humidity. The humidity of the atmosphere is key, because water makes the infectious agent less susceptible to damage from UV radiation. The higher the RH, the less likely an aqueous aerosol will dry out. For maximum effectiveness of UVGI, RH should be ,75%. 34

According to an American Biological Safety Association position paper, biological effects in humans from overexposure to UV-C radiation vary with wavelength, photon energy, and duration of exposure. 52 In general, adverse effects are limited to the skin and eyes. Erythema (eg, reddening of the skin, as in sunburn) is the most commonly observed skin effect. Chronic exposure to UV radiation can accelerate the skin aging process and increase the risk of skin cancer. The National Toxicology Program (NTP) classifies UV-C as a probable human carcinogen. Excessive exposure to UV-C radiation can adversely affect the eyes, causing photokeratitis and/or conjunctivitis. Based on the current guidelines, repeated exposure at or below the current guideline would not be expected to cause adverse health effects; however, it should be emphasized that UV radiation has been implicated in both skin cancer and cataracts in humans.

On May 18, 2007, NIOSH received a request from the Director of Environmental Affairs at Brigham and Women's Hospital (BWH) in Boston, Massachusetts. Some BWH orthopedic surgical staff members were concerned about unspecified skin and eye symptoms, which they attributed to germicidal UV-C radiation produced by ceiling-mounted UVGI lamps in orthopedic operating rooms (ORs). The use of UVGI in orthopedic ORs was investigated by the Occupational Safety and Health Administration (OSHA) on January 19, 2007 , in response to a formal complaint submitted after staff discovered that the UVGI lamp controls in an OR had been tampered with and set at an inappropriately high setting. After an inspection, OSHA recommended that BWH provide annual UV-C and personal protective equipment (PPE) training and medical screening for all affected employees, as well as ensure that all affected employees use the required PPE. In July 2008, BWH moved the orthopedic operating suite to an area equipped with laminar airflow and discontinued the use of UVGI for intraoperative infection control. NIOSH investigators recommended the use of alternative infection control technologies, such as laminar airflow. 53 

The use of direct UVGI as an air-cleaning method for intraoperative infection control is a relatively uncommon application that has been used by some surgeons since the 1930s. [54] [55] [56] Some evidence suggests that the use of UVGI in this manner might reduce the incidence of surgical site infections by minimizing intraoperative levels of airborne bacterial contaminants. This design differs from upper-room devices in that the UV-C irradiation is directed down to expose the entire OR. Eye protection and other attire are required for those in the OR. The relative efficacy of direct UVGI on intraoperative air quality and prevention of infection has not been well defined, however, because studies that have examined its use did so at a variety of UV intensities in association with other infection prevention methods and surgical techniques. In addition, most studies have been observational, before-after investigations, which are limited by biases and other confounding variables. Investigators have reported that UVGI is usually used not alone, but rather in conjunction with laminar airflow or body exhaust techniques, with discrepancies in wound rates under the same conditions. 56 The CDC recommends against using UVGI to prevent surgical site infections. 26 Overall, for general ventilation effectiveness, there is little advantage to increasing the effectiveness of the UVGI beyond 4-6 ACH. UVGI is effective when at low ACH, and its efficacy diminishes as ACH increases, because the kill rate is dependent on the duration of exposure to the UV dose. With high ACH, exposure time is significantly decreased.

For personnel safety, NIOSH strongly encourages employers to protect employees using a hierarchy of controls approach. The objective of this approach is to minimize the risk of failure of preventive measures, resulting in a hazardous exposure. According to the hierarchy, initial efforts should be made to eliminate the hazardous agent or source of exposure. With regard to intraoperative UVGI use, this could be achieved by substituting other infection prevention methods or technologies, such as vertical laminar air flow, before implementing direct UVGI inside the OR. 53 It should be noted that a more recent design for the OR uses nonaspirating diffusers with unidirectional airflow over the surgical site but at lower velocities than traditional high-velocity laminar sir flow, thereby minimizing the risk of hypothermia. This design is now required in the 2010 FGI guidelines 36 and is described in detail elsewhere. 57 

Given the foregoing discussion, we recommend that UVGI system designers take the following considerations into account: d Apply safety factors to their designs, particularly as they depart from operating modes for which they have performance data and field experience. d Know the actual lamp output under the most challenging operating conditions. d Avoid relying solely on design equations to determine the performance of their systems. Actual testing with the contaminants of interest is highly recommended. d View claims regarding UVGI systems' high level of inactivation of pathogenic bioaerosols with caution. Whereas the microbiological science underlying these conclusions applies to pathogenic bioaerosols as well as environmental organisms, much greater caution is required in the former case. It would be irresponsible to claim a high inactivation rate for a pathogenic bioaerosol without substantial testing. Even with substantial testing, design failures may occur.

Although many laboratory studies have been conducted to analyze the efficacy of UVGI for numerous microorganisms in a range of temperature and humidity conditions, little has been done to evaluate the practical application of UVGI in health care buildings. 3 In fact, Beggs et al 58 concluded that ''the knowledge base that exists on UVGI and its application is relatively small, and health care authorities have few guidelines on which to make decisions.''

As discussed earlier, potentially infectious droplet nuclei emitted from an infected host might be coated with mucus and consist of more than one bacterium. Study bacteria, aerosolized in deionized water and lacking a mucus coating, may be more sensitive to UVGI compared with bacteria in droplet nuclei from an infected host. 44 Installation and maintenance UVGI is associated with human health risks and unpredictable results. UV rays can cause harm to building occupants if not properly installed and maintained. Installation techniques widely vary among manufacturers and currently are not regulated by a governing body to ensure proper efficacy of UVGI after installation.

UVGI lamp manufacturers (eg, Philips PLD), acknowledge that some important information is not available. For example, regarding to the sizing of UV lamps for installation in ductwork systems, a Philips technical document on UV disinfection states that ''in the calculation.it should be emphasized that it results only in a rough estimation; we did not incorporate the possible effects of humidity and temperature on the killing rate. Philips is not a specialist in that field; we always advise to contact qualified authorities to evaluate the bacteriological aspects.'' 59 The use of CFD models and improved distribution studies on UVGI lamps and fixtures is moving the industry in the right direction. The CFD models characterize the room and air distribution in coordination with any UVGI systems applied within the space to evaluate the effectiveness quantitatively. 3 For UVGI applications in AHU and ductwork, maintenance personnel may be at increased risk even if their exposure time to the UVGI irradiation is short, because they will be in close proximity to the UVGI source.

Service personnel and occupants are at risk without special care measures. Service staff need to ensure that the system is turned off when working. The need to wear protective clothing and eyewear should be stressed to prevent any possibility of harm to workers. Room occupants may be exposed to higher doses of UVGI irradiation if the fixtures are not located or installed properly within the space. Health care providers are at a greater risk because they occupy the space for longer periods than most patients. UVGI overexposure has the potential to cause unpleasant eye and skin irritations; however, these effects appear to be temporary and have involved no known long-term consequences to date. 60 

Additional areas of research needed to determine the most effective upper-room UVGI systems include UVGI measurements, air mixing, the effect of low humidity, microbial sensitivity, and testing and validation of upper-room UVGI systems. More research is also needed on the ability of UVGI systems to kill or inactivate microorganisms in respirable droplet nuclei of variable sizes and droplet nuclei coated with actual or simulated sputum. 5 Methods for determining whether existing room air mixing is sufficient for UVGI effectiveness are needed, and research should explore whether the use of mixing fans has a negative impact on the intended design of the mechanical ventilation systems or a negative impact on other infection control measures.

There is some indication that low RH (,25%) might adversely affect the ability of UVGI systems to kill or inactivate airborne bacteria. Additional research is needed in this area. Research in full-scale rooms to better ascertain the effects of high humidity (eg, 80% RH) on airborne microorganisms is needed as well. Experimental research has indicated that mechanical ventilation of up to 6 ACH does not have a significant effect on the effectiveness of upper-room UVGI systems; studies are needed to examine whether mechanical ventilation .6 ACH decreases the effectiveness of upper-room UVGI systems.

Tests to determine the relative sensitivity of microorganisms to UVGI are not standardized among laboratories. Laboratory testing guidelines are needed to ensure that these tests are reproducible and reflect real-world situations. Laboratory tests of the efficacy of UVGI upper-room systems should be standardized as well. Protocols for testing and validating upper-room UVGI systems are needed to ensure that the systems perform as designed. 1

Guidelines are needed to determine the most practical method for planning effective UVGI systems in a variety of rooms or areas. Theoretically, CFD modeling can be used to evaluate many of the variables associated with installing an upper-room UVGI system and provide an estimate of the UVGI dose received by droplet nuclei. Experiments involving photoreactivation of microorganisms in full-scale test rooms should be conducted, as should tests of the effectiveness of UVGI on airborne bacteria over a wide range of temperatures. In real-world situations, potentially infectious droplet nuclei will vary in size and may be coated with sputum. Both of these factors can decrease the effectiveness of UVGI. Although some laboratory research has been done to evaluate these parameters, 34, 44, 61 more work is needed to further characterize microbial susceptibility to UVGI based on the size of respirable (up to 5 mm) droplet nuclei and droplet nuclei coated with actual or simulated sputum.

Data for real-world applications As this and previous literature reviews have shown, although numerous studies address the efficacy of UVGI, there remains a lack of definitive epidemiologic data demonstrating that these systems prevent HAIs endemic to health care facilities. Also lacking is objective, reproducible evidence of improved energy efficiency of coils and fans with UVGI systems installed in AHUs. The efficacy of an upper-room UVGI application depends strongly on sufficient exposure of microorganisms to UV-C, which can occur if there is good mixing of upper and lower air in the room or area where installed. Furthermore, there are many marketing claims suggesting that such systems, as well as mobile systems, will protect occupants against emerging diseases such as SARS CoV, influenza, M tuberculosis, and bioterrorism agents. These claims have not been substantiated by the existing data, however, and must be weighed against the many variables discussed in this literature review. For TB, there is ample laboratory and reasonable evidence from animal studies, but the key question remains the relative role of UVGI in the context of the hierarchy of controls to prevent health care-associated TB.

Some of the agents that might be used for bioterrorism, such as anthrax spores, are not very susceptible to UV-C. Because the clinical effectiveness of UV systems may vary, UVGI is not recommended for air management before air recirculation from airborne isolation rooms. It also is not recommended as a substitute for HEPA filtration, local exhaust of air to the outside, or negative pressure.

The use of UV lamps and HEPA filtration in a single unit offers only minimal infection control benefits over those provided by the use of a HEPA filter alone. Duct systems with UVGI are not recommended as a substitute for HEPA filters when the air from isolation rooms must be recirculated to other areas of the facility. Regular maintenance of UVGI systems, involving keeping the bulbs free of dust and replacing old bulbs as necessary, is crucial. Safety issues associated with the use of UVGI systems are described in guidelines.

When UVGI units are required for air cleaning, as demonstrated by a risk assessment of the AII area, the units should be installed in the exhaust air ducts of the HVAC system to supplement HEPA filtration. When UVGI is used as a supplemental engineering control, fixtures should be installed on the wall near the ceiling or suspended from the ceiling as an upper-air unit, in the air-return duct of an AII room, or in designated enclosed areas or booths for sputum induction.

In summing up the role of UVGI in today's health care facilities, UVGI should continue to be viewed not a routine replacement for ventilation, but rather as a supplement when needed under the conditions and parameters described in this review. It does not appear to have a role in the OR, where air changes are well above 4-6 ACH, or in properly designed AII rooms. Many questions remain regarding how to achieve a balance between utility and safety; hopefully, the necessary research will continue.

",0.7196582511214766
Commentary Considerations for Recommending Extended Use and Limited Reuse of Filtering Facepiece Respirators in Health Care Settings,"Public health organizations, such as the Centers for Disease Control and Prevention (CDC), are increasingly recommending the use of N95 filtering facepiece respirators (FFRs) in health care settings. For infection control purposes, the usual practice is to discard FFRs after close contact with a patient (""single use""). However, in some situations, such as during contact with tuberculosis patients, limited FFR reuse (i.e., repeated donning and doffing of the same FFR by the same person) is practiced. A related practice, extended use, involves wearing the same FFR for multiple patient encounters without doffing. Extended use and limited FFR reuse have been recommended during infectious disease outbreaks and pandemics to conserve FFR supplies. This commentary examines CDC recommendations related to FFR extended use and limited reuse and analyzes available data from the literature to provide a relative estimate of the risks of these practices compared to single use.","Analysis of the available data and the use of disease transmission models indicate that decisions regarding whether FFR extended use or reuse should be recommended should continue to be pathogen-and event-specific. Factors to be included in developing the recommendations are the potential for the pathogen to spread via contact transmission, the potential that the event could result in or is currently causing a FFR shortage, the protection provided by FFR use, human factors, potential for self-inoculation, the potential for secondary exposures, and government policies and regulations. While recent findings largely support the previous recommendations for extended use and limited reuse in certain situations, some new cautions and limitations should be considered before issuing recommendations in the future. In general, extended use of FFRs is preferred over limited FFR reuse. Limited FFR reuse would allow the user a brief respite from extended wear times, but increases the risk of self-inoculation and preliminary data from one study suggest that some FFR models may begin to lose effectiveness after multiple donnings.

The Centers for Disease Control and Prevention (CDC)-including the National Institute for Occupational Safety and Health (NIOSH), as well as the Occupational Safety and Health Administration (OSHA) and the Food and Drug Administration (FDA)-develop regulations and/or recommendations for the use of respiratory protection in health care settings, and each agency plays a different role which impacts the use of them in health care. CDC develops recommendations for the use of respirators to reduce the spread of disease in health care settings. NIOSH certifies respirators and develops recommendations on the use of respiratory protection in health care workplaces to protect workers. OSHA develops and enforces workplace regulations on respiratory protection. FDA clears the sale of certain types of respirators as medical devices.

The most commonly used type of respirator in health care settings are NIOSH certified N95 filtering facepiece respirators (FFRs). These devices are disposable, tight-fitting airpurifying respirators that have a filter efficiency of 95% or greater for a standard test aerosol. (1) FFRs are also used by workers in many industries to reduce the amount of harmful dusts and aerosols they inhale. Workers are expected to wear their FFR during all periods of exposure. However, there are times of non-exposure when workers need to remove their FFR (e.g., take a drink of water, use the restroom, or go on a rest break) or situations during use when their FFR must be replaced.

Employers have several options for FFR usage to handle these situations. During ""single use,"" users put on (""don"") a new FFR each time they need one and discard their used FFR each time they take it off (""doff""). Another option is commonly referred to as ""FFR reuse."" Reuse involves donning and doffing the same FFR more than once until the FFR is discarded. Employers benefit from FFR reuse compared to single use by extending the lifetime of the FFR so that fewer need to be purchased. There is no specific restriction on the number of uses or donnings. Rather, historical guidance is focused on the length of time the FFR can be used and identifying situations when the FFR should be discarded. In general, NIOSH (2) specifies that the service life of all filters on NIOSH-approved respirators is limited by considerations of hygiene, damage, and breathing resistance and that any filter should be replaced if it becomes soiled, damaged, or causes noticeably increased breathing resistance. In workplaces that could produce high cumulative particulate filter loading (i.e., >200 mg), the service time for N95 FFRs should only be extended beyond 8 hr of use (continuous or intermittent) by performing an evaluation that demonstrates that continued use will not reduce the filter efficiency.

(product code = MSH) occurred in 1996, after FFRs were first recommended by CDC as the minimum level of protection for health care workers (HCWs) treating patients with tuberculosis (4) and NIOSH updated its certification requirements to create the N95 class of filters. (1) Most (22/31 = 71%) of the surgical N95 respirator models in the FDA database were cleared after 2005, which coincides with a period of increased interest in these types of products due to concerns about an infectious disease pandemic.

Because of the concerns that previously used FFRs may be contaminated with infectious material (i.e., act as a fomite), the factors that a health care employer considers in formulating FFR use policies (e.g., single vs. reuse) for its employees are also different from employers in industrial settings. Despite this concern, FFRs are reused under certain conditions in health care. (11) In the health care context, reuse is defined as a HCW donning the same FFR for a series of close patient contacts and doffing it at the end of each of the close patient contacts before it is discarded. Even when FFR reuse is practiced or recommended (discussed in the next section), restrictions are in place (e.g., discard when FFR is contaminated or damaged, becomes difficult to breathe through, and so on) which limits the number of times the same FFR is reused. Thus, FFR reuse is sometimes referred to as ""limited FFR reuse."" Options for limited FFR reuse were provided when FFRs were first introduced as the minimum level of respiratory protection for HCWs in close contact with patients with tuberculosis. (4) (5) (6) Another related FFR use practice, termed ""extended use,"" involves donning a FFR and wearing it for multiple patient encounters without doffing and redonning between patient visits. Thus, the same FFR is worn continuously (for up to several hours) across multiple patient encounters before it is doffed. This practice is only practical when bundled with the practice of cohorting, which involves locating patients with a common diagnosis in the same unit, ward, or zone. Extended use can be implemented separately from reuse (i.e., like single use, discard the FFR once it is doffed) or combined with reuse. Compared to single use and reuse, recommendations for extended use in health care are fairly recent. The first time extended use of FFRs was identified as an option was during the 2009 H1N1 pandemic. (12) Both extended use and limited reuse of FFRs allow the employer to reduce its consumption of FFRs, prolonging existing supplies during a pandemic or respiratory pathogen outbreak or to save money and reduce waste during day-to-day operations (e.g., close contact with tuberculosis patients) by using fewer FFRs, (13) similar to the benefits found for industrial settings. This commentary examines recommendations related to extended use and limited reuse of FFRs in health care. Key scientific and policy issues are highlighted along with considerations for policy makers to weigh when making decisions on whether to recommend extended use and/or limited reuse of FFRs during routine health care situations and for public health emergencies involving respiratory pathogens that have the potential for aerosol transmission. Finally, key knowledge gaps are discussed to identify additional data needs that could enhance understanding of the risks for transmission of diseases associated with FFR extended use and limited reuse. Table I summarizes past and current recommendations for extended use and limited reuse of  FFRs. CDC recommendations were selected for this analysis because of their widespread  recognition in health care. In 2007, CDC published general infection control guidance for isolation precautions, which included a list of all pathogens and medical procedures in which respiratory protection was recommended. (14) For certain pathogens affecting defined populations (e.g., TB) or infectious agents of special interest to health care (e.g., epidemiologically important organisms such as severe acute respiratory syndrome (SARS)] and influenza), CDC publishes detailed specialized infection control guidance. For this analysis, we selected all of the respiratory pathogens in which specialized infection control guidance was published as either interim or final recommendations and included the use of respiratory protection (N95 FFR or higher). This strategy provided a diversity of respiratory pathogens for analysis. These situations include two recent outbreaks/pandemics (2004 SARS and 2009 H1N1 flu), two routine situations (TB and seasonal influenza), and two pathogens of concern (Avian Influenza A (H5N1) and Avian Influenza A (H7N9)).

Cost can be a consideration for adopting extended use and limited reuse practices as it was in adopting the recommendation to allow limited reuse of FFRs when working in close contact with TB patients. However, the CDC recommendations on limited reuse and extended use have primarily considered the specific pathogens involved and the specific characteristics of the event. The first key factor is whether contact transmission is possible for the pathogen. Contact transmission of pathogens occurs through direct or indirect contact with the patient or the patient's environment via blood or body fluids (e.g., respiratory secretions). For pathogens in which contact transmission (e.g., fomites) is not a concern, limited reuse of FFRs has been determined to be a viable option. For TB, the CDC maintains that ""a respirator classified as disposable can be reused by the same HCW as long as it remains functional and is used in accordance with local infection control procedures."" (15) Infection control guidelines for TB (14) recommend only airborne precautions; contact isolation precautions are only needed if extrapulmonary lesions are draining, which occurs rarely. Contact transmission of TB is thought to be highly unlikely. (16) This contrasts with the recommendations for seasonal influenza where contact with contaminated surfaces and objects is considered a possible mode of transmission. (17) In situations where airborne precautions are recommended, and contact precautions are recommended or contact transmission is possible, the second key factor in the CDC recommendations is the likelihood of a localized shortage of the FFRs needed to protect HCWs during high-risk procedures. The use of FFRs for protection of HCWs during routine infectious disease procedures generally does not result in a FFR shortage, as evidenced by CDC's guidance to wear a FFR during aerosol generating procedures (AGPs) on patients diagnosed with seasonal influenza; this does not include an option for FFR extended use or reuse. (17) extended use, or limited reuse, but instead refer back to the general CDC infection control guidance (14) which specifies single use. These recommendations are consistent with the other four recommendations in Table I based on the potential for contact transmission of these pathogens and that FFR shortages are unlikely in the near-term.

However, during periods of high usage (e.g., public health emergencies such as an influenza pandemic (20) or widespread respiratory pathogen outbreak), supplies of FFRs can quickly become depleted because most hospitals maintain only a small inventory of FFRs. Not surprisingly, shortages were reported at the hospital level during both the 2004 SARS outbreak and the 2009 H1N1 influenza pandemic. (21) (22) (23) In a recent evaluation of respiratory protection programs in California hospitals, it was reported that half of the hospital managers interviewed (n = 48) reported shortages of FFRs during the 2009 H1N1 outbreak due to increased demand and supplier lag time in filling orders. (11) During the 2004 SARS and 2009 H1N1 events, recommendations were made allowing the option for extended use and limited reuse, although both recommendations acknowledged situations in which these strategies would not be appropriate.

For SARS, CDC stated in its interim guidance that ""health care facilities may consider reuse as long as the device has not been obviously soiled or damaged (e.g., creased or torn)"" and ""if a sufficient supply of respirators is not available."" (24) The recommendation recognized the importance of preventing contamination through contact with infectious material on the outside of the respirator. CDC also addressed concerns about a shortage of FFRs during the 2009 H1N1 flu pandemic with supply-conserving strategies for hospitals that included the possibility of extended use and limited reuse of FFRs, with extended use preferred over limited reuse. (12, 25) Reuse of FFRs was reported to occur quite often in California hospitals during 2009 H1N1 as either a response to shortages or as standard practice; 81% of survey respondents indicated that their hospital had a plan to implement reuse, while only 12.5% indicated plans to apply extended use. (11) 

As shown in Table I and discussed above, prior and current CDC recommendations made for FFR extended use and reuse were largely based on the type of infection control precautions or transmission mode(s) associated with that pathogen and whether shortages of FFRs were observed or anticipated. Those recommendations were based upon the data available at that time, which often lacked evidence to answer key questions regarding the effectiveness of extended use or limited reuse and the risk of disease transmission from handling potentially contaminated FFRs. In 2006, the Institute of Medicine (IOM) addressed (26) the reusability of facemasks, and summarized the data available to support previous recommendations. The committee agreed with the previous CDC guidance and recommended that ""avoiding contamination [of FFRs] will allow for limited reuse."" The IOM also identified key knowledge gaps that served as a catalyst for increasing awareness of the research needs.

Since publication of the IOM report, numerous research groups have attempted to address some of these knowledge gaps. In the following sections, we discuss studies published since Fisher 2006 that address key areas of FFR extended use and reuse, including FFR protection, human factors (e.g., physiological/psychological effects), self-inoculation, and secondary exposures (e.g., from particle reaerosolization and co-contaminants). Some earlier studies (pre-2006) are also discussed to provide context where needed. The purpose of this analysis is to improve the scientific basis for future recommendations for employers in health care settings to consider when implementing FFR extended use and/or limited reuse. For each of the issues below, a qualitative assessment of the risks of extended use and limited reuse versus single use is presented (see Table II) .

One possible concern with FFR extended use and reuse is that extending the useful life of a FFR could reduce its protective effectiveness (i.e., when worn properly and used in a complete respiratory protection program it provides exposure reduction consistent with the assigned protection factor for this class of respirator). The protection provided by a properly used FFR results primarily from a combination of its ability to filter out (remove) biological aerosols from the inhalation air stream of the wearer and seal tightly to the face (i.e., ""fit""). Each of these concerns has been studied (to some extent) or can be assessed using existing data.

Filter Media-Most N95 FFRs contain a polypropylene electret filtering medium within the layers of a FFR ( Figure 1 ). The electret filtering medium has been shown to capture and retain a majority of airborne biological particles compared to the layers next to the face and farthest from the face, although particle size could affect particle deposition location. (27, 28) Electrets and other similar types of nonwoven air filter media are not unique to FFRs. (29) They are commonly found in various dust collection systems (e.g., vacuum cleaners, clean rooms, and home heat ventilation and air conditioning (HVAC) systems). Recommended replacement life for electret filters in air cleaning systems is typically 3 months of normal use, as the fundamental mechanisms (diffusion, interception, impaction, electrostatic, and so on) of these types of filters do not readily degrade over time with normal use.

Only a few studies have been done to verify FFR performance in extended use or reuse type scenarios. Moyer and Bergman (30) conducted a laboratory evaluation of the intermittent use (short-term use once per week) of N95 filters over several months. Filtration efficiency was reduced to below 95% for filters from 2 of the 3 manufacturers after 9 and 13 weeks of simulated reuse. Researchers at the Institut de recherché Robert-Sauvé en santé et en sécurité du travail (IRSST) validated the long-term filter performance of a single N95 FFR model. (31) For inert particles below 200 nm, filter efficiency levels remained above 97.3%, even after 5 hr of particle loading (i.e., continuous use). Not surprisingly, another study found that samples from 19 of 21 N95 FFR models stored for up to 10 years had expected levels of filtration performance. (32) Fit-Fit is a measurement of the efficacy of the seal between the FFR and the face of the wearer. Components of the FFR, such as straps, face seal material, shape, and adjustable nose bands influence FFR fit. Several studies have analyzed strap performance and fit for multiple donnings of FFRs. Roberge simulated donnings and reported reduction in the strap load for each successive donning with the majority of the reduction occurring after the first donning. (33) However, the FFR model with the lowest restorative strap performance load was still able to pass fit-testing. Bergman et al. examined the effect of FFR reuse on fit by measuring the fit factors of 6 FFR models donned by 10 subjects up to 20 times with wear times of approximately 2 min between each donning. (34) FFR fit gradually decreased over multiple consecutive donnings; however, good fit was observed for some subjects on some models even after 20 donnings. The best levels of fit were observed for the first five donnings, likely because of the relatively little wear on FFR components (e.g., head straps and nosepieces) compared with later donnings.

It was concluded from that study that five donnings could be performed before fit factors started to drop below 100. Catastrophic failure of the FFR (e.g., complete head strap breakage, nosepiece becomes damaged, and so on) should have no effect on risk, if users diligently perform device inspection procedures required during the FFR donning process. Fit of FFRs is also a concern for extended use where the FFR may become wet and deformed due to moist exhaled breath and facial perspiration. Hauge et al. measured realtime fit while HCWs performed three 10-min simulated patient care scenarios. It was determined that initial fit was predictive of fit during the tasks as the five subjects with initial fit factors greater than 200 registered simulated workplace protection factors greater than 400, and the three subjects with initial fit factors less than 200 had simulated workplace protection factors ranging from 132 to 326. (35) Although the tasks were only a combined 30 min, the study design could be considered an extended use scenario covering three patient encounters.

Workplace Protection Factors-Few studies in health care settings measure workplace protection factors (WPF). WPF is a measure of the protection provided by a properly functioning respirator when correctly worn and used in the workplace and is determined as the ratio of the particle concentration outside the respirator over the particle concentration inside the respirator. Infectious bioaerosols are hard to detect and differentiate from noninfectious bioaerosols. (36) Furthermore, assuring compliance during all periods of exposure in the health care setting is challenging. (37) Several studies in other workplaces have assessed protection over extended periods of continuous use by measuring the WPFs: up to 224 min in a steel foundry (38) ; 172 min in a concrete factory (39) ; and 60 min on farms. (40) All three studies concluded that the N95 FFRs provided levels of protection consistent with expectations (i.e., protection factors were ≥ the assigned protection factor of 10), with reported geometric mean WPF values ranging from 18 to 223. No evidence of reduced protection as a function of time was noted in these studies. The aerosol challenge encountered at the farm locations consisted of biological aerosols such as endotoxins and fungal spores which are more closely related to the bioaerosols in a hospital than to the dust encountered at the foundry and concrete factory.

Summary-Overall, the scientific studies provide evidence that extended use is unlikely to reduce the protection afforded by a FFR (see Table II ) and support the CDC TB infection control guidance which states in the Frequently Asked Questions section, ""Disposable respirators can be functional for weeks to months."" However, as noted in Table II , some additional cautions may apply for reuse. Reuse involves multiple repeated uses (donnings) of the same device, and it is possible that some components (straps, nose clips, and so on) could begin to degrade over time and reduce protection. These effects are likely specific to each model of FFR, but the only study published (34) to date on this topic suggests that limiting FFR reuse to no more than five donnings or reuses would provide an adequate safety margin.

One of the consequences of extended use is the need to wear the FFR continuously for up to several hours, compared with single use or reuse in which the FFR would only be worn during the period of close contact with the patient (typically less than 15-20 min). Thus, questions have been raised regarding the safety of long-term FFR use and, if safe, how long HCWs can physiologically and psychologically tolerate extended use.

NIOSH researchers found that FFR use caused no or minimal increases in heart rate, respiratory rate, and transcutaneous carbon dioxide as well as no differences in oxygen saturation on test subjects during 1 hr of low-moderate treadmill exercise when compared with wearing no respirator (control). (41) (42) (43) They also reported that 2 hr of continuous FFR use at low-moderate work rate did not cause a change in core body temperature, (42) and there was no significant increase in FFR deadspace heat or humidity after the first hour. (44) Taken together, these studies suggest that FFR use for 1-2 hr should cause minimal physiological stress to individuals medically cleared to wear FFRs.

A study by researchers affiliated with Department of Veterans Affairs reported how long 27 HCWs could tolerate multiple bouts of 2-hr-long extended use periods, interspersed with 15-30 min breaks. (45) Median tolerance times of 6.6 hr and 5.8 hr were reported for the two FFR models without exhalation valves. Only 16 and 18 of the 27 subjects using those two models were able to complete all four 2-hr use periods of continuous use; the most reported reason for stopping use was head and facial discomfort (e.g., heat). In a follow-up analysis of the same data, it was concluded that FFR discomfort negatively affects respirator tolerance over time, but respirator intolerance is not associated with perceived self-reported exertion. (46) Although the number of participants was small, a recent study reports greater tolerance of extended use of FFRs among HCWs. (47) They reported that 9 of 10 study participants (nurses) were willing to wear FFRs for the entirety of two full 12-hr shifts, stopping only to eat and drink, because it was the end of their shift, or because the FFR was too uncomfortable. The nurses tolerated FFR continuous wear for an average of 223 min on day A study conducted in a teaching hospital in Brazil considered changes in appearance and possible physical damage resulting from FFR reuse. (48) A new N95 FFR was distributed to each nurse once per month and reused as needed until the next new N95 FFR was provided. The researchers found that within 5 days, the majority of the distributed cone-shaped FFRs exhibited visible ""wear and tear,"" indicating possible physical damage (caused by folding them for storage in a pocket) and visible stains/dirt on the FFR interior and exterior surfaces.

Although the performance of the respirators was not assessed, the data suggest that some models may be more suitable for reuse (e.g., those that fold easily) or that hospitals should enforce some restrictions on reuse (e.g., replace every 5 days, rather than every 30 days).

Overall, the available scientific studies provide evidence that HCWs will experience greater discomfort during periods of extended continuous wear of FFRs, but this discomfort will likely be tolerable for most HCWs. Continuous FFR use over extended periods of time up to 12 hr is unlikely to harm workers (see Table II ) who have been medically cleared for respirator use. Furthermore, because HCWs need to take occasional breaks during their work shift (e.g., to use the rest room, eat or drink, and so on) FFR extended use of greater than 4 consecutive hours is unlikely in most settings.

One knowledge gap often cited against allowing FFR extended use and limited reuse is whether a FFR worn during close contact with an infected patient is likely to serve as a fomite. Historically, little data were available to assess the transfer potential of respiratory pathogens from the FFR to the hands of the HCW, resulting in the potential for selfinoculation. Similar to other potential fomites (e.g., surfaces, medical devices, and stethoscopes (49) ) assessing the level of risk of self-inoculation associated with touching a used FFR is complex. It is very difficult to trace a specific hospital-acquired infection to a particular object. Thus, while no studies have identified the use of a contaminated FFR as a source of infection, the possibility cannot be ruled out.

Nicas and Sun and Nicas and Jones have provided models for transmission of pathogens, including influenza, in health care settings. (50, 51) Nicas and Sun considered fomite hazards of textile and nontextile surfaces and in room air to estimate the expected pathogen dose to a HCW's mucous membranes and respiratory tract. (51) Nicas and Jones modeled four influenza virus exposure pathways including fomite transmission. A similar approach is used below to estimate the potential fomite hazard of used FFRs. Factors that influence the risk of self-inoculation directly associated with handling a contaminated FFR include the quantity of respiratory pathogens deposited on the FFR surface (i.e., contamination levels), viability of the pathogen, transfer efficiency of the pathogen from FFRs to the hands of the wearer, and area of hand contact with the contaminated surface.

FFR Contamination Levels-There are no published studies that quantify the amount of pathogens on FFRs used in clinical settings. However, simple mathematical models can be used to provide some estimates. In one study, influenza aerosol concentration, breathing rate of the wearer, time of patient interaction/FFR use, and particle retention efficiency of the FFR were used as inputs to a linear model to estimate influenza contamination levels inside and on the surface of the FFR (C FFR ). (52) Using this model, an increase in any parameter results in higher levels of C FFR (i.e., total number of pathogens on the FFR). For a typical HCW scenario, using model input values estimated from the peer-reviewed literature, the model calculated that C FFR would be approximately 4500 influenza viruses given an influenza aerosol concentration of 12,000 viruses m -3 , a breathing rate of 1.140 m 3 hr -1 , a particle retention efficiency of the FFR of 0.991, and a 20-min patient interaction/FFR use time. The values for influenza aerosol concentration and wear time found in the literature varied more than other parameters used in the model. Thus, for extended use which involves longer wear times, the number of pathogens available for transfer to the hands is increased.

This model illustrates the need to take into account HCW procedures (e.g., AGPs) which can increase C FFR by up to 2200% and the potential for administrative controls such as source control of patients (e.g. asking patients to wear face-masks) which can reduce C FFR by up to 71%. (53, 54) In addition to administrative controls, the use of engineering controls such as local exhaust ventilation might reduce C FFR . Similarly, previous recommendations issued during the SARS outbreak suggested the use of a surgical mask or faceshield on top of a FFR to reduce C FFR (26) ; although subsequent work has identified a number of potential concerns, including regulatory compliance with this approach. (55) While developed for influenza, this model could be used to approximate C FFR resulting from any respiratory pathogen if estimates of the concentrations of the pathogen near the breathing zone of the HCW could be obtained.

Pathogen Survival-Given that FFRs can become contaminated with pathogens when used in close contact with infectious patients, the next factor under consideration is how long these pathogens can survive (remain infectious) and, for some types of microorganisms, grow (propagate) on the FFR surface. Some studies in the early 1990s found that under ideal conditions (e.g., humidity >78%), fungi and certain bacteria could grow on filters made of cellulose because they are capable of digesting cellulose. (56, 57) However, modern (post-1995) FFRs are made of polypropylene, which cannot serve as a nutrient for bacteria. (58) Studies confirmed that surrogates for TB were not able to grow on polypropylene-based filter media, even under incubation conditions. (58) (59) (60) (61) Although bacteria were found to survive for several days, this was not considered a concern because contact transmission for TB is considered unlikely (see Table I ). These studies lent support for the FFR reuse guidance being drafted at that time.

Respiratory viruses have received more recent attention. While growth is not an issue because these pathogens require a host organism to propagate, their persistence or survival on surfaces is a concern. In general, the evidence indicates that viruses are more persistent on nonporous substrates compared with porous materials such as FFRs. Bean et al. reported laboratory-grown influenza A and influenza B survived for 24-48 hr on hard, nonporous surfaces but survived for <8-12 hr on porous substrates. (62) Similarly, another study (63) found that influenza remained viable for 8 hr on FFR samples, but infectivity dropped below detection limits at <24hr. However, Tiwari et al. examined the persistence of two avian respiratory viruses including influenza H13N7 on various substrates and although they found that both viruses survived longer on nonporous surfaces than on porous ones, the viruses remained active for up to 6 days. (64) In one laboratory study, pH1N1 was detected on FFRs for up to 6 days with an average of 90% reduction (1 log) in viability during this time period. (65) Similar findings were found using MS2 phage as a surrogate for respiratory viruses. (66) A surrogate for SARS coronavirus, transmissible gastroenteritis virus, was shown to remain viable for 24 hr on FFR samples with an estimated 99% (>2 log) reduction in titer. (67) )

Another study found that inactivation of Φ6 bacteriophage spiked on a N95 FFR surface was highly sensitive to environmental conditions, with a ∼1 log reduction over 24 hr at 40% relative humidity versus ∼4 log reduction over 24 hr at 60% relative humidity. (68) Although it is difficult to generalize from these conflicting findings, it is clear that for reuse during a work shift with short storage times (< 1 hr) most of the trapped pathogen will remain viable. Some reduction in viability might occur for overnight (>12 hr) or weekend (>24 hr) storage depending upon storage conditions (temperature, humidity, light, and so on) and pathogen type and strain.

In many cases where pathogens remain persistent and pose a contact threat, cleaning and disinfection regimens are routinely used. For example, countertops, exam tables, and other surfaces of patient rooms are often cleaned when a patient is discharged. Research has been conducted on cleaning and disinfecting procedures for FFRs for possible reuse by the same HCW. Although the results appear to be promising, the practice is not currently recommended (69) (70) (71) (72) and thus is not a viable solution at this time to reduce the fomite potential of a reused FFR.

Recent improvements in antimicrobial chemistries have allowed some manufacturers to begin incorporating these technologies into FFRs. There are now a few surgical N95 FFRs incorporating antimicrobial technologies (product code = ONT) that have been cleared by the FDA as medical devices. (9) Interestingly, one device has been cleared by the FDA with claims of 8 hr of continuous use. Unfortunately, none of these devices has been evaluated in the peer-reviewed literature for claims regarding their ability to reduce fomite potential. However, several studies (73) (74) (75) (76) (77) have looked at the ability of prototypes or devices, not cleared by FDA, that incorporate some type of antimicrobial chemistry in them to render trapped pathogens inactive over time (i.e., storage time between uses). These studies suggest that efficacy of antimicrobial FFRs for this application is dependent on the pathogen, antimicrobial agent, storage conditions, and specific test method used which makes generalization of findings difficult. (73, (78) (79) (80) (81) Although promising, the lack of conclusive evidence suggests that additional work is needed before FFRs incorporating antimicrobial technologies can be factored into FFR reuse recommendations.

Transfer Efficiency-Because FFRs can become contaminated with pathogens likely to remain infectious during typical extended use and reuse scenarios, the next factor to assess is the likelihood of pathogens transferring from the FFR to the hands of HCWs. Unfortunately, no studies exist that quantify the percentage of pathogen transferred from the FFR to the hands of HCWs. However, similar to estimating contamination levels, models can be used where estimates of the key input parameters are available. A simple model for estimating the amount of pathogen transferred to the hands (C hand ) of HCWs from contaminated FFRs uses C FFR (the number of pathogens on the FFR as discussed above), transfer efficiency of the pathogen (E t ), and contact area of the hands (A h ) and the FFR (A FFR ).

Unfortunately, no peer-reviewed sources are available on the transfer efficiency of relevant pathogens from a FFR to skin and others surfaces. However, an unpublished conference presentation reports the transfer efficiency of a bacterium, Bacillus atrophaeus, from FFRs to synthetic skin as 0.005% and 0.05% for touching and rubbing, respectively. (82) Other microbial transfer studies for porous surfaces have shown similar results. For example, Rusin et al. reported transfer efficiencies for a bacterium, Micrococcus luteus, of 0.13% from a 100% cotton substrate and 0.06% from a 50:50 cotton/polyester substrate. Even lower transfer efficiencies (<0.01%) from those surfaces were reported for bacteriophage PRD-1. (83) Another recent study compared the transfer efficiency of bacteria and viruses from several porous and nonporous surfaces to the fingers. (84) In general, the lowest transfer efficiencies were found for porous surfaces under low relative humidity. Isoelectric point and hydrophobicity of the surface were also important factors.

As discussed previously, C FFR can be estimated. For simplicity, we use the influenza values reported above from Fisher et al. as a surrogate for all respiratory pathogens. (52) The contact area of the hands depends upon the action of the HCW (Table III) . For extended use, it is likely that only the finger tips are used to touch the FFR surface (e.g., to reposition the FFR). The total surface area of the volar portion of the fingertips has been estimated to be 7.34 cm 2 . (85) However, when implementing FFR reuse, the proper donning process requires a user seal check step, which requires the user to cover the entire FFR surface by cupping both hands around the filter surface. In this situation, A h would be very similar to A FFR , which has been estimated to be approximately 175 cm 2 , but varies among the various FFR models. Assuming uniform deposition of the pathogen over the surface of the FFR, applying input values of 4,500 FFR -1 for C FFR and 0.1% as an approximation for E t to the equation results in an estimated 4.5 pathogens being transferred to the hands of the HCW during the user seal check step and <1 pathogen for each touch involving a fingertip.

Summary-While the model above indicates that some pathogens from a contaminated FFR could transfer to the hands, other factors also affect the risk of infection. Steps in the fomite pathway such as the transfer of viable pathogens from hands to respiratory tract ports of entry, transport of viable pathogens to the site of infection, and the infectious dose of the pathogen are not unique to extended use and reuse of FFRs, but are common to any potential fomite. A full assessment that takes into account these steps is beyond the scope of this commentary. However, the model developed by Nicas and Sun indicates that each successive step in the fomite pathway further reduces the number of infectious pathogens reaching the site where infection can occur, reducing the risk of self-inoculation from practicing FFR extended use and/or limited reuse. (51) In theory, extended use should not present a significant self-inoculation hazard, as ideally, the HCW's hands should never come in contact with the contaminated filtering surface when proper doffing protocols are followed. (86) However, the Rebmann study (47) reported that HCWs touched or adjusted their FFR on average 10-20 times per 12 hr. shift. Even with this amount of contact, our analysis, based on the data and the models discussed above, suggests that very few pathogens are likely to make it to the site of infection each time the hand or fingertip comes in contact with the FFR. Thus, extended use is considered minimal risk for typical patient interactions (Table II) when coupled with training and education to reinforce proper use (e.g., don't touch the FFR surface) and adherence to hand hygiene recommendations.

Reusing FFRs provides multiple opportunities for the hands of HCWs to come in contact with any infectious microbes on the respirator surface and thus involves a higher level of risk compared to extended use (Table II) . HCWs' hands would presumably contact the contaminated FFR surface when placing the FFR onto the face, adjusting the position of the FFR and flexible strap across the nasal bridge (if applicable), and when performing the user seal check, a requirement after donning a respirator and after each adjustment to the respirator. Similar to extended use, fomite risks from FFR reuse can be mitigated through training and education to reduce unnecessary touching of the FFR and rigorous adherence to hand hygiene. Steps to limit FFR contamination (e.g., masking patients, use of engineering controls, face shields, and so on) can also limit fomite risks, as C hand is proportional to C FFR .

Concerns have been raised that extended use of FFRs could result in additional opportunities for pathogen transmission to co-workers and patients due to reaerosolization of trapped pathogens to the environment from a sneeze, cough, or through rough handling. Several studies have addressed this issue. Most recently, Fisher et al. examined virus reaerosolization from FFRs and concluded that the risk of virus transfer to the environment from the FFR was negligible, a finding key to extended use and reuse. (87) FFRs were challenged with virus-containing droplet nuclei with a size range of 0.65 to 7.0 μm (with the majority <1.1 μm) and challenged with reversed airflow to simulate a sneeze or cough. The highest reaerosolization of 0.21% occurred with a droplet nuclei challenge while a droplet challenge led to reaerosolization of less than 0.0001%. These findings are consistent with earlier studies that examined reaerosolization of bacteria and inert particles. Qian et al. and Willeke and Qian reported the reaerosolization of less than 0.2% for bacteria deposited on N95 FFRs as aerosols and challenged with a reverse airflow consistent with a violent sneeze or cough. (88, 89) Kennedy and Hines found that less than 0.3% of polystyrene latex microspheres reaerosolized from FFRs when dropped from a height of 3 feet (90) Overall, these data provide evidence that the risks of secondary exposure due to reaerosolization or rough handling associated with FFR extended use or limited reuse can be considered negligible (Table II) . Similar to the fomite concerns discussed above, secondary exposure risks could increase as C FFR , the number of pathogens on the FFR, increases (i.e., higher C FFR = higher levels of reaerosolized pathogen), so steps taken to limit FFR contamination (e.g., masking patients, faceshields, local exhaust ventilation systems) should be implemented where possible.

In situations where patients are under contact precautions, such as those co-infected with common health care pathogens with the ability for prolonged environmental survival (e.g., Vancomycin-resistant enterococci, Clostridium difficile, and norovirus), it may be prudent to have HCWs discard FFRs after close contact because these pathogens could be transferred to other patients via the unclean hands of the HCW.

Sharing FFRs among HCWs could also result in a secondary risk if at least one of the users is infectious (symptomatic or asymptomatic). For example, a specialized face mask containing electret filter media (similar to those found in N95 FFRs) was worn in one study (92) to successfully collect infectious virus from the exhaled breath of symptomatic test subjects. Because of respirators' ability to trap respiratory pathogens, sharing a contaminated FFR could result in disease transmission. However, proper labeling, training, and education can be effective at limiting any inadvertent sharing of FFRs during reuse.

We also conducted an Internet search and reviewed FFR extended use and reuse recommendations issued by other United States agencies (e.g., FDA and OSHA) and professional organizations (e.g., Association for Professionals Infection Control and Epidemiology). (93, 94) In terms of FFR extended use and limited reuse, we identified no major discrepancies among the recommendations from the Association for Professionals in Infection Control and Epidemiology (APIC), OSHA, and the CDC recommendations in (Table I) . For example, OSHA TB guidance (7, 95) indicates that disposable respirators (i.e., FFRs) can be reused by the same HCW, as long as the functional and structural integrity of the respirator is maintained and the outside of the filter is inspected before each use for signs of physical damage or soiling, and discarded if signs are present.

While OSHA is responsible for regulating employers to provide a safe workplace for their employees and CDC makes public health recommendations that are often adopted by hospitals, FDA has a different role in health care settings. The FDA regulates the manufacture and labeling of medical devices. (96) Medical devices are cleared by the FDA under the Food, Drug, and Cosmetic Act based upon data submitted by the manufacturer to support the claimed intended use of the product. Under 21 CFR 878.4040, FDA classifies surgical N95 respirators as a type of surgical apparel, intended to be worn by operating room personnel during surgical procedures to protect both the surgical patient and the operating room personnel from transfer of microorganisms, body fluids, and particulate material. As part of the labeling requirement, FDA recommends that manufacturers state whether a device is intended to be a reusable device or a single-use disposable device. (9) Some surgical N95 respirator models are cleared by the FDA with claims of being a singleuse device, while other manufacturers do not make such claims. (10) For surgical N95 respirators labeled as ""single use only,"" extended use or limited reuse could be considered as an ""off label"" use of these products. FDA has specific requirements for reuse (""reprocessing"") of single-use medical devices. (97) Unfortunately, as discussed earlier in this manuscript, some hospital use practices for these types of medical devices such as limited FFR reuse were first recommended (4) (5) (6) (7) and put into practice prior to FDA's involvement. There is also a general lack of awareness among infection control professionals and safety/ employee health administrators in understanding FDA's role in regulating surgical N95 respirators. (98) These factors contribute to the prevalence of ""industrial N95 FFRs"" used in health care settings. These industrial N95 FFRs are NIOSH-certified FFRs, but have not been cleared by the FDA as medical devices. Several of these industrial N95 FFRs were stockpiled by the CDC in the Strategic National Stockpile. (99) In the future the different regulatory and policy perspectives will need to be factored into FFR extended use and limited reuse recommendations. For example, recommendations for operating rooms, where soiling and potential contamination from blood borne pathogens will likely occur, might be different. In those situations, limited reuse should only be considered after consultation with the surgical N95 respirator manufacturer and local hospital infection professionals. benefits (e.g., cost savings, ability to extend existing supplies, reducing the ""burn rate,"" and so on) of FFR extended use and limited reuse.

The primary purpose of this article is to assess recent scientific findings to assist policy makers when making decisions on whether to recommend that employers in health care settings permit FFR extended use and/or limited reuse during routine operations and for future public health emergencies. The authors acknowledge that the evidence discussed above is not always as sufficient as desired to develop evidence-based policy decisions. However, decisions on how to protect exposed workers must be made in the present and cannot wait until additional evidence is available. In the interim the available evidence can be useful for policy-based and pragmatic public health decision ideologies. (100) As discussed by Rosella and coauthors, (100) emerging public health situations require a balance between various factors. Both evidential and policy considerations are important. Policy makers need to use the best evidence available to them, even when it has substantial limitations, acknowledge the uncertainties, and account for them in as practical a way as possible.

For recommending FFR extended use and/or limited reuse for routine events, policy makers should weigh the increased risks for disease transmission from FFR extended use and limited reuse against the inconvenience, cost, and waste of single use. In public health emergencies, policies on FFR extended use and limited reuse should weigh the risks for disease transmission against the risk of disease transmission associated with sacrificing because of FFR shortages (e.g., foregoing respiratory protection or using surgical masks for pathogens or activities where N95 FFRs are recommended). Decisions regarding whether FFR extended use or limited reuse should be recommended need to continue to be pathogenand event-specific. The two most important factors driving this decision should be whether the pathogen is likely to spread (in part) via contact transmission and whether the event could result in or is currently causing a FFR shortage.

This analysis of recent research (post-2006) generally supports CDC guidance issued since 2004 for FFR extended use and limited reuse for routine events such as TB and seasonal influenza (during AGP) as well as the public health emergencies such as the 2004 SARS and 2009 H1N1 flu pandemics. While recent findings largely support these CDC recommendations, some new cautions and limitations should be considered in recommendations issued in the future as discussed subsequently.

Extended use offers a lower risk of self-inoculation compared to limited reuse given that the HCWs hands should ideally rarely contact the contaminated FFR surface. Training and education should be stressed to reinforce the need for strict adherence to guidance to minimize unnecessary contact with the FFR surface and strict adherence to hand hygiene practices. Extended use poses no additional health risk to a medically cleared respirator user and despite the additional discomfort should be tolerable for most HCWs. For these reasons, extended use should be preferred over limited reuse, even though FFR reuse requires the least change to current practices.

Limited FFR reuse would allow the HCW to doff the FFR to provide a brief respite from the psychological and physiological factors that decrease FFR comfort, but increases the potential for contact transfer when donning the used FFR and performing the user seal check. However, fomite transfer models indicate that the potential for transfer of pathogens from FFRs to the hands of the wearer is small suggesting that limited FFR reuse can be employed with minimal additional risk in most cases. An exception is reuse of FFRs after AGPs, where higher FFR contamination levels are likely to occur. Education and training should be emphasized to reinforce the need for proper hand hygiene when redonning the FFR, including inspection of the device for physical damage and performing a user seal check. Strict adherence to these steps should further reduce the potential to transfer virus from the hands to the points of entry of infection.

While limited FFR reuse remains a viable option for reducing usage rates and for situations involving a pathogen that does not spread via contact transmission, data suggest that FFR protection can begin to be reduced for some models after multiple donnings or uses. Guidance should emphasize the need for the employer to consult with the respirator manufacturer regarding the maximum number of donnings or uses suggested for the FFR models used in that location or to presumptively limit the number of reuses to no more than five to ensure an adequate safety margin, in the absence of new information to the contrary. 

",0.7187322348430077
Health care workers' perceptions and reported use of respiratory protective equipment: A qualitative analysis,"Little is known about health care workers' (HCW) perceptions of, or experiences using, respiratory protective equipment (RPE). We sought to characterize their perceptions and identify reasons underlying inappropriate use. Methods: We conducted 12 focus groups with nurses and nursing assistants at 4 medical centers. We analyzed the thematic content of 73 discrete ""stories"" told by focus group participants. Results: We identified 5 story types surrounding RPE use: 1) policies are known and seen during work routines; 2) during protocol lapses, use is reinforced through social norms; 3) clinical experiences sometimes supersede protocol adherence; 4) when risk perception is high, we found concern regarding accessing RPE; and 5) HCWs in emergency departments were viewed as not following protocol because risk was ever-present. Discussion: HCWs were aware of the importance of RPE and protocols for using it, and these supported use when protocol lapses occurred. However, protocol adherence was undermined by clinical experience, perceived risk, and the distinct context of the emergency department where patients continually arrive with incomplete or delayed diagnoses. Conclusions: Protocols, visual cues, and social norms contribute to a culture of safety. This culture can be undermined when HCWs experience diagnostic uncertainty or they mistrust the protocol and instead rely on their clinical experiences.","Advanced respiratory protective equipment (RPE), like powered air-purifying respirators and N95 respirators, are critical for protecting health care workers (HCWs) from contracting and spreading airborne infections. Proper RPE use reduces risk, yet existing research documents low adherence. 1 Moreover, the emergence of pathogens such as Ebola and severe acute respiratory syndrome (SARS), has raised awareness of the importance of respiratory protection. 2, 3 Although much work has been done to understand how discomfort (eg, facial pressure, shortness of breath) might affect use, [4] [5] [6] [7] [8] less is known about how beliefs, perceptions, or work experiences might influence protocol adherence. Understanding what contributes to a system-level safety culture can ensure that when more significant pathogens are present, and increased N95 use is needed, barriers to use can be systemically addressed.

HCW adherence to respiratory infection control guidelines, including vaccinations, are known to be influenced by personal and contextual factors, such as knowledge gaps, perceived risk, ethical and legal concerns, and economic issues 9, 10 Health behavior theories, such as the Health Belief Model, 11 have been used to examine adoption of health-related behaviors. 12 Health Belief Model constructsperceived severity, susceptibility, benefits and barriers to the health behaviors, perceived threat, cues to action, self-efficacy, and demographic factors-may inform whether protective action is taken. 13 The Health Belief Model has been previously used to understand use of respiratory protection. 14, 15 These studies found that perceived seriousness and perceived susceptibility were major factors in HCW decisions to wear respiratory masks during a SARS outbreak. However, there may be other unexplored factors impacting respiratory protection use. We therefore sought to characterize perceptions of RPE, identify reasons for use, and examine how work routines might impede or facilitate protocol adherence.

We used a qualitative study design to examine HCW's perceptions and reported RPE use. We focused on registered nurses (RNs) and nursing assistants (NAs) because they provide frontline care, spend significant time with patients, are frequently exposed to infectious agents, and thus are more likely to require RPE. 1, 16 This design facilitates identifying previously unknown issues from the participants' perspectives. Importantly, whereas some responses may not be ""true,"" the perception of their veracity may still inform behaviors and highlights the use of our qualitative approach. For example, transmission routes described by an HCW may not be biologically plausible, yet this understanding may inform RPE use.

We recruited from hospitals in the Northeastern and Midwestern United States (1 Veterans Health Administration and 1 academic medical center per region). Local contacts at each hospital provided eligible participants from adult inpatient medical, surgical, and intensive care units, and emergency departments (ED) information about our study. Focus groups were restricted to NA only or nurse only; however, they could provide patient care in any of the targeted recruitment units mentioned earlier. Focus groups often had more than 1 nurse or NA from a particular unit. Originally, we planned 2 focus groups per hospital, 1 each with NAs and RNs. However, an international Ebola outbreak spurred an additional focus group at each hospital of RNs who had Ebola prevention training.

The focus group guide (see Appendix), informed by the Health Belief Model, covered experiences using RPE (cues to action), reasons for use (perceived benefits and barriers), experiences with RPE (perceived seriousness and susceptibility), descriptions of situations when masks were not worn (motivating factors), and comfort and usability (motivating factors). We brought N95s and surgical masks to the focus groups. We focused questions and analysis on N95s. After obtaining informed consent, focus groups were audio-recorded and transcribed. Participants completed a survey about their employment and whether they had been fit tested or received RPE training. Study procedures were approved by the hospitals' institutional review boards.

We used a qualitative analytic strategy, initially guided by the Health Belief Model. However, during data review, we noted the Health Belief Model, which is a useful heuristic to organize the data, was insufficient to fully capture the rich narrative content of the data. We noted data were comprised of short stories relating to events surrounding RPE use. To take advantage of this data and reduce disaggregation of the findings, we organized the data into ""story units,"" defined as segments of text with a beginning, middle, and end. 17 Our team subsequently analysed transcripts looking for discrete ""story units."" Two team members independently reviewed each transcript and delineated the stories using a template. Each templated story was given a title, summary, and discussed by the full team. We then conducted an inductive thematic analysis of these stories, sorting them into different story types. We noted when participants brought up droplet or contact precautions. Nurses with advanced training* 5 3.5-23 12 Nursing assistants 2 1-3 VHA, Veterans Health Administration. *The focus groups were conducted at a time of heightened awareness of Ebola. These nurses received advanced training in triaging and caring for patients with potential Ebola.

We conducted 12 focus groups (Table 1) . Across the focus groups, we identified 73 discrete stories about RPE use, which we organized into 5 categories: 1) participants knew their sites' RPE policies and protocols. They described visual cues, such as signs resulting from these policies encountered during work routines that promoted RPE use. 2) Sociocultural norms reinforced RPE use, particularly during unexpected events. 3) HCWs used their clinical experiences to determine use, sometimes opting to wear more RPE than required. 4) Additionally, risk perceptions varied by rural and urban contexts. In urban areas, for example, HCWs who perceived exposure to many high-risk patients reported limited access to RPE. Finally, 5) perceived underuse in the ED was attributed to the constant presence of patients with incomplete or delayed diagnoses. Further descriptions of each category are in the following paragraphs.

Following hospital RPE protocol was considered part of the job. When asked about not wearing RPE when required, a Site 3 participant replied, ""That's not an option."" Participants specified clinical indications that necessitated RPE, including a medical evaluation to ""rule out"" tuberculosis (TB), Ebola, SARS, Middle East respiratory syndrome, meningitis, or upper respiratory infections.

Participants' stories included a variety of cues prompting RPE use, including door signs on patient rooms, personal protective equipment carts in front of patient rooms, documentation in the electronic medical record, and patients being in a negative air pressure room. A Site 1 participant recounted 2 common cues, signs, and nurse reports:

""We have a big sign on the door that says 'airborne precaution' and it will tell you some things that you have to wear, so when it says airborne precaution you know that you have to wear a mask and things like that. And on report, before we get to the room, you need to get report from the other nurse that was taking care of that patient so the report will tell you. . .what to do before you get in.""

Several stories described scenarios highlighting how it was socially acceptable to identify lapses in following the RPE protocol. Wearing RPE was consistently recognized as ""one of the things that you have to do,"" despite RPE being ""suffocating"" and ""claustrophobic."" These feelings could be acute when the nurse had an upper respiratory infection, which meant ""you actually can't breathe at all [with RPE on]."" Despite discomfort, a common sentiment was that RPE was protective, as a Site 2 NA said: ""I wouldn't wanna wear [RPE] all the time. But they're manageable, and I'd rather have them on than have them off.""

The safety culture could be seen in practice. When lapses in protocol adherence occurred, HCWs were enculturated to enforce the policy. At Site 1, several participants told a story about a non-English speaking patient with TB who became hypoxic and disoriented, coughing up blood-tinged sputum as he unexpectedly emerged from his isolation room. Several HCWs quickly gathered, and whereas some began providing direct care, others, who sensed the risk of infection, began yelling to colleagues, ""Put a mask on! Put a mask on!"" In another story, Site 4 participants described how a food service worker walked into a negative pressure room without a respirator, despite an ""airborne precautions"" door sign. After informing this individual, the nursing staff reported the event to supervisors who helped organize a respiratory precaution training for food service staff.

Beyond protocols, participants evaluated patient behaviors and symptoms to determine whether to wear RPE. This meant they might decide to use RPE even if protocol specified droplet or no precautions. Often, patient symptoms served as a cue to don RPE; ""Yeah, I've put [RPE] on if someone is coughing so forcefully that it sounds like one of their organs is gonna come out. . .."" [Site 4] Similarly, several nurses at Site 2 recounted a series of symptoms that prompted ""clinical judgement to kick in."" One participant described likely exposures to TB because of patients being misdiagnosed with pneumonia: ""It took a couple of events where I was exposed [to a patient who had an active, but undiagnosed airborne infection] and then I was like okay, I'm not gonna, you know, make that mistake again."" Now, with symptomatic patients, she dons RPE even when the working diagnosis does not require airborne precautions.

Historical, personal experiences also framed current use. A Site 1 nurse described her history wearing protective equipment:

""HIV had just started to come out in 1983, 84, and so we were trained not wearing gloves when you would do a bed bath. There were no gloves. . . . You would just clean your patient and wash your hands well afterward, so we had just been introduced to gloves as HIV came out in the '80s, early '80s, so the masks were, geez, like I can't wear that [laughing] . . . Like when that was introduced it was a whole learning curve . . . And now we have this whole-body thing.

A colleague noted that in light of current outbreaks, RPE use might increase, ""It's not just Ebola anymore. . .there's a lot more viruses coming down the pike. . .. we could end up wearing masks all the time at work.""

Perceptions of risk, need for RPE, and access to equipment vary by context

We found a relationship between risk perceptions, perceived access to RPE, and local context. Participants reported varying degrees of exposure to patients with potential airborne infectious diseases, which in turn informed their perception of individual risk. For example, at sites treating more rural populations, participants reported few encounters requiring HCWs to don airborne precautions and a lower perception of risk of exposure. They also described RPE as plentiful and accessible. A nurse at Site 2 described access to RPE, saying ""they're everywhere."" At another site serving rural areas, several participants described the multiple ways of ensuring equipment availability: In contrast, participants from urban sites serve populations with a higher prevalence of respiratory infections such as TB and perceive a greater risk of exposure when compared with the rural colleagues. As a nurse from urban Site 1 described, RPE was down a long hallway, ""at the end of the universe."" She noted having a ""small face"" requiring a small-sized mask, which was infrequently stocked. Another nurse at Site 4 stated, ''They keep them [in another area] because they know how expensive they are,'' and further explained, ""some people go to grab the yellow masks for droplet precautions and they might put on the N95 respirator for a droplet"" perceiving that the hospital was trying to prevent HCWs from mistakenly using a more expensive N95 instead of appropriate droplet precautions.

Uncertainty about diagnoses for patients entering the health care system through the ED Participants described receiving inaccurate or delayed clinical information, for example, not knowing the patient had a potential airborne infection. This was especially the case for nurses working in the ED, who described distinctly different experiences. One Site 2 NA noted, ""It's a little scarier in the ER [emergency room], just 'cause you don't know what they're coming with."" Similarly, nurses from other sites described the ED as different, too. A Site 3 nurse reported that when transferring a patient with a diagnosis requiring RPE from the ED, only the accepting department wore protection. She reasoned the ED staff not wearing RPE by saying, ""they've kind of already been exposed to it, then it's too late."" The ED was perceived as a place with less use of RPE, both because diagnosis was unknown, and this was attributed to ED staff being less likely to follow protocol.

We conducted one of the few large, in-depth, qualitative studies of RPE use in hospital settings. 18, 19 In 12 focus groups, spanning 4 hospitals, with RNs and NAs, participants described 2 types of nonadherence. One was of rapidly evolving situations in which HCWs were caught off guard, and unable to immediately don RPE. The other was related to an insufficient safety culture. Importantly, each of these is modifiable to some extent through enhanced communication and multidisciplinary teamwork.

The first type of RPE protocol nonadherence was not HCW oversight or ignorance, but rather unexpected actions by patients and other staff. Illustrating this type was the story about a distressed patient with TB emerging from his negative pressure room without warning. HCWs sprang to action to assist the patient, but without RPE. Nearby colleagues, observing the potentially dangerous situation, quickly reminded the first responding HCWs of the urgent need to don masks. Another example of this type was a food service employee, apparently oblivious to precaution signs, walking into a patient room without the required RPE. Similarly, HCWs requested additional training for food service employees. These instances suggest the HCWs felt empowered to speak up to colleagues when safety standards were not met. This indicates a pervasive safety culture, in which following protocols is habituated. This culture is created, as we and others have found, 20 through trainings, leadership addressing safety concerns, peer influence, and tangible resources like accessible equipment. HCWs appear to have the training to identify ""moments of risk"" and feel empowered to take immediate action to mitigate them. This type of culture and HCW empowerment has been associated with robust patient safety practices. 21, 22 Achieving the appropriate cultural among HCWs, however, has been shown to be challenging in hospital systems perhaps undermined, as we found, by inaccessible equipment.

The other type of nonadherence we found indicated limitations in the safety culture. We found 3 problematic areas, as well as indications of how to address. In the first, some HCWs did not trust the protocols and safety systems in place. Instead they relied on their clinical experience to determine what protection to wear. Several HCWs we spoke with talked about wearing N95s when the protocol specified a surgical mask. This was because they suspected, based on their clinical experience, that the patient might later be diagnosed with a respiratory infection. One nurse stated: ""I'm not gonna, you know, make that mistake again."" This was attributed to, in part, experiences that HCWs had in which they had initially worn droplet protection, only to learn that the patient was later diagnosed with an airborne infection, which would require a higher level of RPE. Clinical experience has been shown to improve adherence, 23 yet it may also spur overuse.

In our data, when HCWs did not trust the working diagnosis they relied on their own clinical judgement, which led them to use a higher level of RPE protection than the protocols specified. This behavior can result in variable RPE use owing to the different levels of experience across staff. Further, inappropriate overuse may desensitize people to the importance and value of RPE, and send a confusing, and potentially alarming, message to others. Overuse of RPE may also result in equipment being unavailable when needed, as we and others have found. 19 Moreover, availability is an important factor in adherence. 23 When HCWs do not trust the diagnosis, huddles could help team members communicate about risks, address potential concerns, and lead to consistent and appropriate RPE use. 24 Team huddles are a proven management and communication approach 25 that could be used to review emerging patient diagnostic data and discuss with team members how to best use RPE for the unique situation. This deliberate review and clarification of risk levels may lead to HCWs' increased trust in infection control systems and belief that the hospital is motivated not by finances, but instead HCW safety.

A second problem area was the perception of heightened risk and the related feeling of inadequate RPE availability. Some HCWs believed that their site had many high-risk patients, particularly those in larger facilities in dense urban areas. In contrast, HCWs at sites that reported that there were few high-risk patients, described plentiful, accessible equipment. Other HCWs reported the hospital not having their specified mask size or that RPEs were locked away, leading study participants to speculate that the hospital was trying to save money by limiting access to N95 use to discourage inappropriate use. Prior research has documented that HCWs in larger, more urban hospitals are at greater risk of respiratory infections, especially during outbreaks. 26 The relationship between site type and risk of infections may be further complicated by risk perceptions.

The third problem we found related to the unique circumstances in EDs. Patients coming into the ED arrive without a diagnosis, which puts HCWs at greater risk of exposure to infectious agents. Yet, perplexingly, this seems to have desensitized these HCWs. Some HCWs reported that even after an ED patient had received a diagnosis warranting use of RPE, ED staff might continue to forgo RPE, because, as one HCW noted, the staff believed they had ""already been exposed."" HCWs working in the ED may perceive that exposure risks are omnipresent, with RPE being unable to protect from the myriad of potential exposures. This is problematic because these HCWs may habituate to not wearing RPE when protocol requires use. Other research has shown lower adherence to personal protective equipment, including N95s, among HCWs in EDs. 23 Our findings were consistent with several domains in the Health Belief Model. 11 For example, we found that HCW's desire to wear RPE may increase in the presence of symptomatic, but undiagnosed, patients, a feature of perceived susceptibility. RPE use was also informed by perceptions of the seriousness of patient symptoms or disease. Additionally, the Health Belief Model may provide guidance for strengthening safety systems, such as providing cues to action (eg, signs, carts) to help initiate donning RPE. However, whereas the Health Belief Model was useful in developing the focus group guide, and used to guide parts of the analysis, it had limitations; our additional use of an inductive analytic approach was useful where the Health Belief Model was lacking. For example, we encountered stories around RPE availability or rapidly developing emergent situations that may have precluded HCWs' abilities to adequately process the severity and susceptibility. The Health Belief Model was originally developed with the individual in mind to understand what influenced their likelihood of getting vaccinated. This origin helps explain why it was limited for explaining HCW behavior because HCWs are enmeshed in complexities of health care facilities and systems.

Workplace culture, training, resource constraints, and clinical experiences create a multilayered work context above and beyond the individual perceptions of risk, susceptibility, and threat.

Our study has limitations. It was conducted at 4 hospitals in 2 regions of the United States, and not designed to determine differences among settings or differences by unit. Findings related to the unique context of the ED were emergent and not part of our original study design, thus, more work needs to be done to understand ED microculture. Study participants were limited to RNs and NAs; other clinicians, staff, and patient and family perspectives were not represented. The timing of our study was unique given the Ebola outbreak and therefore increased sensitivity to RPE use. Therefore, we may have heard greater concerns about RPE availability and use. Moreover, our data collection method (focus groups) may have led to social desirability biases, with reluctance to report nonadherence.

Recent Ebola and SARs outbreaks remind us that a large-scale pandemic is always possible. Adherence to respiratory precautions may become critical with little advanced notice. Although government and public health agencies should continue to develop data-driven protocols, hospitals need to assess their own unique context, 27 including local norms, particularly in the ED where patients arrive without a diagnosis or HCWs may not fully trust the protocols for RPE use. Our data provide insight into reasons for RPE nonadherence; importantly, these are to a large extent modifiable. Early appraisal of facility-level-or ward-level in the case of the ED-vulnerabilities in patient safety culture surrounding RPE use could be a useful strategy for ensuring improved adherence during high incidence respiratory illness seasons when RPE use is critical.

Supplementary material associated with this article can be found in the online version at https://doi.org/10.1016/j.ajic.2019.04.174.

",0.717966050676978
Veterinary Microbiology Detection of respiratory viruses in shelter dogs maintained under varying environmental conditions,"b r a z i l i a n j o u r n a l o f m i c r o b i o l o g y 4 7 (2 0 1 6) 876-881 h t t p : / / w w w . b j m i c r o b i o l . c o m . b r / a b s t r a c t Three dog shelters in Rio Grande do Sul were investigated for associations between the occurrence of respiratory viruses and shelter environmental conditions. Nasal secretions randomly collected during the cold season were tested via PCR, and this data collection was followed by nucleotide sequencing of the amplicons. In shelter #1 (poor sanitary and nutritional conditions, high animal density and constant contact between dogs), 78% (58/74) of the nasal samples were positive, 35% (26/74) of which were in single infections and 44% (32/74) of which were in coinfections. Shelters #2 and #3 had satisfactory sanitary and nutritional conditions, outdoors exercise areas (#2) and animal clustering by groups (#3).","Canine infectious respiratory disease (CIRD) may be associated with single virus infections or with a multifactorial etiology and are assigned to infectious agents that replicate sequentially or in synergy. 1 The main viral agents involved in CIRD include Canine distemper virus (CDV), Canine parainfluenza virus (CPIV), Canine adenovirus type 2 (CAdV-2) and Canid herpesvirus 1 (CaHV-1). 2 In Brazil, CDV infection is endemic in dog populations, is associated with respiratory and/or multisystemic disease, and causes thousands of deaths each year. 3, 4 Due to its impact on animal health, CDV is one of the most important infectious diseases in dogs. 2, 5 Similarly to CDV, CAdV-2 has a worldwide distribution and is a major agent of canine infectious tracheobronchitis (CIT) or ""kennel cough"", a disease characterized by restricted infection of the respiratory system. 6 CPIV has a wide distribution in canine populations with an estimated seroprevalence ranging from 30 to 70%. 7 CPIV infection is related to high population density; the virus is highly transmissible and presents with rapid dissemination between animals. 2 CaHV-1 has a worldwide distribution and is associated with respiratory and reproductive disease. 8 Like other Alphaherpesviruses, CaHV-1 establishes latent infections in nerve ganglia and can periodically reactivate the infection. 9 An estimated 30-100% of domestic dogs have antibodies to CaHV-1. 10 The transmission of respiratory viruses occurs through direct or indirect contact between animals, primarily through contaminated nasal secretions and aerosols. 1 CIRD may affect dogs of both genders and ages; puppies under 90 days old are more susceptible, as well as immunosuppressed dogs, animals without a history of vaccination; vaccination failures or maternal immunity may also contribute. 11 The disease presents a seasonal pattern with a higher incidence in cold months. 12 The diagnosis of CIRD is largely based on the epidemiology, clinical signs and response to therapy. However, an etiologic diagnosis requires the identification of the agent or its products (proteins or nucleic acids). 4 Vaccination is largely used to prevent or control respiratory infections in dogs and helps minimize clinical disease; however, current vaccines are not always effective. 11 In Brazil, despite the wide distribution of these infections and informal reports by veterinarians, very few reports describe viral respiratory disease in dogs. [13] [14] [15] [16] [17] [18] Additionally, there is little information regarding these infections in local environments with high densities and constant animal movement such as dog shelters. The identification of the more common respiratory viruses in dogs in various epidemiological conditions is essential for developing efficient control and prevention measures.

Thus, the objective of this study was to investigate respiratory viral infections in dogs in shelters. For this, three shelters located in Rio Grande do Sul state, Brazil, presenting diverse sanitary and nutrition conditions were included in an attempt to associate the occurrence of viral infections with the conditions observed. The viruses were detected in nasal secretions via polymerase chain reaction (PCR) and focused on the main agents involved in this condition (CDV, CPIV, CAdV-2 and CaHV-1).

Dogs from three shelters located in Rio Grande do Sul state (RS), Brazil, were included in this study. Two shelters (#1 and #2) are located in Cachoeira do Sul (30 • 02 21 S and 52 • 53 38 W), and one shelter (#3) is located in Passo Fundo (28 • 15 46 S and 52 • 24 24 W). The sample collection was performed in 2014 in months of low temperatures (July and August). Fig. 1 illustrates the environmental conditions observed in these shelters. Shelter selection was performed to include a variety of shelter conditions, including those with low temperature seasons, varying population densities (to take into account the appearance and frequency of cleaning of the premises), and the nutritional states of the dogs (taking into consideration the type of food and the frequency of feeding according to healthy/unhealthy animal appearance). The selection of the animals within each shelter was performed randomly.

Shelter #1 hosts stray dogs and cats of both genders, of all ages and primarily crossbred animals. The animal population of the shelter was 150 dogs and 30 cats on the date of sampling. The young dogs (six months up to two years old) and adults (more than two years old) were maintained in individual cages/small barns held by leashes in an open space, and most animals had direct and indirect contact with each other. Small, medium and large dogs had individual cages/houses shelters within the same area (approximately 1 m 2 ). Puppies were maintained in collective cages indoors without direct contact with adult animals. Shelter #1 was visited in the cold season when the temperatures ranged of 5-10 • C. At the visit, several animals presented with nasal discharge, indicating respiratory infection. Sanitary and nutritional conditions were inadequate, and the locality had not recently been cleaned. The animals did not receive good quality food and were not fed sufficient amounts.

Shelter #2 hosts stray dogs of both genders independent of age and primarily crossbred animals. On the day of the visit, the number of animals was 70. During the day, the animals remained outdoors in fenced areas or held by leashes and were grouped according to gender and age. During the night, the animals were allocated indoors, in collective cages, with approximately 10 animals/cage. The dogs had a wide area in which to run and exercise during the day and had contact with each other. Shelter #2 was visited when the outdoor temperatures were between 10 and 15 • C. The sanitary and nutritional conditions were fair to good; the animals were fed once per day, and the cages were cleaned three times per week.

Shelter #3 hosts stray dogs and cats of both genders, varying ages and primarily crossbred animals. At the visit, 180 dogs and 20 cats were present in the shelter. The dogs were allocated according to gender and age in collective fenced barns that had at least one dog house per animal. The animals had constant direct contact with other animals from the same cage/barn. The individual area was approximately Nasal swabs of 74, 35 and 77 dogs in shelters #1, #2 and #3, respectively, were randomly collected; approximately 50% of the dogs in each shelter were sampled. After sample collection, the swabs were maintained in RNAlater solution (Life Technologies, Carlsbad, CA, USA), and the samples remained in dry ice during transport to the laboratory where they were stored at −80 • C. All proceedings involving animal manipulation were performed under the supervision of a veterinarian and according to the recommendations of the Brazilian Committee of Animal Experimentation (Comitê Brasileiro de Experimentação Animal -COBEA, law #6.638, May 8, 1979) . This research was approved by the institutional Ethics and Animal Welfare Committee (UFSM, Comitê de Ética e Experimentação Animal: approval number 080/2014).

RNA and DNA extraction from nasal swabs were performed using an RTP DNA/RNA virus extraction kit (Invitek, Hayward, CA, USA) according to the manufacturer's instructions. After RNA extraction, complementary DNA (cDNA) was synthesized using an enzyme Super Script III Reverse Transcriptase Kit (Life Technologies, Carlsbad, CA, USA). The PCR reactions were initially standardized to optimize the concentration of each reagent. Viruses obtained from two commercial vaccines were used as controls for CDV, CPIV and CAdV-2. For CaHV-1, nucleic acid extracted from the liver of a puppy naturally infected with CaHV-1 was used as a control. 17 Ultrapure water was used as a negative control in all reactions. The primers used in all reactions are described in Table 1 . All reactions were performed using a total volume of 25 L with 2 L of total DNA (100-200 ng) according to the PCR conditions described for each virus. Primers to CPIV were obtained using the Clone Manager 7 program (http://www.scied.com), and the sequences are shown in Table 1 For nucleotide sequencing, 90 L of each PCR product was purified using a PureLink ® Quick Gel Extraction and PCR purification Combo Kit (Life Technologies, Carlsbad, CA, USA) according to the manufacturer's instructions. Positive samples were randomly selected and sequenced in quadruplicates in an automatic sequencer ABI-PRISM 3100 Genetic Analyzer (Applied Biosystems, Foster City, CA, USA). The obtained sequences were analyzed using the Staden Package for consensus sequences achievement. 22 The matrix of sample identity with sequences deposited in GenBank was performed using the BioEdit 

The present study investigated the presence of respiratory viruses in dogs of three shelters in Rio Grande do Sul state, Brazil, through virus detection in nasal secretions via PCR.

Considering the previous serological studies on canine respiratory viruses in Brazil, 14, 15 the primary difference of the present study was the direct demonstration and identification of the viruses involved in CIRD.

Our results showed the occurrence of the main canine respiratory viruses in these shelters with varying frequencies and combinations of single and mixed infections. In shelter #1, 78% of the 74 samples were positive for at least one virus; CPIV was the most frequent agent (71% of the samples). CPIV was detected in single (30%) or in mixed infections and was associated with CAdV-2 (23%), CDV (4%), or both (14%). CDV and CAdV-2 were found in a high percentage of animals, especially in coinfections (Table 2 ). In shelters #2 and #3, unlike shelter #1, a small percentage of samples were positive for the virus and only in single infections. In shelter #2, CPIV was detected in 9% of the samples and CaHV-1 was detected in 6%. In shelter #3, 9% of the samples were positive for CAdV-2 and 1% for CDV ( Table 2 ). The varying sanitary and nutritional conditions and the dog crowding/density of the respective shelters may explain the important differences in the rates of positive animals.

Shelter #1 had precarious nutritional and sanitary conditions, poor infrastructure and poor food quality (Fig. 1A) . In shelter #2, the animals had a wide outdoors area in which to play and exercise; however, the dogs of varying ages had direct contact (Fig. 1B) . Fig. 1C shows shelter #3 with individual dog houses and cages with a low population density and good sanitary conditions (approximately six dogs/cage). Factors associated with animal overcrowding, such as excessive noise, poor air quality and diet, in addition to bad kennel cleaning, may cause stress, which may in turn promote the establishment and dissemination of viral infections. [23] [24] [25] Thus, the poor sanitary and nutritional conditions of shelter #1 may have favored the high rate of respiratory viruses.

In this shelter, CDV, CPIV and CAdV-2 were detected in single or mixed infections, corresponding to 78% of the positive dogs. CPIV was detected in 71% of the samples, of which 30% were single infections and 41% were associated with CAdV-2 and/or CDV. CPIV is considered the primary virus involved in respiratory disease in dogs, 2,7,26-29 and has been most frequently reported in conditions of high animal density. 2 CPIV infection produces pathology in the tracheal epithelium 15 and favors secondary respiratory infections by other pathogens such as CAdV-2. 6 In shelter #1, CDV was detected only associated with CAdV-2 and/or CPIV, corresponding to 21% of the positive samples. CDV replication occurs in epithelial cells and macrophages of the upper respiratory system, pharynx and tonsils, followed by lymph node infection and systemic dissemination that can evolve to multisystem disease and immunosuppression. 30 For this reason, bacterial secondary infections are often detected in dogs with distemper in addition to coinfection by other viruses, such as CAdV-2 and CaHV-1. 5, 31, 32 CAdV-2 detection in 45% of the samples from shelter #1 may have been influenced by the high CPIV and CDV infections in the kennel because CPIV promotes primary lesions in the tracheal epithelium 15 and CDV induces immunosuppression. 30 Additionally, adenoviruses are highly resistant in environmental conditions and remain viable in the environment for an extended duration, thereby favoring dissemination among animals. 6 Notably, a high prevalence of CAdV in dog populations has been reported in shelters without a history of vaccination. 33, 34 An investigation of respiratory viruses in dogs in Germany analyzed 58 samples of shelter animals with and without respiratory signs and detected 22.4% (13/58) to be positive for CPIV and one positive for CAdV-2 and CPIV. 29 A similar study performed in Germany examined 68 nasal swabs of domestic dogs 28 ; in this study, 7.4% (5/68) of the samples were positive for CPIV, 2.9% (2/68) for CAdV-2 and 1.5% (1/68) for CDV. Despite varying frequencies, these studies reported CPIV to be the most frequent respiratory virus in dogs, followed by CAdV-2 and CDV.

There are few reports of direct diagnosis of respiratory viruses in dogs; however, some serological studies have been performed in Brazil. 14, 15 In southern Brazil, a serological investigation of 817 domestic dogs without a vaccination history showed that 43% of the animals were seropositive to CAdV and 27.3% to CDV. 14 A similar study was conducted in a population of 173 dogs in shelters, also from the RS state, in which antibodies to CPIV and CDV were detected in 51.4% and 4.1-9.3% of the samples, respectively. 15 These studies showed that respiratory viruses circulate among domestic and shelter dogs in southern Brazil in varying combinations and prevalences that likely reflect environmental and epidemiological differences between regions and dog populations.

In shelters #2 and #3, the respiratory viruses were detected only in single infections with 14% of infections caused by CPIV or CaHV-1 (shelter #2) and 9% by CDV or CAdV-2 (shelter #3). CaHV-1 was detected in samples collected only from the dogs of shelter #2, corresponding to 6% of the collected samples. Although CaHV-1 may cause respiratory disease, the infection has also been associated with other clinical outcomes, including reproductive disease. 35, 36 Due to the ability of CaHV-1 to remain latent in the host, its diagnosis in dog populations should preferentially be performed via serological testing. [37] [38] [39] [40] In this sense, we detected positive serology for CaHV-1 in 7 out of 8 dogs in shelter #1 (not shown). A two-year longitudinal investigation in a shelter in the United States involving 211 necropsied dogs showed CaHV-1 involvement in 12.8% and 9.6% of trachea and lung samples, respectively, reinforcing the involvement of CaHV-1 in respiratory disease in dogs. 2 The identity of the sequenced matrix of the shelter samples with sequences deposited in GenBank revealed 96 to 99% identity (KU341102, KU341103, KU341104 and KU341105) with the N gene (AJ009656. Thus, the results obtained in this research showed that respiratory virus infections (CPIV, CDV, CAdV-2 and CaHV-1) are common in dogs housed in public shelters. The frequency and dissemination of these viral infections appear to be related to a high population density and poor sanitary and nutritional conditions. These results also indicate the need for control/prevention measures, such as vaccination and good environmental conditions, to minimize these infections in shelter dogs. CPIV infection appears to play an especially predominant role in winter respiratory infections in dog shelters and warrants further preventive measures.

The authors declare no conflicts of interest.

",0.7169410509219006
Passive immunization does not provide protection against experimental infection with Mycoplasma haemofelis,"Mycoplasma haemofelis (Mhf) is the most pathogenic feline hemotropic mycoplasma. Cats infected with Mhf that clear bacteremia are protected from Mhf reinfection, but the mechanisms of protective immunity are unresolved. In the present study we investigated whether the passive transfer of antibodies from Mhf-recovered cats to naïve recipient cats provided protection against bacteremia and clinical disease following homologous challenge with Mhf; moreover, we characterized the immune response in the recipient cats. Ten specified pathogen-free (SPF) cats were transfused with pooled plasma from cats that had cleared Mhf bacteremia; five control cats received plasma from naïve SPF cats. After homologous challenge with Mhf, cats were monitored for 100 days using quantitative PCR, hematology, blood biochemistry, Coombs testing, flow cytometry, DnaK ELISA, and red blood cell (RBC) osmotic fragility (OF) measurement. Passively immunized cats were not protected against Mhf infection but, compared to control cats, showed significantly higher RBC OF and B lymphocyte (CD45R/B220 + ) counts and occasionally higher lymphocyte, monocyte and activated CD4 + T lymphocyte (CD4 + CD25 + ) counts; they also showed higher bilirubin, total protein and globulin levels compared to those of control cats. At times of peak bacteremia, a decrease in eosinophils and lymphocytes, as well as subsets thereof (B lymphocytes and CD5 + , CD4 + and CD8 + T lymphocytes), and an increase in monocytes were particularly significant in the passively immunized cats. In conclusion, passive immunization does not prevent bacteremia and clinical disease following homologous challenge with Mhf, but enhances RBC osmotic fragility and induces a pronounced immune response.","Hemotropic mycoplasmas (hemoplasmas) are noncultivable epierythrocytic bacteria that infect a variety of mammalian species worldwide [1] . In recent years, hemoplasmas have attracted scientific attention due to their host diversity and pathogenic potential [1] . The main pathogenic feature of hemoplasmas is hemolysis, and clinical signs such as lethargy, anorexia, pale mucosal membranes, pyrexia, jaundice and pigmenturia may be present in severely affected animals [1] . Reports of hemoplasma infections in humans emphasize the need to characterize these agents in more detail [2] [3] [4] [5] [6] [7] . Feline hemoplasmas can thereby serve as a model because of their extensive molecular and clinical characterization within this group of organisms.

Feline hemoplasmas comprise at least three different species: Mycoplasma haemofelis (Mhf), ""Candidatus Mycoplasma haemominutum"" (CMhm) and ""Candidatus Mycoplasma turicensis"" (CMt) [8] [9] [10] . Concurrent infections with two or three hemoplasma species have been documented [11] [12] [13] [14] , suggesting that no immunological cross-protection exists between the feline hemoplasmas, which has recently been experimentally confirmed [15] . Mhf is the most pathogenic of the three feline hemoplasma species and can induce severe hemolytic anemia, which is potentially fatal if left untreated. In contrast, the other two feline hemoplasmas may induce mild anemia, and the infection often remains subclinical [16] .

The natural route of hemoplasma transmission between cats is still unresolved, but aggressive interactions and blood-sucking arthropods have mainly been implicated [17] [18] [19] . For experimental transmission, the intraperitoneal, intravenous or subcutaneous inoculation of hemoplasma-containing blood has been successful [10, [19] [20] [21] . Recently, a low-dose infection model for Mhf that aimed to more accurately mirror the natural transmission of hemoplasmas was developed [22] . Different antibiotic regimens reduce hemoplasma blood loads and alleviate clinical signs but, so far, no treatment protocol has successfully and consistently cleared feline hemoplasma infections [21, [23] [24] [25] [26] . This limitation emphasizes the need to further investigate protective immune mechanisms against these agents. Recently, cats that were experimentally infected with Mhf or CMt and overcame bacteremia were shown to be protected from reinfection with the same hemoplasma species [27, 28] . A study by Novacco et al. [27] suggested a significant role for the humoral immune response in protecting against CMt reinfection: nine out of the ten cats that were protected from reinfection showed intermediate to high antibody levels against CMt before challenge. Furthermore, a transient decrease in antibody levels was observed in the protected cats immediately after attempted reinfection, which could be due to the binding of antibodies to the inoculated antigens. In the early phase after re-challenge, compared with the control group, the protected cats exhibited significantly higher IL-4/IL-12 ratios and CD4 + T lymphocyte counts and a pronounced eosinophilia. Therefore, the authors concluded that an early Th2 immune response, prior to the onset of bacteremia, is beneficial for protection against CMt reinfection [27] . This result was not found in the study by Hicks et al. [28] , where an early increase in the pro-inflammatory cytokines tumor necrosis factor-α (TNF-α) and interleukin-6 (IL-6) was observed in cats protected from Mhf reinfection. Furthermore, the immune response seemed to be skewed towards a Th1 response after primary Mhf infection, whereas a switch from an initial Th1 to a delayed Th2 response was observed after primary CMt infection [27, 28] . These results suggest that cats respond to infection by different feline hemoplasma species with different immune mechanisms.

Important data on the immune response elicited by hemoplasma infection have been provided by previous studies [27, 28] , but the mechanisms that confer protection against re-infection have yet to be clarified. Passive immunization transfers humoral immunity to a nonimmune individual in the form of antibodies and allows the protective role of antibodies in the absence of cellular immune mechanisms to be assessed. The present study aimed to investigate whether the passive transfer of antibodies from Mhf-recovered to naïve recipient cats induced partial or complete protection against bacteremia and clinical disease following homologous challenge with Mhf. Different parameters addressing the humoral and cellular immune response were monitored in passively immunized and control cats.

In the main experiment, 15 4-month-old male specified pathogen-free (SPF) cats from Liberty Research, Inc. (Waverly, New York, USA) were used as recipient cats. Five adult SPF cats served as blood donors: three of these cats had overcome a previous Mhf infection (HBU2, HBZ2 and HCD2) [28] , while two cats were naïve adult SPF cats (GCN5 and JCR4). Moreover, in a pre-experiment, a 2-year-old male castrated SPF cat (HCC4) was used. All cats were housed in groups in a confined university facility under ethologically and hygienically ideal conditions [29] . All experiments were approved by the veterinary office of the Canton of Zurich (TVB 92/2014) and were conducted in accordance with Swiss laws.

Fifty days prior to plasma transfusion and experimental infection, the SPF status of all the cats was confirmed by testing for the absence of infection with feline hemoplasmas, feline calicivirus, feline herpesvirus-1, feline coronavirus, feline leukemia and feline immunodeficiency virus, as well as Bartonella henselae and Chlamydia felis, as recently described [19, 30] ; the absence of Mhf infection was again confirmed by real-time TaqMan ® quantitative (q)PCR [12] on day 0 prior to plasma transfusion and Mhf inoculation. All donor cats and the cat from the preexperiment were blood-typed using a commercial immunochromatography technique (Feline Lab Test A + B, Alvedia, France). The recipient cats had been bloodtyped by Liberty Research, Inc. (Waverly). A standard saline-agglutination cross-matching procedure was performed to ascertain the compatibility of transfusion [31] .

For passive immunization, a total of 118 mL of plasma was collected from the three cats that had overcome previous Mhf infection (HBU2, HBZ2 and HCD2) [28] . The plasma was collected from these cats on day 538 post Mhf inoculation. HBU2 had cleared the infection without treatment, whereas HBZ2 and HCD2 had received antibiotic treatment to clear the infection (HBZ2: 10 mg/kg/day doxycycline for 44 days; HCD2: 10 mg/ kg/day doxycycline for 27 days, followed by 2 mg/kg/ day marbofloxacin for 23 days); in the latter two cats, antibiotic treatment was stopped 59-129 days prior to plasma collection. All cats tested negative for Mhf for at least eight consecutive weeks following antibiotic treatment and prior to the plasma collection, as determined using weekly collected blood samples that were analyzed in triplicate with a Mhf-specific qPCR assay [12] . For plasma transfusion of the control cats, a total of 70 mL of plasma from two adult naïve SPF cats (GCN5 and JCR4) was collected. Prior to plasma collection, the two cats were confirmed to be negative for all three feline hemoplasmas using qPCR [12] and to be free from all commonly known feline pathogens, as described [19] .

For plasma preparation, whole blood was collected from the donor cats from the jugular vein under shortduration general anesthesia (10 mg/kg ketamine, Narketan ® , Vétoquinol AG, Belp, Switzerland; 0.1 mg/kg midazolam, Dormicum ® , Roche Pharma AG, Reinach, Switzerland); the blood was anti-coagulated with acidcitrate-dextrose (ACD) to a final concentration of 3.5%. Plasma was separated from RBCs by centrifugation at 3000g for 10 min and stored at −80 °C until use. Prior to transfusion, the plasma was thawed, pooled (pool A: plasma from the Mhf-recovered cats HBU2, HBZ2 and HCD2; pool B: plasma from the naïve SPF cats GCN5 and JCR4), and filtered through a 0.22 µm pore-size filter (JET BIOFIL, Madrid, Spain), and 9 mL aliquots were prepared. Before freezing and after thawing and filtration, the plasma was tested in triplicate with a Mhf-specific qPCR assay for the absence of Mhf organisms [12] .

For the plasma transfusion, all recipient cats were put under short-duration general anesthesia (10 mg/kg ketamine, Narketan ® , Vétoquinol AG; 0.1 mg/kg midazolam, Dormicum ® , Roche Pharma AG) and 9 mL of whole blood was collected for baseline analysis and to prevent circulatory volume overload. The plasma was prewarmed to 38 °C and intravenously administered over a duration of 30 min using standard blood transfusion sets (HEMO-NATE ® , 18 Micron, Utah Medical Products, Inc., Utah, USA). During transfusion, the cats were closely monitored for transfusion reactions.

In the pre-experiment, an adult naïve SPF cat (HCC4) was intravenously transfused with a 10 mL aliquot of plasma pool A that was later used for the passive immunization of the cats in group A. After the transfusion, weekly blood samples were collected from the cat for 23 weeks and analyzed using Mhf-specific qPCR [12] .

For the main experiment, the recipient cats were assigned to two groups: group A (n = 10, passive immunization, cats DHR1, DHR2, JHW1, JHW2, JHW4, JHW5, JHX1, JHX2, JHZ1 and JIC1) and group B (n = 5, control group, cats DHP1, DHT1, JHV1, JHW3 and JIC2). The cats of each group were housed together during and after the end of the study period. On day 0, plasma transfusion was performed, and the cats were experimentally inoculated with Mhf. For the passive immunization, each cat in group A was transfused with a 9 mL aliquot of plasma pool A. Each cat in group B was transfused with a 9 mL aliquot of plasma pool B. Ten minutes after the completion of the transfusion, all cats in groups A and B were inoculated with Mhf by a subcutaneous injection of 10 µL of 20% dimethyl sulfoxide (DMSO)-preserved blood containing 10 3 copies of Mhf diluted with 90 µL of phosphatebuffered saline (PBS), as previously described [22] . An aliquot of the same Mhf inoculum was used to infect the recipient cats in this study that had been used to infect the plasma donor cats (HBU2, HBZ2 and HCD2) in a previous study [28] . Clinical condition, body temperature and body weight were recorded, and blood samples collected prior to plasma transfusion and Mhf inoculation (day 0), twice weekly post inoculation (pi) until week 7 and weekly thereafter up to day 100 pi.; an additional blood collection to measure red blood cell (RBC) osmotic fragility (OF) was performed on day 179 pi because RBC OF was still increased compared with baseline values in several cats of group A and B at day 100 pi. All samples were collected without anesthesia, with the exception of the samples collected at day 0. Samples for PCR analysis and serology were stored at −80 °C until analysis. Flow cytometry, hematology, blood biochemistry, Coombs tests and RBC OF assays were carried out within 4 h of blood collection.

Hematological parameters were determined on day 0, twice weekly pi until week 7 and weekly thereafter up to day 100 pi on a Sysmex XT-2000iV instrument (Sysmex Corporation, Kobe, Japan), as previously described [32] . White blood cell differential analysis was confirmed using manual evaluation of Wright-Giemsa stained blood smears. Severity of anemia was defined as mild (25-33%), moderate (15-25%) and severe (<15%). Bilirubin, total protein and albumin concentrations were measured on day 0, on days 3 and 7 pi and weekly thereafter until day 100 pi using a Cobas Integra 800 system (Roche Diagnostics, Rotkreuz, Switzerland). Globulin values were calculated by subtracting the albumin value from the total protein concentration. Reference intervals (mean ± standard deviation, SD) for PCV and total protein concentrations for kittens of 16 and 30 weeks of age were obtained from the literature [33] . Because bilirubin concentrations reach adult values after 1 week of age [33] , the laboratory's device-specific reference interval was used for this parameter.

RBC OF was determined on day 0 and on days 21, 100 and 179 pi using a published protocol [10] . The reference interval was determined in nine healthy cats during a previous study (50% hemolysis in NaCl 0.50-0.57% w/v) [10] . Direct Coombs tests were performed on day 0 and on days 21 and 100 pi. RBCs from EDTA-anticoagulated blood samples were washed, diluted in NaCl 0.9% w/v solution and incubated for 1 h at 37 °C with feline antiglobulin reagent (MP Biomedicals, LLC., Solon, Ohio, USA) in dilutions ranging from 1:2 to 1:10240, as described [10] . Agglutination in dilutions of ≥1:8 was defined as positive.

Quantification of Mhf blood loads by qPCR was performed on day 0, twice weekly pi until week 7 and weekly thereafter up to day 100 pi. Total nucleic acid (TNA) was extracted from 100 μL of EDTA anti-coagulated blood using the MagNa Pure LC (Roche Diagnostics AG, Rotkreuz, Switzerland) and the MagNa Pure LC TNA Isolation Kit (Roche Diagnostics) following the manufacturer's instructions. TNA was eluted in 100 µL elution buffer and stored at −80 °C until use. With each batch of extraction, a negative control consisting of 200 µL of phosphate-buffered saline (PBS) was used to monitor for cross-contamination. All TNA samples were tested with a Mhf-specific qPCR assay to detect and quantify Mhf as previously described [12] . For absolute quantification, tenfold serial dilutions of a standard plasmid were used as described [12] . Positive and negative controls were included in each PCR run.

Antibodies against the recombinant DnaK protein of Mhf were measured on day 0, on days 3 and 7 pi and weekly thereafter until day 100 pi using a previously described ELISA [20] . The serum was diluted 1:200, and 50 ng of recombinant protein per well was used as described [20] . All samples collected from one cat were measured on the same plate, and all plates were antigen coated within the same batch. Absorbance was measured at a wavelength of 415 nm (OD 415 ) using a SpectraMax Plus 348 microplate spectrophotometer (Molecular Devices, Sunnyvale, CA, USA). An OD 415 ≤ 0.33 was defined as negative based on DnaK ELISA results obtained from 20 SPF cats, as described [20] .

Flow cytometric analysis was performed on day 0 and on days 3, 7, 14, 21, 28, 42, 56, 70 and 98 pi. Three different staining combinations of primary antibodies were used: (1) Fluorescein isothiocyanate (FITC)-conjugated mouse anti-feline CD5 antibody (f43, Southern Biotech, Allschwil, Switzerland); (2) an R-phycoerythrin (RPE)conjugated mouse anti-feline CD4 antibody (Vpg34, AbD Serotec, Puchheim, Germany) and a FITC-conjugated mouse anti-feline CD25 antibody; and (3) a FITC-conjugated mouse anti-feline CD8 antibody (fCD8, Southern Biotech) and a RPE-conjugated rat anti-mouse CD45R/ B220 antibody (RA3-6B2, AbD Serotec). CD5 is a marker for feline T lymphocytes [34] , and CD4 + -and CD8 +positive T lymphocytes represent helper and cytotoxic T lymphocytes, respectively [35] . CD4 + CD25 + T lymphocytes represent activated CD4 + T lymphocytes, and CD45R/B220 antibody was used to identify B lymphocytes [36, 37] .

Prior to the start of the experiment, the antibodies were titrated for optimal dilution as follows: CD4 and CD8, 1:50 dilution; CD25 and CD5, 1:100 dilution; and CD45R/B220, undiluted. A 50 µL aliquot of EDTA anticoagulated blood was incubated with 5 µL of the aforementioned antibodies. To rule out non-specific binding, isotype control antibodies (RPE-conjugated Mouse IgG1 and FITC-conjugated Mouse IgG1, AbD Serotec) and unstained blood samples from each cat were used as negative controls. Blood samples were stained according to published protocols [27, 28] .

Flow cytometry was performed using a guava easy-Cyte ™ 8HT Flow Cytometer (Millipore, Darmstadt, Germany) using the GuavaSoft 2.5 software. Gates representing the lymphocyte population were set based on forward and side scatter, and 10 000 events were acquired for each sample. The absolute number of each lymphocyte subset was calculated by multiplying the absolute lymphocyte number from hematology by the subset percentage as previously published [38] .

Up to 22 different parameters per cat were statistically analyzed using Analyse-it ® for Microsoft Excel version 1.0.5.0 (Analyse-it Software, Ltd., Leeds, UK) and Graph-Pad Prism 5.03 (GraphPad Software, Inc., CA, USA). The Mann-Whitney U test (p MWU ) was used to compare the two groups A and B at each time point. One cat (JHW3) in group B stayed PCR-negative and seronegative throughout the 100-day study period. To investigate whether significant differences observed between groups A and B were related to the inclusion of this cat, the Mann-Whitney U tests were repeated without the data of this cat for all significant parameters. The results from these analyses were reported if they differed from the original results including cat JHW3. Friedman's test (p F ) followed by Dunn's post test (p D ) was used to analyze the parameters over time when more than two time points were considered. Multiplicity adjusted P values for each comparison in a family of comparisons were computed. Fisher's exact test was used to determine significant differences of proportions. P values <0.05 were considered significant.

All donor cats, the cat from the pre-experiment and all recipient cats were confirmed to be blood type A. Crossmatching revealed no incompatibilities between the donor cats, the cat of the pre-experiment and the recipient cats. All plasma samples used for transfusion tested Mhf PCR-negative.

The adult cat (HCC4) transfused with an aliquot of plasma pool A during the pre-experiment tested Mhf PCR-negative in each of the samples collected during the 23 weeks after the transfusion (data not shown). The cat stayed clinically healthy throughout the entire experiment.

Prior to plasma transfusion and experimental infection (day 0), all cats in both groups tested Mhf PCR-negative. All cats in groups A and B became Mhf PCR-positive within 7-31 days and 7-38 days pi, respectively ( Figures 1A and B) , except for one cat (JHW3) in group B. Cat JHW3 remained PCR-negative throughout the 100-day follow-up period ( Figure 1B ) but became Mhf PCR-positive after the end of the experiment (day 154 pi, data not shown). Peak hemoplasma loads (group A: 2.3 × 10 8 -1.7 × 10 9 copies/mL blood; group B 1.8 × 10 8 -8.6 × 10 8 copies/mL blood) were reached between days 17 and 49 pi in group A and days 17 and 63 pi in group B. There was no significant difference in Mhf blood loads between the two groups during the 100-day follow-up period, except for day 100 pi, when group A showed significantly higher Mhf blood loads (p MWU = 0.0280; Figure 1C ); this difference was not significant when the PCR-negative cat JHW3 in group B was excluded from the analysis (p MWU = 0.0759).

The cats in both groups tested negative in the DnaK ELISA (defined as an OD 415 ≤ 0.33) prior to the plasma transfusion (Figures 2A and B) . After passive immunization and subsequent infection, group A cats showed slightly but significantly higher DnaK ELISA OD 415 values at days 3, 7 and 14 pi compared with the OD 415 values of cats in group B (p MWU < 0.05; Figure 2C ). From day 21 until day 100 pi, no significant difference in the DnaK ELISA OD 415 values was evident between the two groups. When cat JHW3 was excluded from the analyses, the anti-DnaK antibody level in cats in group A was still significantly higher early after passive immunization (days 3 and 7 pi, P MWU < 0.05), but not at day 14 pi and thereafter until day 100 pi when compared to cats in group B. There was no significant difference in the time of seroconversion (OD 415 > 0.33) between the two groups; cats in both groups, A and B, seroconverted between days 21 and 49 pi, with the exception of cat JHW3 (group B), which did not develop anti-Mhf DnaK antibodies throughout the study ( Figure 2B ). Two other cats (JHW2, group A, and JHV1, group B) were seronegative (OD 415 ≤ 0.33) by the end of the experiment ( Figure 2B ); one of these cats (JHW2) was treated with doxycycline between days 28 to 42 pi because of a pronounced decrease in packed cell volume (PCV) to 21% (day 28 pi, see below).

Seven out of ten cats in group A became moderately anemic (PCV between 15 and 25%) at days 28 to 56 pi ( Figure 3A ). In group B, one cat showed moderate anemia (PCV 25%) and one cat severe anemia (PCV 10%) at days 35 and 26 pi, respectively ( Figure 3B ). The lowest PCV observed during the study was found for cat DHT1 (PCV 10%, 26 days pi) in group B. There was no significant difference in the mean PCV values between the two groups ( Figure 3C ). There was a significant change in PCV over time for both groups (group A, p F < 0.0001; group B, p F = 0.0003); PCV values of the cats were higher towards the end of the study period when compared to the first weeks pi (Figures 3A and B) . This finding may be attributed to the increasing age of the cats; reference intervals of PCV (±SD, %) were reported to increase from the age of 16 weeks (34.9 ± 1.1) to 30 weeks (37.1 ± 3.4) [33] .

Three cats in group A (cats JHW2, JHW4 and JHZ1) and two cats in group B (cats DHT1 and JHV1) developed elevated body temperature >39.5 °C during the course of the experiment: JHV1 at day 12 pi, JHW4 at day 23 pi, DHT1 at day 26 pi, JHW2 at day 28 pi and JHZ1 at day 48 pi. In addition, apathy, anorexia and weakness were observed in three cats in group A (JHW2 and JIC1 at day 28 pi; and JHX2 at day 36 pi) and in one cat in group B (DHT1 at day 26 pi). Three cats necessitated oral antibiotic treatment with doxycycline (10 mg/kg/day, Supracycline, Grünenthal GmbH, Mitlödi, Switzerland) for 14-16 days. The decision to treat the cats was based on the presence of severe anemia (group A: DHT1, PCV of 10%, day 26 pi) or a pronounced decrease in PCV within 24 h (JHW2, PCV of 21%, day 28 pi; JHX2, PCV of 15%, day 36 pi). All three cats showed clinical signs (apathy, anorexia, weakness and fever) when the treatment was initiated.

At day 0, RBC OF was significantly lower in cats in group A when compared to cats in group B (p MWU = 0.0127), but mean RBC OF of both groups remained within the reference interval (group A and B, 50% hemolysis in NaCl 0.54 and 0.56% w/v, respectively; reference interval, 50% hemolysis in NaCl 0.50-0.57% w/v, Figure 4C ). Thereafter, at days 21 and 100 pi, RBC OF was significantly higher in cats in group A compared to cats in group B (p MWU < 0.05; Figure 4C ). When cat JHW3 was excluded from the analyses, there was no longer a significant difference between the groups on day 100 pi. Remarkably, compared with baseline values, RBC OF was still increased in several cats in groups A and B at day 100 pi (Figures 4A and B ) ; therefore, one further measurement was obtained at day 179 pi. RBC OF significantly changed during the course of infection only in cats in group A (p F = 0.0004, Figure 4A ). The RBC OF reached maximal values at day 21 pi in eight out of ten animals in group A (range, 50% hemolysis in NaCl 0.63-0.79% w/v) and at day 100 pi in cat JHZ1 (50% hemolysis in NaCl 0.62% w/v) and at day 179 pi in cat JHW1 (50% hemolysis in NaCl 0.66% w/v; Figure 4A ). Cat JHW3 in group B, which turned Mhf PCR-positive only after the end of the experiment (day 154 pi), showed a pronounced increase in relative RBC OF at the time of Mhf bacteremia (50% hemolysis in NaCl 0.75% w/v, day 179 pi; reference interval, 50% hemolysis in NaCl 0.50-0.57% w/v; Figure 4B ). All cats in both groups tested negative in the direct Coombs test at all time points (data not shown).

Cats in both groups showed an increase in leukocyte counts immediately after infection, followed by a significant decrease, with the nadir being reached three to four weeks pi (data not shown). There was no significant difference in leukocyte counts between the two groups during the 100-day follow-up period. The lymphocyte cell counts showed an initial increase followed by a significant decrease, with the nadir reached at day 21 pi, coinciding with the onset of peak bacteremia in cats in group A (p F < 0.0001, Figure 5A ); this pattern was less pronounced in cats in group B (p F = 0.0033, Figure 5A ). Furthermore, compared with cats in group B, cats in group A had significantly higher blood lymphocyte counts at days 3 and 35 pi (p MWU < 0.05), as well as a tendency for higher counts at day 42 pi (p MWU = 0.0553, Figure 5A ). When cat JHW3 was excluded from the analyses, the lymphocyte cell counts tended to be Mhf at day 0. Significant differences between groups are indicated with asterisks (p MWU < 0.05). The reference interval for RBC OF based on measurements in nine healthy cats is shaded grey (50% hemolysis in NaCl 0.50-0.57% w/v) [10] . RBC OF significantly changed during the course of infection in cats in group A (p F = 0.0004, significantly higher levels at days 21 and 100 pi compared with day 0 pre-inoculation, p D < 0.05), but not in cats in group B.

higher in group A compared to group B during the study period, but significance was not achieved. The eosinophils showed a similar pattern to the lymphocyte counts in cats in group A, but the decrease in cell counts was delayed, and the nadir was reached at 6 weeks pi (p F < 0.0001, Figure 5B ); again, this pattern was less pronounced in cats in group B (p F = 0.0067, Figure 5B ). In contrast, the monocyte counts increased after infection in cats in group A, with maximal values reached at day 35 pi (p F < 0.0001, Figure 5C ); again, this pattern was less pronounced in cats in group B (p F = 0.0135, Figure 5C ). When compared to the counts in group B, the monocyte counts in group A were higher at most of the time points pi, with significance reached at days 3, 21, 35, and 100 pi (p MWU < 0.05, Figure 5C ). The monocyte cell counts were higher in group A compared to group B at most time points pi when cat JHW3 was excluded, with significance reached at days 3 and 21 pi (P MWU < 0.05). The neutrophils significantly changed over time only in cats in group A (p F = 0.0007, Figure 5D ). There were no significant differences in the neutrophil counts between the two groups.

When the course of the different white blood cell subsets was compared with the course of PCV and Mhf bacteremia, most cats showed a decrease in the leukocyte, lymphocyte, and neutrophil cell counts just prior to the decrease in PCV and the onset of maximal Mhf blood loads (data not shown). A similar pattern was also observed for the eosinophils, whereas the monocyte counts peaked at the onset of maximal anemia in most of the cats (data not shown).

In the passively immunized cats, all analyzed lymphocyte subsets [CD5 + , CD4 + and CD8 + T lymphocytes, activated CD4 + T lymphocytes (CD4 + CD25 + ) and B lymphocytes (CD45R/B220 + )], showed a significant change over time (p F < 0.05). In the control cats, a significant change during the course of infection was only observed for the activated CD4 + T lymphocyte subset (p F < 0.05). Specifically, cats in group A showed a significant decrease in the CD4 + , CD8 + and CD5 + T lymphocyte counts, with the nadir reached at days 21, 21 and 28 pi, respectively, coinciding with the onset of peak bacteremia (CD4 + , p F = 0.0012; CD8 + , p F = 0.0002; CD5 + , p F < 0.0002, Figures 6A-C) . The CD4 + /CD8 + ratio was significantly increased at 2-3 weeks pi in the passively immunized cats (p F = 0.0002, Figure 6D ). Cats in group A showed a significant decrease in their B lymphocyte counts during maximal bacteremia, with the nadir reached at day 28 pi (p F = 0.0103, Figure 6E ), and the B lymphocyte counts were significantly higher at days 3, 14, 42 and 98 pi compared with cats in group B (p MWU < 0.05; Figure 6E ). When cat JHW3 was excluded from the analyses, the B lymphocyte counts were also higher in cats in group A compared to cats in group B, with significance reached at days 3 and 14 pi (P MWU < 0.05). The activated CD4 + T lymphocyte subsets showed a somewhat different pattern than the other lymphocyte subsets in group A. The activated CD4 + T lymphocyte counts increased early during the course of infection into the onset of PCRpositivity and peak bacteremia, and then, they markedly decreased and reached a nadir at day 42 pi (p F < 0.0001); this pattern was also present but less pronounced in group B (p F = 0.0249, Figure 6F ). Furthermore, compared with cats in group B, cats in group A showed significantly higher activated CD4 + T lymphocyte counts at day 14 pi (p MWU = 0.0400) and significantly lower levels at day 42 pi (p MWU = 0.0193; Figure 6F ). When cat JHW3 was excluded from the analyses, a tendency for higher activated CD4 + T lymphocyte counts in cats in group A compared to group B was found at day 14 pi (P MWU = 0.0539); the difference at day 42 pi was still significant (lower counts in cats in group A when compared to cats in group B; P MWU = 0.024).

Bilirubin concentrations significantly increased in both groups during the course of the experiment and peaked at day 49 pi (group A, p F < 0.0001; group B, p F = 0.0036; Additional file 1A). Bilirubin concentrations were lower in group A than in group B at days 0 and 14 pi (p MWU = 0.04) but tended to be higher from day 28 until the end of the experiment, with significance reached at day 91 pi (p MWU = 0.0080; Additional file 1A). The mean bilirubin concentrations in both groups remained within the reference interval (bilirubin concentration <3.5 μmol/L) throughout the study period; bilirubin concentrations exceeding the reference interval were observed in three cats in group A (DHR 1, day 49 pi, JHW1, day 49 pi; JHW5, day 56 pi, bilirubin concentrations, range 4.4-7.7 μmol/L). The total protein concentrations significantly changed over time in groups A (p F < 0.0001) and B (p F = 0.0003; Additional file 1B) and peaked at days 63 and 42 pi, respectively. Higher total protein concentrations were observed in cats in group A compared to cats in group B, with significance reached at days 21, 35 and 49 pi (p MWU = 0.0400; Additional file 1B). When cat JHW3 was excluded from the analyses, total protein concentrations of group A were also higher compared to cats in group B with significance reached at days 3, 21 and 42 pi (P MWU < 0.05). The mean total protein concentrations of both groups remained within the reference interval (total protein, reference interval for 16-30 weeks of age, 33-75 g/L) throughout the study period; total protein concentrations above the reference interval were observed in two cats in group A and one cat in group B (total protein concentrations between 76.2-78.6 g/L). The globulin concentrations significantly increased over time only in group A (p F < 0.0001; Additional file 1C). Compared with cats in group B, cats in group A showed significantly higher globulin concentrations at days 21 and 35 pi (p MWU < 0.05; Additional file 1C).

This is the first study to investigate the protective role of the humoral immune response against hemoplasma infection using a passive immunization experiment. Our study demonstrated that the passive transfer of antibodies from Mhf-recovered to naïve SPF cats does not prevent infection, high bacterial loads and the development of clinical signs following homologous challenge with Mhf. The passively immunized and control cats showed no differences in the onset and extent of bacteremia and anemia during the course of Mhf infection. Hicks et al. [28] recently documented that Mhf-recovered cats were protected from reinfection following re-challenge with a homologous Mhf isolate. Our study indicates that the presence of antibodies to Mhf cannot mediate protection against homologous challenge, but that cellular or innate immune mechanisms may be necessary to provide protection against Mhf infection. This is also in line with the study by Hicks et al. [28] , which reported protection from Mhf reinfection in the absence of a pronounced Th2-type response in the cats after re-challenge. In the latter study, the protected cats showed no increase in anti-DnaK antibody and IL-10 mRNA levels following Mhf re-challenge. The anti-DnaK antibody levels in the passively immunized cats were only higher in the first 2 weeks after transfusion than in the control cats, and they remained below the threshold for seropositivity up to day 28 pi. It is possible that the level of antibodies in the passively immunized cats following transfusion was not sufficiently high to prevent bacteremia. However, Hicks et al. [28] documented protection from Mhf although the antibody levels to DnaK did not rise after Mhf challenge infection and remained at rather low levels (mean log-transformed relative antibody level (RAL) < 1.2) when compared to the control cats with de novo Mhf infection (peak mean RAL > 2.2). They concluded that if Mhf-specific antibodies had been responsible for immune protection in these cats, then low levels of anti-DnaK antibodies could be sufficient to provide protection against Mhf infection. Because the assay and the calculations used to quantify anti-DnaK antibodies in that study were different from those used in the present study, a direct comparison of antibody titers was not possible. Furthermore, it needs to be considered that antibodies with different epitope specificities that are not detected with current DnaK ELISA could mediate immune protection. However, assays to measure such antibodies are not available.

Infection enhancement, i.e. earlier onset of bacteremia and anemia, was recently documented in cats that had recovered from CMt infection and were re-challenged with Mhf [15] . All CMt-recovered cats were serologically positive before Mhf inoculation. The study suggested that the pre-existing antibodies against CMt might have had enhanced infection kinetics in the CMt-recovered cats [15] . Although infection kinetics were not different between the passively immunized and control cats in this study, our results still suggest that the transfer of antibodies from Mhf-recovered cats could potentially be harmful. The passively immunized cats showed a significant increase in RBC OF during the course of infection. This effect was not observed in the control cats, indicating that the increase was not simply due to a non-specific effect of plasma transfusion on RBC fragility. It can be hypothesized that the antibodies bound to the Mhf organisms attached to RBCs. RBC-bound antibodies have been found after primary Mhf infection [16, 39, 40] and can induce receptor-mediated RBC phagocytosis or the activation of the complement system [41] . In the present study, RBCbound antibodies were not detected in the cats by Coombs test, but the sensitivity of this assay may be limited [42] .

The bilirubin concentrations were also higher in the passively immunized versus control cats at some time points during infection. RBC destruction leads to the formation of free hemoglobin, which is processed by the mononuclear phagocytic system. During this process, bilirubin is formed, released in the blood stream and further metabolized and excreted by the liver. During pronounced RBC destruction, the capacity of the liver to metabolize bilirubin is overwhelmed, and hyperbilirubinemia occurs. Hyperbilirubinemia was observed in three cats of group A, although mean bilirubin concentrations in both groups remained within the reference interval. Nevertheless, the higher RBC OF values and occasionally higher bilirubin concentrations could point towards a more pronounced RBC destruction in the passively immunized cats following subsequent Mhf challenge exposure. The passively immunized cats showed signs of a more pronounced immune response when compared to control cats. Cats of group A showed higher lymphocyte, monocyte and B lymphocyte counts and higher total protein and globulin concentrations than the control cats at several time points during the experiment. Furthermore, peak globulin concentrations coincided with peak anti-DnaK antibody levels in both groups. This result was also found in our recent study, where we documented polyclonal hypergammaglobulinemia during Mhf infection coinciding with high anti-DnaK antibodies [15] . We speculated that a large portion of the immune globulin pool was not hemoplasma-specific and was potentially due to a polyclonal B lymphocyte activation. The induction of autoreactive antibodies has recently been reported for the porcine hemoplasma Mycoplasma suis and is thought to be caused by the upregulation of B lymphocytes in response to changes to the RBC surface of the infected host [43] .

It could be argued that the use of the homologous Mhf isolate for experimental challenge of the recipient cats that had been used to infect the plasma donor cats contributed to the more pronounced immune response in the passively immunized cats. This has been reported for other feline pathogens, i.e. feline coronavirus (FCoV) which can cause feline infectious peritonitis (FIP) [44] . During the pathogenesis of FIP, the virus targets macrophages and infection of these cells can be enhanced in the presence of antibodies (antibody-dependent enhancement, ADE) [45] . Takano et al. [44] showed that cats passively immunized with antibodies to serotype I FCoV showed an enhanced onset of disease following inoculation with the homologous serotype; this was not found when cats passively immunized with antibodies to serotype II FCoV were challenged with serotype I. The authors concluded that FCoV re-infection with the same serotype might induce ADE and could advance the development of FIP. Although ADE has also been suspected in bacterial infection [46] , it is unknown whether it might play a role in the pathogenesis of feline hemoplasma infections [15] . Signs of infection enhancement have recently been documented in ""Candidatus M. turicensis""-recovered, seropositive cats following a challenge with Mhf [15] . The study suggested that the presence of antibodies directed against CMt could enhance Mhf infection. However, to the best of our knowledge, disease enhancement after rechallenge with the same feline hemoplasma species has not been documented. In contrast, two studies showed that cats that had recovered from Mhf or CMt infection were protected from re-infection following re-challenge with the same hemoplasma species, respectively [27, 28] . Both studies had used an aliquot of the same Mhf or CMt isolate for re-infection that had been used for primary infection of the cats (personal communication, RHL).

The passively immunized cats showed a significant decrease in lymphocyte counts near the onset of peak bacteremia (around 3 weeks pi). This comprised decreases in absolute counts of CD4 + T lymphocytes, CD8 + T lymphocytes and B lymphocytes around three to 4 weeks pi, and was followed by an increase of the lymphocyte subsets until the end of the study. In two recent studies we reported a very similar pattern in the lymphocyte subsets following Mhf infection of naïve and CMt-recovered cats. The decrease was explained by the migration of the cells from the peripheral blood to the draining lymph nodes, where they become activated and proliferate [15, 28] .

In the individual cats, the decrease in leukocyte, lymphocyte and neutrophil counts occurred just prior to the development of anemia and the onset of peak bacteremia. A similar pattern was also observed for the eosinophils, whereas the monocyte counts peaked at the onset of maximal anemia. A decrease in leukocyte and neutrophil counts could be caused by the increased consumption of these cells, which are involved in bacterial killing or, less likely, by reduced production due to undefined inhibitory factors [47] . Monocytosis could be found due to hemolysis [48] and was shown to be associated with Mhf infection in naturally infected cats [49] . We documented leukopenia and neutropenia, as well as decreased eosinophils, lymphocytes and increased monocytes, at times of peak Mhf bacteremia also in a recent study [15] . It is difficult to judge whether the decrease in the white blood cell subsets was due to bacterial replication and cell consumption or, conversely, whether the decrease in white blood cells facilitated bacterial replication.

Interestingly, one cat in group B (JHW3) stayed PCRnegative and seronegative during the 100-day follow-up period, but it developed bacteremia and seroconverted 154 days after Mhf inoculation. Although low-level bacteremia, below the detection limit of the PCR assay, cannot be completely excluded in this cat, we would expect a productive infection to result in seroconversion [20, 50] . Because all cats in this study were kept under strictly controlled hygienic conditions, vector-borne transmission between the cats can be excluded. However, all cats of group B were housed together and four out of five cats in group B tested Mhf PCR-positive at the time that bacteremia and seroconversion occurred in cat JHW3. Therefore, direct transmission between the cats, i.e., by aggressive interactions, seems most likely, although no obvious clinical signs of aggressive interactions were observed in the cats in this study at any time during the experiment. A direct transmission of Mhf through saliva seems unlikely because only low hemoplasma loads can be detected in saliva of Mhf-infected cats [22] and transmission by oral or subcutaneous inoculation of saliva has not been successful for another feline hemoplasma species, CMt [19] .

The present study had some limitations. No masking was used during data collection and analysis. Furthermore, the relatively small groups size used in this study for animal welfare reasons could have masked significant differences between the passively immunized and control cats. However, as no protection but rather signs of infection enhancement were found in the passively immunized cats, the limited group size should not have affected the principal hypothesis addressed in this study.

The present study used an experimental set-up to address the protective role of passively transferred antibodies in Mhf infection. Experimental infection studies do have some inherent limitations when results are generalized to natural infections. However, to mirror the natural transmission of hemoplasmas most accurately, a published low-dose infection model was applied in this study [22] . The inoculated dose contained only 1000 copies of Mhf, which corresponds to approximately 0.05 μL of infectious blood from a naturally infected cat [22] . This small blood volume can easily be transmitted by bloodsucking arthropods or via aggressive interaction between cats-both of the latter transmission routes are assumed to be natural ways of transmission for feline hemoplasmas [17] [18] [19] . Therefore, the infectious dose applied to the cats should not be the reason for the lack of protection in the passively immunized cats.

Several measures were undertaken to ensure that the plasma used for passive immunization did not contain viable Mhf organisms that could transmit infection. The donor cats were tested weekly for at least eight consecutive weeks before the plasma was collected. All these samples and the plasma pool itself were tested in triplicate with a highly sensitive Mhf-specific qPCR assay [12] and revealed PCR-negative results. Furthermore, an aliquot of the plasma pool used for passive immunization was transfused into an adult SPF, the cat was followed for 23 weeks after transfusion and stayed PCR-negative.

In conclusion, passive immunization did not provide protection against experimental infection with Mhf but instead enhanced RBC fragility and was associated with a more pronounced immune response after infection. This result suggests that a humoral immune response in the absence of cellular immune mechanisms is insufficient to provide protection from Mhf infection. Potential vaccine candidates should include the induction of a cellular immune response against Mhf. and the plasma transfusions. FSB was responsible for the clinical aspects of the study and supported the plasma transfusions of the cats. RHL supported the statistical analyses. SS and BW drafted the manuscript. BW and RHL edited the manuscript. All authors read and approved the final manuscript.

",0.7169315807286583
pharmaceuticals Use of Aptamers as Diagnostics Tools and Antiviral Agents for Human Viruses,"Appropriate diagnosis is the key factor for treatment of viral diseases. Time is the most important factor in rapidly developing and epidemiologically dangerous diseases, such as influenza, Ebola and SARS. Chronic viral diseases such as HIV-1 or HCV are asymptomatic or oligosymptomatic and the therapeutic success mainly depends on early detection of the infective agent. Over the last years, aptamer technology has been used in a wide range of diagnostic and therapeutic applications and, concretely, several strategies are currently being explored using aptamers against virus proteins. From a diagnostics point of view, aptamers are being designed as a bio-recognition element in diagnostic systems to detect viral proteins either in the blood (serum or plasma) or into infected cells. Another potential use of aptamers is for therapeutics of viral infections, interfering in the interaction between the virus and the host using aptamers targeting host-cell matrix receptors, or attacking the virus intracellularly, targeting proteins implicated in the viral replication cycle. In this paper, we review how aptamers working against viral proteins are discovered, with a focus on recent advances that improve the aptamers' properties as a real tool for viral infection detection and treatment.","Viruses are infectious agents that enter and replicate only inside the living cells of other organisms. Once the virus replicates inside the cell, it may remain dormant for long periods of time or be released immediately and attach to other healthy cells to begin the infection process again. Many diseases are caused by viruses such as the influenza, hepatitis, human immunodeficiency virus (HIV) or emerging viral diseases. While they differ in symptoms such as fever and weakness, some present no symptoms at all. Rapid and secure diagnosis of viral infections is a key factor for treatment of these diseases avoiding new spread.

Viruses cause different types of damage to the body which, if left untreated, can lead to death. There are many antiviral drugs that block the infection process at different stages. Some drugs prevent the virus from interacting with the healthy cell by blocking a receptor that helps internalize the virus into the cell. Other drugs inhibit the proliferation of the virus within the cell. The simultaneously use of several drugs affecting different processes increases the probability of recovery of the patient. Although some viral infections such as hepatitis or HIV remain latent for a long time current treatments control the virus and prevent further damage to the body. Viral infections usually produce an immune response in the host that eliminates the infecting virus. The same protective effect is produced by vaccines, which confer an artificially acquired immunity to the viral infection. However, some viruses including those that cause acquired immune deficiency syndrome (AIDS) and viral hepatitis evade these immune responses and result in chronic infections. Antibiotics have no effect on viruses, but several antiviral drugs have been developed. Because viruses use vital metabolic pathways within host cells to replicate, they are difficult to eliminate without using drugs that cause toxic effects to host cells in general. The most effective medical approaches to viral diseases are vaccinations to provide immunity to infection, and antiviral drugs that selectively interfere with viral replication.

Most of the antiviral drugs are nucleoside analogues which lack the hydroxyl groups. Viruses mistakenly incorporate these analogues into their genomes during replication and, in consequence, the newly synthesized DNA is inactive and the life-cycle of the virus is then halted. Some of the most frequently prescribed antiviral nucleoside analogues based-drugs are aciclovir for Herpes simplex virus infections and lamivudine for HIV and Hepatitis B virus infections [1] . During the last years, the nucleoside analogue drug ribavirin combined with interferon has been used for hepatitis C treatment [2] , although currently there is a more effective treatment that includes simeprevir available for patients with genotype 1 and genotype 4 [3] . The treatment of chronic carriers of the hepatitis B virus by means of a similar strategy using lamivudine has been developed [4] . Today, the first line treatment of choice includes one of three drugs: Peg-IFN, entecavir or tenofovir because of their greater power and because they produce a very low rate of resistance.

Novel anti-viral agents have emerged from the field of in vitro selection of nucleic acid aptamers [5, 6] . Aptamers are single-stranded folded nucleic acids (RNA or ssDNA) able to specifically recognize a target molecule with high affinity. The term aptamer, derived from the Latin word ""aptus"" which means to fit, was firstly introduced by the Nobel laureate Szostak and Ellington [7] when they described the in vitro selection of RNA molecules that bind specifically to a variety of organic dyes. This in vitro process, called SELEX (Systematic Evolution of Ligands by EXponential enrichment), was developed by Gold and Tuerk [8] .

The SELEX process begins with the synthesis of an oligonucleotide library consisting of a central region with random sequence flanked by constant 5 and 3 ends that serve as primers ( Figure 1 ). Every member of the library is a linear oligonucleotide with a unique sequence that acquire three-dimensional structure depending on the experimental conditions (pH, ionic strength, temperature, etc.) or the presence of a ligand [9] . These highly structured aptamers are capable of binding to the target with high affinity and specificity. The diversity of an oligonucleotide library depends on the number of random nucleotides that contains each oligonucleotide molecule. Thus, an oligonucleotide library whose molecules contain a random sequence of 40 nucleotides (4 40 ) would be represented by 1.2 × 10 24 different sequences. However, in practical terms, the complexity of a combinatorial library of oligonucleotides is limited to 10 12 -10 18 different individual sequences [10] .

The first selection step implies the incubation of the target molecule with the initial library in the optimized conditions (temperature, pH, salt concentration) for the final use of the aptamer [9] . During the selection step, a subpopulation of individual sequences specifically interacts with the target molecule and this enriched subpopulation is isolated by physicochemical techniques [11] [12] [13] . Subsequently, bound sequences are eluted and amplified for a next round of selection in which the stringency of the selection conditions may be increased to identify the tightest-binding sequences. Iterative rounds are performed until the population is enriched with sequences that display high affinity and specificity for the target (Figure 1 ). During the last 25 years, several modified SELEX processes have arisen that allow adapting the technology to different targets (whole cells, small molecules, organic dyes, peptides, etc.) or to different final applications. As a final point, the selected aptamers are produced by chemical synthesis and purified to a very high degree and, therefore, eliminating the batch-to-batch variation found when using antibodies. The main advantages of aptamers in relation to antibodies are summarized in Table 1 . Table 1 . Main advantages of aptamers over antibodies.

Aptamers are identified through an in vitro process (SELEX)

Selection conditions can be manipulated to obtain aptamers stable in a wide range of environmental conditions Aptamers may be obtained against non-immunogenic proteins and toxins

Aptamers are produced by chemical synthesis Little or no batch to batch variation Aptamers can be modified increasing their stability Reporter molecules can be attached to aptamers at precise locations not involved in binding

Aptamers are oligonucleotides They can be amplified to be easily detected Denatured aptamers can be regenerated within minutes Aptamers are stable to long term storage and can be transported at ambient temperature They are not immunogenic Their small size allows for more efficient entry into the cell and its compartments During the last 25 years, several modified SELEX processes have arisen that allow adapting the technology to different targets (whole cells, small molecules, organic dyes, peptides, etc.) or to different final applications. As a final point, the selected aptamers are produced by chemical synthesis and purified to a very high degree and, therefore, eliminating the batch-to-batch variation found when using antibodies. The main advantages of aptamers in relation to antibodies are summarized in Table 1 . RNA and DNA aptamers have specific characteristics that would give them advantages for different applications. For instance, the process of selection of DNA aptamers is shorter and the chemical synthesis of DNA oligomers is cheaper and easier than the RNA oligomers. In addition, DNA aptamers usually have greater chemical stability and longer shelf life than RNA oligomers and are more resistant to nucleases activity inside living organisms. These characteristics would seem to confer to DNA aptamers important advantages to be used. However, RNA aptamers seem to have greater flexibility when it comes to folding and acquiring tertiary structures and they can be genetically encoded, and so they can be expressed directly by the target cells or organisms. Although it is commonly accepted that RNA aptamers are preferably used for therapy, while DNA aptamers are preferentially used as diagnostic tools, there are some exceptions to this non-wrote rule [14] .

Individual aptamers can be further modified in order to improve their approachability [12, 15] . For instance, chemical modifications may be introduced rising the aptamer in vivo stability. Additionally, more variations may be needed for intended applications like biotin and/or digoxigenin labelling, fluorescent reporters, or any other chemical group (thiols, amines, etc.) required for biosensing or diagnostic purposes. Moreover, aptamers can be further truncated to eliminate the oligonucleotide sequences which are not important for the interaction with the target or for the correct three-dimensional aptamer structure [16, 17] . Identification of truncated aptamers limited to the minimum domain of interaction requires considerable efforts even though aptamers of less than 40 nucleotides in length have been already reported [18] [19] [20] .

Human immunodeficiency virus is a lentivirus (a subgroup of retrovirus) that causes HIV infection and over time AIDS [21] . HIV infects essential cells in the human immune system such as CD4 + T cells, macrophages, and dendritic cells. When CD4 + T cell numbers decline below a critical level, cell-mediated immunity is lost, and the body becomes progressively more susceptible to opportunistic infections. HIV enters cells by endocytosis through the interaction of gp120 viral surface protein (SU) with CD4 host cell. The subsequent interaction of this complex with chemokine coreceptors produces a conformational change in viral protein gp41 that promotes the fusion of virion and target cell membranes leading to the release of HIV particles into the cell. Once inside the cell, viral uncoating generates the viral reverse transcription complex, and the reverse transcription gives the HIV preintegration complex (PIC). The PIC gets into the nucleus and the HIV DNA (provirus) is integrated into the cellular chromosome. Integration can lead to either latent or transcriptionally active forms of infection. The latent form gives the viral latency in cells that can replicate in new infected cells; this provirus can remain hidden during years or replicate and form new viral particles in any moment. The transcriptional active forms are transcript and translated forming new viral particles that dead the host cell and goes to infect new cells. Great efforts are being made to get sensitive, fast and simple diagnostic methods and effective therapies.

At present, the initial clinical testing for HIV in human is made with an antigen/antibody combination immunoassay that detects HIV-1 and HIV-2 antibodies and HIV-1 p24 antigen to screen for established infection with HIV-1 or HIV-2 and for acute HIV-1 infection [22] . Enzyme-linked immunosorbent assay (ELISA) and real time PCR are the methods used and accepted in clinical samples.

Aptamers that recognize HIV proteins, like Tat and Rev, have been mainly used in several biosensor systems based in Surface Plasmon Resonance (SPR) and quartz crystal microbalance (QCM) techniques. Thus, Tombelli et al. generated biosensors based on SPR and QCM technique. They introduced aptamers capable of detecting the HIV-1 Tat protein, using biotin-streptavidin interaction. This approach allows for high specificity distinction between Tat and Rev (other HIV protein, structurally similar to Tat) [23] . Other system target Tat protein using biosensor based on the diamond field-effect transistor (FET) technique [24] . These ""apta-biosensors"" have high sensibility and specificity but the devices are complex and expensive.

At present, the treatment HIV-1/AIDS is by a combination of several antiretroviral drugs (cART), which can slow the progress of the disease and reduce the risk of death and disease complication, but it is not curative. Moreover, many patients do not tolerate cART because it has severe side effects, and it is too expensive for patients in developing countries. In this regard, aptamers have been considered an alternative or adjuvant to the chemical antiviral agents in cART to overcome these limitations. To date, highly specific, nucleic acid-based aptamers that target various parts of HIV-1 genomes, HIV-1 proteins (including HIV-1 protease (PR), reverse transcriptase (RT), nucleocapsid, gp120, and Gag) and cellular proteins (nucleolin, CD4 or CCR5) have been isolated and shown to effectively suppress viral replication to apply in HIV therapy [5, [25] [26] [27] (Figure 2 ). diamond field-effect transistor (FET) technique [24] . These ""apta-biosensors"" have high sensibility and specificity but the devices are complex and expensive.

At present, the treatment HIV-1/AIDS is by a combination of several antiretroviral drugs (cART), which can slow the progress of the disease and reduce the risk of death and disease complication, but it is not curative. Moreover, many patients do not tolerate cART because it has severe side effects, and it is too expensive for patients in developing countries. In this regard, aptamers have been considered an alternative or adjuvant to the chemical antiviral agents in cART to overcome these limitations. To date, highly specific, nucleic acid-based aptamers that target various parts of HIV-1 genomes, HIV-1 proteins (including HIV-1 protease (PR), reverse transcriptase (RT), nucleocapsid, gp120, and Gag) and cellular proteins (nucleolin, CD4 or CCR5) have been isolated and shown to effectively suppress viral replication to apply in HIV therapy [5, [25] [26] [27] (Figure 2 ). (1) The HIV viral particle has an inner capside containing ssRNA viral genome and integrase and retro-transcriptase proteins, mainly; (2) The outer envelope has gp120 and gp40 proteins involved in interaction with cellular receptors (CD4, CCR5, NLS) and fusion to cellular membrane; (3) In the cytoplasm the ssRNA viral genome is released and the retro-transcription step is produced; (4) The integrase protein binds to dsDNA viral genome by LTR ends sequences and other cellular proteins forming the pre-integration complex (PIC); (5) The PIC goes into nucleus through the nuclear pore and is integrated in the cellular genome by the integrase protein activity (provirus); (6) The viral RNAs are transcripted from proviral DNA and exported to cytoplasm to translate viral proteins as protease and a big pre-protein that are assembled to new RNA viral genomes and leave the cell with outer envelope from the cellular membrane; (7) After the budding viral particle, the proteases process the big pre-protein and get a mature viral particle.

Long terminal repeats (LTRs) are sequences necessary for proper expression of viral genes. Interference with the function of these RNA domains either by disrupting their structures or by blocking their interaction with viral or cellular factors may seriously compromise HIV-1 viability. Srisawat and Engelke selected RNA aptamers that can bind to the LTRs of HIV-1 DNA [28] . They (1) The HIV viral particle has an inner capside containing ssRNA viral genome and integrase and retro-transcriptase proteins, mainly;

(2) The outer envelope has gp120 and gp40 proteins involved in interaction with cellular receptors (CD4, CCR5, NLS) and fusion to cellular membrane; (3) In the cytoplasm the ssRNA viral genome is released and the retro-transcription step is produced; (4) The integrase protein binds to dsDNA viral genome by LTR ends sequences and other cellular proteins forming the pre-integration complex (PIC); (5) The PIC goes into nucleus through the nuclear pore and is integrated in the cellular genome by the integrase protein activity (provirus); (6) The viral RNAs are transcripted from proviral DNA and exported to cytoplasm to translate viral proteins as protease and a big pre-protein that are assembled to new RNA viral genomes and leave the cell with outer envelope from the cellular membrane; (7) After the budding viral particle, the proteases process the big pre-protein and get a mature viral particle.

Long terminal repeats (LTRs) are sequences necessary for proper expression of viral genes. Interference with the function of these RNA domains either by disrupting their structures or by blocking their interaction with viral or cellular factors may seriously compromise HIV-1 viability. Srisawat and Engelke selected RNA aptamers that can bind to the LTRs of HIV-1 DNA [28] . They showed that conserved segments present in several of the aptamers could form duplexes via Watson-Crick base-pairing with preferred sequences in one strand of the DNA, assuming the aptamer invaded the duplex and, in consequence, these specific aptamers would inhibit the transcription process. Meanwhile, Sanchez-Luque et al. reported the in vitro selection of specific RNA aptamers against the 5 -untranslated region of HIV-1 genome. Those aptamers inhibited more than 75% of HIV-1 production in a human cell line. The analysis of the selected sequences and structures allowed for the identification of a highly conserved 16 nt-long stem-loop motif containing a common 8 nt-long apical loop (RNApt16; 5 -CCCCGGCAAGGAGGGG-3 ) that produced an HIV-1 inhibition close to 85%, thus constituting the shortest RNA molecule so far described that efficiently interferes with HIV-1 replication [29] . The reason to use RNA aptamer is to go into the cell as DNA plasmid and to get intracellular expression of RNA aptamer to block the target.

Aptamers to Protease (PR) During its life cycle, HIV must successfully complete several key steps in order to replicate in the host environment. One such critical step involves the processing of its Gag and Gag-Pol polyprotein precursors into their mature functional components during viral maturation. This function is provided by the virally encoded aspartyl protease (PR) and is thought to occur either during or immediately after budding [30, 31] . In its active form, this protein is a 22 kDa homodimer consisting of two 99-amino acid long subunits each of which contributes a catalytic aspartate residue to the active site. Inhibition the proteolytic activity of PR leads to the production of immature and non-infectious particles. Duclair et al. have developed RNA aptamers against viral protease that inhibited HIV replication in vitro [32] .

Several small aptamers containing G-quadruplex selected against HIV proteins have demonstrated antiviral activity [33] . The viral enzyme integrase (IN) is essential for retroviral replication, catalyzing the integration of the newly synthesized double-stranded viral DNA genome into the host genomic [34] . Ojwang et al. obtained a modified aptamer, named T30177, able to inhibit integrase activity with IC50 values in the nanomolar range [35] . T30177 was the first IN inhibitor tested in clinical trials (Zintevir™, developed by Aronex Pharmaceuticals, The Woodlands, TX, USA) [36] . Derivatives of T30177, more stable than the parental molecule and also capable of efficiently inhibiting HIV-1 replication in cell culture have been later developed [37] [38] [39] .

Reverse transcriptase has two enzymatic activities, a DNA polymerase activity that can copy either a DNA or an RNA template, and an RNase H that cleaves RNA only if the RNA is part of an RNA/DNA duplex. The two enzymatic functions of RT, polymerase and RNase H, cooperate to convert the RNA into a double-stranded linear DNA [40] . DeStefano and Nair confirmed in vitro effectiveness of DNA aptamer, named 37NT, directed against the reverse transcriptase of HIV HXB2 strain. The aptamer competed with the natural template for the binding site in the enzyme, subsequently producing inhibition of the viral replication [41] . In parallel, Michalowski et al. identified three aptamers (RT5, RT6 and RT47) which contained a bimodular structure comprising a 5 -stem-loop module linked to a 3 -G-quadruplex. In addition, the authors demonstrated that this DNA aptamers inhibited RT from diverse primate lentiviruses with low nM IC 50 values [42] .

Another interesting approach is to inhibit the RNase H activity associated with RT. With this purpose, Andreola et al. identified two DNA aptamers with G-rich sequences, named ODNs 93 and 112, capable of forming G4 structures. These aptamers inhibited the RNase H activity of HIV-1 RT in vitro with IC 50 values in the sub-micromolar range, while no effect was observed on cellular RNase H [43] . Shorter DNA aptamers derived from ODNs 93 and 112, named 93del and 112del, which maintained the capability to form stable G4 structures, were able to inhibit also HIV-1 integrase in the nanomolar range [44, 45] .

The nucleocapsid (NC) protein of HIV-1 plays an important role in the encapsidation of viral RNA and assembly of viral particle and the progress of some viral infections can be prevented by inhibition of nucleocapsid synthesis [46] . Since the NC protein is resistant for mutation, it might be an excellent target for the anti-viral therapy. Kim et al. isolated RNA aptamers that bind to the mature form of the NC protein with high affinity and compete for the packaging element (psi) RNA binding to the NC protein. Authors suggested that stabilized RNA aptamer is expected to act as an inhibitor for the viral packaging [47] .

Aptamers to Surface Glycoprotein (gp 120) Gp120 is essential for virus entry into cells as it plays a vital role in attachment to specific cell surface receptors mainly on helper T-cells. Several small aptamers containing G-quadruplex selected against gp120 have demonstrated antiviral activity [33] . The first of these molecules was the phosphorothioate 8-mer d(TTGGGGTT), named ISIS 5320, which forms a tetrameric G-quadruplex structure that binds the V3 loop of gp120 inhibiting virus entry [48] . Later on, Koizumi et al. synthesized a set of G-rich oligonucleotides and identified the hexadeosyribonucleotide d(TGGGAG), known as Hotoda's sequence, [49, 50] . Several authors have used the Hotoda's sequence as a lead sequence to make a series of modifications at the 5 and 3 ends of the molecule or mutations in the sequence that allowed to find molecules with high anti-HIV activity [50] [51] [52] [53] [54] [55] [56] .

Khati et al. in 2003 and Dey et al. two years later described the isolation of 2 -fluoropyrimidinesubstituted RNA aptamers that bind specifically to the surface glycoprotein (gp 120) of HIV-1 that potently neutralized HIV-1 infectivity in human peripheral blood mononuclear cells [57, 58] . One of these aptamers (B40) and its truncated form (B40t77) were further structural characterized [59] . Shortly later, these authors showed that the aptamer binds to the CCR5-binding site on gp120 in a relatively CD4-independent manner, providing a mechanistic explanation for its neutralizing potency [58, 60] .

Other typical therapeutic target is Gag polyprotein, because of its low variability, as compared to other sequences of HIV-1 genome [61] . Two aptamers have been developed against this protein. Thus, Lochrie et al. isolated RNA ligands that bind to the HIV-1 gag protein in the regions corresponding to the matrix (MA) protein or to the nucleocapsid (NC) protein. Interestingly, although the sequence of the aptamer was different to the HIV-1 RNA packaging element (psi), it bound to NC region interfered with binding of psi [62] . Years later, Ramalingam et al. selected a new RNA aptamer against HIV-1 Gag protein, named DP6-12. This aptamer displayed 20-fold inhibition in the extracellular capsid levels and reduced cellular levels of mRNA for Gag, probably by perturbation of specific Gag-genomic RNA interactions [63] . These results suggest that RNA aptamers may provide a novel method for inhibiting HIV replication.

Another strategy to block HIV infection is to target human proteins in host cells, like the cell co-receptor that inhibits HIV entrance into the host cell, which may have less side effects.

HIV-1 commonly uses C-C chemokine receptor type 5 (CCR5) or C-X-C chemokine receptor type 4 (CXCR-4) as co-receptors along with CD4 to enter target cells. Human CCR5 is an important co-receptor for macrophage-tropic virus expressed by T-cells and macrophages. Differences in CCR5 are associated with resistance or susceptibility to HIV-1. As an essential factor for viral entry, CCR5 has represented an attractive cellular target for the treatment of HIV-1. Thus, Zhou et al. have reported the selection of RNA aptamers against CCR5 using high throughput sequencing (HTS) to analyze the RNA pools from selection rounds 5 to 9. The individual sequences were classified into six major groups (Group 1-6). Group 2, 4 and 5 shared a conserved sequence, which is comprised of 10 nucleotides UUCGUCUG(U/G)G, named G3. The G3 activity was studied by a ""prophylactic"" HIV-1 experiment determining whether the aptamer would block HIV infectivity of R5 viruses in cell culture. The results showed that the G3 aptamer efficiently neutralized HIV-1 infectivity of R5 strains with IC 50 about 170~350 nM [25] .

Aptamers to Nucleolin (NCL) Nucleolin (NCL) is a multifunctional cellular protein that is overexpressed in cancer cell membranes. NCL is involved in the very initial step of HIV-1 virion-cell recognition. NCL is in cellular fractions containing the HIV genome, viral matrix and reverse transcriptase in addition to in complexes with CD4 and CXCR4/CCR5 at the cell membrane. This supports the potential role of this protein in viral entry. In the absence of the cellular receptors as CD4 and CXCR4/CCR5, HIV-1 attachment can occur through coordinated interactions with heparan sulfate proteoglycans and cell-surface-expressed NCL.

AS1411 is a G-rich aptamer that form a stable G-quadruplex structure and displays antineoplastic properties both in vitro and in vivo [14] . The major molecular target of AS1411 is NCL. Perrone et al. tested whether the aptamer AS1411 was able to interfere with HIV-1 cellular entry using different HIV-1 strains, host cells and at various times post-infection [26] . The results demonstrated that AS1411 efficiently inhibited HIV-1 attachment/entry into the host cell in the absence of cytotoxicity at the tested doses.

Aptamers can also serve as elements that selectively recognize and bind to defined cell types or tissues. By attaching drug molecules, the aptamers can be used to deliver cargo molecules to or into specific cells or tissues of interest [64] . In order to reach efficient RNAi activity, aptamer-siRNA conjugates must be successfully internalized and released into the cytoplasm where they can meet the RNAi machinery [65] . To improve the Dicer entry and processing of the siRNA, one pair of complementary guanosine and cytosine (GC)-rich ""sticky bridge"" sequences can be chemically appended to the 3 end of the aptamer and one of the siRNA strands, respectively. Both the aptamer and siRNA portions are chemically synthesized and subsequently annealed via ""sticky bridge"" [66] .

Through either covalent conjugation or physical assembly, different siRNA molecules have been successfully functionalized with aptamers against HIV-1 gp120 and the CD4 receptor to achieve targeted RNAi efficacy which relies on specific interactions between the aptamer and its receptor expressed on the targeted cells or tissue. Zhou et al. isolated RNA aptamers against the HIV-1(BaL) gp120 protein that were used to create a series of dual inhibitory function anti-gp120 aptamer-siRNA chimeras [67] . The authors also demonstrated that one of these anti-gp120 aptamer-siRNA chimera is specifically taken up by cells expressing HIV-1 gp120, and that the attached siRNA is processed by Dicer, resulting in specific inhibition of HIV-1 replication and infectivity in cultured CEM T-cells and primary blood mononuclear cells (PBMCs). Interestingly, both the aptamer and the siRNA portions in the aptamer-siRNA chimera have potent anti-HIV activities [68] . Finally, the authors tested the antiviral activities of these chimeric RNAs in a humanized mouse model with multilineage human hematopoiesis showing that treatment with either the anti-gp120 aptamer or the aptamer-siRNA chimera suppressed HIV-1 replication by several orders of magnitude and prevented the viral-induced helper CD4 + T cell decline [69] . In order to improve the utility of aptamers as siRNA delivery vehicles, the same authors chemically synthesized a modified gp120 aptamer that was complexed with three different siRNAs (HIV-1 tat/rev and two HIV-1 host cell proteins, CD4 and TNPO3), resulting in an effective delivery of siRNAs in vivo, knockdown of target mRNAs and potent inhibition of HIV-1 replication in a humanized mouse model [70] . Very interestingly, following ending of the aptamer-siRNA cocktail treatment, HIV levels rebounded facilitating a follow-up treatment with the aptamer cocktail of siRNAs that resulted in complete suppression of HIV-1 viral loads that extended several weeks beyond the final injection.

Another interesting approach to targeted delivery was developed by Zhu et al. [27] . In this work, the authors show that a DNA aptamer obtained from the conversion of a previously reported RNA aptamer could be used to deliver siRNA into CD4 + T cells specifically. This DNA aptamer was covalently conjugated to the sense strand of the siRNA targeting HIV-1 protease (HIV-PR) and the resulting DNA aptamer-siRNA chimera specifically entered into CD4 + T cells and efficiently knockdown the expression of exogenous HIV-PR gene. This study demonstrated that DNA aptamers with intrinsic stability had a greater potential to be used for siRNA delivery. Table 2 shows information on the aptamers described against HIV. A direct application of the use of aptamer-siRNA chimera has been proposed by Wheeler et al. [71] . They demonstrated that CD4 aptamer-siRNA chimeras (CD4-AsiCs) specifically block gene expression in CD4 + T cells and macrophages in vitro, in polarized cervicovaginal tissue explants, and in the female genital tract of humanized mice. Thus, CD4-AsiCs could be used as the active element of a microbicide to avoid HIV sexual transmission.

In summary, all these interesting results point out the use of aptamers for development of novel anti-HIV-1 therapies.

Hepatitis B virus (HBV) is a partially double-stranded DNA virus of the Hepadnaviridae family classified into eight genotypes from A to H. The main element of the viral particle of HBV virus and also the most characterized component is the hepatitis B surface antigen (HBsAg) [72] .

One of the current objectives in the diagnostic of HBV is to develop a daily screening assay with a short period of detection between infection and recognition. Therefore, Suh et al. have developed a fast and low cost detection test based on competitive binding assay combined with fluorescence resonance energy transfer (FRET) [73] . The assay was built with an aptamer selected against the hepatitis B virus surface antigen (HBsAg), the best characterize and most frequently used HBV marker [74] . The described aptasensor was approximately 40-fold more sensitive than the conventional method. In 2015, a new set of three different DNA aptamers was selected against HBsAg and applied to develop a chemiluminescence platform. The new aptasensor was designed with aptamers-conjugated to magnetic nanoparticles reaching a detection limit five-fold better than the current enzyme-linked immunosorbent assay (ELISA) kits used in hospitals [75] .

During the last years, different strategies to inhibit HBV activity have been described using aptamers selected against diverse viral target proteins. First, in 2010, Liu et al. proposed as a therapeutic tool RNA aptamers selected against HBsAg protein that are able to discriminate between HbsAg-expressing liver cells and HBsAg-negative cells [74] . Later, Feng et al. described an innovative strategy to fight against HBV infection suppressing the ribonucleoprotein complex interaction between the reverse transcriptase (named P protein) and the RNA stem-loop (ε). With this purpose, they isolated individual RNA aptamers with high affinity for the recombinant truncated HBV P protein that compete with the ε RNA interaction, without cytotoxic effects in culture cells, suggesting a potential antiviral activity of described aptamers [76] . On the other hand, Zhang et al. have chosen HBV core protein (HBVc) as a target to isolate DNA aptamers to inhibit nucleocapsid formation. They have shown that selected aptamer Apt.No.28 prevents nucleocapsid assembly and viral replication in the hepatic cellular line HepG2.2.15 [77] . Finally, Orabi et al. have isolated DNA aptamers to recognize specifically the matrix binding domain (MBD) but not the domain mutated in the residue 126 (I126A). One of the isolated aptamers, AO-01, has been proposed as a therapy molecule by inhibition of the virion production interfering the interaction between the matrix domain and the MBD [78] . Table 3 shows information on the aptamers described against HBV. 

HCV viral genome is a positive-strand RNA that contains approximately 9.6 kilobases and codified for a polyprotein of around 3000 amino acids. The HCV polyprotein maturation process mediated by proteases gives rise to 10 viral proteins, four structural (C, E1, E2 and p7) and six non-structural (NS2, NS3, NS4A, NS4B, NS5A and NS5B) [79] . To date, only three proteins (p7, NS4A and NS4B) have not been used as antiviral target for isolate specific aptamers.

Aptamer-based biosensors are a promising diagnostic platform to allow HCV infection detection in early stages or in immunosuppressed patients. Thus, different groups have developed diverse aptasensors to improve diagnostic assay of HCV infection. First, Lee et al. developed a biosensor prototype that specifically recognizes the HCV core protein from sera of an infected patient using selected RNA aptamers against core antigen. The HCV viral particles were retained by the 2 -F aptamers immobilized in a 96-well plate and detected by sequential steps with anti-core and Cy3-labeled secondary antibodies [80] . Later on, Chen et al. developed an early diagnostic assay based on sandwich-ELISA to recognize HCV viral proteins using biotin-labelled DNA aptamers against HCV Envelope glycoprotein E2. The obtained results from infected patients showed a good correlation between viral genome quantification assay, HCV antibody detection and sandwich-ELISA aptasensor [81] . Afterwards, Shi et al. developed a similar platform for early detection, coating the bottom of the well with C7, a DNA aptamer against HCV core labelled with biotin, and HCV-core antibody conjugated with horseradish peroxidase (HRP) is applied over the surface. The platform was applied to the detection of the protein in sera from HCV-infected patients and showed a proportional relationship between amplified RNA copies and HCV core protein concentration [82] . Moreover, Wang et al. designed a rapid, easy-to-use diagnostic platform composed of lateral flow strips treated with thiol-DNA aptamers against HCV core antigen. HCV ELISA assay and core aptamer lateral flow strips showed positive coincidence rates when compared with HCV RNA amplification assay [83] . In an effort to develop a diagnostic test to monitor the infectivity of HCV samples, Park et al. have designed an ELISA-like assay replacing the capture and detection antibodies for DNA aptamers selected against HCV E2. The Enzyme Linked Apto-Sorbent Assay (ELASA) has been described to be used for qualitative and quantitative analysis of virus in infected samples [84] . Further, two laboratories have developed label-free aptasensor to eliminate the labelling step and simplify the HCV detection method. Hwang et al. have described a highly sensitive label-free aptasensor based on nanomechanical microcantilevers. The biosensors were able to measure the surface stress due to the interaction between immobilized RNA aptamers and the HCV helicase [85] . On the other hand, Roh et al. have developed a label-free diagnostic platform to detect and quantify the presence of HCV polymerase NS5B viral protein using conjugated streptavidin-biotin RNA aptamers on an Octet biosensor [86] .

Eradication of HCV disease is one of the main objectives of global public health. Currently, HCV infected patients are treated combining protease inhibitors, as Telaprevir (TVR) and Boceprevir (BOC), with pegylated-interferon and Ribavirin. However, the new direct-acting antivirals (DAA), TVR and BOC, generate a high rate of side effects, are too expensive and are also susceptible to new resistant viruses [87] . Therefore, it is necessary to develop new DAA treatments that are more effective and with fewer side effects than current therapies. To this end, different advances have been made based on aptamers against HCV and host cell proteins as therapy [88] (Figure 3 ). amplification assay [83] . In an effort to develop a diagnostic test to monitor the infectivity of HCV samples, Park et al. have designed an ELISA-like assay replacing the capture and detection antibodies for DNA aptamers selected against HCV E2. The Enzyme Linked Apto-Sorbent Assay (ELASA) has been described to be used for qualitative and quantitative analysis of virus in infected samples [84] . Further, two laboratories have developed label-free aptasensor to eliminate the labelling step and simplify the HCV detection method. Hwang et al. have described a highly sensitive label-free aptasensor based on nanomechanical microcantilevers. The biosensors were able to measure the surface stress due to the interaction between immobilized RNA aptamers and the HCV helicase [85] .

On the other hand, Roh et al. have developed a label-free diagnostic platform to detect and quantify the presence of HCV polymerase NS5B viral protein using conjugated streptavidin-biotin RNA aptamers on an Octet biosensor [86] .

Eradication of HCV disease is one of the main objectives of global public health. Currently, HCV infected patients are treated combining protease inhibitors, as Telaprevir (TVR) and Boceprevir (BOC), with pegylated-interferon and Ribavirin. However, the new direct-acting antivirals (DAA), TVR and BOC, generate a high rate of side effects, are too expensive and are also susceptible to new resistant viruses [87] . Therefore, it is necessary to develop new DAA treatments that are more effective and with fewer side effects than current therapies. To this end, different advances have been made based on aptamers against HCV and host cell proteins as therapy [88] (Figure 3) . 

Non-translated 5′ and 3′ regions have highly conserved sequences and structured regions closely related with transcription and replication of the HCV virus. Specifically, 5′ end contains the Internal 

Non-translated 5 and 3 regions have highly conserved sequences and structured regions closely related with transcription and replication of the HCV virus. Specifically, 5 end contains the Internal Ribosome Entry Site (IRES) domain responsible of transcription initiation by ribosome recognition of HCV viral genome. However, 3 UTR includes a region essential for viral replication named cis-acting replication element (CRE).

In 2003, Toulmé et al. decided to use subdomain IIId of IRES element as an antiviral target. They selected RNA aptamer and verified that isolated aptamers inhibit HCV translation in vitro and in cell culture [89] . In the same year, Kikuchi et al. isolated RNA aptamers capable of binding to the domain II of HCV IRES and showed that IRES-mediated in vitro translation was reduced from 20% to 40% by using the 2-02 aptamer [90] . Later, they isolated a new RNA aptamer population against the HCV IRES domains III-IV and corroborated that 3-07 aptamer had a high inhibitory effect on IRES-mediated translation in vitro and in vivo [91] . To improve the inhibitory effect of selected aptamers, they constructed two new molecules, named 0207 and 0702, composed by 2-02 and 3-07 aptamers linked by their ends. The fused aptamers recognized two different subdomains of IRES element and are at least 10 times more efficient than the parental aptamers in the inhibition of mRNA IRES-dependent translation in vitro [92] . Following with IRES as an anti-viral target, Romero-López et al. described an innovative in vitro selection method to isolate aptamers fused to a hammerhead ribozyme with capacity to inhibit RNA translation mediated by IRES. Selected chimeric aptamer-ribozymes were able to recognize the IRES element and cleavage the 5 end at nucleotide position 363 [93] . The success of combining two functional elements in the same molecule was shown in the selected chimeric molecule HH363-50. Thus, the aptamer-ribozyme chimera did anchor to domain IV of the IRES element and inhibited in vitro and in vivo IRES-mediated translation [94] . Therefore, recruitment of ribosomal particles mediated by the IRES element was inhibited by the chimera HH363-24 that prevented both translation and replication in a hepatic cell line [95] . Moreover, to avoid HCV genome replication, Konno et al. isolated RNA aptamers against the 3 end of the negative strand of the virus genome [96, 97] . Interestingly, a RNA aptamer, named AP30, was able to recognize this minus-IRES region and reduce positive-strand genomic RNA synthesis [96] . To inhibit HCV replication, Marton et al. selected RNA aptamers against CRE element that were able to repress replication of HCV replicon in hepatic cells [98] . Subsequently, two selected aptamers, P58 and P78, interact with subdomain 5BSL3.2 of the CRE element and produce a structural reorganization of the 3 end HCV genome and a significant decrease of HCV replication in vivo [99] .

Aptamers to Nonstructural Protein 2 (NS2) NS2 protein is a remarkable HCV target for the development of direct-acting antivirals due to the fact that NS2 protein is implicated in HCV replication and is essential in viral cycles. Recently, Gao et al. have isolated DNA aptamers against NS2. Specifically, they have shown that aptamer NS2-2 inhibited viral particle production as a result of N-terminal protein domain interaction, preventing NS5A/NS2 complex [100] .

Multifunctional enzyme NS3 is an essential protein for virus survival and it is considered a good target for the development of new antiviral-drugs. The protease activity of the protein is found in the N-terminal domain and the helicase activity is present in the C-terminal domain of the enzyme. During the last years, the group of Nishikawa has been working with different sets of RNA aptamers against the full-length or truncated NS3 protein to inhibit its dual-activity. Initially, they isolated NS3-specific aptamers that inhibited the protease activity (10-G1) or the dual activity, protease/helicase, of the enzyme NS3 (G6-16 and G6-19) [101, 102] . Afterward, new RNA aptamers against the helicase domain of NS3 protein, named G9-I, II and III, were able to inhibit protease activity in vitro [103] . Later on, the authors described the interaction between G9-I aptamer with Arg161/Arg130 residues in the truncated NS3 form as a putative target for protease activity inhibition [104] . To stabilize and protect G9 aptamers against exonuclease activity in vivo, Nishikawa et al. conjugated G9-II aptamer to the stem IV region of the Hepatitis delta virus (HDV) ribozyme. In addition, to allow nuclear export of the aptamer, the chimeric molecule HDV-G9-II (HA) was fused to a constitutive transport element (CTE) generating HAC molecule. Finally, the protease-inhibition capability of G9-II aptamer was checked, using HA and HAC expression vector in vivo [105, 106] . In order to inhibit the dual activity of NS3, a poly U tail in the 5 or 3 ends of G9-I aptamer (5 -14U-NEO-III or NEO-III-14U) was added. The two constructions were able to inhibit with high efficiency of the protease and helicase activities of NS3. Moreover, NEO-III-14U decreased the interaction between NS3 protein and the 3 end of the positive or negative sense HCV RNA and inhibited protease activity of NS3 in vivo [107] . Next, a new set of RNA aptamers were selected against the helicase domain using the truncated NS3 protein (NS3h) and the aptamer with greatest capability to deplete helicase activity in vitro was identified and named aptamer #5 [108] . Finally, a dual-functional aptamer named G925-s50 was designed using a truncated version of aptamer #5 plus G9-II aptamer linked by 50 mer poly(U) spacer. The designed molecule G925-s50 showed a significant inhibition of NS3 helicase-protease activity in vivo and is proposed by Nishikawa group as the best candidate for anti-HCV therapy [109] .

It has been reported that NS5A protein is essential for HCV production and replication. Recently, Yu et al. have isolated and characterized DNA aptamers against HCV NS5A protein. Particularly, selected aptamer NS5A-5 was able to inhibit HCV virus infection by prevention of protein-protein interactions between NS5A and core protein [110] .

Aptamers to Nonstructural Protein 5B (NS5B) HCV nonstructural protein 5B (NS5B) is a RNA-dependent RNA polymerase protein (RdRp) responsible to the generation of positive-sense genomic HCV RNA and negative-sense RNA template. Reduction of HCV NS5B polymerase activity affects HCV viral life cycle and is one of the main objectives to isolate aptamers against NS5B. Thus, Biroccio et al. identified specific RNA aptamers against a truncated protein NS5B-∆55 without the C-terminal region. One of the selected aptamers, B.2, blocked RNA transcription but not competed with the complex RdRp-RNA, using different binding site than RNA template to the NS5B protein [111] . In the same way, Bellecave et al. selected DNA aptamers against the NS5B viral protein. One of the chosen aptamers, 27v, competed with positive and negative sense HCV viral RNA to bind RdRp polymerase and blocked initiation and elongation steps of RNA transcription [112] . However, 127v aptamer partially competes to dissociate RdRp-RNA complex formation and only inhibited initiation steps of HCV transcription [113] . Moreover, interference of viral production and transcription inhibition of HCV virus was confirmed in vivo using 27v aptamer. Table 4 shows information on the aptamers described against HCV. Five years later, another set of RNA aptamers against NS5B protein were obtained by Lee et al. [114] . To avoid aptamer degradation, oligonucleotides were modified with 2 hydroxyl (R-OH) or fluoropyrimidines (R-F). The R-OH aptamers blocked RNA synthesis of HCV replicon in cell culture without emergence of virus escape mutant or cellular toxicity. On the other hand, R-F oligonucleotides were truncated and conjugated with cholesterol-or galactose-PEG molecules to allow direct and specific liver delivery into cells or tissue. Cholesterol-and Gal-PEG-R-F t2 conjugated aptamer blocked RNA synthesis of HCV genome [115] . The above mentioned aptamers were non-genotype-specific; however, Jones et al. described for the first time aptamers against NS5 protein that exclusively recognized and inhibited RNA-polymerase activity of HCV virus subtype 3a [116] .

Envelope E1 and E2 glycoproteins are putative targets in therapy due to its role in HCV viral recognition to enter into hepatic cells. Chen et al. have isolated DNA aptamer against E2 glycoprotein. The selected aptamers have higher affinity to genotype 1a, 1b and 2a than others, and strongly prevented HCV viral infection in Huh7 5.1 cells [81] . Afterwards, Yang et al. described the potential antiviral action of DNA aptamers selected against E1E2 protein by HCV infection suppression in HuH7.5 cells without innate immune response action [117] . In the case of core, an essential protein for HCV viral assembly, Shi et al. have applied for therapy the above-mentioned aptamers in diagnostics. In Huh7.5 cells, the aptamers against HCV core protein repressed viral production as a result of defective assembly of virus particle without stimulation of innate immune response [82] .

Finally, an innovative approach to inhibiting HCV viral infection has been designed based on sequestration of miR-122, implicated as a regulator of fatty-acid metabolism in mammals, exclusively in infected cells. To this end. Lee et al. have generated a chimeric molecule composed by a hammerhead ribozyme conjugated with an aptamer against NS5B protein. After aptamer recognition of HCV infection, ribozyme domain released a sequence complementary to miR-122 producing the inhibition of HCV replication in Huh-7 cells [118] .

Selected aptamers against HCV have been shown to be good tools for inhibiting viral protein activity. However, none has been tested in clinical trials because it is necessary to overcome a number of limitations such as degradation, biodistribution, immune response or cellular internalization. Nevertheless, recent publications have described different strategies to overcome aptamer restrictions using cholesterol or ribozyme conjugation [115, 118] .

Human papillomavirus (HPV) is a DNA virus from the papillomavirus family. Most HPV infections cause no symptoms and resolve spontaneously, but some of them persist and result in warts or precancerous lesions which increase the risk of cancer of the cervix, vulva, vagina, penis, anus, mouth, or throat [119, 120] .

Several proteins from human papillomavirus, particularly E6 and E7, promote tumor growth and malignant transformation and are frequently associated with cervical cancer. Thus, these proteins represent ideal targets for diagnostic and therapeutic strategies. Belyaeva et al. reported two RNA aptamers to E6, named F2 and F4, which induced apoptosis in cells derived from an HPV16-transformed cervical carcinoma. This aptamers were able to inhibit the interaction between E6 and PDZ1 from Magi1, with F2 being the most effective inhibitor, while none of them inhibited E6-p53 interaction or p53 degradation [121] .

Toscano-Garibay et al. isolated an aptamer (G5α3N.4) that exhibited specificity for E7 with a Kd comparable to aptamers directed to other small targets [122] that may be used for the detection of papillomavirus infection and cervical cancer. The same group characterized an RNA aptamer, named Sc5-c3, that recognized baculovirus-produced HPV-16 L1 virus-like particles (VLPs) with high specificity and affinity (Kd = 0.05 pM). This aptamer produced specific and stable binding to HPV-16 L1 VLPs even in biofluid protein mixes and thus it may provide a potential diagnostic tool for active HPV infection [123] . Recently, Graham and Zarbl identified several DNA aptamers that have high affinity and specificity to the non-tumorigenic, revertant of HPV-transformed cervical cancer cells, which can be used to identify new biomarkers that are related to carcinogenesis produced by HPV [124] .

All these reports show the potential benefits of the E6/E7 aptamers as potential diagnostic agents in the future.

E7 has been shown to bind a number of cellular proteins, including the cell cycle control protein pRb. In an interesting study, Nicol et al. selected an RNA aptamer, termed A2, with high affinity to HPV-16 E7 [125] . Transfection of this aptamer into HPV-16-transformed cells resulted in induction of apoptosis and consequent inhibition of cell proliferation. In addition, the authors demonstrated that A2 bound to the N-terminal residues of E7 required for interaction with pRb and that, consequently, A2 disrupted the interaction between E7 and pRb in vitro [125] . Furthermore, the authors demonstrated that A2 enhanced E7 localization in the ER and that the A2-mediated reduction of E7 was not associated with proteasomal degradation suggesting that A2 perturbs normal E7 trafficking through promoting E7 ER retention [126] .

For a different purpose, Gourronc et al. selected RNA aptamers that entered with significant internalization capacity (~5-fold) into HPV-16 E6/E7-human tonsillar epithelial cells (HTECs). In addition, although individual aptamers internalized into E6/E7 and primary HTECs with similar efficiency, one of them exhibited~three-fold better internalization into E6/E7-HTECs. The authors claim that aptamers that internalize into cells may be useful for delivering therapeutic agents to HPV-16 associated malignancies [127] .

Herpes simplex virus 1 and 2 (HSV-1 and HSV-2) are two members of the herpesvirus family, Herpesviridae, that infect epithelial tissues before invading the nervous system, where it becomes latent. Unfortunately until now, it has not found any treatment to eradicate the virus [128] . Table 5 shows information on the aptamers described against HPV and HSV. Aptamer technology has been used by Corbin-Lickfett et al. to identify RNA sequences capable of being recognized by HSV-1 ICP27 protein, an important regulator for viral gene expression. After SELEX procedure, GC-rich RNA sequences were isolated, which did not form stable secondary structures [129] . With a therapeutic purpose, Gopinath et al isolated two RNA aptamers (aptamer-1 and aptamer-5) against the ectodomain of the gD protein of HSV-1, which plays an important role in viral entry to the host cells. These aptamers specifically bind to gD protein of HSV-1 with high affinity but not the gD protein of HSV-2. Furthermore, aptamer-1 efficiently blocked the interaction between the gD protein and the HSV-1 target cell receptor (HVEM) in a dose-dependent manner with a EC 50 in the nanomolar range. Anti-HSV-1 activity of aptamer-1 was analyzed by using plaque assays and the results showed that this aptamer efficiently inhibited viral entry. A shorter variant of aptamer-1 named mini-1 aptamer (44-mer) had at least as high an affinity, specificity, and ability to interfere with gD-HVEM interactions [130] . In a similar way, Moore et al. have reported the isolation and characterization of one aptamer, G7a, that binds the gD protein of HSV-2 and neutralizes infection through the Nectin1 and HVEM entry receptors with IC 50 of 20 nM [131] . Interestingly, aptamers that prevent HSV-2 infection may also reduce the morbidity associated with HIV-1 as HSV-2 is a major risk factor for the acquisition of HIV-1. 

Influenza is considered the most prevalent infectious disease in humans. Three emerging influenza viruses were responsible for major pandemics in the twentieth century: the 1918 Spanish influenza virus, the 1957 Asian influenza virus, and the 1968 Hong Kong influenza virus [132] . Indeed, the 1918 Spanish influenza virus was estimated to have killed 20-50 million people worldwide [133] . More recently, a highly pathogenic avian virus of the H5N1 subtype has produced sporadic infections in humans and, while it is associated with high rates of mortality, its poor transmission in humans prevented a more extensive spread among human populations. However, in 2009, a new influenza A virus of the H1N1 subtype emerged (pH1N1) that possessed high transmissibility but relatively low virulence, rapidly spreading across the entire globe and causing the first pandemic of the 21st century [134, 135] . Subsequently, 2013 witnessed the appearance of a new highly pathogenic avian virus of the H7N9 subtype in China [136] .

Influenza viruses are enveloped RNA virus of the family Orthomyxoviridae. The virion surface carries two membrane glycoprotein components, hemagglutinin (HA) and neuraminidase (NA) and, in the central core, the viral RNA (negative-sense) genome fragmented into eight single-stranded molecules and viral proteins that package and protects this RNA. Each segment contains one or two genes that code for the 15 viral proteins. Highly variable surface proteins, HA and NA, are used to classify influenza subtypes. The combination of hemagglutinin and neuraminidase mainly determines the host organism and the viral infectiousness. Currently, 18 HA and 11 NA types have been identified being the subtypes H1, H2 and H3, and N1 and N2 commonly found in humans.

The detection rapid of influenza virus as well as the categorization of these viruses is particularly important due to the high risk of infection, the rapid propagation and the high frequency of mutation that often induces the arrival of new strains that can cause epidemics and even pandemics. An extensive review about the diagnostic strategies for influenza has been recently published [137] .

The antibodies are the most common probe used to detect either the viral particles or host antibodies developed during the infection. However, although in most cases antibodies are able to distinguish between influenza A and B, only a few antibodies that differentiate subtypes of Influenza A or B have been reported. Alternative probes for subtyping are the aptamers. Thus, aptamers to hemagglutinin (HA) have been successfully and broadly used for the development on sensors for influenza detection. HA is expressed in high amounts in the viral surface and is required for binding and fusion with the host cell. Currently, more than 40 DNA and RNA aptamers to HA have been described since 2004, selected to recombinant hemagglutinins (H1, H3, H5, H9 and Ha from virus B) and to whole viruses (H5N1) (reviewed in [138] ). Misono and Kumar selected an RNA aptamer against to HA of A/Panama/ 2007/1999 (H3N2) using SPR-based SELEX [139] . Gopinath et al. generated two RNA aptamers against intact influenza virus A/Panama/2007/1999 and HA of B/Johannesburg/05/1999. These RNA aptamers are able to discriminate among both A and B influenza viruses [140, 141] .

The recent advances in the development of rapid, automatic, point of care devices for the diagnosis and subtyping of influenza virus are sustained in two facts: (i) the rapid spread of influenza-associated H1N1 viruses that has caused serious concern in recent years; and (ii) H5N1 subtype of the avian influenza virus (AIV) caused the most lethal outbreaks of highly pathogenic avian influenza (HPAI) in poultry and fatal infections in human cases for over a decade. Thus, aptamers have been generated and found to be specific against these recent pandemic influenza viruses A/H1N1pdm [142] and H5N1 [143] .

Lee et al. developed an integrated microfluidic system that was used to screen a specific aptamer for the influenza A/H1N1 virus in an automated and highly efficient manner [144] . The selected aptamer showed a specific and sensitive detection of the influenza A/H1N1 virus, even in biological samples such as throat swabs. Later, they used a new approach for fluorescence-based detection of the influenza A H1N1 virus using a sandwich-based aptamer assay that is automatically performed on an integrated microfluidic system [145] . The entire detection process was shortened to 30 min using this chip-based system which is much faster than the conventional viral culture method. The limit of detection was significantly improved due to the high affinity and high specificity of the H1N1-specific aptamers. In addition, this two-aptamer microfluidic system had about 10 3 times higher sensitivity than the conventional serological diagnosis. The conformation of the aptamers changes in response to the solvent composition, including ion type and concentration, pH, and temperature. On the basis of this, Wang et al. have developed a microfluidic system that exploited the predictable change in conformation of the aptamer previously used in the group, exposed to different ion concentrations in order to detect multiple types of the influenza virus [146] . Thus, a single fluorescent-labelled aptamer is able to identify three different influenza viruses (influenza A H1N1, H3N2, and influenza B) at the same time, by modifying operating conditions, in 20 min. This chip-based aptamer-binding assay has several important advantages; it is rapid, accurate, and cheaper than multiple-aptamer screening.

Current methods for H5N1 AIV detection are virus isolation and RT-PCR that requires several days and expensive equipment and reagents. Rapid detection assays are also available (such as ELISA or immunochromatographic strips) but are less sensitive and specific. The alternative approach is biosensors technology, several biosensors have been developed to detect AIV among them biosensors using as probe aptamers (aptasensors) (reviewed in [147] . In the Li's lab, a highly specific DNA aptamer that can bind H5N1 virus with high affinity was selected. Using this aptamer, other authors have developed different aptasensors based on Surface Plasmon Resonance (SPR) [148] , a quartz crystal microbalance (QCM) aptasensor crosslinked polymer hydrogel [149] and several aptasensors based on impedance methods [150] [151] [152] . These aptasensors were able to detect H5N1 quickly and/or with more sensitivity than antibody-based biosensors.

The impedance-based aptasensor described Fu et al. has the lowest detection limit, however, it requires signal amplification with labels and a prolonged detection limit [150] . The impedance aptasensor with microfluidics chips has a lower detection limit than the SPR-based aptasensor [148] and the same sensitivity as the QCM aptasensor [149] , but the QCM-based aptasensors are not practical for in-field use due to the QCM's predisposition to environmental noise. The major advantage of the impedance aptasensor with gold nanoparticles for signal amplification described by Karash et al. is that it requires a small sample volume and is cheaper than the detection platforms based on QCM or that use interdigitated electrode microfluidic chips [152] . Recently, Nguyen et al. developed a sandwich-type SPR-based biosensor for the detection of H5Nx viruses using a pair of aptamers selected against a mixture of H5Nx whole viruses using Multi-GO SELEX [153] . The sensitivity of the dual aptamer-based system increased by more than 50-fold than for single-aptamers. In addition, the sensitivity was additionally enhanced when the secondary aptamer was conjugated with gold nanoparticles.

Several aptamers against influenza virus have been developed for therapeutics purposes, mainly targeting hemagglutinin (reviewed in [5] ) (Figure 4) . These aptamers are able to inhibit the entry of the virus of the cells by blocking hemagglutinin activity. The common technique to measure the inhibitory activity of the aptamers in vitro is the hemagglutination inhibition assay. The model was more extensively used to test the effect of the aptamers on the viral infection involving the use of cell cultures, mainly Madin-Darby canine kidney (MDCK) cells. The cells are infected with the virus and incubated with the aptamers and the inhibition of viral infectivity is tested. Using these assays, DNA and RNA aptamers selected against HA from Influenza A virus [142, [154] [155] [156] [157] [158] or avian influenza virus [159] [160] [161] , able to significantly decrease the viral infection in cells, have been described. However, only a few studies have described aptamers capable of mediating a reduction in viral pathogenicity in mice models. Jeon et al. evaluated the effect of the administration intranasal of the A22 aptamer, a DNA aptamer selected against the HA-(91-261) peptide, in mice before, at the same time and after virus infection [154] . The aptamer-induced inhibition of viral infection was determined by prevention of weight loss, decrease of viral load in the lungs and restriction of the level of inflammation and cellular infiltration. A22 reduced up to 95% of infection in all the strains tested (H1N1, H2N2 and H3N2). A22 was most effective when administered concomitantly with the viral infection leading to 95% reduction in viral burden. The administration of A22 one day prior to infection (preventive treatment) was less effective, probably because the DNA is partially degraded. Interestingly, the treatment with A22 two days following the infection (therapeutic treatment) still leads to almost 95% reduction in viral titer in the lungs of the mice. In 2014, Musafia et al. used A22 aptamer as a starting point and the quantitative structure-activity relationship (QSAR) tool to produce aptamers with 10-15 times more potent antiviral activity in animal models than A22 aptamer. The binding of these aptamers to the virus (20 times higher than A22) may not necessarily be sequence-specific being the most important properties the aptamer length, 2D-loops and repeating sequences of C nucleotides [157] .

Other aptamers targeting NS1 or the PA polymerase subunit 1 have also been studied. NS1 is a nonstructural protein of small size, between amino acids 230 and 238 and with a molecular weight of 26 kDa. In view of its interaction with both RNAs and viral and cellular proteins, NS1 has been implicated in many of the alterations that occur during influenza virus infection. Moreover, NS1 has anti-interferon (IFN) properties leading to the inhibition of the host's innate immunity [162] . Thus, the importance of NS1 in viral infection makes it an attractive therapeutic target. Woo et al. selected a DNA aptamer specific to NS1 that induced IFN-β production by inhibiting NS1 function. In addition, the selected aptamer was able to inhibit the viral replication without affecting cell viability [163] .

Another antiviral strategy is the inhibition of the enzymes involved in the viral replication, transcription and translation. The polymerase complex of Influenza virus catalyzes the viral replication and transcription. This heterotrimer is composed of three subunits named PA, PB1 and PB2 [164] [165] [166] . PA plays the role of an endonuclease, cleaving host mRNAs downstream of their mRNA cap structures, which are recognized and bound by PB2 [167] . The N-terminal of the PA subunit (PA N ), which holds the endonuclease activity site, is highly conserved among different subtypes of influenza virus, which suggests it is an attractive target in the development of anti-influenza agents. Yuan et al. selected DNA aptamers against both PA protein (three aptamers), and the PA N domain (six aptamers) of an H5N1 virus strain [168] . Four of the six PA N selected aptamers inhibited both endonuclease activity and H5N1 virus infection whereas the three PA-selected aptamers did not inhibit endonuclease activity and virus infection. Finally, one of the four effective aptamers, exhibited cross-protection against infections of H1N1, H5N1, H7N7, and H7N9 influenza viruses, with a 50% inhibitory concentration (IC 50 ) around 10 nM.

Pharmaceuticals 2016, 9, 78 19 of 33 aptamers, exhibited cross-protection against infections of H1N1, H5N1, H7N7, and H7N9 influenza viruses, with a 50% inhibitory concentration (IC50) around 10 nM. The association of the viral polymerase, bound to the cap, and eIF4GI may be involved in the preferential translation of viral mRNAs during influenza infection. In addition, the interaction of NS1, bound to a conserved 5untranslated region (UTR) element of the viral mRNA, with eIF4GI and PABP1 could promote the formation of a ""closed loop"" between the 5′ and 3′ ends of the viral mRNA; (4) RIG-I is a cytosolic receptor for non-self RNA that mediates immune responses against viral infections through IFNα/β production. Mitochondrial antiviral-signaling (MAVS) protein. Table 6 shows information on the aptamers described against influenza virus. Vaccination is a powerful approach to diminish the effects of influenza epidemics, but the use of antiviral drugs can also be very useful, particularly in delaying the spread of new pandemic viruses. Neuraminidase inhibitors like oseltamivir, laninamivir, zanamivir, and peramivir are commonly used as antiviral agents to treat influenza infection, especially in Japan. However, because of the rapid increases in drug-resistant influenza virus, it is essential to develop new antiviral drugs as an emerging strategy to block cellular factors important for the infective cycle. The advantage of blocking important cellular pathways for the virus inhibitory effect is that, in principle, it is not specific of influenza strain and the emergence of resistant virus is minimized. A limited number of aptamers targeting host cell factors have been described. Of these, the use of RIG-I as a target for aptamers to control viral infection should be emphasized [169] . RIG-I is a cytosolic receptor for nonself RNA that mediates immune responses against viral infections through IFNα/β production [170] . The use of a specific RIG-I aptamer that activates RIG-I efficiently blocks the replication of the Newcastle disease virus, vesicular stomatitis virus and influenza virus in infected cells, evidencing that aptamers targeting cellular factors can act as efficient antiviral agents [169] . The association of the viral polymerase, bound to the cap, and eIF4GI may be involved in the preferential translation of viral mRNAs during influenza infection. In addition, the interaction of NS1, bound to a conserved 5-untranslated region (UTR) element of the viral mRNA, with eIF4GI and PABP1 could promote the formation of a ""closed loop"" between the 5 and 3 ends of the viral mRNA; (4) RIG-I is a cytosolic receptor for non-self RNA that mediates immune responses against viral infections through IFNα/β production. Mitochondrial antiviral-signaling (MAVS) protein. Table 6 shows information on the aptamers described against influenza virus. Vaccination is a powerful approach to diminish the effects of influenza epidemics, but the use of antiviral drugs can also be very useful, particularly in delaying the spread of new pandemic viruses. Neuraminidase inhibitors like oseltamivir, laninamivir, zanamivir, and peramivir are commonly used as antiviral agents to treat influenza infection, especially in Japan. However, because of the rapid increases in drug-resistant influenza virus, it is essential to develop new antiviral drugs as an emerging strategy to block cellular factors important for the infective cycle. The advantage of blocking important cellular pathways for the virus inhibitory effect is that, in principle, it is not specific of influenza strain and the emergence of resistant virus is minimized. A limited number of aptamers targeting host cell factors have been described. Of these, the use of RIG-I as a target for aptamers to control viral infection should be emphasized [169] . RIG-I is a cytosolic receptor for non-self RNA that mediates immune responses against viral infections through IFNα/β production [170] . The use of a specific RIG-I aptamer that activates RIG-I efficiently blocks the replication of the Newcastle disease virus, vesicular stomatitis virus and influenza virus in infected cells, evidencing that aptamers targeting cellular factors can act as efficient antiviral agents [169] . However, aptamers directed against cellular factors that establish essential interactions with influenza virus proteins had not been reported before. The mRNAs of influenza virus possess a 5 cap structure and a 3 poly (A) tail that makes them structurally indistinguishable from cellular mRNAs. However, selective translation of viral mRNAs occurs in infected cells through a discriminatory mechanism, whereby viral polymerase and NS1 interact with components of the translation initiation complex, such as the eIF4GI and PABP1 proteins [171] [172] [173] . Thus, the inhibition of viral protein-translation factor interactions or their destabilization can be potentially used as an antiviral strategy. Recently, Rodriguez et al. studied whether two aptamers which bind hPABP1 with high affinity (ApPABP7 and ApPABP11) are able to act as anti-influenza drugs [174] . Both aptamers inhibit influenza virus replication of H1N1 or H3N2 subtypes at high and low multiplicity of infection and the viral polymerase-eIF4GI interaction. In addition, aptamer ApPABP11 inhibits the interactions between NS1 and eIF4GI or PABP1. These results indicate that aptamers targeting the host factors that interact with viral proteins may potentially have a broad therapeutic spectrum, reducing the appearance of escape mutants and resistant subtypes.

An emergent virus is a virus that has adapted and emerged as a new disease/pathogenic strain, with attributes facilitating pathogenicity in a field not normally associated with that of virus. This includes viruses that are the cause of a disease which has notably increased in incidence; this is often a result of a wide variety of causes from both the influence of man and nature. Most emergent viruses can be categorized as zoonotic (an animal disease that can be transmitted to humans), and this has the advantage of possibly having several natural reservoirs for the disease.

Most of these viruses have newly appeared in a population or have existed but are rapidly increasing in incidence or geographic range and only recently aptamers against emergent viruses such as Rift Valley Fever, Tick-borne encephalitis, Dengue, Ebola viruses or other arboviruses have been developed [175] .

Rift Valley fever virus (RVFV) is a mosquito-borne bunyavirus (genus Phlebovirus) responsible for widespread outbreaks of severe disease such as hepatitis, encephalitis and hemorrhagic fever in humans [176] . The virus is endemic throughout much of the African continent. However, the emergence of RVFV in the Middle East, northern Egypt and the Comoros Archipelago has highlighted that the geographical range of RVFV may be increasing, and has led to the concern that an incursion into Europe may occur. At present, there is no licensed human vaccine [177] .

The nucleocapsid protein (N) of RVFV is an RNA binding protein required for the production of viable virus because of its involvement in several stages of viral replication. This protein protects the viral genome from degradation and prevents the formation of double stranded RNA intermediates during replication and transcription by encapsidating viral genomic and antigenomic RNA [178] . Ellenbecker et al. isolated RNA aptamers that bound N with high affinity and identified GAUU and pyrimidine/guanine motifs in their sequences, which are also present within the coding region of the RVFV genome. Furthermore, the authors developed a truncated RNA aptamer labeled with fluorescein using a fluorescence polarization (FP) system. Titration of N with the 3 -FAM-labeled RNA aptamer gave an apparent Kd of 2.6 µM. Competitive binding experiments were conducted with four different aptamers and the apparent Ki values were all in the~200 nM range. These data demonstrate that these aptamers might be used to construct a sensitive fluorescence based sensor of N binding with potential applications for drug screening and imaging methodologies [179] .

Tick-borne encephalitis virus (TBEV) belongs to the family Flaviviridae, genus Flavivirus. This virus produces tick-borne encephalitis (TBE), an important emerging infectious disease that targets the central nervous system (CNS) [180] . There is currently no specific antiviral treatment for TBE because the specific immunoglobulin used in clinical practice has several disadvantages. The purpose of Kondratov et al. was to obtain an aptamer population against a fragment of the surface protein E of the TBEV, since it is available for aptamers outside of the host cell [181] . Authors showed that the treatment with the library of aptamers produced a TBEV neutralization index comparable with the results of neutralization of the commercial human immunoglobulin against tick-borne encephalitis (NPO Microgen, Russia). In addition, the enzyme immunoassay systems based on the immobilization of viral particles on antibodies are most commonly used for the TBEV diagnosis and the authors claim that protein E aptamers could substitute antibodies in these systems.

Dengue viruses (DENVs) belong to the Flaviviridae family, and contain four serologically and genetically distinct viruses, termed DENV-1, DENV-2, DENV-3 and DENV-4. The envelope (E) protein plays an important role in viral infection but, however, there is no effective antibody for clinical treatment due to antibody dependent enhancement of infection. Chen et al. identified an aptamer (S15) that can bind to DENV-2 envelop protein domain III (ED3) with a high binding affinity. S15 aptamer was found to form a parallel quadruplex structure that together with the sequence on 5 -end were necessary for the binding activity to a highly conserved loop between βA and βB strands of ED3. Although S15 aptamer was selected against DENV-2, the authors demonstrated that this aptamer can neutralize the infections by all four serotypes of DENVs [182] .

The DENV capsid (C) protein functions as a structural component of the infectious virion but it may also have additional functions in the virus replicative cycle [183] . Balinsky et al. showed that the DENV C protein interacts and colocalizes with the multifunctional host protein nucleolin (NCL) and that this interaction can be disrupted by the addition of a NCL binding aptamer (AS1411), developed as AGRO100 by Aptamera (Louisville, KY, USA). Treatment of cells with AS1411 produced a significant reduction of viral titers after DENV infection. Moreover, the authors showed that treatment with AS1411 affected the migration characteristics of the viral capsid and identified a critical interaction between DENV C protein and NCL that represents a potential new target for the development of antiviral therapeutics [184] .

From a technological point of view, aptamers have been used for efficient isolation of endogenously assembled viral RNA-protein complexes. Hence, Dong et al. developed an affinity purification strategy based on an RNA affinity tag that allows large-scale preparation of native viral RNA-binding proteins (RBPs) using the streptavidin-binding aptamer S1 sequence that was inserted into the 3 end of dengue virus (DENV) 5 -3 UTR RNA, and the DENV RNA UTR fused to the S1 RNA aptamer was expressed in living mammalian cells. This allowed endogenous viral ribonucleoprotein (RNP) assembly and isolation of RNPs from whole cell extract, through binding the S1 aptamer to streptavidin magnetic beads. This strategy led to identify several novel host DENV RBPs by liquid chromatography with tandem mass spectrometry (LC-MS/MS), including RPS8, which were further implicated in DENV replication [185] .

Ebola virus belong to the genus Ebolavirus. Four of five known viruses in this genus cause a severe and often fatal hemorrhagic fever in humans and other mammals, known as Ebola virus disease (EVD). Ebola virus has caused the majority of human deaths from EVD, and is the cause of the 2013-2015 Ebola virus epidemic in West Africa.

Viral protein 35 (VP35) is a multifunctional dsRNA binding protein that plays important roles in viral replication, innate immune evasion and pathogenesis. These multifunctional proteins offer opportunities to develop molecules that target distinct functional regions. With this purpose, Binning et al. used a combination of structural and functional data to determine regions of Ebola virus (EBOV) VP35 (eVP35) to target aptamer selection. Two distinct classes of aptamers were characterized based on their interaction properties to eVP35. These results revealed that the aptamers bind to distinct regions of eVP35 with high affinity (10-50 nM) and specificity. In addition, the authors showed that these aptamers compete with dsRNA for binding to eVP35 and disturb the eVP35-nucleoprotein (NP) interaction. Consistent with the ability to antagonize eVP35-NP interaction, select aptamers can inhibit the function of the EBOV polymerase complex reconstituted by expression of select viral proteins [186] .

In many cases, aptamers have been used as a technological and research tool to identify RNA sequences that are recognized by different virus proteins. The zinc-finger antiviral protein (ZAP) is a host factor that specifically inhibits the replication of Moloney murine leukemia virus (MLV), Sindbis virus (SIN) and Ebola virus [187] , by targeting the viral mRNAs for degradation and preventing the accumulation in the cytoplasm. With the aim to identify RNA sequences that could be a target of ZAP, Huang et al. used aptamer technology identifying G-rich RNA aptamers that contained conserved ""GGGUGG"" and ""GAGGG"" motifs in the loop region. Interestingly, overexpression of the aptamers significantly reduced ZAP's antiviral activity and the substitution of the conserved motifs of the aptamers significantly impaired their ZAP-binding ability and ZAP-antagonizing activity, suggesting that the RNA sequence is important for specific interaction between ZAP and the target RNA [188] .

Severe acute respiratory syndrome (SARS) is a disease caused by SARS coronavirus (SARS-CoV) that caused a pandemic pneumonia in 2002-2003, with a total of 8096 reported cases, including 774 deaths in 27 countries. SARS-CoV belongs to the Coronavirus genus in the Coronaviridae family and is an enveloped, positive-sense RNA virus with a genome of 27.9 kilobases. This RNA encodes two large polyproteins, pp1a and pp1ab, and four structural proteins including spike (S), membrane (M), envelope (E), and nucleocapsid (N) proteins. Pp1a and pp1ab are proteolytically cleaved into 16 non-structural proteins (nsps) that form the viral replicase-transcriptase complex (reviewed in [189] ).

Since the SARS outbreak, several diagnostic assays have been developed based on RT-PCR, ELISA or using biosensors. Nucleocapsid (N) protein is the target choice as it is one of the most abundant structural proteins. Both DNA and RNA aptamers against N protein have been developed with Kd of 4.93 and 1.65 nM, respectively [190, 191] . DNA aptamer efficiently detects N protein by Western blot suggesting that it could be an alternative to the antibody. Ahn et al. have developed a nanoarray aptamer chip with the RNA aptamer selected as an antigen-capturing agent, which is able to detect N protein at a concentration as low as 2 pg/mL [190] .

Only a few studies have been focused on the development of aptamers against SARS-CoV as antivirals, in spite of the fact that there is still no effective therapeutic treatment against the virus. Two studies have selected DNA and RNA aptamers against the non-structural nsp13 protein. This protein possesses NTPase, duplex RNA/DNA-unwinding and RNA-capping activities that are essential for viral replication and proliferation. These aptamers inhibited helicase activity with subnanomolar IC 50 , while the ATPase activity was not affected, suggesting that the aptamers may bind to the nucleic acid binding site of the helicase and block the unwinding activity [192, 193] . Table 7 shows information on the aptamers described against emerging viruses. [190, 191] Severe acute respiratory syndrome n.d. DNA/RNA non-structural nsp13 protein [192, 193] n.d. = not determined.

Aptamer technology began to be developed in the early 90s and has seen major success in the last 10 years. However, despite all, the number of aptamers used in clinical practice is limited, probably due to the ignorance that still exists towards this technology and the advantage that the antibodies have in many diagnostic and therapeutic applications. Indeed, aptamers are molecules with extraordinary potential.

In the field of viral diseases, the number of drugs for treating these infections is very small and most of the available therapeutics are not very effective [194] . In addition, current diagnostic tools for viral infections are expensive and time consuming. These important diagnostic and therapeutic limitations have favored the development of aptamer-based systems, mainly because these show several interesting advantages in relation to antibodies. Thus, aptamers can recognize and/or inhibit target activity through specific and strong interactions superior to other biologics and small molecule therapeutics, with lower toxicity and immunogenicity profiles. In this sense, during the last years, aptamer technology is being used in a wide range of diagnostic and therapeutic applications associated with viral pathologies [195, 196] . It is significant that aptamers selected as specific anti-viral molecules are effective in infected cells, however, none of the selected antiviral aptamers entered into clinical trials. In conclusion, it is necessary to continue research studies and successfully develop clinical trials to establish the use of aptamers as antivirals.

The success of treatment in viral diseases depends on the early detection of the infective agent. The most probable use of aptamers in virus diagnostics involves the development of more simple, fast and cheap diagnostics devices. One of these simple detection systems can be the Lateral Flow Immunoassays (LFIAs) which are currently used for qualitative monitoring in resource-limited or non-laboratory environments. The LFIA biosensing platform mainly comprises the sample pad and test pad, which is generally composed of nitrocellulose membrane, and provides a platform for both reaction and detection where the capturing molecules are antibodies [197] . Lateral Flow biosensing platform has been developed using an aptamer against hepatitis C virus (HCV) core antigen [83] and could be applied for HIV or emerging virus detection using aptamers against specific proteins. This method allows detection of viruses in endemic or transit of human areas. Another interesting approach to obtaining cheaper diagnostics/genotyping devices is using only one aptamer to detect several targets. From this point of view, the strategy by Wang et al. [146] , in which they use the conformational change of one aptamer exposed to different ion concentrations to detect multiple types of the influenza virus could be used for genotyping of other viruses such as HBV or HCV.

From a therapeutic point of view, aptamers offer a hopeful solution in viral diseases because they can target elements of the virus or the infected host cell easier than the antibodies mainly due to their small size. The potential design of aptamers working against different targets might block the virion penetration into the cells or inhibit enzymes responsible for viral replication or other critical processes. In the case of HIV-1, despite efficient antiretroviral therapy, eradication of latent HIV-1 provirus is challenging and requires novel biological insights and therapeutic strategies. For this aim, novel target proteins should be chosen in HIV reservoir organs for the isolation of aptamers that could be applied to drug delivery or targeting of nanoparticles loaded with drugs to obtain HIV transcriptional activation.

As already mentioned above, RIG-I has been used as a target for aptamers to control viral infection [169] . Recently, Olagnier et al. investigated the inhibitory effect of a RIG-I agonist on the replication of Dengue and Chikungunya viruses [198] . The authors demonstrated that RIG-I stimulation generated a protective antiviral response against both pathogens. It would be motivating to study the use of RIG-I aptamers developed by Hwang for Dengue and Chikungunya therapy. Likewise, the effect of the aptamers developed by Guerra et al. against PABP in decreasing replication of influenza virus [174, 199] could be studied in other viruses that also use the PABP of the infected cell [200] .

Nanoparticles have been considered for a wide range of applications, both in soluble and insoluble forms. An advantage of soluble forms of nanoparticles is that they can encapsulate antibiotics/drugs and then release them when they reach the cellular environment, making them highly applicable for drug delivery systems. Studies on aptamer-based enhanced drug delivery have been reported for prostate cancer and lymphoblastic leukemia cells [201] . With this purpose, for HIV therapy, nanoparticles successfully loaded with the antiretroviral (ARV) drugs efficiently inhibited HIV-1 infection [202, 203] . These results showed the benefit of the nanoparticles' application to delivery of antiviral drugs to improve its bioavailability.

In conclusion, the use of aptamers in the development of diagnostic platforms or as therapeutic drugs is a promising alternative for the treatment of viral diseases.

",0.7165173411516372
Intranasal DNA Vaccine for Protection against Respiratory Infectious Diseases: The Delivery Perspectives,"Intranasal delivery of DNA vaccines has become a popular research area recently. It offers some distinguished advantages over parenteral and other routes of vaccine administration. Nasal mucosa as site of vaccine administration can stimulate respiratory mucosal immunity by interacting with the nasopharyngeal-associated lymphoid tissues (NALT). Different kinds of DNA vaccines are investigated to provide protection against respiratory infectious diseases including tuberculosis, coronavirus, influenza and respiratory syncytial virus (RSV) etc. DNA vaccines have several attractive development potential, such as producing cross-protection towards different virus subtypes, enabling the possibility of mass manufacture in a relatively short time and a better safety profile. The biggest obstacle to DNA vaccines is low immunogenicity. One of the approaches to enhance the efficacy of DNA vaccine is to improve DNA delivery efficiency. This review provides insight on the development of intranasal DNA vaccine for respiratory infections, with special attention paid to the strategies to improve the delivery of DNA vaccines using non-viral delivery agents.","Majority of the current licensed vaccines for the prevention of infectious diseases are live-attenuated vaccines, inactivated vaccines, or subunit vaccines. Each of them has its pros and cons. The live-attenuated vaccines can stimulate both cellular and humoral immune responses, and induce prolonged immunity that closely resembles natural infection. However, there are safety concerns associated with the use of the live attenuated virus or bacterial vaccines as they may revert to disease causing forms. It is also difficult to target multiple viral subtypes or pathogens using live-attenuated vaccines. Inactivated and subunit vaccines are safer options as they cannot replicate and do not cause disease. They confer protection mainly through humoral immune responses with little or no cellular immunity. The induced immunity lasts for a shorter period of time; therefore, supplemental doses are always required.

In recent years, DNA vaccines have attracted considerable attention as an alternative vaccination method against infectious diseases, with the potential to provide broad immune responses similar to the live-attenuated vaccines without the risk associated with the replicating micro-organisms. DNA vaccine approach relies on the in situ production of target antigens. Plasmid DNA encoding antigenic proteins is delivered to the appropriate tissues in the body, leading to the expression of the desired antigens, eliciting specific immunogenic responses and thereby inducing immune protection against the pathogens. Since the host cells are responsible for antigen production, the natural glycosylation and folding of the protein are warranted. Plasmid DNA encoding different bacterial and viral antigens have been tested for their immunogenicity and protective efficacy in vivo, confirming their clinical potential [1] [2] [3] [4] . In addition, DNA vaccines offer several distinct advantages over conventional vaccines. The double helical structure of DNA is simple and stable at high temperature, allowing easy storage and transportation. Large-scale manufacture of DNA vaccines is convenient and relatively cheap. It only requires standard cloning of antigen coding sequence into plasmid vectors, avoiding the complex procedures of repeated culture and inactivation of infectious pathogens, or the purification of recombinant proteins. Apart from their advantageous physicochemical properties, DNA vaccines have the ability to generate the cellular immunity in addition to the humoral immunity. They are also highly flexible, encoding several types of genes including viral and bacterial antigens, as well as immunological proteins. The advantages of DNA vaccines compared to conventional vaccines are summarized in Table 1 .

The field of DNA vaccination is developing rapidly. DNA vaccines are currently approved for veterinary use against various infectious diseases [5] [6] [7] [8] . However, the results in clinical trials have been less encouraging. DNA vaccines are generally safe and well tolerated in human, but the immune response is often too low to offer sufficient protection [5, [9] [10] [11] . In early studies, DNA vaccines alone were not able to generate T cell responses at a magnitude that was enough to protect against difficult diseases in humans [12, 13] . Recent attempts still failed to overcome this problem. A plasmid pTHr DNA HIV-1 vaccine candidate evaluation in phase I clinical trials on healthy volunteers showed that it had weak immunogenicity in human. No significant HIV-1-specific cell-mediated immune response difference was found between vaccine recipients and placebo recipients, in addition to no HIV specific antibody production [14] . Another phase I trial of HIV vaccine using DNA prime-virus vector vaccine boost strategy on healthy volunteers was proved effective in eliciting T-cell responses but incapable of inducing neutralizing antibody activities [15] . In 2012, a human HIV-1 gag DNA vaccine with or without interleukin (IL)-12 and/or IL-15 plasmid cytokine adjuvant was reported to produce poor cellular immunogenicity with no vaccine-induced anti-gag humoral immune responses on healthy volunteers, which contrasted with the previous findings in macaques [11] . Several strategies have been introduced to optimize DNA vaccines [16] . One of them is to enhance the DNA delivery efficiency, which is the focus of this review. DNA delivery efficiency is dependent on the administration route and the delivery system used. Mucosal surfaces are attractive sites of vaccine administration against infectious diseases as they are the portals of entry for many pathogens. Vaccination at the mucosal sites where pathogens initiate infections can be more efficacious than parenteral administration as invading pathogens may be neutralized at the front lines before generating any systemic effect. In particular, intranasal vaccine has been extensively investigated in recent years. Vaccination at nasal mucosa can stimulate respiratory mucosal immunity by interacting with the nasopharyngeal-associated lymphoid tissue (NALT) where large amounts of local lymphocytes are present. Furthermore, intranasal delivery is a needle-free, non-invasive route of administration with the possibility of self-administration. Intranasal DNA vaccination has become a promising approach in offering immune protection against various pathogens that affect the respiratory system including tuberculosis, coronavirus infection, influenza and respiratory syncytial virus (RSV). In this article, the current developments of DNA vaccine delivery systems that are specifically designed for intranasal administration against respiratory infectious diseases are discussed in detail.

Typically, DNA vaccines are administered by intramuscular injection although other administration routes including intradermal, subcutaneous, oral and intranasal routes are also investigated. Upon administration, somatic cells (e.g., myocytes or keratinocytes) and professional antigen presenting cells (APCs) are transfected. As the antigens are expressed intracellularly, both humoral and cell-mediated immunity can be activated to offer broad immune protection. The host-synthesized antigens become the subject of immune surveillance in the context of both major histocompatibility complexes (MHC) class I and class II molecules of APCs. Antigen expressed APCs then travel to the draining lymph nodes where they present the antigenic peptide-MHC complexes and stimulate T cells. Alternatively, B cells are activated, initiating the antibody production cascades. The major advantage of DNA vaccines is their ability to activate CD8 + T-cells, the cytotoxic T lymphocytes, which are important in controlling infections [17] . This action is lacking in inactivated or subunit vaccines. The induction of CD8 + T-cells by DNA vaccines can occur in two major ways: (i) direct DNA transfection of the APCs such as dendritic cells (DCs); (ii) cross-presentation which occurs when somatic cells such as myocytes are transfected with DNA and the expressed antigens are taken up by the APCs, or when the transfected apoptotic cells are phagocytosed by the APCs. The mechanisms of DNA vaccines are illustrated in Figure 1 . It is interesting to note that immunization may occur rapidly before a DNA vaccine expresses the antigens, and antigens expressed in somatic cells may not qualitatively be the major player in eliciting immune response. Comparing to the secondary role of somatic cells, bone marrow derived antigen presenting cell (APC) activation is an important indicator for successful induction of DNA vaccine [18] . In this study, DNA vaccine was delivered into the skin of mouse ears by gene gun. Immune response was produced after the inoculation site (i.e., the ear) was rapidly removed after immunization before antigens were expressed, indicating that mobile cells are important in elaborating immunity. In another similar study, surgical removal of the injected muscle within 10 min of DNA vaccines administration did not affect the magnitude or longevity of antibody responses to the encoded antigen [19] . Again, the results confirmed the importance of APCs over somatic cells such as myocytes and keratinocytes for eliciting immune responses.

Early studies showed that DNA vaccines are poorly immunogenic with low levels of antigen expression. To improve the immunogenicity of DNA vaccines, CpG motifs are commonly employed in the construct of the plasmid backbone [20] . Bacterial or viral DNA contains unmethylated CpG motifs, whereas in mammalian cells, CpG dinucleotide motifs are rare and are usually methylated [21] . It has been demonstrated that the unmethylated CpG motifs have immunostimulatory effect and are considered by mammalian cells as pathogen-associated molecular patterns (PAMPs). Unmethylated CpG activates innate immune cells through binding to Toll-like receptor 9 (TLR-9), which is constitutively expressed in the endosomal compartments of APCs and B cells. Once bound to the DNA that is rich in CpG motifs, TLR-9 activates the immune system by initiating pro-inflammatory response that result in the production of cytokines such as interferon (IFN)-γ and interleukin (IL)-12. However, it was found that TLR-9 deficient mice also responded to DNA vaccines, suggesting that TLR-9 may not be the sole mediator of the adjuvant effect [22, 23] . DNA vaccines also interact with cytoplasmic DNA sensors including TANK-binding kinase 1 (TBK1) [24] and stimulator of IFN genes (STING) [25] , activating TLR-independent pathways and inducing IFN-γ. These pathways are crucial in contributing to the immunogenicity of DNA vaccines.

Although persistent antigen expression of DNA vaccine is usually expected to provide long-term immune protection against infectious diseases, the effect of sustained expression of antigen must be carefully examined and controlled. It has been reported that prolonged expression of antigen may lead to the switch of type-1 IFN from an antiviral cytokine to an immunosuppressive cytokine [26] , or may deplete the pool of memory T cells [27] .

To evaluate the efficacy of DNA vaccine in humans, serum antibody titer or the enzyme-linked immunoSpot (ELISpot) assays are the commonly employed methods to measure the immunogenic response, although the induction of antigen-specific immune effectors by an immunization process does not imply that these antibodies or cytokines represent surrogates or correlates of vaccine efficacy. In early stage of vaccine development, in vitro serum antibodies and ELISpot assays are the direct detectable indicators of the clinical potential of a vaccine formulation. At later stage of development, morbidity and mortality (especially the improvement of survival rate after vaccination) in animals upon target pathogen challenge is a more certain way to confirm the protective efficacy of vaccines [28, 29] , as the ultimate goal of vaccine is to prevent the targeted disease. The efficacy of vaccine such as influenza vaccine could be monitored in human during subsequent influenza epidemic season [30, 31] or challenged with a controlled influenza virus [32] . However, some lethal virus challenge studies are difficult to conduct directly on human. Hence, the measurement of antibodies production and immune responses in humans remain the most direct way to assess vaccine efficacy. Longer study is required to investigate if the vaccine is indeed able to prevent disease.

Safety is always a primary concern with any vaccine products. DNA vaccines are generally considered to be safer than conventional vaccine approaches as they lack the risk of reversion to a disease causing state or secondary infection. Similar to other gene therapy, the major safety issue related to DNA vaccines is the risk of integration of the plasmid DNA into the host genome, causing insertional mutagenesis, which may lead to the inactivation of tumour suppressor genes or activation of oncogenes, resulting in devastating adverse effects. According to preclinical and clinical studies, there is little evidence of genomic integration following DNA vaccines administration, and the risk of integration is found to be significantly lower than the spontaneous mutation rate [33] [34] [35] [36] .

Another safety issue of DNA vaccines is related to the development of anti-DNA immune responses. Animal studies showed that there is no increase in anti-nuclear or anti-DNA antibodies after DNA vaccination. In clinical trial studies, signs and symptoms of autoimmunity, and the markers of autoimmunity are sometimes monitored in the human subjects. There has been no evidence that autoimmunity is associated with DNA vaccines [5, [37] [38] [39] . It has been suggested that proper purification of E. coli can effectively prevent pathogenic anti-DNA antibody production [2, 40] . Antibiotic resistance is another issue related to DNA vaccines. Typically, large-scale manufacture of plasmid DNA involves the use of antibiotic-resistant marker. There is a safety concern that resistance to the same antibiotic might be introduced. In response to this issue, antibiotic-resistance genes in DNA vaccine should be restricted to those that are not used to treat human infections. Alternatively, the use of antibiotic-resistance genes should be avoided completely [41] . Another concern of DNA vaccines is the development of tolerance to the encoded antigen, which appears to be age-related. Newborns have immature immune system and are more likely to develop tolerance rather than protection when exposed to foreign antigens. In contrast, immunity instead of tolerance occurred when DNA vaccines are administered to young animals [42] [43] [44] .

In recent years, there has been an increasing concern that vaccination in general may induce harmful systemic inflammation, which may lead to increase of cardiovascular risk [45] [46] [47] [48] [49] . DNA vaccine is still considered as a relatively new approach to vaccination but its potential to induce systemic inflammation must not be overlooked. It was reported that little or no local inflammatory infiltration was observed at the DNA vaccine injection site, especially after the acute effects of the vaccination have disappeared [9] . The first clinical trial of a DNA-based vaccine for HIV-1 infection was published in 1998 in 15 asymptomatic HIV-infected patients who were not using antiviral drugs. The immunization was well tolerated with neither local, systemic reaction nor laboratory abnormalities were detected after three doses of vaccines [38] . In addition, no patient developed anti-DNA antibody or muscle enzyme elevations. No consistent change of CD4 + or CD8 + lymphocyte counts occurred. Another early experiment conducted on pigs showed that electroporation of DNA vaccines was more efficient in enhancing immune response, but also stimulated inflammatory response and accompanying cellular infiltration, whereas the conventional intramuscular injection of DNA vaccines only showed low gene expression and low inflammatory cell infiltration [50] . It was suggested that improved antigen presentation was one of the possible mechanisms by which increased inflammatory cell infiltration may enhance immune responses to DNA vaccines delivered with electroporation. However, the long-term safety effect was not investigated.

Overall, many recent preclinical studies and clinical trials have indicated that DNA vaccines are generally well tolerated with good safety profile, and no systemic inflammation was reported [11, 14, [51] [52] [53] [54] . Nonetheless, DNA vaccines are relatively new vaccination approaches and yet to be approved in human use, the long term safety of their uses must be thoroughly evaluated for routine prophylactic and therapeutic use in human, especially when new delivery systems or adjuvants are introduced into the formulation.

Conventional vaccines are usually administered by parenteral injections which mainly target the systemic immune system, eliciting only weak mucosal immune response. When the vaccines are delivered directly to the mucosal site, mucosal immune response can be more efficiently potentiated. In particular, nasal mucosa has attracted considerable attention as the site of vaccination in recent years, including DNA vaccines, due to several distinct advantages. However, there are also some formidable barriers that need to be overcome to allow successful development of intranasal DNA vaccines.

The intranasal route of drug administration has been frequently used to treat local conditions such as nasal congestion and allergy. Intranasal administration is characterized by easy administration, rapid onset of action and avoidance of first-pass metabolism. The needle-free administration route is non-invasive and can avoid the risk of spreading blood-borne infections, which is a particular problem in developing countries. These desirable features lead to the exploration of the systemic delivery of polar drugs or biomolecules including vaccines that are not feasible in other administration routes.

Intranasal vaccination has been investigated for over a decade. The majority of currently available vaccines are administered by intramuscular, subcutaneous or intradermal injection. Although these parenteral routes of administration are effective in inducing systemic immune responses, they are ineffective in inducing local immunity at mucosal sites. As many as 70% of pathogens infect human through the mucosal surfaces [55] . Mucosal vaccination could provide better protection than injectable vaccines against infectious diseases by inducing both systemic and mucosal immunity [56, 57] . Since the strongest immune response is usually induced at the vaccination site and the adjacent mucosal sites, intranasal immunization is able to elicit protective immune response effectively in the lungs and the upper respiratory tract [58] . Nasal mucosa appears to be an appropriate site of vaccine administration against respiratory infectious diseases, not only because the nasal cavity is the first site of contact with inhaled macromolecules and a common site of infection by respiratory pathogens, it can also stimulate respiratory mucosal immunity by interacting with the NALT. Current, licensed intranasal vaccines include FluMist ® , a live-attenuated vaccine that targets influenza types A and B [59] ; and NASOVAC ® , a live-attenuated vaccine that targets H1N1 influenza virus [60] . Apart from live-attenuated vaccine, intranasal route of administration is also favorable to protein-based vaccination, as evidenced by many studies including the intranasal pneumococcal protein immunization against pneumonia [61] , and a recent study on the intranasal respiratory syncytial virus (RSV) vaccine based on a recombinant fusion protein [62] . With the success of intranasal live-attenuated virus vaccine and the promising effect of protein-based vaccine, it is highly plausible that DNA vaccines can adopt the same delivery route to achieve efficient immunization.

It is well established that mucosal vaccination can induce humoral and cell-mediated immune response systemically as well as at mucosal sites [56, 57] . Immune response induced by mucosal vaccination is mainly initiated at specific mucosa-associated lymphoid tissue (MALT). The MALT lining the nasal cavity is known as the nasopharyngeal-associated lymphoid tissue (NALT), which include the Waldeyer's ring of tonsils, adenoids and a collection of isolated subepithelial lymphoid follicles [63] . The NALT is rich in immunocompetent cells, including B cells, T cells and phagocytic APCs such as macrophages and DCs [64] . In addition, the overlying epithelium of mucosal follicles forms a specialized cell layer. These cells have microfolds on their apical surface and are known as microfold cells (M cells). M cells play a crucial role in the initial phase of induction of mucosal immune responses. Therefore, M cell targeting is an important strategy to achieve mucosal immunity [65, 66] . M cells are efficient in taking up particles from the epithelial surface, transporting them across the cells and releasing them to the underlying extracellular space. This process is known as transcytosis. At their basal surface, the cell membrane of M cells is extensively folded around the underlying immune cells including B cells, T cells and APCs, which take up the particles released from M cells and process them for antigen presentation. The initiation of mucosal immune response is summarized in Figure 2 . Upon B cells activation following nasal vaccination, the production of antigen-specific secretory immunoglobulin A (sIgA) is triggered. sIgA is a critical component in the mucosal immune system. It is protease resistant, and can effectively bind and neutralize pathogens and their toxic products on the nasal mucosa surface despite the protease rich environment, thereby preventing the pathogens from breaching the mucosal barrier [67] . Local immunoglobulin G (IgG) production is also detected after mucosal vaccination [68] and partly contributes to the neutralization of pathogens. However, IgG concentration is around 30-100-fold lower than that of the sIgA due to its susceptibility to protease degradation [56] . Indeed, sIgA provides the first barrier to pathogens invasion, so induction of potent sIgA response is an important goal of mucosal vaccination. In addition, nasal immunization can also result in the production of serum IgA and serum IgG, which can potentially neutralize pathogens that enter the mucosa and prevent systemic spread. When the DCs at the mucosa are presented with antigens, the activated cells may migrate to the proximal draining lymph node and disseminate immune responses to other sites of the body. Apart from the humoral immune response, cell-mediated immune response is also induced after mucosal vaccination. Although the cytotoxic T cells in the mucosal tissues may not prevent pathogen entry, they are crucial for the clearance of pathogens [56] .

Overall, cells of NALT are involved in the regulation of both humoral and cell-mediated immune responses locally and also systemically, offering a broad immune response. Since the nasal mucosa is an important portal of entry for respiratory pathogens, the nasal route has become attractive for the administration of vaccines by reinforcing the nasal mucosal immune response.

The defense mechanism of the nasal cavity presents a significant barrier to the entry of pathogens and potentially harmful substances; however, it has also become an important barrier to intranasal DNA vaccines. The nasal mucosa, which constitutes the outmost layer of the nasal passage, consists mainly of ciliated columnar cells, non-ciliated columnar cells, goblet cells and basal cells. The proportions of these cells vary in different regions of the nasal cavity. Nasal mucus, which is produced by goblet cells and submucosal glands, provides a protective physical barrier to foreign materials. It is a highly viscous, gel-like heterogeneous mixture that contains glycoproteins, enzymes, immunoglobulins, salts, proteins and lipidic components [69] . DNA vaccines that are administered to the nasal cavity have a propensity to be trapped by the nasal mucus, leading to enzymatic degradation. The effect of mucus depends on its viscosity and pore size, which affect the diffusivity of agents delivered to mucosal surfaces. In addition, the entrapped DNA vaccines may also be removed by the mucociliary action of the ciliated cells that drives the overlying mucus layer continuously towards the nasopharynx, clearing the mucus from the nasal passage, resulting in short residence time at the mucosal surface. Another challenge of intranasal vaccine is that the vaccine formulation may be diluted in mucosal fluids, and bulk fluid may limit effective deposition onto the epithelium of the mucosal system.

To overcome these barriers, a safe and efficient DNA delivery system must be developed. Ideally such delivery system should target the mucosal APCs for antigens processing that lead to specific B and T cell activation. The ultimate goals of DNA delivery systems are to facilitate the uptake of DNA to the target tissues and cells, protect DNA from enzymatic degradation, increase the residence time of the formulation in the nasal cavity, enhance the expression of the antigens and to increase the immune response without compromising safety. The different DNA vaccine delivery systems currently being investigated for intranasal administration are discussed in detail in Section 5.

Despite the numerous merits of intranasal immunization, the potential hazard of nasal vaccines must not be overlooked. The concern of the safety of intranasal vaccination was raised after an intranasal inactivated influenza vaccine called NasalFlu, developed by Berna Biotech, was found to be associated with Bell's palsy, a temporary neurological paralysis of one side of the face [70] . NasalFlu consists of influenza virosomes which are formulated to contain hemagglutinin (HA) and neuraminidase (NA) antigens, as well as heat-labile enterotoxin (LT) from E. coli as mucosal adjuvant. Since parenteral administration of inactivated influenza vaccine did not confer an increased risk of Bell's palsy, nor the natural influenza virus infection, it was soon concluded that adjuvant LT from E. coli. was the culprit of these cases. For this reason, FluMist ® and NASOVAC ® -both are intranasal live-attenuated influenza vaccines without enterotoxin as adjuvants-do not appear to confer an increased risk for this condition.

Understanding the pathogenesis of the Bell's palsy that was connected to NasalFlu has become an important research focus for vaccine development. Following intranasal administration in mice, enterotoxins were found in the olfactory nerve and the olfactory bulb for an extended period. Since the olfactory epithelium is the only part of the central nervous system (CNS) that is exposed to the external environment, drugs and nanoparticles, including intranasal vaccines, may bypass the blood brain barrier and enter the CNS through olfactory transmission. There is a reason to concern the neurotoxic effects of vaccine containing enterotoxin adjuvant for intranasal administration. While the nasal delivery of neuronal-binding LT-derived adjuvants is inadvisable [71] , other toxin-derived adjuvants such as cholera toxin-derived CTA-DD and double mutant cholera enterotoxin (CT) are claimed to be safe and effective adjuvant candidates without causing any inflammation or CNS toxicity [72, 73] . Nevertheless, thorough evaluation must be performed with the use of toxin derivatives as intranasal vaccine adjuvants. Tremendous efforts are now focusing on the development of alternative adjuvants with better safety profile.

Mankind has been haunted by respiratory infectious diseases for aeons. They have created public health concerns since ancient times. With the emergence of new or drug-resistant strains, it is becoming a challenge to protect the public from infections using conventional vaccine methods. DNA vaccines have huge potential for the prevention of respiratory infections due to their ability to offer broad immunity, the relatively rapid process of designing new DNA vaccine construct and the possibility of large-scale production in a short period of time. In this section, four pathogens that cause severe diseases in the airways are highlighted, including tuberculosis, coronavirus, influenza and respiratory syncytial virus, with a brief discussion of current DNA vaccine development against these infections.

Tuberculosis (TB) is a bacterial infectious disease caused by Mycobacterium tuberculosis which is transmitted by respiratory aerosols. TB has become a major public health problem that threatens the progress made in TB care and control in the world. The only TB vaccine currently available is an attenuated strain of Mycobacterium bovis, Bacillus Calmette-Guérin (BCG), developed in the 1920s. However, its efficacy against adult pulmonary TB remains controversial [74] . With the emergence of drug-resistant TB and increasing rates of HIV/AIDS and TB co-infection, a new effective TB vaccine is urgently in need. Effective protective immunity to Mycobacterium tuberculosis requires cell-mediated immune responses, including both CD4 + and CD8 + T cells [75] [76] [77] . Since DNA vaccines have the ability to induce strong cellular immunity, it has become an attractive vaccine approach against TB. The first two studies that reported promising protective effect with DNA vaccine against tuberculosis were conducted in mice using plasmid DNA encoding antigen 85A (Ag85A) of Mycobacterium tuberculosis [78] and the 65 kDa heat-shock protein of Mycobacterium leprae (hsp65) [79] . Other different antigens such as Ag85B ESAT-6, IL-23, MPT64, PstS-3 and other fusion proteins have also been explored as DNA vaccines against tuberculosis [80] [81] [82] [83] [84] [85] . Most of these DNA vaccines encode mycobacterial proteins that are either secreted in mycobacterial culture filtrate or exposed on the mycobacterial cell-wall surface.

Coronaviruses (CoV) are potentially lethal pathogens, characterized by the presence of spike proteins on the viral surface. Two new strains, severe acute respiratory syndrome CoV (SARS-CoV) and Middle East respiratory syndrome CoV (MERS-CoV), have been identified. Both of them could cause acute respiratory distress syndrome (ARDS) and are associated with high mortality rates [86] . CoV vaccines have historically exhibited poor capacity for cross-protection [87] , the development of safe, broad spectrum and effective vaccines that can be rapidly made available during an emerging epidemic is required. Currently, there are no approved vaccines for human CoV infections, and most of the studies have focused on the SARS-CoV. Spike and nucleocapsid proteins, which are the immunodominant CoV proteins, are the antigens of interest for vaccine development [88, 89] . DNA vaccines that encode nucleocapsid protein induced strong cell-mediated immunity but are not protective after high titer of viral challenge [90, 91] . In addition, nucleocapsid DNA vaccine could induce delayed-type hypersensitivity even in the absence of an antibody response. This effect was not observed with spike protein DNA vaccines.

Influenza is caused by orthomyxoviruses which are RNA viruses that affect mainly the upper respiratory tract. In recent years, zoonotic or variant influenza has become a serious threat to human health, including the avian influenza virus H5N1 and H9N2, and the swine influenza virus H1N1 and H3N2. Although these animal viruses are distinct from human influenza viruses and do not usually transmit between humans, they may still occasionally infect humans and cause severe pneumonia and even death. Furthermore, if such a virus acquired the capacity to spread easily among people, it could start an epidemic or even a pandemic [92, 93] . To protect the populations from influenza infection, highly effective, broad-spectrum influenza vaccines that could be prepared rapidly are in demand. Current influenza vaccines mainly target the induction of antibodies against the viral glycoproteins, particularly surface glycoproteins hemagglutinin (HA) and neuraminidase (NA). Antibodies to HA neutralize the infectivity of the virus while antibodies to NA prevent the release of the virus from the infected cells. Apart from surface glycoproteins, internal proteins such as nucleoprotein (NP) and matrix protein (M1), as well as the ion channel protein (M2), which are highly conserved between and within different subtypes, have also become very attractive target antigens for vaccines to provide broad, cross-strain protection [94, 95] .

DNA vaccines can potentially solve the mismatch problem by shortening the lag time [96] , which is particularly useful when facing influenza pandemic. In addition, the strategy of combined immunization with DNA vaccines encoding surface protein (e.g., HA) and internal protein (NP and M1) could offer better protection against influenza virus than single DNA vaccine alone in mice and ferrets [97] [98] [99] [100] . With the success of DNA vaccines in various animal models, several phase I & II clinical trials on DNA vaccine against influenza have been being carried out. Results so far have been encouraging, demonstrating both safety and immunogenic response in human [32, 52, 101] .

Respiratory syncytial virus (RSV) is a single stranded RNA pneumovirus which belongs to Paramyxoviridae family. It accounts for one of the leading pathogeneses of lower respiratory tract infections and hospitalization in infants and young children [102] , as well as the elderly and high-risk population [103] . Immunity against RSV is dependent on the induction of antibody responses. In addition, CD8 + T cells responses have been shown to reduce disease severity [104] . Although maternal antibodies appear to protect infants against infection, their amount gradually decreases within the first few months of life. Human RSV lacks an approved vaccine or an antiviral therapy. To prevent infant and childhood infection, vaccine should be able to induce immune responses rapidly after birth. This could be a challenging task because the immune system at the first few months of life is immature, and the persistence of maternal antibodies may limit the induction of infant antibodies responses. Three RSV proteins, namely the fusion (F) protein, attachment glycoprotein (G) and matrix protein (M2), are the leading candidates for RSV vaccine development [105] [106] [107] [108] [109] [110] [111] .

Delivery is one of the major barriers to DNA vaccine. Administration of naked DNA is usually inefficient with only a small fraction of DNA being taken up by the cells and subsequently expressed [112] . This is because DNA is a negatively charged, hydrophilic macromolecule; it is incapable of crossing the biological membrane unassisted. Therefore, a safe and efficient DNA delivery system is sometimes employed as adjuvant to facilitate efficient cellular uptake of DNA vaccines, promote DNA release inside the cells, induce high level of antigen expression and hence immune responses. Physical method such as gene gun, also known as the particle-mediated epidermal delivery, has been studied to deliver DNA to the skin [101, [113] [114] [115] . Gold beads coated with DNA vaccines are discharged directly into the cytoplasm and nuclei of skin cells. This method of delivery has enjoyed some success, but is not applicable for intranasal administration. Considerable efforts have been made to improve the efficacy by developing effective DNA delivery systems for intranasal vaccines. Formulation of DNA vaccines in synthetic non-viral vectors such as polymeric nano-/micro-particles and liposomes has been reported to increase the uptake of plasmid DNA by cells, increasing immunogenicity in animal models and humans. Additional adjuvants may also be used to further improve the immunogenicity of these delivery systems.

The elicitation of immune responses of DNA vaccines mainly relies on professional APCs that present antigens to both B cells and T cells. To ensure good immune response, the DNA vaccine delivery systems should be able to target APCs. In addition, M cells in NALT, which is a major site of pathogen entry, are also a target of DNA vaccine.

APCs are a heterogeneous group of immunocompetent cells that mediate immune response by processing and presenting antigens to the T cells. T cells recognize only antigenic peptide fragments on the surface of APCs through the T cell receptors. Helper T cells recognize antigen in association with class II MHC proteins, whereas cytotoxic T cells recognize antigen in association with class I MHC proteins. An additional co-stimulatory signal is then produced by the APCs, leading to the activation of T cells. Non-professional APCs lack the co-stimulatory signaling, and therefore do not simulate T cells sufficiently. There are three types of professional APCs, namely DCs, macrophages and B cells. Among them, DCs have the broadest range of antigen presentation and are considered as the most efficient cells for induction and regulation of immune responses. They play a central role in bridging the innate immune system with the adaptive immune system [116] [117] [118] . To achieve efficient DNA vaccination, it is logical to target the plasmid DNA to DCs where the encoded antigen could be expressed endogenously.

DCs express a large number of surface receptors such as C-type lectin receptors (CLRs) and TLRs, which are engaged in the recognition of pathogens. It has been reported that targeting antigens to receptors on DCs can significantly enhance immune responses [119] . These receptors could be exploited for DNA vaccine targeting with the aid of antibodies or natural ligands. In particular, CLRs are endocytic receptors which recognize carbohydrate structures that resemble pathogen cell-wall components. They are responsible for internalizing pathogens. One of the most commonly studied receptors for vaccine targeting is the DC C-type lectin receptor 205 (DEC-205) which is specifically expressed on DCs. However, ligands for DEC-205 have yet to be identified. Several studies have demonstrated the employment of anti-DEC-205 antibodies to achieve DC targeting for DNA vaccines, including intranasal immunization [120] [121] [122] . Another identified DC-specific target is C-type lectin domain family 9 member A (CLEC9A). Activation of CLEC9A leads to the stimulation of antibody production [123] . Alternatively, DCs could be targeted by using the natural ligands to the mannose receptors [124] . However, the effectiveness of these targeting components in mucosal vaccines remains to be investigated.

There are also several molecules being investigated to target APCs in general. One of the most widely studied molecules is the Flt3 ligand. Flt3 ligand is a growth factor that stimulates the proliferation of hematopoietic cells. It binds to the fms-like tyrosine kinase receptor Flt3. Flt3 expression is, in hematopoietic tissue, restricted to CD34 + progenitors, including DC progenitors. In vivo treatment of Flt3 ligand is found to up-regulate the number of DCs, but not their activation [125, 126] . Furthermore, Flt3 ligand treatment could also enhance immune response when delivered via the mucosal route [127] . It has been reported that when plasmid DNA encoding Flt3 ligand was co-administered with plasmids encoding protein antigens, effective immune responses were induced [128] . In addition to its APCs targeting ability, Flt3 ligand is an efficient and safe mucosal adjuvant that facilitated expansion of DCs following nasal administration [129, 130] .

As discussed in Section 3.2, improving M cells uptake is another strategy to enhance vaccine immunity. Effective mucosal immunity often correlates with the uptake of antigen by mucosal inductive tissues, such as NALT in the upper respiratory tract following intranasal immunization. Since M cells are responsible for antigen sampling on the mucosal surface for eventual antigen presentation to mucosal B and T cells, targeting of vaccines to M cells can be an effective method to achieve strong immune response. Particle size is an important parameter for M cell uptake. A number of studies have been conducted to identify the optimal particle size for cellular uptake of the mucosal system. Some studies suggest that particle size of less than 1 μm is optimal for oral vaccine delivery for Peyer's patch M cell uptake [131] [132] [133] . Another NALT nanoparticle uptake study also suggested that particles with sub-micron size are optimal for mucosal M cells uptake [134] . It is generally accepted that NALT M cells can uptake nanosized particles rapidly with no definite size range being established [135] . Apart from cellular uptake, particle size also affects the kinetics of lymphatic drainage. It appears that nanoparticles less than 200 nm are more readily transported by the draining lymph compared to larger particles [136] .

Apart from controlling particle size to achieve specific targeting passively, inclusion of targeting ligand could also increase uptake by M cells [133, 137] . A number of pathogens including reovirus [138] , Salmonella typhimurium [139] and Mycobacterium tuberculosis [140] target M cells as a mode of entry into the host. By identifying the key molecules expressed by these pathogens that are crucial for their invasion, it would be extremely helpful to design an effective delivery system for M cells targeting [141] . One example is related to reoviruses which target M cells using their surface protein sigma-1 (σ1). In this regard, Wu et al. reported an M cell targeting DNA vaccine delivery system consisting plasmid DNA and the recombinant protein σ1 as targeting ligand which was covalently attached to poly-L-lysine (PLL) for intranasal vaccination in mice. The results showed significant mucosal sIgA production as well as enhanced cell-mediated immunity [65] . Other ligands such as Co-1 peptide [142] , Claudin 4 targeting peptide [134, 143] and M cell specific monoclonal antibody (NKM 16-2-4) [144] have been investigated for M cell targeting in mucosal protein vaccine, with the potential to be explored for mucosal DNA vaccine delivery. However, mucosally induced tolerance may develop with M cell targeting delivery system. Following nasal administration of protein σ1 genetically conjugated with ovalbumin, systemic unresponsiveness was induced instead of mucosal IgA immunity [145] . Therefore, special attention must be paid with the development of M cell targeting delivery system.

High versatility is one of the attractive features of polymer-based DNA delivery systems. Cationic polymers can form complexes (polyplexes) with nucleic acids through electrostatic interaction. Polymer synthesis is relatively cheap and is easy to scale-up. Particle size and surface properties of polymeric particles can be controlled by using different polymers and fabrication methods in order to optimize their cellular uptake and transfection efficiency. The polymeric particles can also be modified to include specific function groups or ligands to enhance immune responses.

Polyethylenimine (PEI) (Figure 3) is one of the early generation polymers being investigated for gene delivery. It has high transfection efficiency and is frequently regarded as the gold-standard of non-viral gene delivery vectors. PEI has high pH buffering capacity, which allows its cargo to escape from endosomal entrapment via a mechanism known as ""proton sponge hypothesis"" [146] . Transfection efficiency of PEI depends on its molecular weight and the level of branching. Shim et al. described the use of a simple method to prepare PEI (25 kDa)-DNA complexes for vaccine delivery [147] . Plasmid DNA encoding SARS-CoV spike protein without transmembrane domain was employed in the study. Mice that were immunized intranasally with the PEI-DNA vaccines produced significantly higher systemic spike protein specific IgG and mucosal secretory IgA in the lung compared to those immunized with naked DNA. Furthermore, cellular immune responses were detected with an improvement of specific T cell responses. In another study, Torrieri-Dramard et al. demonstrated the utilization of PEI (in vivo-jetPEI ® ) as DNA vaccine carrier for intranasal administration [148] . Plasmid DNA encoding HA from influenza A viruses was used. The intranasal administration of the PEI/DNA vaccines induced cellular and humoral immune response capable of providing protective immunity against a divergent virus of H5N1 subtype in mice. The protection could be further improved by including the plasmid DNA encoding NA.

Although PEI appeared as a promising vector for gene delivery including DNA vaccines, the cationic PEI is highly charged and non-biodegradable, and it often encounters toxicity problems which cannot be ignored. In this regard, many groups are developing low toxic or biodegradable PEI derivatives for gene delivery application. Mann et al. has developed a PEI derivative, deacylated PEI (dPEI), as DNA vaccine delivery agent [149] . dPEI is a nearly fully hydrolysed linear PEI with 11% additional free protonatable nitrogen atoms, enabling more efficient binding with DNA, reduced toxicity and high transfection efficiency. It is an effective DNA vaccine carrier for pulmonary delivery to elicit both systemic and mucosal immune responses, and offers protection against influenza challenge in vaccinated mice. This system has a potential to be exploited for intranasal administration. (PEI) (a,b) , Chitosan (c) and Poly(lactic-co-glycolic acid) (PLGA) (d).

Chitosan (Figure 3) is a natural polysaccharide that has been frequently studied for drug delivery. It is derived from chitin which is found abundant in crustacean. It is biodegradable and biocompatible with low toxicity [150, 151] . The properties of chitosan can be tuned by changing its molecular weight and degree of deacetylation. Because of its cationic nature, chitosan has strong binding affinity with nucleic acids, making it a suitable candidate for DNA delivery agent. In addition, chitosan and its derivatives are found to display strong mucoadhesive property, making them particularly suitable to facilitate intranasal delivery [152] [153] [154] . Moreover, chitosan was also reported to have an immunostimulating effect, such as increasing the accumulation and activation of macrophages, promoting resistance to infections by cytokines, and enhancing cytotoxic T cell response [155, 156] . A number of studies have described the use of chitosan nanoparticles to deliver DNA vaccine formulation for intranasal administration. Kumar et al. reported the exploitation of chitosan nanoparticles to deliver DNA vaccine against acute respiratory syncytial virus (RSV) infection [156] . A cocktail of plasmid DNA encoding a number of RSV antigens was used to complex with chitosan to form nanoparticles. Following the nasal vaccination in mice, high levels of serum IgG and mucosal IgA antibodies, as well as cytotoxic T cells responses were induced. There was also an elevated lung-specific production of IFN-γ with antiviral action. A single dose of DNA vaccine was able to decrease the RSV titers by 100-fold on primary infection. Similar study was performed by another group who described the use of chitosan nanoparticles to deliver plasmid DNA encoding a T cell epitope from the M2 protein of RSV [157] . It was found that intranasal administration of the formulation in mice induced specific cytotoxic T cell response that was comparable to those induced via intradermal immunization. Following RSV challenge of the nasal immunized mice, the virus load in lungs was significantly reduced.

In a recent study, Raghwanshi et al. investigated a sophisticated DC targeted chitosan nanoparticle system for nasal DNA immunization against SARS-CoV [122] . The chitosan nanoparticles were surface functionalized with ligands to achieve DC selective targeted delivery. DEC-205 receptor is C-type lectin receptor found in DCs for recognition and uptake of pathogens. The authors developed a bifunctional fusion protein (bfFp) vector which consists of truncated core-streptavidin fused with anti-DEC-205 single chain antibody. The core-streptavidin arm of the fusion protein binds with biotinylated chitosan nanoparticles while anti-DEC-205 scFv imparts targeting specificity to DC DEC205 receptor. Plasmid DNA encoding nucleocapsid protein of SARS-coV was loaded into the chitosan nanoparticles. Following intranasal administration of the DC targeted nanoparticles in mice, the levels of mucosal IgA and systemic IgG against nucleocapsid proteins were significantly enhanced, whereas no mucosal and systemic immune responses were detected when the naked plasmid DNA was intranasally administered. The results showed that such DC targeting delivery system could be a promising strategy for low-dose nasal DNA vaccines.

To enhance the transfection efficiency of chitosan for intranasal administration, thiolated chitosan derivative has been introduced. Thiolated chitosan derivative has strong mucoadhesive properties due to the formation of disulphide bonds between thiol groups of the modified polymer and cysteine-rich subdomains of glycoproteins in the mucus layer, leading to an improvement in mucoadhesion of up to 140-fold when compared to unmodified chitosan [158] . Improved and sustained gene expression could be achieved both in vitro and in vivo with thiolated chitosan derivative [159] . This technology has a huge potential to be adopted for intranasal DNA vaccine delivery.

Poly(lactic-co-glycolic acid) (PLGA) (Figure 3 ) is a synthetic biodegradable copolymer that has been extensively investigated for the delivery of different therapeutic agents including proteins and nucleic acids [160] . Due to its biocompatibility and excellent safety profile, PLGA is approved by the FDA in various drug delivery systems for human use. Since the degradation rate of PLGA can be adjusted by modifying the molecular weight of the polymer and the lactic acid to glycolic acid ratio, the rate of drug release can also be controlled accordingly. However, the negative charge and hydrophobic nature of PLGA limit its interaction with the negatively charged DNA. Cationic surface modification of PLGA micro/nanoparticles using polycations such as PEI and chitosan can overcome this problem and allow efficient nucleic acids delivery [161] [162] [163] [164] . This strategy has also been applied to the delivery of DNA vaccines. Oster et al. first employed the use of micro-particles consisting PLGA and PEI as DNA vaccine carrier for injection [165] . Later on, Wang et al. reported the use of chitosan coated PLGA nanoparticles to deliver plasmid DNA encoding FMDV (foot-and-mouth disease virus) capsid protein together with IL-6 as mucosal adjuvant for intranasal vaccination [166] . Chitosan coated PLGA nanoparticles were first prepared by emulsion-diffusion-evaporation technique [167] , followed by the incorporation of plasmid DNA to the nanoparticles by simple complexing. The samples were then freeze-dried with mannitol before use. After intranasal administration in guinea pigs and rats, both cellular and humoral immune responses were detected. IL-6 was also found to be an effective mucosal adjuvant which significantly enhanced mucosal and systemic immune responses. More importantly, the vaccines could offer some immune protection to animals against FMDV challenge.

Liposomes are vesicles comprised of phospholipid bilayers. They have been extensively investigated for delivering DNA into mammalian cells as well as vaccine adjuvants. The duo functions make them an excellent carrier system for DNA vaccine [168] [169] [170] [171] . For DNA delivery, the negatively charged plasmid DNA can be absorbed to the surface of cationic liposomes through electrostatic interaction to form complexes. Alternatively, DNA can be encapsulated in the aqueous core of the cationic, non-ionic or anionic liposomes. In general, transfection efficiency of cationic liposomes is superior to their non-ionic or anionic counterparts [172] , whereas anionic liposomes provided enhanced antibody responses [171] . Surfaces of the liposomes can be decorated with targeting ligands or antigenic components to improve the immune response in vaccine formulation [173] .

Currently, there are at least two approved liposomal vaccine formulations on the market for antigen delivery, including Inflexal ® V (influenza vaccine) and Epaxal ® (hepatitis A vaccine). Both formulations employed the virosomes technology (Figure 4) , in which the viral proteins are bound to the surface of a liposome in an array, similar to what is seen on viral particles [171] . The idea is to create a safe viral-like particle that can induce strong protective immune response. Similar technology could be applied to DNA vaccines to improve immunogenicity. In fact, liposomes on their own could elicit immune response even in the absence of other antigens. It has been demonstrated by Lay et al. that DOTIM (octadecenoyloxy-ethyl-heptadecenyl-3-hydroxyethyl imidazolinium chloride)/cholesterol cationic liposome-DNA complexes (JVRS-100), in which an empty plasmid DNA vector was incorporated, were able to induce high levels of antibody and T cell immunity in mice and non-human primates [174] . Since lipid composition, particle size, surface charge and DNA entrapment efficiency of the liposomes can affect their immunogenicity and potency, these parameters must be carefully characterized and controlled. The major limitation of liposome as DNA vaccine carrier is long-term stability, as lyophilization of liposomes may not be always possible [171] . [175] . Plasmid DNA encoding Ag85A was complexed with the lipids. Following intranasal immunization in mice, naked DNA was completely ineffective, probably due to the degradation of the DNA by mucosal nuclease. The lipid-DNA formulation was capable of inducing a weak cell-mediated immune response, and no humoral immune response was detected. The co-lipid intranasal formulation was compared with another cationic lipid formulation, Vaxfectin, which was used for intramuscular administration. It was found that the intramuscular formulation was able to induce a better immune response. However, combining intranasal and intramuscular administrations resulted in stronger immune responses in the lungs. Considerable improvement is needed to further develop the formulation for intranasal use.

Rosada et al. developed another liposome-based formulation of DNA vaccines against TB [176] . The non-toxic, cationic liposome, EPC/DOPE/DOTAP (Egg phosphatidylcholine/1,2-dioleoyl-snglycero-3-phosphoethanolamine/1,2-dioleoyl-3-trimethylammonium-propane) was used. Plasmid DNA encoding the 65 kDa mycobacterial hsp65 was either entrapped inside or complexed with the cationic liposomes, and the intramuscular and intranasal routes of administration were compared in mice. When administered intramuscularly, both liposomal formulations were ineffective in preventing tuberculosis infection in mice even after two doses. On the contrary, the complexed liposomal formulation of DNA vaccine was able to offer protection against infection even after a single dose, with a significant reduction of colony forming unit (CFU) in lungs after the immunized mice were challenged with Mycobacterium tuberculosis. However, four doses of intranasal administration of naked DNA vaccines failed to offer any protection. The authors reasoned that the intranasal vaccination enhance the immune response by stimulating the mucosal immunity, but the naked DNA failed to cross the mucosal barriers in the nasal cavity, demonstrating the importance with the use of delivery carrier for intranasal DNA vaccination.

Apart from TB vaccine, there are studies that reported the use of liposome to deliver influenza DNA vaccine [177, 178] . Cationic liposomes DODAC/DOPE/PEG (1,2-dioleoyl-sn-glycero-3- phosphoethanolmine/dioleylphosphatidylethanolamine/polyethylene glycol) were used to encapsulate plasmid DNA encoding influenza virus HA. After intranasal immunization in mice, the liposome system was effective at eliciting both IgG and IgA humoral responses systemically. Local IgA level was enhanced. Cell-mediated immune response was also successfully induced. In addition, the immunized mice were able to withstand a lethal challenge of influenza virus. On the other hand, intramuscular immunization of the same system enhanced IgG level only with no effect on IgA level either locally or systemically. Intranasal administration of naked DNA failed to induce antibody response. The promising results demonstrated the potential of the intranasal liposomal DNA vaccine system. To improve the DNA vaccine delivery efficiency of liposomes for intranasal administration, Khatri et al. modified the surface of liposomes by coating with glycol chitosan [173] . The major function of glycol chitosan is to provide mucoadhesive and immune stimulating property [179] . In the study, cationic liposomes, PC/DOPE/Chol (Phosphatidylcholine/dioleylphosphatidylethanolamine/cholesterol) were used to entrap plasmid encoding the S region of hepatitis B antigen, and the glycol chitosan was adsorbed on the liposome surfaces through electrostatic interaction and hydrogen bonding. Following intranasal administration in mice, the surface modified liposomes could elicit both humoral mucosal and cell-mediated immune responses which were better than the uncoated liposomes. Such system has the potential to be exploited for intranasal DNA vaccine of respiratory infectious diseases.

A number of studies have already demonstrated the potential of liposomal DNA vaccine system for intranasal administration, and some could offer considerable immune protection against respiratory infections in animals. However, the lipid composition of different liposomal systems varied greatly, and currently there is a lack of knowledge of how the composition may affect the immune response. To enable the utilization of liposomal DNA vaccine for clinical application and approval, a better understanding of how these factors govern the efficacy and immunity of the liposomal delivery system must first be sought.

To further enhance the immune responses of the DNA vaccines, adjuvants are included in the formulation in many studies. Adjuvants are generally defined as agents that could enhance the immune response of the vaccinated subjects to an antigen. In DNA vaccine, since the delivery of DNA is a major hurdle, DNA carrier system using bacterial, viral or non-viral vectors, as well as the cell specific targeting ligands, which are discussed above, are also considered as DNA vaccine adjuvants. The summary of DNA vaccine adjuvants being investigated are shown in Table 2 . In this section, proteins and other macromolecules with immunopotentiating properties but are not directly involved in the delivery of DNA are discussed, especially those that are commonly employed for intranasal vaccination.

Enterotoxins are protein exotoxin released by pathogens that infect the gut. Enterotoxin-based mucosal adjuvants are the most potent and well-established strategy for the induction of both mucosal and systemic immunity to co-administered protein antigens [180] . Heat-labile enterotoxin (LT) from E. coli and cholera enterotoxin (CT) are very potent adjuvants but they are too toxic to be used in human. Therefore, detoxified mutants of enterotoxins have been produced by site-directed mutagenesis and they are extensively investigated as adjuvants for mucosal vaccine including intranasal vaccine. Intranasal antigen immunization with LT mutant adjuvants can provide effective protection against infectious diseases in animals [181] [182] [183] [184] [185] . It is suggested that the LT mutant adjuvants could induce potent cytotoxic T lymphocyte responses. The mechanism of action is believed to arise from enhanced permeation of antigens across epithelial barriers and a marked increase in antigen presentation by APCs [66] . Mutants of CT have also showed strong adjuvant activity [73, 186, 187] , and could retain good adjuvant function when administered intranasally [73] . It is expected that LT mutants and CT mutants have similar mechanisms of adjuvant activities [58] . The major concern with the intranasal administration of mutant LT or CT is that these toxin derivatives may gain access into the central nervous system through the olfactory nerve. It has been reported that both native and mutant LT used as adjuvants were associated with the development of Bell's palsy following intranasal delivery in humans [70, 71, 188] . The risk of enterotoxin as mucosal adjuvant for intranasal administration is already discussed in Section 3.4. Lipopolysaccharides (LPS) are the major component of the outer membrane of Gram-negative bacteria, and could elicit strong immune response. However, they are also highly toxic. In order to make them safe and suitable as vaccine adjuvants, LPS derivatives are produced to reduce the endotoxic effect but to retain their immunostimulatory function. Monophosphoryl lipid A (MPL) is one example of LPS derivative that is investigated as vaccine adjuvant. MPL is prepared by removal of a phosphate and fatty acid group from the lipid A of Salmonella minnesola. MPL is thought to interact with Toll-like receptor 4 (TLR-4) on APCs. It has been demonstrated that MPL could activate macrophages, increase their cytokine secretion and hence immune response [216] [217] [218] [219] [220] . Regarding safety, MPL appears to retain the immunogenic activity of LPS but with significantly reduced toxicity [221] . MPL has been extensively evaluated in the clinic as adjuvants for various diseases including infectious diseases with an acceptable profile of adverse effects [182] . MPL has been used successfully as a mucosal adjuvant when formulated with liposomes or virosomes for intranasal administration in animals [222] [223] [224] .

Cytokines are small proteins that are important in regulating immunological response by recruiting and stimulating T cells, or by directly acting on infected cells. They have potential to be natural adjuvants for DNA vaccines [225] . Cytokines that have been evaluated as possible DNA or intranasal vaccine adjuvants include IL-1, IL-2, IL-6, IL-12, IL-15 and GM-CSF [205, 206, 226, 227] . In particular, IL-12 is found to be an effective mucosal adjuvant [228, 229] . Lynch et al. demonstrated that intranasal administration of pneumococcal polysaccharide conjugate vaccine in the presence of IL-12 was able to enhance systemic and mucosal immune responses to pneumococci in mice [228] . However, cytokines have short half-life in vivo and poor stability. They are also expensive and are associated with dose related toxicity. Therefore, these molecules may not be suitable for use as adjuvants in vaccines designed to protect against infectious diseases [182] . Nevertheless, intranasal administration of IL-12 induced less toxicity than parenteral administration [230] . Alternatively, cytokines can be expressed from plasmid DNA to allow long-lasting expression in vivo and to reduce the cost of production [196, 198] .

With the emergence of new or antimicrobial-resistant bacteria and viruses, and the ease of transmission, especially the respiratory pathogens, respiratory infections are becoming serious threats to human health. Safe and effective vaccines are important to safeguard public health. Intranasal DNA vaccination appears to be a promising non-invasive approach to provide protection against various infectious diseases. Evidence shows that intranasal DNA vaccine could elicit strong and long-lasting humoral as well as cell-mediated immune responses in many animal models. DNA vaccines are already successfully used in veterinary products for protection against infections, but their immunogenicity needs to be further enhanced to make them suitable for human use. Improving DNA delivery and formulation is one of the several strategies to enhance the immune response. Various studies have demonstrated that significant improvement of immune response that could be achieved by the employment of DNA carrier system, or to target the DNA vaccines to APCs. DNA vaccines generally have good safety profile, but the potential toxicity associated with DNA delivery systems, especially when they are used at high concentration, must not be neglected. DNA vaccines may circumvent many problems associated with conventional vaccines such as high costs of protein vaccine purification and bacterial/viral inactivated or attenuated process, the incorrect folding of antigen and viral mutation risk, thereby offering a safer alternative to benefit humans. In addition, mass manufacture of DNA vaccine is easier and faster, and DNA product is usually highly stable. Once an effective intranasal DNA vaccine delivery system is identified and optimized, a delivery technology platform could be established to allow the development of DNA vaccine formulations for different infectious diseases in the future.

",0.7164322205507739
Emerging Advances in Rapid Diagnostics of Respiratory Infections,"Diagnostic laboratories play a central role in the recognition of new and emerging infections. The identification of the severe acute respiratory syndrome (SARS) coronavirus in 2003 highlighted how modern diagnostic tools and collaboration between clinicians, public health professionals, and laboratorians can lead to the rapid characterization of a new respiratory pathogen. 1 Similarly, the development and rapid dissemination of a polymerase chain reaction (PCR) method to detect the novel H1N1 influenza A strain by the US Centers for Disease Control and Prevention in 2009, relied on the most recent diagnostic technology and played an important role in the response to the latest influenza pandemic. 2 These events remind us of how much recent developments in diagnostics have improved our ability to identify respiratory","viruses. For nonviral respiratory pathogens, developments in laboratory technology have been less profound in general, but have still led to modest improvements in the diagnostic capability.

For the diagnostic microbiology laboratory, the routine evaluation of patients with suspected respiratory infections continues to rely on methods that have been used for a long time: microscopy and culture of respiratory tract specimens, blood cultures, detection of antigens in urine and upper respiratory specimens, and serology. Recent advances in pneumonia diagnostics have mostly occurred in the areas of antigen and nucleic acid detection. Despite these technological advances, there remain several major challenges that hinder the search for the causes of respiratory infections, particularly for pneumonia. 3 These challenges include difficulty collecting lower respiratory tract specimens, problems distinguishing colonization from infection, poor clinical (diagnostic) sensitivity of assays, and often inadequate evaluation of new diagnostics.

This review focuses on recent advances in laboratory diagnostics that enable rapid identification of respiratory pathogens.

Assays to detect microbial antigens in body fluids have been used for the diagnosis of respiratory infections for many years, using various formats such as immunofluorescence, enzyme-linked immunosorbent assay (ELISA), latex agglutination, coagulation, and chromatographic immunoassay. These methods are the diagnostic tools most easily applied as near-patient tests, but development is reliant on the identification of suitable antigens that are present in detectable quantities in clinical specimens. To date, commercial assays have been developed only for a limited range of pathogens. The most widely available assays have focused on the detection of selected bacterial pathogens in urine and the detection of viruses in respiratory specimens.

Among bacterial respiratory pathogens, assays for Streptococcus pneumoniae and Legionella pneumophila are the most developed. A newer generation immunochromatographic test that detects the C-polysaccharide cell wall antigen in urine (NOW) has been an important advance in the diagnosis of pneumococcal disease. 4 This test has a sensitivity of 70% to 80% and a specificity of greater than 90% compared with conventional diagnostic methods for detection of pneumococcal pneumonia in adults. Unfortunately, the NOW test cannot be used reliably in children as it also detects pneumococcal carriage. 5 Alternative pneumococcal antigens for diagnostic purposes, such as pneumolysin, have shown promising results, although none has been demonstrated to perform better than existing commercial C-polysaccharide antigen assays. [6] [7] [8] The combination of a pneumolysin-specific antigen detection ELISA together with the NOW test may result in a better diagnostic yield because of the higher specificity of the pneumolysin detection ELISA. 7 Detection of soluble Legionella antigen in urine is an established and valuable tool for the diagnosis of Legionnaires' disease, although current commercial assays can only reliably detect infection caused by Legionella pneumophila serogroup 1. 9 Some assays have been intended to detect other legionellae, 10 although the performance is not as good as for L pneumophila serogroup 1.

Detection of respiratory viral antigens in respiratory secretions has become an important diagnostic tool. [11] [12] [13] Antigen detection using immunofluorescent techniques were pioneered in the 1970s, and commercial reagents are now widely used for the detection of influenza viruses, respiratory syncytial virus (RSV), parainfluenza viruses, adenoviruses, and human metapneumovirus. These assays require technical expertise and have the advantage of allowing direct evaluation of specimen quality. More recently, commercial rapid diagnostic tests (RDTs) have become widely used for the detection of influenza or RSV directly in respiratory specimens. These diagnostic test kits, produced as dipsticks, cassettes, or cards, contain internal controls, and a positive result is signaled by a color change. Results are produced by these tests within 5 to 40 minutes.

The sensitivity of rapid tests for the detection of seasonal influenza in clinical specimens ranges from 10% to 96%, 14, 15 and varies with virus type or subtype, timing of specimen collection, specimen type, patient age, and the test comparator. 16, 17 With the emergence of the pandemic influenza A (H1N1) 2009 virus, RDTs have been widely used for patient triaging, although there are limited data available on their clinical accuracy. 18, 19 The sensitivity of these assays for detecting this new strain is 10% to 69% compared with real-time PCR. [20] [21] [22] Specificity of RDTs for seasonal influenza is 90% to 100% according to the available data for H1N1 2009. 22 Commercial RSV RDTs have sensitivities of 71% to 95% and specificities of 80% to 100% compared with culture. [23] [24] [25] Poorer performance has been observed in adults, 26 which may be related to the decreased viral titer in adults compared with children.

To correctly interpret results of RDTs, the prevalence of influenza or RSV disease in a community must be considered. 15 During peak disease activity, positive predictive values are highest, but false-negative results more likely. The opposite is true during times of low disease activity. 17 When the disease prevalence is low or unknown, RDT results become difficult to interpret and of limited use. 17 

The use of nucleic acid amplification tests (NAATs) has transformed our understanding of respiratory infections, demonstrating the relevance of new agents such as human metapneumovirus, and providing new insights into previously recognized ones such as rhinoviruses. The progressive commercialization and clinical application of these methods is placing them at the forefront of respiratory diagnostics.

NAATs possess several advantages over more traditional techniques for the detection of respiratory pathogens. 27 These tests have improved sensitivity for detecting organisms that are fastidious, no longer viable, or present in small amounts. NAATs can provide rapid genetic information regarding sequence evolution, geographic variation, or the presence of virulence factors or antibiotic resistance. Their rapid turnaround times allow them a more prominent role in patient management, and the ability of NAATs to test for multiple pathogens simultaneously has aided in the diagnosis of nonspecific respiratory syndromes, such as in outbreak settings. Within the laboratory, NAATs offer enhanced opportunities for automation, and have a lower safety risk than culture for the detection of highly virulent pathogens.

Among the NAATs, the PCR is the most common and thoroughly evaluated method. 28, 29 The PCR formats most relevant for respiratory diagnostics can be classified into conventional, real-time, and multiplex platforms, with various amplicon detection methods such as gel analysis, ELISA, DNA hybridization, or the use of fluorescent dyes or chemical tags. Real-time PCR has several features that place it at an advantage. First, the two steps of amplification and detection are combined in one reaction, increasing the speed and efficiency of testing and reducing the risks of operator error and cross-contamination. Real-time PCR also allows for the possibility of quantifying the amount of starting nucleic acid material.

Multiplex PCR systems, in which multiple PCR targets are sought after simultaneously in one reaction, have gained wider acceptance, particularly among commercial assays. These systems have the advantage of increasing the number of Rapid Diagnostics pathogens tested for, without increasing the required amount of operator time or specimen material. Multiplex assays have broadened the scope of respiratory surveillance studies, and have also led to the increasing recognition of dual or triple infections in the same individual. 30 As noted in Table 1 , these assays can be differentiated by either their amplification or detection steps. In the amplification step, all multiplex platforms must balance the competing optimal PCR conditions for each individual target, and must overcome problems of competition and inhibition among the various primers and probes. Each platform uses a unique method to address these issues, such as nested primer combinations, 30,31 complex primer structures, 32,33 and nontraditional nucleotides. [34] [35] [36] These assays are even more varied in their detection stages, where the common task is to differentially detect and report distinct populations of amplified targets. Several platforms involve solid-phase arrays, such as polystyrene microbead suspensions that use fluorescent dyes to differentiate targets, 34, 37, 38 or the microchip formats that identify targets by binding to a specific physical location. [39] [40] [41] The former has been developed into platforms detecting 17 to 20 targets, whereas the latter can identify between a few dozen to thousands of targets. The increased breadth of targets afforded by microarrays, however, comes at the expense of decreased sensitivity. 42 Multiplex PCR products can also be distinguished by their size, using resolution techniques such as agarose gel electrophoresis to differentiate by weight, and capillary-based auto-sequencers that identify targets by length and sequence. 32, 33 Mass spectrometry can also be used for identification, either by the attachment of high molecular weight tags to primers [43] [44] [45] [46] or by the analysis of specific nucleotide base ratios that can be resolved by molecular weight. 47 Regardless of the platform, all PCR assays require good primer design taking into consideration gene target, gene number, mobility of genes between species, stability of gene, and the presence of mutations. Bacteria have large genomes with many genes for a fully functional organism, including their own genes for replication and enzyme product. Owing to the large genome size there are many targets available for specific detection of a bacterial species. Housekeeping genes, those genes that are essential for the survival of the organism, are desirable gene targets because they have conserved regions and hypervariable regions (eg, the 16S rRNA gene). Genes found in multicopies will also increase the sensitivity of PCR assays. The choices of viral pathogen gene targets are limited because of the limited size of the viral genome. Genes that are highly conserved are desirable targets for PCR because they allow the detection of many strains. Other genes that process areas of nucleotide hypervariability caused by genetic mutation should be avoided because changes over primer and probe sites can cause poor PCR efficiency and the potential for falsenegative results. Table 2 lists some of the more common respiratory pathogen target genes.

The published literature on NAATs can be difficult to interpret, because study designs vary and rarely involve head-to-head comparisons among the different assays. Calculation of clinical sensitivity and specificity is complicated because NAATs often are more sensitive than the reference culture-based standards. Comparisons of study results are also problematic because of the use of different specimen types that may have differential yields for pathogens. 48 Finally, several NAAT platforms require investment in specialized equipment, the cost of which can only be recovered through high-volume testing. Therefore, few NAAT assays for respiratory diagnosis are licensed for clinical use, and their daily use in clinical practice remains uncommon. To promote widespread adoption in the future, developers of NAAT diagnostics will need to standardize evaluation methods, particularly in comparison with reference techniques, reduce complexity and cost, and better demonstrate their utility in the clinical environment.

Although NAATs have been developed for all important respiratory pathogens, the clinical application of these tests varies. Perhaps the area that NAATs have had the greatest impact is for the diagnosis of infections caused by respiratory viruses. 29, 49, 50 For most, if not all, respiratory viruses, detection of viral nucleic acid is the most sensitive diagnostic approach, and current ''gold standards'' (namely, culture and direct immunofluorescence) will be eventually replaced by NAATs. 50 PCR has become the diagnostic test of choice for some respiratory viral infections (eg, for influenza during the current influenza H1N1 pandemic), and is a useful epidemiologic tool for characterizing the role of viruses in various disease states. 51 NAATs can provide results rapidly and are able to detect many viral pathogens that are unable to be readily detected by culture. Perhaps more so than for other respiratory pathogens, considerable effort has been directed toward the development of multiplex assays to enable the simultaneous detection of multiple viral pathogens. Given the increasingly large number of respiratory viruses, this can be a challenging task.

The need for improved diagnostic tools for pneumococcal disease has lead to the evaluation of several NAATs. For pneumonia, PCR has a sensitivity for detecting S pneumoniae in blood samples ranging from 29% to 100%, 27 with a tendency for higher sensitivity in children than adults. The finding of positive pneumococcal PCR results from asymptomatic control subjects complicates interpretation. [52] [53] [54] When testing sputum samples from adults with pneumonia, PCR positivity has ranged from 68% to 100%, 27 although it is unclear how often this reflects upper respiratory tract colonization rather than infection. 55 Further refinement of PCR assays, including the use of multiple targets, has increased the specificity, 56 with lytA assays potentially offering advantages over other assays. 57, 58 Quantification of S pneumoniae DNA load may provide additional diagnostic and prognostic information. Quantitative PCR may help distinguish colonization from infection, with a higher bacterial burden in pneumococcal disease than in a carrier state. 59 High pneumococcal DNA loads in blood have been recently shown to be associated with severe disease in various settings. [60] [61] [62] NAATs have improved the ability of diagnostic laboratories to detect respiratory pathogens that are difficult to culture, such as Mycoplasma pneumoniae, Legionella species, and Chlamydophila pneumoniae. An extensive evaluation of 13 antibody detection assays using PCR as the comparator standard concluded that few commercial serologic assays for detection of M pneumoniae performed with sufficient sensitivity and specificity, and highlighted the increasing importance of NAATs. 63 Indeed PCR is considered by many to be the method of choice for detection of M pneumoniae infection. 64 Both upper and lower respiratory tract samples are suitable for testing for M pneumoniae by PCR, although throat swabs and nasopharyngeal samples may be preferred because of high sensitivity, high specificity, and convenience. In practice, PCR has been successfully used to rapidly diagnose mycoplasma pneumonia during outbreaks, and was particularly useful in children, immunocompromised patients, and in early-stage disease. 65, 66 Legionnaires' disease can be difficult to diagnose, and NAATs have proven a useful adjunct to culture and antigen detection. 9 PCR has repeatedly been shown to have sensitivity equal to or greater than culture when testing lower respiratory specimens. [67] [68] [69] [70] [71] [72] [73] Legionella DNA can also be detected in nonrespiratory specimens, such as urine, serum, and peripheral leukocytes, 9 although testing these specimen types is not well established. Abbreviations: DFA, direct fluorescence assay; ND, not determined; TCID 50 , tissue culture infective dose needed to produce 50% change. 

PCR has been extensively evaluated for the rapid diagnosis of C pneumoniae infection using various assays. 74 A standardized approach to C pneumoniae diagnostic testing was published in 2001 by the US Centers for Disease Control and Prevention and the Canadian Laboratory Center for Disease Control. 75 However, there are still few evaluations that have extensively used clinical samples, and the great variety in the methods used makes it difficult to make firm conclusions about performance. To further complicate matters, significant interlaboratory discordance of detection rates have been recorded for some assays. 76, 77 The diagnostic yield from PCR is consistently greater than for culture when testing nasopharyngeal samples for Bordetella pertussis. 27 PCR remains positive for a longer period after the onset of symptoms and thus is useful for individuals who present late in their illness. 78 In the investigation of a pertussis outbreak, the combination of PCR and culture for samples obtained 2 weeks or less after illness onset and PCR alone for samples obtained more than 2 weeks after illness onset proved to be the most diagnostically useful. 79 PCR has greater sensitivity than cytologic methods for the detection of Pneumocystis jiroveci, although it has been difficult to interpret the common finding of PCR-positive samples that are negative by standard methods. 27 The latter may reflect P jiroveci colonization of uncertain clinical significance. The performance of PCR has been shown to vary with different assays, 80 although the results correlate well with clinical evidence of pneumocystis pneumonia. 81 The need for improved diagnostic methods for tuberculosis has focused attention on the potential role of NAATs. Advances in this area have been relatively slow, with NAATs for mycobacteria failing to provide greater sensitivity than culture-based methods. The relatively high false-negative rate with NAATs for Mycobacterium tuberculosis probably reflects a combination of the paucibacillary nature of samples, presence of inhibitors in samples, and suboptimal DNA extraction methods. The situation is changing, with new developments in rapid diagnosis and antibiotic susceptibility testing. 82 For direct detection of M tuberculosis in respiratory samples, all commercial assays have high specificity (>98%), but variable sensitivities: 90% to 100% for smear-positive samples and 33% to 100% for smear-negative samples. 27 Consequently, it is recommended that use of these tests is restricted to only smearpositive samples. Evaluations of PCR for the diagnosis of tuberculosis in high-prevalence populations have been promising. [83] [84] [85] [86] Alternative strategies under development to diagnose tuberculosis by molecular tools include detection of mycobacterial DNA in urine 87, 88 and direct detection in respiratory specimens by microarray. 89 

The NAATs discussed herein target known pathogens. When NAATs fail to identify an agent, additional tools are needed to pursue an etiologic diagnosis as might be indicated in an outbreak setting. These additional methods include microarrays and high-throughput sequencing. 42, 90, 91 Proteomics also has a potential for being developed as a tool for pathogen discovery. 92 

Breath analysis is an exciting new area with enormous diagnostic potential. [93] [94] [95] Alveolar breath contains many biomarkers derived from the blood by passive diffusion across the alveolar membrane, 93 and also contains direct markers of lung injury. [96] [97] [98] Breath testing is noninvasive, easily repeatable, and requires minimal specimen workup. Various testing methodologies and sample types have been used in breath research, usually involving the measurement of exhaled permanent gases, detection of volatile organic compounds, or analysis of exhaled breath condensate.

The use of breath analysis for the investigation of respiratory infections has not yet been extensively evaluated. Electronic nose devices detect volatile molecules as they interact with chemical sensor assays. [99] [100] [101] Based on the reactivity of multiple sensors to the volatile molecules, an electronic signature is generated. Testing of exhaled breath by a portable electronic nose has been used to diagnose pneumonia in mechanically ventilated patients. [102] [103] [104] The clinical impact of this device needs further evaluation, but it could be used as a trigger for further diagnostic studies in pneumonia such as bronchoscopy.

Microorganisms produce volatile metabolites that may be used as biomarkers. 105 Detection of these biomarkers in breath samples by gas chromatography/mass spectroscopy or similar methods may provide an etiologic diagnosis of respiratory tract infection. Ideally, specific biomarkers need to be identified, and it may be difficult to discover unique markers for each pathogen produced in sufficient quantities to enable detection. Potential biomarkers have been reported for some respiratory pathogens, such as Aspergillus fumigatus 106, 107 and M tuberculosis, 108,109 but it is still uncertain whether they will prove to be useful as clinical diagnostic tools.

Diagnostic tests for respiratory infections will continue to evolve and become more user-friendly. Antigen-detection assays in immunochromatographic or similar formats are rapid, simple to perform, and are most easily developed as near-patient tests. These methods are among the most attractive diagnostic tools, but further development is reliant on the discovery of suitable antigens that can be reliably detected in readily obtained specimens. NAATs have now been developed to a stage where multiplex assays that detect the common respiratory pathogens are commercially available, although not all have been rigorously evaluated in clinical settings. Further improvements in design and performance are expected, and an emphasis should be placed on clarifying the clinical usefulness of NAATs, developing standardized methods, producing even more user-friendly platforms, and exploring the role of quantitative assays. New approaches for respiratory pathogen detection are desperately needed. Breath analysis is an exciting new area with enormous potential, and it will be interesting to follow progress in this area over the next few years.

",0.7153982969177097
A Quantitative Assessment of the Total Inward Leakage of NaCl Aerosol Representing Submicron-Size Bioaerosol Through N95 Filtering Facepiece Respirators and Surgical Masks HHS Public Access,"Respiratory protection provided by a particulate respirator is a function of particle penetration through filter media and through faceseal leakage. Faceseal leakage largely contributes to the penetration of particles through a respirator and compromises protection. When faceseal leaks arise, filter penetration is assumed to be negligible. The contribution of filter penetration and faceseal leakage to total inward leakage (TIL) of submicron-size bioaerosols is not well studied. To address this issue, TIL values for two N95 filtering facepiece respirator (FFR) models and two surgical mask (SM) models sealed to a manikin were measured at 8 L and 40 L breathing minute volumes with different artificial leak sizes. TIL values for different size (20-800 nm, electrical mobility diameter) NaCl particles representing submicron-size bioaerosols were measured using a scanning mobility particle sizer. Efficiency of filtering devices was assessed by measuring the penetration against NaCl aerosol similar to the method used for NIOSH particulate filter certification. Results showed that the most penetrating particle size (MPPS) was ~45 nm for both N95 FFR models and one of the two SM models, and ~350 nm for the other SM model at sealed condition with no leaks as well as with different leak sizes. TIL values increased with increasing leak sizes and breathing minute volumes. Relatively, higher efficiency N95 and SM models showed lower TIL values. Filter efficiency of FFRs and SMs influenced the TIL at different flow rates and leak sizes. Overall, the data indicate that good fitting higher-efficiency FFRs may offer higher protection against submicron-size bioaerosols.","Influenza and other pandemic infectious diseases cause illness and death worldwide. The mode of transmission of infection appears to be through large droplets, aerosols, fomites, or person-to-person contact. (1) Infected subjects are known to release a wide size range of particles during breathing, coughing, sneezing, and talking. The droplets travel some distance and evaporate to form smaller-size particles. Normal human subjects and infected individuals release considerable numbers of submicron diameter particles in the exhaled breath. (2) (3) (4) In one study, exhaled breath of seven subjects infected with influenza was collected on Teflon filters and exhaled particle concentrations measured using an optical particle counter. (2) Filters were tested for influenza virus by quantitative polymerase chain reaction (qPCR). Results for four subjects showed influenza virus particles in exhaled breath and over 87% of particles were under 1 µm in diameter. Recently, appreciable numbers of influenza particles were found in the ambient air in different locations. (5) Submicron aerosols can remain airborne for prolonged periods because of their low settling velocity. Infectious aerosol, when inhaled by susceptible persons, is likely to cause disease.

Respiratory protection is known to reduce the inhalation of infectious aerosols. The Centers for Disease Control and Prevention (CDC) has developed recommendations on the use of the National Institute for Occupational Safety and Health (NIOSH)-approved N95 filtering facepiece respirators (FFRs) and facemasks for protection against pandemic influenza virus transmission for home, community, and occupational settings. (6) SMs are used as barriers to limit the dissemination of secretions or large droplets from patient to others. The Food and Drug Administration (FDA) clears the SMs for sale, based on the test report provided by the manufacturers. SMs are confused with respirators because both look similar and are worn on the face. In general, the filter efficiency of N95 FFRs is superior to SMs. (7, 8) Filter efficiency is enhanced by electrostatic charge on filter media of N95 FFRs. The most penetrating particle size (MPPS) for N95 FFRs is ~50 nm (electrical mobility diameter). (8) In the case of SMs, both electrostatic as well as mechanical (MPPS >100 nm) types are available. (8) FFRs are fit-tested before use in workplaces whereas SMs are not. SMs were used for respiratory protection in health care facilities when there was a shortage of respirators during pandemic seasons. (9) Therefore, knowing the effectiveness of SMs against infectious bioaerosols is of public health importance.

The effectiveness of N95 FFRs and SMs in health care settings has been reviewed. (10, 11) One study evaluated the health risk of nurses using respiratory protection during the severe acute respiratory syndrome (SARS) epidemic in Canada (12) and showed that N95 respirators were more protective than the SMs. Similarly, N95 respirators and hand washing were found to be effective in protecting health care workers against SARS transmission. (13) Another study reported a dramatic decrease of SARS infection from 52 to 8 among health care staff after implementation of the use ofN95 masks, gloves, and gowns. (14) Recently, the efficacy ofN95 FFRs or SMs against influenza transmission was evaluated with human subjects exposed to live attenuated influenza vaccine particles. (15) Analysis for influenza virus in the nasal washes of test subjects by reverse transcription-polymerase chain reaction technique showed that wearing N95 respirators offered a higher level of protection than SMs. Another study measured the protection factor for SMs and FFRs on test subjects in a controlled environmental test chamber and showed that SMs may not be as protective as FFRs. (16) Some studies have reported that SMs are as effective as N95 FFRs for respiratory protection from viral respiratory pathogens. (17) (18) (19) (20) Protection performance was tested using a fluorescein-KCl aerosol spray onto the faces of subjects wearing N95 FFRs or SMs and performing intermittent exercises on a treadmill in a chamber. (17) Test aerosol size was assumed to be about 0.1-0.3 µm based on the comparison of the filtration efficiency obtained for N95 FFRs in their study with the efficiency reported by a different group. (21) After the experiment, fluorescent stain on the faces and KCl concentrations in different layers of FFRs and SMs were analyzed to calculate the filter efficiency. Results showed that both N95 FFRs and SMs gave 95% or greater filtration efficiency, and N95 FFRs had about 2% filtration efficiency higher than the SMs indicating that SMs and N95 FFRs can provide protection in a relatively low viral aerosol loading environment. A case-control study in Hong Kong hospitals showed that both SMs and N95 FFRs were significantly effective in reducing the risk of SARS infection among staff. (18) In another study, influenza virus collected during coughing of patients wearing N95 FFRs or SMs was analyzed by quantitative real time RT-PCR. (20) The efficacy of SMs and N95 FFRs was found to be similar in preventing the spread of influenza virus from patients. Similarly, the use of SMs compared with N95 FFRs showed a non-inferior rate of laboratory-confirmed influenza. (19) Comprehensive information on the relative efficacy of FFRs and SMs for submicron-size bioaerosols is lacking. To address this issue, the Institute of Medicine (IOM) recommended further research in key areas including the effectiveness of facemasks and respirators against infectious particles and faceseal leakage contributing to the overall total inward leakage (TIL). (22) TIL is defined as an inverse function of a protection level offered by a respirator when the contributions of aerosol penetration through filter media, faceseal leakage, and leakage through other components are considered. It is known that FFRs are designed to provide good fitting on the human face unlike the SMs. Because of the difference in facefitting characteristics, SMs will have a larger faceseal leakage than FFRs when used by workers. One way to compare the performance of FFRs with SMs is to measure the TIL under controlled leak sizes.

In this study, TIL for two N95 FFR models and two SM models sealed to a manikin was measured as a ratio of particle concentration inside the breathing zone (space covered around the face by the filtering device) (C in ) to outside (ambient) concentration (C out ) at different size artificial leak holes introduced on the filtering devices at two different breathing flow rates. Submicron diameter size NaCl aerosol was used to measure the TIL. This size range of particles is similar to the size of bioaerosols released by subjects under breathing conditions as reported previously. (2) (3) (4) (5) Moreover, TIL, a measure of filter penetration and faceseal leakage for submicron-size particles would also be applicable to larger-size bioaerosols. TIL values for the two N95 FFR models and the two SM models were compared. The significance of filter penetration and faceseal leakage contributing to the TIL, and the efficacy of N95 FFRs and SMs against submicron-size bioaerosols are discussed.

Two NIOSH-approved N95 FFR models and two FDA-cleared SM models were tested in the study. These models were selected based on their performance in previous studies in our laboratory. (8, 23) The manufacturers and models (in parentheses) of the N95 FFRs were: Willson (model 1105N,) and San Huei United Company (model 1895N,) labeled as N1 and N2, respectively, and the SM models were: Primed (model PG4-1073,) and 3M (model 1800) labeled as SM1 and SM2, respectively. None of the N95 models tested in the study had exhalation valves.

Instantaneous filter penetration of FFRs and SMs was measured to assess their filter efficiency. Penetration of FFRs and SMs was measured using NaCl aerosol (count median diameter (CMD) 75±20 nm) generated by an Automated Filter Tester (AFT) TSI 8130 (TSI Inc., Shorewood, Minn.). (23) The AFT measures penetration based on the light scattering of particles that pass through the filter. A Plexiglas test box (L 20 cm × W 20 cm × H 10 cm) with a top and bottom plate containing a hole (2.5 cm diameter) in the center was used for measuring aerosol penetration. (23) A FFR or SM with its concave side facing down was sealed to a Plexiglas plate (L 20 cm × W 20 cm × H 0.5 cm) using melted wax. A silicone sealant was used to seal the top and bottom plates to make the Plexiglas box airtight. The Plexiglas box containing the FFR or SM was placed between the two filter chucks of the AFT and aligned to keep the top and bottom plate holes facing the upstream and downstream filter chucks, respectively. Penetration was measured for 1 min at 85 L/min constant flow under airtight conditions by closing the filter chucks. Figure 1 shows a manikin setup employed to evaluate the effect of faceseal leakage on TIL as described previously. (24) TIL was measured in two general configurations: (1) sealed to the manikin face with no artificial leaks induced through needles; and (2) sealed to the manikin face with artificial leaks induced through needles. AFFR or SM was sealed to a manikin head form using a silicone sealant and placed inside a test chamber (48 × 48 × 48 cm 3 ). The head form was connected to a breathing simulator (Breathing Simulator Series 1101, Hans Rudolph, Inc., Shawnee, Kans.) through an isolation chamber consisting of a rubber bladder inside an airtight glass container. A metal tube (2.5 cm diameter) from the back of the mouth was connected to an inflatable rubber bladder, which mimics a human lung, inside the glass container connected to a breathing simulator. The breathing simulator allows air to go back and forth into the glass container. In response, ambient air enters the bladder through the FFR sealed to the manikin head form during inhalation and exits during exhalation. Thus, the isolation chamber prevented particles created by the breathing simulator pump from getting inside the breathing zone of the respirator. The breathing simulator allowed for several parameters to be varied including tidal volume and breathing rate, which provided simulation of more realistic breathing conditions. NaCl aerosol used for TIL measurement was different from the aerosol used for testing filter penetration. Size distribution of NaCl aerosol was obtained in a manner similar to that described previously. (24) Briefly, polydisperse NaCl aerosol was generated using a 1.5% NaCl solution with a constant output atomizer (TSI 3076) and passed through a dryer, a 85 Kr charge neutralizer (TSI model 3077A), diluted with 50 L/min of dry air passed through a high efficiency particulate air filter (HEPA) and then into the test chamber (48 × 48 × 48 cm 3 ; Figure 1 ). Excess aerosol exited through a hole (1.3 cm diameter) in the back of the test chamber. A small fan was installed at the bottom of the chamber to ensure an even distribution of particles throughout. Aerosol samples from the test chamber were analyzed for number concentration for different size monodisperse particles (20-800 nm, electrical mobility diameter) over 240 sec and repeated after a 30 sec interval, using a scanning mobility particle sizer (SMPS) (TSI model 3080) with a long differential mobility analyzer (DMA), and an ultra-fine condensation particle counter (UCPC, TSI 3776). The DMA separates particles based on their electrical mobility. The count median diameter (CMD) and mode size (peak size) of the test aerosols were obtained from the SMPS scans.

The test FFR was equipped with a sample probe to measure aerosol concentration inside the FFR and two leak probes to introduce artificial leakage (Figure 1, Inset) . (24) The leak probes (~3 mm diameter and ~1 cm long) were filled with non-hardening putty and increasing leak sizes were obtained by carefully inserting hypodermic needles (16 and 13 gauge sizes with inner diameters of 1.18 and 1.80 mm, respectively) through the putty to provide consistent leak channels through the needles (~2.56 cm long). Care was taken to ensure the needle was kept open after inserting it into the putty. The tip of the needle was positioned proximately close to the inner surface of the respirator. Because the above leak sizes did not produce a significant difference in the TIL for SMs, larger leak sizes were used.

For comparison, SMs as well as FFRs were fixed with larger leak probes (~3 mm diameter and ~1 cm long). Each leak size was created using two leak probes, one on each side. TIL was measured with three different leak sizes (two 3 mm, four 3 mm or six 3 mm). Samples from inside and outside the FFRs and SMs were withdrawn and analyzed by two SMPS systems simultaneously. (24) The two SMPS systems scanned the particles in the 20-800 nm size range three times each three min. Samples were withdrawn simultaneously during manikin breathing at 8 and 40 L minute volumes with tidal volumes of 0.5 and 1.5 L, respectively. These tidal volumes corresponded to 16 and 26.7 breaths per minute, respectively. TIL was calculated as the ratio of particle concentration inside (C in ) of the FFR or SM to the outside concentration (C out ) and multiplied by 100%.

NaCl aerosol penetrations for N95 FFR models were lower than the penetrations for the SM models at 85 L/min flow rate (Table I ). In addition, penetrations for N1 and SM1 were relatively lower than the values obtained for N2 and SM2, respectively. Based on the penetration values, N1 and SM1 are described as higher-efficiency FFR and SM models, respectively, throughout the article.

The size distribution of NaCl aerosol used for TIL measurement showed a CMD of ~82 nm and a mode size (peak size) of ~75 nm. Figure 2 shows the TIL measured at no leak condition and with two small leak sizes at 8 L (left panels) and at 40 L (right panels) breathing minute volumes for the two N95 models. TIL for different size particles increased with increasing breathing minute volumes from 8 to 40 L with no leaks. The most penetrating particle size (MPPS) was ~45 nm for both FFR models which can be easily seen at 40 L breathing minute volume. With increasing leak sizes (2×1.18 mm and 2×1.80 mm), the TIL for different size particles increased for the two FFR models at both breathing rates. The MPPS remained at ~45 nm with different leak sizes. The TIL for the MPPS was higher than the values for the other size particles. Among the two N95 models, N1 showed lower TIL values for different size particles than N2 at both breathing rates. Figure 3 shows an increase in the TIL for different size particles with increasing leak sizes from 3 to 5 (2×3 mm, 4×3 mm, and 6×3 mm, respectively) for both FFR models, at 8 and 40 L/min. Larger leak holes (4×3 mm and 6×3 mm) tend to produce similar TIL values for different size particles. Similar trends in TIL results were obtained for SM1at different leak sizes and flow rates (Figure 4 , top panels). The MPPS was ~45 nm with no leaks and with a smaller leak size (2×3 mm), which can be seen at 40 L/min. For SM2, however, TIL values for the various size particles at no leak condition and with different induced leak sizes showed very little change at both breathing flow rates (Figure 4 , bottom panels). The MPPS for SM2 was ~350 nm at all test conditions. Table II shows the TIL for the two FFR models and the two SM models at different leak sizes and flow rates. Models N1, N2 and SM1 showed higher TIL values for 45 nm particles than for 300 nm size particles at smaller leak sizes as reported previously. (24) For SM2, however, TIL values were smaller at 45 nm than at 300 nm at all test conditions.

TIL measured for 20-800 nm diameter size NaCl aerosols for the two N95 FFR models were lower than the values obtained for the two SM models at the two different breathing flow rates without induced leaks. TIL value without induced leaks represents penetration through filter media and agrees with the trend in penetration measured at NIOSH certification test condition. The inverse relationship between TIL and filter efficiency can also be seen among the FFR models, N1 (higher efficiency) and N2 (lower efficiency) as well as between the SM models, SM1 (higher efficiency) and SM2 (lower efficiency). With increasing leak sizes, TIL for 20-800 nm size particles increased with increasing breathing flow rates for both FFR models as well as for the SM1 model. TIL values for the two FFR models were lower than the values for the SM models at similar flow rates and leak sizes, indicating the influence of filter efficiency. TIL values for the FFR models and SM1 did not vary significantly at larger leak sizes where minimum protection can be expected. However, TIL values between FFRs and SM2 were markedly different. Similar difference in TIL can also be seen between SM1 and SM2. The results can be explained by the large difference in filter efficiency between the filtering devices (FFRs and SM1 vs. SM2), and the inverse relationship between efficiency and TIL.

Results obtained in the present study are consistent with the data for four different N95 FFR models tested previously. (24) In that study, two relatively higher-efficiency N95 FFR models showed lower TIL values than two lower-efficiency models with different leak sizes and flow rates. The inverse relationship between filter efficiency and TIL provides a better explanation for the higher levels of respiratory protection offered by the N95 FFRs than the SMs reported previously. (12, 14, 15) The MPPS was ~45 nm for N1, N2, and SM1 models, and ~350 nm for SM2 with no faceseal leakage. Similar results were obtained with smaller leak sizes at different breathing rates. Results from the study indicated that FFRs producing smaller TIL value at the MPPS may provide relatively higher protection against submicron virus aerosols. Among the two SM models tested, SM1 appears to bemore effective than SM2 for submicron-size virus aerosols.

The relative impact of filter penetration is believed to be minimal or insignificant once leaks are introduced in the facemask. In this study, artificial leaks introduced in the N95 FFRs and SMs sealed to the manikin allowed the test aerosols (mode size ~75 nm) to enter and exit the breathing zone (space covered around the face by the filtering device) during breathing flow conditions. Interestingly, the MPPS values for FFR and SM models with induced leak sizes were similar to the MPPS obtained with no leaks. The above phenomenon can be explained by the effect of filter penetration or filter media characteristic regulating the concentration of different size particles inside the FFR or SM sealed to the breathing manikin at different leak sizes. The results are consistent with our previous finding (24) that faceseal leakage acts as a gatekeeper and indiscriminately allows the test aerosols to flow through the leaks and increases the concentration of all size test aerosol inside the breathing zone, while filter penetration or filter media characteristic assigns the TIL values for different size particles. The results obtained in the study indicate that filter penetration potentially influences the TIL of different size particles. The data provide a better understanding on the contribution of faceseal leakage and filter penetration to the overall TIL.

The contributions of filter penetration and faceseal leakage to the TIL results obtained with the manikin raise the question of how well these processes are represented when a respirator is worn by a human subject. Faceseal leakage is known to be a major pathway that contributes to the TIL of particles. (25) (26) (27) The number of particles penetrating through the faceseal leakage pathway of the respirators and SMs tested on subjects has been shown to far exceed the number of particles passing through the filtermedium. (27) The influence of filter penetration and faceseal leakage on the TIL measured for test subjects has been described. (25, 26) In one study, the overall TIL values for Korean half-masks and three different class (top class, 1st class, and 2nd class) FFR models donned on test subjects were measured. (25) Among the FFRs, top class FFRs (≥99% efficiency) showed average TIL values of ~5.0%. However, the TIL values for lower-efficiency FFRs (""1st class"", ≥94% and ""2nd class"", ≥80%) were ~2 times higher than the TIL values obtained for ""top class"" FFRs. Overall, the results indicated lower TIL values for the higher-efficiency FFRs. This finding is supported by the data obtained in our recent study on the inter-laboratory comparison of TIL measurement. (26) Five different N95 FFR models with different filter efficiencies were tested on 35 human subjects performing the Occupational Safety and Health Administration (OSHA) fit-testing exercises in two different test laboratories. A PortaCount Pro (TSI, Shorewood, Minn.) measured the C out /C in ratio which was then converted to TIL values based on the inverse relationship between the two parameters. Filter efficiency was obtained only for four of the five models. Results showed that the overall TIL values were lower for a relatively higher-efficiency N95 model, and higher for three lower efficiency models in both laboratories. Moreover, a good agreement between the two laboratories on the TIL values measured for different N95 models was obtained, indicating the measurement was reproducible. Filter efficiency dependence of TIL obtained for human subjects in the above studies may explain the higher protection offered by the N95 FFRs compared to the SMS in health care settings. (12, 14, 15) Filter efficiency of the N95 FFRs is generally higher than that of SMs because of the difference in the filter media used for construction. The N95 FFRs are developed to meet more challenging test conditions than are the SMs. Filter efficiency for N95 FFRs is >95% when tested using charge neutralized NaCl aerosols with a CMD of 75±20 nm at 85 L/min. The penetration level does not exceed 5%, up to 200 mg aerosol loading. However, the performance among SMs may vary widely because of the far less challenging test methods used for their clearance by the FDA. (28) Filtration efficiency of high and moderate barrier SMs is >98% and low barrier SMs is >95% based on the penetration measured against nonneutralized Staphylococcus aureus bacteria of 3000±300 nm at 28.3 L/min. Some types of SMs are also tested with 100 nm diameter non-neutralized polystyrene latex spheres (PSL) at 1 to 25 cm/sec face velocity which may produce wide differences in their efficiencies. Non-neutralization of test aerosol may overestimate the filter efficiency and partly contribute to the enormous difference in the filter performance among SMs. (7, 8) TIL is dependent on efficiency of the filter device. (24, 25) Because of the higher filter efficiency, N95 FFRs are expected to show lower TIL values than do SMs as described previously. (24, 26) Faceseal leakage is a major pathway for aerosol transport inside the filtering device. (25, 27) The SMs are not designed to provide a good fitting on a human face that may allow more aerosol leakage. However, SMs were found to be as effective as N95 FFRs against aerosol particles similar to the size of infectious aerosols. (17, 19, 20) In one study, the transmission of influenza during routine health care activities by hospital nurses using N95 FFRs and SMs was assessed. (15) These authors showed that SMs were equally effective in preventing influenza virus transmission among health care workers. A similar conclusion was obtained in other studies. (16, 17) However, the performance of N95 FFRs may be higher where considerable aerosol generation can occur during procedures such as intubation or bronchoscopy. (19) Other factors, including training and consistency in the use of the device and concentration of aerosol exposure, can also influence the overall effectiveness of protective devices.

A shortage of respiratory protection devices during pandemic diseases is possible. To address the issue, the CDC has stockpiled large numbers of them. Respirators were stockpiled based on several factors, including their approval for use in health care facilities and availability in the market. Results obtained in the present study may be important for this stock-piling. For example, relatively higher efficiency N95 FFRs, as well as SMs, are expected to produce lower TIL values representing higher protection against infectious aerosols. This indicates that filter efficiency of respiratory protection devices should also be considered for stockpiling purposes.

The limitations of the current study include the small number of N95 FFR and SM models tested for TIL measurement. Additional models, including those equipped with an exhalation valve, need to be tested to obtain conclusive information on filter efficiency dependence of TIL. Another limitation of the study is the TIL measurement for particles below 800 nm size range. TIL study for a wide size range of airborne particles using additional equipment may provide more realistic information. Nevertheless, the measurement for 20-800 nm size range provides the underlying mechanism of regulation of TIL by filter penetration and faceseal leakage processes. Further studies on TIL, using test subjects, are important to evaluate the performance of N95 FFRs against submicron-size bioaerosols.

Filtration efficiencies of the two N95 FFRs were higher than those of the two SMs tested in the study against NaCl aerosol. Efficiencies of N1and SM1 were relatively higher than those of N2 and SM2, respectively. TIL for NaCl aerosol (CMD ~82 nm) using a manikin setup showed a MPPS of ~45 nm for N95 FFR models N1 and N2 and SM1 models, and ~350 nm for the SM2 model at different flow rates and leak sizes. Leakage of test aerosols through artificial holes increased the TIL for different size particles while the MPPS remained at the same sizes obtained at sealed condition with no artificial leaks, showing that filter penetration regulates TIL. In general, higher-efficiency N95 and SM models showed lower TIL values than the lower-efficiency models, indicating the potential influence of filter efficiency. TIL results obtained in the study indicate that faceseal leakage allows all the different diameter size test aerosols to enter and exit the filtering device while filter penetration assigns the TIL for different size particles. Overall, the data suggest that higherefficiency N95 FFRs with good fitting characteristics would provide higher protection against submicron-size bioaerosols. Flow diagram of the manikin experimental setup used for submicron-size particle leakage under simulated breathing conditions (The rubber bladder mimics a human lung and allows breathing air to enter and exit through the mouth. A typical FFR with a sample probe and one leak probe is shown in the inset. The differential mobility analyzer (DMA) of the SMPS separates particles based on their electrical mobility.) (color figure available online) Rengasamy Typical TIL values for the two surgical models SM1 and SM2 at 8 L/min (left column) and 40 L/min (right column) breathing minute volume (The symbols indicate: sealed with no leaks (•), two 3 mm leaks (○), four 3 mm leaks (▼), and six 3 mm leaks (△ 

",0.7153009758976446
Precautions are Needed for COVID-19 Patients with Coinfection of Common Respiratory Pathogens,"With the ongoing outbreak of Coronavirus Disease 2019 , infected patients within and beyond the epidemic area, Wuhan, China, showed different epidemiological and clinical characteristics. There is a paucity of data concerning coinfection with other common respiratory pathogens in COVID-19 patients outside of Wuhan.","At the beginning of December 2019, a cluster of ""pneumonia of unknown aetiology"" emerged in Wuhan, Hubei Province, China. The disease has soon developed into an outbreak posing a pandemic threat. Since no causative pathogen was identified at the onset of the disease, it was once called ""Wuhan pneumonia"" by the health officials and the public. On December 31, 2019, a total of 27 cases were reported; meanwhile, a rapid response team led by the Chinese Centre for Disease Control and Prevention (China CDC) was formed to conduct detailed epidemiologic and aetiologic investigations in Wuhan. 1 

Laboratories in Qingdao and Wuhan adopted a similar protocol for detection of IgM- 

Raw data were entered by two persons (double data entry) who were not aware of the arrangement of study groups. Continuous variables (non-normal distribution) were expressed All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint as median with interquartile range (IQR) and compared with the Mann-Whitney U test; categorical variables were presented as number (%) and compared by χ ² test or Fisher's exact test between Wuhan and Qingdao groups. A two-sided α of less than 0.05 was considered statistically significant. Statistical analyses were done using the SAS software, version 9.4.

By February 16, 2020, a total of 68 patients with laboratory-confirmed SARS-CoV-2 infection was included in the final analysis, among whom 30 were from Qingdao and 38 were from Wuhan ( Table 1 All patients had respiratory specimens tested for specific IgM antibodies against IFV-A, IFV-B, RSV, ADV, PIV, MP, LP, CP and COX. Among the 30 patients admitted in Qingdao, 24 patients had IgM antibodies detected against at least one of the above-mentioned pathogens, and the overall positive rate was 80.00% (Table 3) ; whereas only one (2.63%) of the patients in Wuhan had positive results for respiratory pathogens. The most common respiratory viruses detected were IFV-A (60.00%) and IFV-B (53.33%), followed by MP (23.33%) and LP (20.00%).

Ages of healthy control group ranged from 20 to 55 years, with a median age of 40 years All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint (IQR: 33-50), and 14 (46.67%) were men. Only 4 people (13.33%) of this group had specific-IgM antibody detected in their serum, suggesting asymptomatic infection with single virus (IFV-B). The total infection rate in healthy control was significantly lower than that in COVID-19 patients (P<0.0001, Table 4 ), and none of the individual in control group showed evidence of combined infection with two or more pathogens. The climatic characteristics of Qingdao and Wuhan from December to January of following year were shown in Table 5 , where differences could be observed between the two cities.

Although the climate in Qingdao is drier and colder than Wuhan, major respiratory pathogens circulate in the two cities were quite similar.

This is an extended descriptive study on COVID-19 patients between Wuhan and Qingdao, represented as within and beyond the epidemic centre, respectively. Since the early onset of COVID-19 till the specific definition of novel coronavirus (previously known as 2019-nCoV) releasing on January 7, 2020, 4 the term ""illness/pneumonia of unknown aetiology"" was repeatedly quoted by the health officials and the public during this one-month period. One of the possible explanations for such failure to clearly define the disease is that no causative pathogen could be found at the early stage. We speculated that if any common respiratory pathogen, such as influenza and parainfluenza viruses, RSV, ADV, MP and CP, or the previous emerging novel coronaviruses including SARS-CoV and MERS-CoV, was isolated from body fluids and secretions of the infected patients, related treatment and management could have been implemented in the first place. As such, it was very unlikely that ""pneumonia of unknown causes"" would still be emphasized, although this might cause delay in the discovery of SARS-CoV-2. Therefore, we assumed that the possibility of coinfection in All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint COVID-19 patients was very rare. Our assumption was led support by two recent studies conducted in Wuhan showing that there was no coinfection of respiratory pathogens in COVID-19 cases. 3, 9 According to our data, the majority of COVID-19 patients in Qingdao were not from the endemic area; they were infected indirectly without a history of traveling to Wuhan. Despite the high coinfection rate in Qingdao patients who had more complicated clinical conditions Here we also compared the geographical and climatic characteristics of Qingdao and Wuhan. Wuhan is located in the centre of southern China and has a subtropical climate; 16, 17 while Qingdao is situated in the coastal area of northern China in the temperate zone, which has a relatively lower humidity than Wuhan. 18 Despite the difference in natural characteristics between the two cities, common respiratory pathogens circulate in Wuhan and Qingdao (including IFV-A, IFV-B, RSV, and ADV) have shown to be generally similar during the peak season of respiratory diseases in wintertime (from January to February). [19] [20] [21] [22] The incidence of coinfection in COVID-19 patients in Wuhan was rather low. Whereas in places with relatively low temperature like northern Qingdao, it is more common to find combined SARS-CoV-2 infection with other seasonal respiratory pathogens. It is not yet known whether this phenomenon also exists in other regions, leaving a gap for future studies. There are limited data to address whether coinfection with other respiratory pathogens would affect All rights reserved. No reuse allowed without permission. author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint the pathogenesis and outcome of severe acute respiratory illnesses like SARS and MERS. [23] [24] [25] [26] [27] Fortunately, SARS-CoV-2 RNA was detected in all of our patients before other respiratory pathogens being detected. Otherwise these COVID- 19 It is notable that there are several limitations of this study. Two critically ill patients and one patient who died in the end were excluded due to lack of aetiological data other than SARS-CoV-2. As of February 16, 2020, there were 60 cases of confirmed SARS-CoV-2 infection in Qingdao, however, we only analysed 30 non-severe cases whose complete aetiological and clinical information was available. The age of patients in Qingdao ranged from 1.5 years to 80 years; whereas patients in Wuhan were all adults as they were medical professional infected through work. Such age difference between the two groups might bring in bias to this study. We performed nucleic acid testing for the confirmation of SARS-CoV-2 infection, while coinfection with other pathogens was detected by serological testing of antibodies. In spite of superior accuracy, PCR-based molecular testing using throat swabs requires more complicated techniques of laboratory personnel with prolonged reporting time, which may not be suitable for emerging cases of SARS-CoV-2. 28,29 Thus, we applied rapid testing of aetiological agents by IIF in collected acute phase serum to guide clinical decision making. Since both the hospitals in Qingdao and Wuhan adopted the same protocol for the diagnosis of coinfection, we believe this will not affect the determination of final outcomes. All rights reserved. No reuse allowed without permission. author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint

To test the reliability of serum specific IgM detection, we recruited a control group of normal people without clinical symptoms. The low infection rate in our control population suggested that our method was reliable in early and rapid diagnosis of respiratory infections. However, we were unable to exclude the possibility that coinfection with other respiratory pathogens may make the patients more susceptible to SARS-CoV-2 infection. Specific-IgM antibody could be detected in serum from one week of illness onwards and the amount progressively author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The data are expressed as n (%) or median (IQR).

All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint The data are expressed as n (%) or median (IQR).

All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint Table 5 All rights reserved. No reuse allowed without permission.

author/funder, who has granted medRxiv a license to display the preprint in perpetuity.

The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.02.29.20027698 doi: medRxiv preprint

",0.7152401015756688
Internet-based surveillance systems for monitoring emerging infectious diseases,"Emerging infectious diseases present a complex challenge to public health offi cials and governments; these challenges have been compounded by rapidly shifting patterns of human behaviour and globalisation. The increase in emerging infectious diseases has led to calls for new technologies and approaches for detection, tracking, reporting, and response. Internet-based surveillance systems off er a novel and developing means of monitoring conditions of public health concern, including emerging infectious diseases. We review studies that have exploited internet use and search trends to monitor two such diseases: infl uenza and dengue. Internet-based surveillance systems have good congruence with traditional surveillance approaches. Additionally, internet-based approaches are logistically and economically appealing. However, they do not have the capacity to replace traditional surveillance systems; they should not be viewed as an alternative, but rather an extension. Future research should focus on using data generated through internet-based surveillance and response systems to bolster the capacity of traditional surveillance systems for emerging infectious diseases.","Emerging infectious diseases are of particular concern to public health. Emergence is driven by sociocultural, environmental, and ecological factors. 1 The vulnerability of people to emerging infectious diseases has been shown by the emergence of AIDS in the late 1970s, severe acute respiratory syndrome (SARS) in 2003, pandemic infl uenza H1N1 in 2009, and multidrug-resistant nosocomial pathogens, as well as the re-emergence of dengue, chikungunya, and malaria. Traditionally, eff ective disease surveillance is expensive and needs a formal public health network. 2 Such systems are maintained by most countries, to varying degrees. Data sources, surveillance methods, analytical approaches, and factors aff ecting these systems are varied and have been reviewed in detail elsewhere. 3, 4 Traditional, passive surveillance systems typically rely on data submitted to the relevant public health authority by physicians, laboratories, and other health-care providers; they provide information crucial to the eff ective functioning of health systems. 5 These systems can be com plex and expensive. Time and resource constraints, as well as a lack of operational knowledge of reporting systems, adversely aff ect the completeness of reporting, 6 resulting in an incomplete account of disease emergence. Furthermore, substantial lags between an event and its notifi cation are common; a result of late or failed reporting and the hierarchical structure of these systems. 7 The average delay from receipt to dissemination of data by traditional sentinel surveillance networks is roughly 2 weeks. 8 Internet availability and use has increased greatly in the past 10 years (fi gure 1). 9, 10 The availability of healthrelated information on the internet (of varying quality and legitimacy) has also changed how people seek information about health. 10, 11 These changes provide a new means to detect and monitor infectious diseases. The nature of emerging infectious diseases often limits the eff ectiveness of traditional surveillance systems. 12 Digital surveillance could improve both the sensitivity and timeliness of detection of health events. 13 We review recent studies that have exploited internet use and search trends to monitor two acute-onset viral illnesses of worldwide importance that have substantial seasonal and geographic variation: infl uenza and dengue. We critically analyse the eff ectiveness of monitoring internet data to track these diseases and discuss the advantages and limitations of this approach. Finally, we make recommendations for future research into these systems.

Digital surveillance attempts to provide knowledge of public health issues by analysis of health information stored digitally, as well as the distribution and patterns governing access to these data. Approaches to digital surveillance vary according to the media targeted. However, all exploit changes in behaviour related to information seeking, collection, storage, and communication pathways that have occurred with the development and increased availability of the internet and associated technologies.

Several surveillance systems use non-structured, eventbased, digital data. 14 The Global Public Health Intelligence Network (GPHIN)-developed by the Public Health Agency of Canada-automatically retrieves information about potential public health emergencies from news feed aggregators and distributes this information to public health agencies, including the WHO Global Outbreak Alert and Response Network. 2, 15 The eff ectiveness of this system was shown during the SARS outbreak; GPHIN detected SARS more than 2 months before the fi rst publications by the WHO. 2 Other systems-eg, HealthMap 16 and ProMED-mail 17, 18 -provide information about emerging public health problems by aggregating information about emerging diseases from various structured and non-structured data sources. These and other similar systems are reviewed elsewhere. 13, 14, 19 Internet use has increased consistently in almost every country. 20 Internet users in the USA alone generate 8 million queries for health-related information every day. 21 The increase in worldwide internet availability and use over the past 10 years, combined with these changes in health-seeking behaviour, has created new possibilities for the development of innovative surveillance systems. 9, 10, 22, 23 Although still very much in its infancy, analysis of digital data has been used to monitor communicable 2,24-33 and non-communicable diseases, 34, 35 as well as mental health, 36, 37 illegal drug use, 38 health policy impact, 39 and behaviours with potential health implications. 40 Numerous studies have sought to exploit online healthseeking behaviour to monitor disease incidence. Although these studies use diff erent data sources, they all rely on the premise that people who contract a disease will seek information about their condition from the internet and that incidence can be estimated by tracking changes in frequencies of searches for key terms. By monitoring search queries submitted to the search engine Yahoo!, Polgreen and colleagues 41 predicted increases in positive infl uenza cultures 1-3 weeks before their occurrence. Similarly, Hulth and co-workers 42 developed a model for estimating intensity and peak incidence of infl uenza in Sweden by monitoring queries submitted to the medical web site Vårdguiden. This model correlated closely with both data for infl uenza-like illness (R²=0·89) and laboratory-confi rmed cases of infl uenza (R²=0·90). A subsequent study showed this model to have good congruence with sentinel data over the course of the 2009 infl uenza H1N1 pandemic (r=0·88-0·90). 43 More recently, infl uenza incidence in China was estimated by assessment of searches submitted to Baidu (the most commonly used search engine in China). 44 This study reported a correlation of R²=0·96 between a composite search index (eight terms) and monthly Ministry of Health infl uenza reports. Furthermore, using a combination of Ministry of Health and Baidu data, the researchers produced accurate estimates (R²=0·95) of incidence 1-2 weeks before of Ministry of Health reports.

Google search queries also correlate highly with disease incidence. Historical logs of aggregated Google search queries-presented as normalised time seriesare publically available through Google Trends from Jan 1, 2004. These data are available by country, state, and city in the USA, but only at country-level for many other regions (especially low-income countries). Previously, Google off ered two user interfaces to access search reports: Google Trends and Google Insights for Search, which were merged in September, 2012. 45 Carneiro and Mylonakis 24 used Google Trends to analyse worldwide search frequency for the term ""bird fl u"". They reported an increase in search frequency between 2005, and 2006, coinciding with the spread of avian infl uenza from China to Turkey. Other studies reported the use of Google search data to monitor the frequency of searches for manually selected terms related to infl uenza in Chinese, 46 Spanish, 31 and French. 28 These studies reported high degrees of correlation, which shows the potential application of this technology in languages other than English. Ginsberg and colleagues 47 used an automated approach to select search terms from Google search logs with the greatest correlation with the US Infl uenza Sentinel Provider Surveillance Network of the US Centers for Disease Control and Prevention (CDC). The terms were then used to develop a model for monitoring infl uenza activity. Estimates from the model correlated highly with regional Centers for Disease Control and Prevention data (r=0·80-0·96, nine regions) and accurately estimate incidence of infl uenza-like illness 1-2 weeks before surveillance reports. 47 An online infl uenza surveillance tool-Google Flu Trends-is based on the model of Ginsberg and coworkers and now includes 29 countries.

To date, two publications have reported the use of internet search data to estimate incidence of dengue. Chan and colleagues 48 used a similar method to Ginsberg and coworkers 47 to create models of dengue transmission for Bolivia, Brazil, India, Indonesia, and Singapore. Correlations between model estimates and holdout surveillance data (data excluded from the model, used for validation) were high for all countries (r=0·83-0·99). These models have been used to develop a free, publically available online resource for dengue surveillance: Google Dengue Trends. Althouse and colleagues 49 used Google Insights for Search to monitor searches for dengue-related terms and applied these results to step-down linear regression models for Bangkok (Thailand) and Singapore. Both models showed a high degree of correlation with surveillance data (R²=0·95 for Bangkok and 0·94 for Singapore). Additionally, this study developed support vector machine 50 and logistic regression models to predict periods of high dengue incidence. Area-under-the-receiveroperating-characteristic-curve, using the 75th percentile, was 0·960 for Bangkok and 0·906 for Singapore according 

to the support vector machine model compared with 0·960 and 0·896 respectively for the logistic regression model.

Several studies have compared the performance of Google Flu Trends with national data for infl uenza-like illness. Google Flu Trends was visually compared with surveillance data for Australia 51 53 These fi ndings accord with the results of Hulth and colleagues 43 and Valdivia and colleagues 54 who showed that Google Flu Trends correlated strongly with estimates of infl uenza incidence and peak incidences produced from data collected by sentinel physician networks throughout Europe. Finally, Google Flu Trends correlated highly with the Electronic Surveillance System for the Early Notifi cation of Community-Based Epidemics (ESSENCE; a syndromic surveillance system run by the US Department of Defence; r=0·88) 55 and with infl uenzalike illness estimates produced for Flanders, Belgium, by the Great Infl uenza Survey (a weekly, online infl uenza survey; r=0·62-0·94). 56 Traditional infl uenza surveillance systems commonly monitor incidence with virological data, rather than infl uenza-like illness. Data from Google Flu Trends was highly correlated with data from the US Infl uenza Virologic Surveillance System (r=0·72); 57 however, this correlation was lower than that reported for Google Flu Trends and CDC infl uenza-like illness data (r=0·94). Google Flu Trends estimates have been reported to correlate highly with laboratory-confi rmed infl uenza at a provincial and city level. Malik and colleagues 12 reported the correlation between weekly counts of laboratoryconfi rmed H1N1 infl uenza cases in Manitoba, Canada, and Google Flu Trends data during the 2009 infl uenza pandemic (R²=0·69; 2 week lag). Similarly, Google Flu Trends had a high level of congruence with virology data from a Baltimore hospital (adult r=0·88; paediatric r=0·72). 58 Dugas and coworkers 58 noted that Google Flu Trends correlated well with paediatric emergency department crowding measures, leading them to suggest that Google Flu Trends could be used for strategic management of emergency department resources. The potential applications of Google Flu Trends data to strategic allocation of resources and priority setting is further shown by Patwardhan and Bilkovski, 59 who compared sales of four drugs commonly prescribed for treatment of infl uenza with Google Flu Trends and CDC ILINet data; aggregate correlation between Google Flu Trends and prescription sales was r=0·92 .

Any changes to the status quo of internet search behaviour could alter how well Google Flu Trends models actual infl uenza incidence. Loss of resolution might occur as a result of media-driven interest or through other events that change search behaviour. 43, 49, 57, 58, 60, 61 Google Flu Trends accounts for changing search behaviour by updating the model each year to best represent reference surveillance data. 62 Despite this precaution, a loss of resolution was reported to have occurred during the 2009 H1N1 infl uenza pandemic. 53 

Studies have predominantly focused on retrospective assessment of the performance of Google Flu Trends. However, almost real-time disease tracking can be done by application of Google Flu Trends data to a seasonspecifi c compartmental mathematical model. 63 Google Flu Trends data can also be used for early detection of epidemics. 64 Pervaiz and colleagues applied various algorithms to Google Flu Trends data to develop early epidemic detection systems capable of generating actionable alerts. Although this study did not identify a single best method, it showed the potential use of Google Flu Trends data in this manner. Zhou and coworkers 65 have developed a system to predict epidemic alert levels from daily Google Trends data. Hidden Markov modelbased methods predicted infl uenza alert levels in realtime with 97·7% accuracy and provided an indication of infl uenza activity up to 4 weeks ahead of the release of CDC reports. In another recent study, ensemble adjustment was used to assimilate Google Flu Trends data into a humidity-driven compartmental mathematical model, enabling real-time predictions of peaks to be made more than 7 weeks in advance of their occurrence. 66 Finally, using a negative binomial generalised autoregressive moving average model-which included Google Flu Trends data as a secondary variable-Dugas and colleagues 67 predicted weekly infl uenza cases at a medical centre with a high degree of accuracy (83% of estimates were within seven cases).

These models are promising and, overall, Google Flu Trends seems to provide timely and accurate estimates of infl uenza-like illness and laboratory-confi rmed infl uenza. However, methods to integrate this information into existing surveillance systems need to be developed. 55 Scarpino and colleagues 68 postulated that the predictive power of the Texas ILINet could be improved by use of a smaller set of carefully chosen sentinel providers. Additionally, they investigated the potential of incorporating Google Flu Trends data into the network as a virtual provider. Google Flu Trends was reported to have a high degree of correlation with the ILINet in Texas (R²=0·77 at a 0 week lag). It was the most informative provider, matching the predictive performance of an optimised network of 44 sentinel providers.

The power of social media as both a source of information and as a means of disseminating information is increasingly recognised in public health. 69, 70 Corley and colleagues 71 have proposed that infl uenza incidence could be estimated by tracking use of key terms in web and social media. They analysed the frequency of English language blog posts that contained the terms ""infl uenza"" or ""fl u"" and compared these with CDC ILINet data. Correlation was r=0·63 for this study and r=0·55 in a subsequent study with an extended dataset. 72 Microblogs (such as Twitter) were not included in these studies. Collier and coworkers 73 used supervised learning to categorise expressions from Twitter messages into fi ve infl uenza-related categories and correlated these expressions with CDC data for positive infl uenza A H1N1 tests. Correlations in this study (r=0·58-0·67) were similar to those for Corley and colleagues. 71, 72 Chew and Eysenbach 74 sorted Twitter posts containing terms related to infl uenza A H1N1 into groups describing ""personal experiences"" or ""concern"" and compared these with H1N1 incidence rates in the USA. Correlations were r=0·77 for ""personal experiences"" and r=0·66 for ""concern"". These correlations are not as high as those reported for approaches based on internet search queries. However, Lampos and Cristianini 75 reported correlations of up to r=0·933 for their analysis of infl uenza created with a supervised learning framework compared with infl uenza-like illnesses reported by the UK Health Protection Agency. They concluded that a supervised learning framework is a suitable method for selection of features for use in digital surveillance systems. Culotta 76 reported that the accuracy of estimates could be improved by use of a document classifi cation component; they reported correlations of up to r=0·97.

Google Flu Trends usually showed an increase of infl uenza incidence 0-2 weeks before traditional systems. Internet-based surveillance systems circumvent the bureaucratic structure of traditional systems. Furthermore, they target a diff erent section of the community to traditional surveillance systems. Zeng and Wagner's 77 model of patient behaviour during epidemics identifi es four phases in health-care seeking: recognition of symptoms, interpretation of symptoms, representation of illness, and seeking treatment. Traditional surveillance systems only source data from people seeking treatment. Internet-based surveillance systems access people from not just the fi nal phase, but also the earlier interpretation of symptoms and representation of illness phases. 48 However, internet-based surveillance systems are limited to people who seek health-related information on the internet (or proxies, such as parents or carers of sick children). Despite this limitation, they can capture many cases. Attrition during disease pathogenesis or healthseeking pathways is both high and cumulative-results of a study done in rural Cambodia showed that 67% of cases of haemorrhagic fever were treated at home, rather than in a health facility; thus, a health-care-based surveillance system would miss 67% of information before it even becomes accessible. 78 Systems that target points earlier in surveillance will produce more timely information. For an infl uenza epidemic with a 20% infection rate, 10% clinical attack rate, 2% case hospital admission rate, and 0·1% symptomatic case fatality rate, 79 the fraction of the population assessable by an internet-based surveillance system (7488 people per 100 000 patients) would be nearly ten-times that of a traditional system (750 people per 100 000 patients), for a population with the internet use of an average highincome country (76·8%; fi gure 2). 9 Internet-based surveillance systems work best for large populations 24 and their use can be limited by national infrastructure (fi gure 3). Although the fraction of people assessable with an internet-based system in the average low-income country (30·7% internet access) is only 2993 people per 100 000 patients (fi gure 2), this fraction still exceeds that of a traditional surveillance system (750 people per 100 000 patients). The number of people who have access to the internet is not the only relevant factor. Internet use and health-seeking behaviour vary between diff erent sectors of the community. 23, 80 The accuracy of national Google Flu Trends estimates is positively correlated with the proportion of the population who use the internet to obtain health-related information. 54 However, large discrepancies exist between availability and uptake of the internet, and seeking health-care information as a proxy for disease has biases stemming from unequal use and access. 20 The spatial resolution of Google Flu Trends (and Google Trends) is improving. At present, Google Flu Trends off ers some city-level estimates of infl uenza incidence in the USA but probably has neither the sensitivity nor spatial resolution necessary to detect small, localised outbreaks. 12 Spatial resolution is limited by the level of data aggregation and search volume; Review resolution should improve over time as overall internet access increases and the internet becomes more widely accepted as a source of health-based information. 54 Results of these systems should also be interpreted carefully. Although internet-based surveillance systems seem to have high correlation with traditional surveillance systems, overall correlations could hide short-term periods of high variance. 62 Translation of internet-based data into an accurate, meaningful, and useful format is a challenge. Bias introduced by self-reporting and media-driven interest might be the biggest confounder of internet-based surveillance systems. Targeting microblogs has the potential to track, not just disease activity, but also related community concerns and perceptions. 73 However, the frequency of posts on social media is generally accepted to be a function of personal experience and perception of what an individual believes the ir friends and followers would fi nd interesting, rather than a true refl ection of the occurrence of an event. 81 Similarly, the media drive search frequency. An increase in searches for ""bird fl u"" occurred in the USA between 2005 and 2006, despite no avian infl uenza being detected; this trend was attributed to media-driven interest about the infl uenza outbreak aff ecting Asia at the time. 24 A similar occurence was reported for dengue-related searches in India in 2006; an unusually large spike in searches was attributed to news that a member of the prime minister's family had been admitted to hosptial for dengue. 48 To reduce the eff ect of media-driven searches, the Google Dengue Trends model replaces spikes that exceed the mean of the previous 4 weeks by fi ve SDs with an imputed value. 48 Mediadriven behaviour does not exclusively aff ect internetbased surveillance systems. On April 26, 2009, the US CDC declared a national public-health emergency in response to the emerging H1N1 pandemic; the following week was termed fear week. 61 Despite state-wide viral surveillance data showing little infl uenza activity, emergency department patient volumes increased substantially. A similar trend occurred in a Baltimore paediatric emergency department. 58 Because changes in Google Flu Trends over this period correlated with the increase in emergency department patient volumes, the investigators suggested that Google Flu Trends could have a role in planning emergency department surge capacity; 58 rather than representing infl uenza incidence, Google Flu Trends identifi ed public perceptions of the threat of infl uenza and predicted the associated increase in health-care demand.

Unlike systems that rely on input from health-care practitioners or laboratories, internet-based surveillance instruments are unlikely to become overwhelmed during a pandemic and, because they are automated, are available year-round (contingent on suffi cient search volume), whereas traditional networks might only operate seasonally. 82 These internet-based systems could be of particular use in countries with poorly developed traditional surveillance systems. 52 However, implementation of such systems in these countries is fraught with diffi culties. Internet-based surveillance systems work on the premise that disease incidence correlates with frequency of information-seeking using specifi c terms. Textual information can be diffi cult to classify and interpret 83 and accuracy might be heavily aff ected by cultural nuances, language shifts, and use of colloquialisms or even memes. The model of Collier and coworkers 73 needed a fi lter to reduce the eff ect of terms such as ""Bieber fever"" (which refers to infatuation with Canadian pop musician Justin Bieber) on the keyword of interest, ""fever"". Changes to search behaviours and information-seeking practices will aff ect the performance of these models; 62 furthermore, such changes are unlikely to occur uniformly. The re-emergence of infectious diseases with similar clinical presentations-eg, chikungunya in dengue-endemic areas-also presents a diffi culty. 48 Models should be designed for a specifi c system (country or region) and be validated against reference data before they are used to guide health policy or action. As such, they cannot replace traditional surveillance. 42 The problem of privacy has been raised by several researchers. 2, 48, 83 For ethical reasons, data are de-identifi ed or-in the case of data from Google-aggregated before public release, precluding identifi cation of the source of specifi c posts or searches. Although not a problem in itself, this process could make interpretation diffi cult. Content cannot be connected with individuals and care should be taken not to commit an ecological fallacy-to make inferences about the characteristics of individuals based on aggregate data. 36 Finally, the security of health information is an imperative. 84 Google Flu Trends and Google Dengue Trends are operated by the philanthropic arm of Google, which is a publicly listed company. Although these services are freely available, Google does not release the search terms used in the algorithms; caution is urged in relying too heavily on closed-source data that are under the control of a multinational company.

Few studies have explored how to translate internetbased surveillance systems into a public health response. Search queries submitted to Vårdguiden have been used to develop an automated system for generation of reports about epidemiological trends. 85 GET WELL (Generating Epidemiological Trends from WEb Logs, Like) extracts search queries from Vårdguiden logs, aggregates the data (weekly), and produces time-series graphs. Additionally, the system enables custom statistical analyses to be integrated; this function is routinely used for norovirus and infl uenza. GET WELL is used by Swedish Institute for Infectious Disease Control in conjunction with traditional surveillance networks to identify emerging concerns and to focus epidemiological investigations.

The potential for internet-based surveillance systems to revolutionise emerging infectious disease surveillance was shown by Scarpino and colleagues. 68 They presented a method for optimisation of sentinel surveillance networks that enabled integration of Google Flu Trends into the network as a virtual provider (enabling it to function as a sentinal provider reporting infl uenza-like illness within the community). Google Flu Trends alone explained roughly 60% of infl uenza-associated hospital admissions in Texas; which is equivalent to the performance of an optimised sentinel network with 44 providers (R²=0·63). Furthermore, Google Flu Trends outperformed the 2008 Texas ILINet which drew information from 82 providers (R²=0·57). An optimised network of 82 providers outperformed Google Flu Trends (R²=0·77); however, the best predictive performance was achieved by optimised hybrid networks, which allowed use of Google Flu Trends as a virtual provider. Allowing Google Flu Trends as a virtual provider in a network of 82 providers increased predictive performance by a further 12·5% (R²=0·90). 68 These studies show potential applications of internet-based surveillance systems in bolstering traditional surveillance system capacity and guiding public health action. However, the routine integration of non-traditional, unstructured, internetbased data into existing surveillance systems will necessitate a change in the structure and rhetoric of units responsible for surveillance if it is to be eff ectively translated into public health action. 86

To date, most studies of internet-based surveillance systems are retrospective analyses of performance; the prospective performance of these systems needs to be assessed. Future studies should not only focus on development of new detection methods nor on application of these methods to new diseases, but they should also explore ways to integrate these approaches into existing systems. 55 In doing so, care must be taken to ensure that new systems add to the capacity of old ones. The potential application of internet-based surveillance systems is not restricted to surveillance. They can also be strategic instruments for resource management and allocation, 58, 59 which warrants further investigation. Finally, despite the potential of internet-based surveillance systems, they No data available <20% 20-40% 40-60% 60-80% >80%

have not been applied with a global focus. Strategies for surveillance of infectious diseases have been criticised for focusing too heavily on high-income countries. 87 New infectious diseases emerge all over the world and their emergence is aff ected by many sociocultural, economic, environmental, and ecological factors. 1 The international nature of emerging infectious diseases, combined with the globalisation of travel and trade, have increased the interconnectedness of all countries. Strategies to detect, monitor, and control emerging infectious diseases should recognise this change-these diseases are a global concern. The potential to develop global surveillance systems for emerging infectious diseases that use internet-based data should be explored.

Assessment of internet queries for surveillance of emerging infectious diseases is a new concept that has been applied with promising results. These systems are appealing from a logistical, economical, and epidemiological standpoint. Internet-based systems are intuitive, adaptable, operate in almost real-time and, once established, are cheap to operate and maintain. 12 Furthermore, these systems do not rely on the healthcare system to provide and analyse data, or a government to disseminate information and advise the international community of emerging concerns-all limitations of traditional surveillance systems. However, internet-based surveillance does not provide an alternative to traditional surveillance systems. Rather, these systems are an extension of traditional systems. The societal eff ect and extent of spread of infectious diseases within a community cannot be measured by any one surveillance system. 43 Surveillance systems should be fl exible, built with models that incorporate several means of collecting information, and integrate information from other sources to create a comprehensive understanding of and approach to addressing emerging problems. 86 Further more, addressing emerging infectious diseases is con tingent on their recognition as global, rather than regional, issues. A global response requires concerted international approaches to strengthen the capacity of emerging infectious diseases surveillance systems worldwide. Future research needs to focus on how to use internet-based surveillance systems to complement existing systems.

WH developed the original idea for this Review. The structure of the Review was developed by WH and GJM. GJM did the literature search, wrote the fi rst draft, and created tables and fi gures. WH produced the map. WH, ACAC, and GMW provided editorial advice on the report and the fi nal version was approved by all authors.

We declare that we have no confl icts of interest.

We searched Medline (via PubMed) and Web of Science with the following search terms: ""digital disease detection"" ""Google Flu Trends"", ""Google Insights"", ""Google Trends"", ""infodemiology"", ""infoveillance"", ""real-time disease surveillance"", and ""syndromic surveillance"". We also did searches with the terms ""dengue"", ""infectious"", OR ""infl uenza"" AND ""early warning"", ""Google"", ""internet"", ""search engine"", ""social media"", ""Twitter"", ""Facebook"", OR ""web"". Finally, we did searches for the terms ""internet"" OR ""web"" AND ""disease surveillance"" OR ""disease detection"". To be eligible for inclusion, studies needed to be peer reviewed, describe the use of internet-search metrics or social media data for surveillance of infl uenza or dengue, and assess performance of this surveillance approach by comparing it with data from traditional surveillance approaches. Results were restricted to those published in English between Jan 1, 2008, and June 30, 2013. The appendix shows the publications that fi t the inclusion criteria.

See Online for appendix

",0.7152008466329367
Validation of Syndromic Surveillance for Respiratory Infections,A key public health question is whether syndromic surveillance data provide early warning of infectious outbreaks. One cause for skepticism is that biological correlates of the administrative and clinical data used in these systems have not been rigorously assessed. This study measures the value of respiratory data currently used in syndromic surveillance systems to detect respiratory infections by comparing it against criterion standard viral testing within a pediatric population.,"In recent years, syndromic surveillance has shown promise for identifying naturally occurring epidemics. [1] [2] [3] [4] Nonetheless, uncertainty persists as to the meaningfulness of this methodology and the proportion of true biological events that it can detect. [5] [6] [7] [8] Importance

The source of data for many syndromic surveillance systems consists of information routinely collected by health care personnel during emergency department (ED) and office-based visits. 5, 9, 10 These types of data lend themselves well to use in surveillance because their acquisition requires minimal additional resources and they are frequently recorded electronically, enabling automated transmission and rapid availability. 3, 10 Studies of the validity of information collected by current surveillance systems have primarily used clinical and public health data for validation, even though these sources have not been shown to provide an acceptable standard. 11, 12 In addition, the greatest utility of surveillance systems would be their ability to detect and monitor infectious outbreaks, a capability that specifically requires further examination. To date, no study has assessed the ability of a syndromic surveillance system to detect and monitor infectious disease activity by measuring virologic disease within the surveyed population. 13 

To measure the value of current syndromic surveillance systems for monitoring infectious respiratory disease, we compared surveillance data on respiratory illnesses derived from an ED population to the results of viral tests from the same population.

We conducted a longitudinal study in the ED of an urban, tertiary care children's hospital. This study was conducted in 2 parts. In the first, retrospective data were used to determine whether variations in the frequency of positive viral cultures performed during routine clinical care correlated with variations in the frequency of cases meeting syndromic surveillance criteria for respiratory illness. All children aged 7 years or younger, who presented to the ED during an 11-year period between January 1, 1993, and July 9, 2004, and who had a presenting complaint related to a respiratory illness or who had viral testing performed as part of their routine clinical care were included in this analysis. In the second part, a prospective validation study was performed to validate the use of the clinically collected viral cultures in the retrospective analysis. We chose to perform this validation because the viral tests collected during routine care were not from a systematically selected population known to have an infectious respiratory illness. Subjects in the prospective study consisted of patients presenting to the ED with a respiratory illness between December 7, 2003, and June 19, 2004 , who met a specific definition for an infectious respiratory illness. Nasopharyngeal aspirates were collected from these patients and tested for respiratory viruses. By comparing the results of these tests to the historical time series, we were able to measure whether the historical time series was a representative sample of the viral distribution among children with infectious respiratory illnesses.

The protocol was approved by the hospital institutional review board. For all patients prospectively enrolled, we obtained written informed consent from a parent and assent from the child when age appropriate.

Patient visits for respiratory syndromes were identified based on presenting complaints, which are routinely elicited from all patients or parents on presentation to the ED and recorded by triage nurses. This free-text description is subsequently numerically encoded, using a constrained list of 181 possible codes. Seventeen of these describe respiratory problems and were used to define a group of patients as having a respiratory illness, using a previously validated classification. 12 Viral tests for respiratory syncytial virus (RSV), influenza A and B viruses, parainfluenza virus types 1 through 3, adenovirus, and enterovirus performed by the hospital during the study period were identified. These tests were ordered by physicians during routine clinical care for patients treated in the ED. We included tests that were ordered up to 7 hours before the ED visit and 24 hours after the ED visit to capture tests performed on patients during clinic visits before referral to the ED and on patients admitted to the hospital from the ED with a respiratory illness and tested after admission. Results for influenza A and B viruses were grouped, as were results for parainfluenza virus types 1 through 3. If a test was positive for more than 1 virus, all viruses identified were included in the analysis.

For the validation group, we screened patients aged 7 years and younger and presenting to the ED with a respiratory problem, such as difficulty breathing, cough, wheezing, and shortness of breath. Patients presenting with fever were also screened because this is frequently the complaint reported by parents of young children with respiratory illnesses. Patients were then further screened to determine whether they met our definition of an infectious respiratory illness and were recruited for the study if they did. We defined an infectious respiratory illness as the presence of at least 2 of the following symptoms: fever, cough, sneezing, sore throat, runny nose, or congestion. This criterion was chosen because we sought to determine the viral distribution among patients with respiratory infections and

What is already known on this topic Syndromic surveillance systems have the potential for providing early warning of infectious outbreaks by identifying unusual patterns of rapidly available data such as emergency department chief complaints or diagnoses.

The authors sought to determine whether chief complaint data suggestive of respiratory syndromes correlate with virologic test results on the same pediatric patient population.

What this study adds to our knowledge By demonstrating that variation in the frequency of respiratory-related chief complaints correlates with variation in positive viral tests, the study adds biological validity to the use of rapidly available chief complaint data for surveillance and detection purposes.

This study will not affect practice on individual patients but may hasten the development of accurate methods for the early detection of infectious epidemics.

wanted to examine the ability of the surveillance system to track these infectious respiratory illnesses.

A total of 81.6% of patients screened met enrollment criteria and participated in the study. The majority of patients who did not meet criteria had fever without other respiratory symptoms. Patients were recruited during a 6-month period from December 7, 2003, through June 19, 2004, for comparison with the patients who had routinely collected specimens during this time. Because of the large number of ED patients treated for respiratory illnesses during the winter, there was only a small overlap between the patients composing the validation group and those who were tested as part of their routine clinical care. The analysis was performed with these patients included and excluded from the study populations. Nasopharyngeal aspirates were obtained from all patients in the validation group and tested for RSV, influenza virus, parainfluenza virus, and adenovirus. A small number of specimens were not tested for all of the study viruses, because of insufficient volume and a brief shortage of cells for viral cultures in December. Rarely, an RSV test was read as indeterminate and was considered a negative test result in the analysis. 14 Routine clinical testing on patients included direct immunofluorescent antibody stains and viral culture. Direct immunofluorescent antibody assays used pooled antibodies for influenza virus, parainfluenza virus, RSV, and adenovirus (SimulFluor Respiratory Screen, Light Diagnostics, Chemicon International, Temecula, CA), or single virus-specific antibodies (Imagen Influenza Virus A and B, DakoCytomation, Carpinteria, CA; Bartels RSV DFA Kit, Trinity Biotech, Carlsbad, CA; ViraStat Parainfluenza Test, ZymeTx, Inc., Oklahoma City, OK; Adenovirus Antibody FITC Reagent, Light Diagnostics, Chemicon International). Viral cultures were performed using RMK, Hep-2, MRC-5, and Hel cells. Cultures with cytopathic effect or hemagglutination were stained with immunofluorescent antibodies for identification of influenza, parainfluenza virus, RSV, or adenovirus. Enterovirus was identified by viral passage and characteristic cytopathic effect.

Samples from the validation set were tested by culture with RMK cells for influenza virus, adenovirus, and parainfluenza virus and by direct immunofluorescent antibody for RSV. To increase the sensitivity for influenza virus, these specimens were also assayed by reverse transcriptase polymerase chain reaction. Ribonucleic acid was purified using the QIAamp Viral RNA Mini Kit (Qiagen, Valencia, CA) and amplified with the Access RT-PCR System (Promega, Madison, WI). Influenza A and B viruses were detected using previously published primers. 15 

Details of the data analysis are available in an online appendix (Appendix E1, available at http://www.annemergmed.com). 16 Three hundred sixty-one specimens were collected during the 6-month period of prospective recruitment. A total of 39.3% (142/361) of tests were positive for one of the viruses tested. The positivity rates for individual viruses were 21.1% (75/356) for RSV, 11.7% (41/351) for influenza virus, 7.2% (25/347) for parainfluenza virus, and 2.0% (7/347) for adenovirus. During the same period, 46.6% of the routine viral tests collected on patients presenting to the ED were positive, with 28.6% (165/576) positive for RSV, 16.2% (58/358) positive for influenza virus, 6.7% (38/570) positive for parainfluenza virus, and 8.6% (23/269) positive for adenovirus. There were 41 subjects who were recruited prospectively and subsequently also tested during routine clinical care.

A strong correlation was found between these 2 test groups, with a Pearson correlation coefficient of 0.914 (PϽ.0001) (Figure 1) . A linear regression model also revealed a powerful association ( 2 ϭ60.64; PϽ.0001). Similar results were found excluding patients who were in both groups (Pearson correlation coefficient of 0.889, PϽ.0001; linear regression model 2 ϭ24.31, PϽ.0001). This association strongly suggests that the results from viral tests obtained during routine clinical care are an appropriate representation of viral activity among children who are treated in the ED for infectious respiratory illnesses, supporting the use of the historical test results in the analysis.

Using the results from routine viral tests for the study period from 1993 to 2004, we measured the relationship between the prevalence of winter respiratory viruses and respiratory However, when all viruses were included as covariates, influenza virus became a significant predictor (adjusted RR 1.47; 95% CI 1.03 to 2.10). Stepwise removal of the variables revealed that the effect of influenza virus depended on inclusion of RSV in the model. Thus, the effect of influenza is dominated by RSV and can only be uncovered when accounting for the variability of RSV in the model. The model with all covariates explains 81.6% of the deviance in the frequency of presentations for respiratory syndromes. We also examined different combinations of viral tests into a single predictor. Combining test results for RSV and influenza produced the best-fitting effect (adjusted RR 1.51; 95% CI 1.10 to 2.07). Figure 3 demonstrates the correlation of respiratory syndrome frequencies with RSV and influenza.

The effect of RSV and influenza virus on respiratory illnesses is shown graphically for the respiratory virus season of 2003-04 in Figure 4 . As in the previous figures, the test results shown are for the routinely collected specimens among ED patients. The earlier peak in respiratory presentations observed in December corresponds to a peak in influenza virus activity while the second peak in February represents RSV activity.

There are some potential limitations to this study. The first is that tests were not performed to identify several respiratory viruses that may have contributed to the observed burden of respiratory illness, including rhinovirus, coronavirus, and human metapneumovirus. 19, 20 Although adding 1 or more of these viruses to our study might have changed the attributed variability, our findings of the influence of RSV and influenza virus are quite robust, and it is unlikely that their effect would be negated by the inclusion of the additional viruses in the model. Another potential concern is that biases in test ordering might make the routine viral test results unrepresentative of the patients who presented to the ED with respiratory syndromes. However, the results of prospective testing among ED patients with respiratory problems are closely correlated with the results obtained among the study population, strongly suggesting that the patients tested are in fact representative of the patients presenting with respiratory syndromes. Finally, our analytic methods may be limited by the presence of yearly seasonality in overall respiratory illness and viral prevalence. Although we have attempted to control for seasonal trends by including month as a categorical variable, it is difficult to know whether the correct adjustments were made for this effect.

The variability over time in rates of positive laboratory tests for common respiratory viruses is largely predictive of the fluctuation in patients presenting with respiratory problems, suggesting that the seasonal trends in respiratory illnesses observed by syndromic surveillance systems are a direct result of respiratory virus activity. RSV and influenza virus appear to have the greatest impact on trends of respiratory illnesses observed in the clinical setting. This is best demonstrated during the most recent respiratory virus season of 2003 to 2004, during which influenza activity began unusually early in October, peaked in late November to December, and then rapidly declined in January and February. 21 RSV followed a typical course with an increase in disease activity beginning in October and peaking in February before gradually declining. 22 Laboratory tests at our institution showed peak influenza and RSV activity in December and February, respectively, and presenting complaint-based respiratory syndrome surveillance demonstrated a bifid peak corresponding to this viral activity.

Many of the current syndromic surveillance systems rely on data collected as part of the routine clinical workflow. 5, 10 Examples of such data include symptoms recorded by telephone triage centers or nurse advice lines, patient complaints obtained on presentation to EDs, and diagnosis assigned by physicians at the end of ambulatory and emergency encounters. 3,10,23-26 The advantage of using these data is that they are readily available in a timely fashion, their collection does not require additional staff resources, and in many cases they are in electronic form. 9 Several attempts have been made to measure the accuracy of these data sources, but none measured the relationship with laboratory-proven viral infections in the same population.

The emergence of West Nile virus, SARS, and avian influenza virus, among other infections, has demonstrated the need for effective surveillance systems. Rapid and accurate disease detection and monitoring are required to reduce the potential morbidity associated with such an outbreak. Our study validates the correlation between viral illness and respiratory syndromic data in a pediatric ED population. The presenting complaints of patients treated by physicians in EDs and office-based practices are likely to reflect the disease activity of winter respiratory viruses and could be a useful early indicator of viral activity for public health purposes. The information may also benefit physicians by alerting them to unusual patterns in illnesses commonly seen in communities and guiding diagnostic and therapeutic decisions.

",0.713033306361739
Frontiers of transcutaneous vaccination systems: Novel technologies and devices for vaccine delivery,"Transcutaneous immunization (TCI) systems that use the skin's immune function are promising needlefree, easy-to-use, and low-invasive vaccination alternative to conventional, injectable vaccination methods. To develop effective TCI systems, it is essential to establish fundamental techniques and technologies that deliver antigenic proteins to antigen-presenting cells in the epidermis and dermis while overcoming the barrier function of the stratum corneum. In this review, we provide an outline of recent trends in the development of techniques for the delivery of antigenic proteins and of the technologies used to enhance TCI systems. We also introduce basic and clinical research involving our TCI systems that incorporate several original devices.","Infectious disease is the most common cause of death, accounting for approximately one-third of fatalities worldwide. Recent waves of transnational migration of people and materials enhanced by the development of transportation facilities, changes in social structure, and war have increased the global spread of emerging infections, such as severe acute respiratory syndrome and avian influenza virus [1, 2] . In addition, declining sanitation and the onset of drug-resistant pathogenic organisms have increased the spread of re-emerging infectious diseases, such as tuberculosis and malaria [3, 4] . Although major treatment for these infectious diseases is antibiotic administration, the only fundamental prophylaxis is vaccination for a biological preparation that improves immunity to a particular disease. Vaccine development, which has a long history, has progressed recently with the development of new approaches and technologies based on advances made in the fields of bacteriology, virology, and molecular biology.

Conventional vaccination is, however, performed mainly by injection, which has several inherent problems: pain, the need for trained personnel, associated needle-related diseases or injuries, and storage or transport issues. In some areas, vaccine coverage against infection is low due to failure in follow-up as well as a lack of trained medical personnel and facilities. The reuse of needles causes the death of at least 1.3 million people per year from hepatitis B and AIDS [5] . Thus, the development of needle-free, easy-to-use, and low-invasive vaccination methods is an urgent task. With its advantages that overcome the inherent problems of vaccination by injection, transcutaneous immunization (TCI) or intranasal immunization (INI) is now attracting attention as an alternative vaccination route.

INI, which is needle-free vaccination method, is highly expected as a hopeful vaccination procedure to stimulate both mucosal and systemic immune responses. The mucosal antigen (Ag)-specific immune response, however, is weak, thus it is necessary to develop a mucosal vaccine adjuvant to develop mucosal vaccines. The cholera toxin (CT) and heat-labile enterotoxin (LT) are potent mucosal adjuvants, but recent reports showed that a human vaccine containing inactivated influenza virus and LT as an adjuvant resulted in a very high incidence of Bell's palsy [6] . Therefore, mucosal vaccine adjuvants with high efficacy and safety for the purpose of a clinical application are necessary.

The skin has important immune functions as a proinflammatory organ [7] [8] [9] . The epidermis and dermis are highly populated by dendritic cells (DCs), which are potent Ag-presenting cells (APCs) with important immunostimulatory and migratory activities (Fig. 1) . Langerhans cells (LCs) in the epidermis and dermal DCs (dDCs) in the dermis are important for the induction of Ag-specific immune responses in the TCI system. Thus, if Ag can be efficiently delivered to LCs or dDCs resident in the epidermal layer or dermis, TCI might elicit an effective immune response. However, there is a difficulty to overcome for development of TCI system. The uppermost layer of the epidermis is the stratum corneum (SC), which consists of about 20 layers off lattened, enucleate, and keratin-filled corneocytes surrounded by lamellae of around eight lipid bilayers [10, 11] . The lipid bilayers consist Fig. 1 . Skin immune system. The skin is enriched with various immunocompetent cells such as LCs, keratinocytes, and several dDCs. Keratinocytes are mainly involved in the induction of innate immunity. LCs and dDCs capture external Ag, migrate into regional lymph nodes, present Ag to T cells, and activate Ag-specific T cells and B cells. Activated T cells and B cells migrate to each tissue and induce Ag-specific immune responses. primarily of cholesterol, free fatty acids, and ceramides. As the SC is the principal barrier to the penetration of substances, it is difficult to efficiently deliver adequate Ag to cutaneous APCs through the SC by just applying Ag onto bare skin. Therefore, in order to develop effective TCI systems, technologies must be established that promote Ag penetration through the SC.

In this review, we outline the mechanisms of the skin immune system and recent transcutaneous antigenic protein delivery techniques, technologies, and devices. Furthermore, we introduce the progress we have made in our research into the practical application of TCI in basic, preclinical, and clinical investigations.

The skin, the access site for TCI, acts not only as a physical barrier but also as an immunologic barrier and is enriched with various immunocompetent cells such as LCs, keratinocytes, and dDCs ( Fig. 1) .

In special, LCs and dDCs take important roles in induction of Agspecific immune responses. Under non-inflammatory conditions, LCs and dDCs are, for the most part, immature, meaning they have a strong endocytic capacity. When external Ag enter the skin, LCs and dDCs capture them and increase the expression of costimulatory factors, which play a role in the presentation of Ag to T cells, and CCR7 to permit the movement of APCs away from the skin and their subsequent entry into and localization within the draining lymph nodes [12] . After that, LCs and dDCs present Ag to CD4 and CD8 Tcells and activate Ag-specific T cells and B cells.

Keratinocytes also involved in induction of Ag-specific immune responses by activating the innate immune system. Keratinocytes could effectively convert exogenous stimuli into host homeostatic responses [7, 13] . In particular, they express numerous toll-like receptors on their surface or in endosomes [14] . Also, another type of receptor has been discovered on keratinocytes: nucleotide binding-domain oligomerization domain-like receptors [15, 16] . These receptors allow the keratinocytes to recognize bacterial components, namely, pattern-associated molecular patterns (PAMPs). In case external Ag do enter, keratinocytes produce cytokines and chemokines. TNF-␣ and IL-1␤ constitute the signals necessary for LCs or dDCs to migrate to a regional lymph node [17] . Like keratinocytes, LCs and dDCs express these receptors that contribute to the maintenance of an inflammatory environment [18, 19] . This inflammatory microenvironment, innate immunity, arises from the first contact with a vaccine component and contributes to different extents to the production of pro-inflammatory molecules that strongly contribute to the primary events of the adaptive immune response, that is, activation of skin-resident APCs. When vaccine Ag is administrated into skin, Ag-specific immune responses are induced by these mechanisms. Thus, the skin is clearly an attractive organ for Ag delivery to elicit immune responses.

Several types of professional APCs inhabit the healthy skin and the studies about function of skin-resident APCs involved in induction of skin immunity have been investigated (Fig. 2) . In mice, skin-resident APCs were classified into two categories; LCs in the epidermis and dDCs in the dermis. LCs and dDCs seemed to induce Th2-type and Th1-type immune responses, respectively [20, 21] . However, some studies suggested that LCs were not involved in induction of immune responses [22] . In a few years, also, reports suggesting the existence of several dDC subsets have been published in mice [23, 24] . It was generally assumed that the expression of langerin in the skin was strictly confined to LCs in the epidermis, but this view has been altered by current data indicating that a large population of langerin-positive cells corresponds to dDCs [25] [26] [27] . Classical langerin-negative dDCs express the macrophage Lipid-based vesicles Nano-bio interaction, flexible bilayer mixes with SC and disrupts it

Ags protected from external environment Disadvantage Low efficiency [84] [85] [86] [87] [88] markers CD11b, F4/80, and CX3CR1, whereas langerin-positive dDCs express CD103, CD8␣, and XCR1 without CD11b, F4/80, or CX3CR1 [28] . It was also reported that CD103-negative, CD11bnegative dDCs exist in the dermis [29] . Especially, CD103-positive dDCs but neither dermal CD103-negative dDCs nor LCs were shown to have a crucial role in the induction of Ag-specific CD8-positive T cells (Th1-type immune responses) [30] . Recent progress was made in identifying potential homologs of mouse dDC subsets by examining human dDCs. Human skin APCs also divided into two groups on the basis of localization, LCs in the epidermis and dDCs in the dermis. Epidermal LCs preferentially induced the differentiation of CD4-positive T cells secreting Th2 cell cytokines and were efficient at crosspriming naive CD8positive T cells [31] . Human dDCs can be distinguished into several subsets; CD1a/1c-positive dDC, CD14-positive dDCs, and CD1a/1cnegative, CD14-negative, CD141-positive dDCs by phenotype and function in the homeostatic and inflamed skin [31] [32] [33] [34] . Human CD1a/1c-positived dDCs and CD14-positive dDCs do not express langerin and can be classified based on their reciprocal expression of CD1a and CD14, which are thought to be equivalent to mouse CD11b-positive dDCs [32] . However, the relative contributions of these subsets to the generation of immunity or tolerance are still unclear [32, 33] . Yet, specialization of these different populations has become apparent. Human CD14-positive dDCs can promote antibody production by B cells [31] . In addition, CD1a/1cnegative, CD14-negative, CD141-positive DCs exhibit specialized cross-presenting function and express a number of markers associated with mouse CD103+ DCs [34] .

Although the immune mechanisms of the skin remain to be completely elucidated and further analyses were should be investigated, improved knowledge of the skin immune system could lead to the induction of optimal immune responses, such humoral immunity or cellular immunity, against infectious diseases.

As previously noted, the SC acts as a physical barrier against the penetration of substances into the skin. Various pharmaceutical approaches and devices have been developed to enable TCI systems to overcome the penetration barrier of the SC. In this section, the techniques, technologies, and devices used for the enhancement of TCI are reviewed (Table 1) .

Electroporation is a method to increase the permeability of the skin by applying single or multiple short-duration pulses. It has been widely used to loosen the cell surface, allowing the delivery of molecules into living cells. With high-voltage pulses (75-100 V) delivered against the skin surface, microchannels or local transport regions are created through lipid bilayer membranes including the SC [35] [36] [37] [38] [39] . Zhao et al. reported that TCI with the SL8 peptide derived from ovalbumin (OVA) and CpG oligodeoxy nucleotide as an adjuvant using electroporation could induce OVAspecific T cell responses equivalent to those induced by intradermal injection [37] , indicating that TCI using electroporation induced Ag-specific immune responses. However, this method requires power-supply equipment, thus they may be useful procedures in medical institutions but they cannot achieve an optimal ease of self-administration. In addition, disrupting SC as skin barriers may lead to secondary infection.

Iontophoresis is a method to enhance the transportation of ionic or charged molecules through a biological membrane by passing direct or periodic electric current through an electrolyte solution with an appropriate electrode polarity. This technique has been applied in the fields of transdermal drug delivery and has been shown by several groups to promote penetration of peptides or proteins such as insulin, calcitonin, or botulinum toxin through the SC [40, 41, 42] . The combination of electroporation and iontophoresis makes substance penetration even more effective [43] . From these reports, iontophoresis enhanced penetration of macro molecules through SC into skin, thus application of this method to TCI systems is expected. However, several problems about lack of convenience and risk of secondary infections remain because it requires powersupply equipment and may break cutaneous barrier.

Sonophoresis is a method to enhance substance penetration by disrupting the structure of the SC with low-frequency ultrasound. Cavitation is the formation of gaseous cavities in an ultrasoundcoupling medium upon exposure to ultrasound and involves the rapid growth and collapse of a bubble (transient cavitation) or slow oscillatory motion of a bubble (stable cavitation) in the ultrasound field. Oscillations and collapse of cavitation bubbles disorder the lipid bilayers of the SC, thereby enhancing transport [44] . Dahlan et al. have shown that TCI using low-frequency ultrasound with tetanus toxoid (TT) induced anti-TT IgG and neutralizing antibodies [45, 46] . Interestingly, Tezel et al. reported that ultrasound treatment induced LC activation and enhanced the Agspecific immune response, suggesting it acts as a physical adjuvant [47] .Although TCI using sonophoresis induced Ag-specific IgG antibody and have advantage of activating immunocompetent cells, this method require power-supply equipment and disrupt cutaneous barrier, thus they have several issues in terms of usefulness and safety.

Jet injectors are devices that use pressure to deliver substances into the skin [48] [49] [50] [51] . The first devices were multiple-use nozzle jet injectors, with which a large number of patient were vaccinated through the same fluid stream and nozzle [48, 49] . However, such devices are no longer used because of cross-contamination. Recent development efforts have resulted in disposable syringe jet injectors. Simon et al. reported a clinical study of the immunogenicity of trivalent inactivated influenza vaccine administrated by the Lec-traJet M3 ® RA disposable syringe jet injector, which was cleared for sale and use by the U.S. Food and Drug Administration in 2009 [52] . In jet injector systems, Ag-specific immune responses are induced and administration methods are simple, but ampoules are needed in the same way as in conventional injection systems, indicating the need of a cold-chain for transport and storage.

Patch formulations are one of the commonly used systems for TCI. Several groups have reported that TCI using gauze patches or adherent patches induced Ag-specific immune responses [53] [54] [55] [56] [57] . Application of a LT-containing single-ply polyester-rayon gauze patch onto human skin increased the anti-LT IgG titer in serum [53] . Although the other groups also have reported developing TCI systems for practical use and showed their safety and efficacy [54] [55] [56] [57] , these systems comprised a gauze patch as the TCI device. Because they require the gauze patch to be saturated with Ag solution just before application to the skin, such TCI systems are inconvenient and require cold storage and transportation of the Ag solution, as do conventional injectable vaccination systems. In addition, the disadvantage of patch-based TCI system is the requirement of skin preparation system (SPS) or cyanoacrylate skin surface stripping (CSSS) procedures to remove SC before patch application for improvement of Ag penetration into skin. These methods may carry a risk of increasing sensitivity to secondary infection by disrupting SC as a cutaneous barrier, which is a safety issue. Thus, the development of more easy-to-use and safer patch-based TCI system is desirable.

In our research group, we have developed a hydrogel patch as a TCI devise, which is made of safe materials that have already been applied to humans [58] [59] [60] [61] [62] and TCI formulation using a hydrogel patch was shown to induce effective immune responses to tetanus and diphtheria after application in absent of any treatment in animal models [59] . We also demonstrated its safety and efficacy by performing a clinical study of our TCI formulation for vaccination against tetanus and diphtheria in humans without disrupting SC [62] .

In our patch-based TCI system, we can prepare a TCI formulation by dropping Ag solution to a hydrogel patch and leaving out at room temperature for a while. The hydrogel patch formulation immersed with TexasRed (TR)-labeled OVA solution formed a concentrated Ag layer on its surface (Fig. 3A) , because only water in Ag solution absorbed by hydrogel polymer.

It is very important to deliver antigenic proteins to the skinresident APCs for induction of Ag-specific immune responses. Therefore, we analyzed biodistribution of Ag after transcutaneous administration by a hydrogel patch. There was marked penetration of the Ag into the epidermal layer of intact skin after 6-h application of a hydrogel patch containing TR-OVA to the auricle skin of mice (Fig. 3B) . In human and tissue-engineered skin models, a hydrogel patch also promoted the penetration of antigenic proteins through the SC [60] . Although theories of conventional transdermal drug delivery suggest that skin structure and composition do not allow for the penetration of materials larger than 500 Da [10, 11] , our transcutaneous vaccination system delivered antigenic proteins (45-150 kDa) into the epidermal layer [58, 59] . We proposed the following mechanisms for penetration of Ag into the skin. First, the concentrated antigenic proteins on the surface of the patch might generate a high concentration gradient of antigenic proteins in the skin, which is critical for producing the driving force needed to accelerate passive diffusion and distribution. This theory is supported by our observation that the distribution of TR-OVA in the epidermal layer was not simply a result of spreading the TR-OVA solution on the intact skin surface, and that the application of the filter paper immersed in Ag solution did not enhance either Ag penetration or antibody titer [58] . Second, humectation and hydration of the skin to which the hydrogel patch is applied might loosen intercellular gaps in the SC, which contributes to improve the penetration of water-soluble substances. According to our observations, Ag penetration via our patch system occurred mainly through the intercellular gaps of the SC. In fact, there are several reports that an increased water content in the SC leads to increased membrane fluidity and decreased electrical resistance [63, 64] . Although it is possible that antigenic proteins penetrate into the epidermal layer through hair follicles -there are some reports that hair follicles allow for even nanoparticles to reach the epidermal layer in skin [65] [66] [67] -our hydrogel patch enhanced Ag penetration on a tissueengineered skin without pores [60] , suggesting that this pathway contributes little to the penetration of Ag into the skin promoted by a hydrogel patch. Through a combination of these mechanisms, our patch vaccine system promoted the penetration of water-soluble macromolecular proteins into the SC.

As shown in Fig. 3C and D, yellow fluorescent spots, indicating that TR-OVA localization accorded with LC localization, were observed in merged images of an epidermal sheet and lymph node sections prepared from mice with intact skin, suggesting that LCs, which are cells critical for the induction of potent immune responses, captured antigenic proteins penetrated into the skin and migrated into the regional lymph node. Thus, Ag-capturing LCs, which migrated from the epidermal layer to regional lymph nodes, would greatly contribute to triggering and amplifying Ag-specific immune responses induced by transcutaneous vaccination using the hydrogel patch formulation.

In an animal model of tetanus and diphtheria infection, the vaccination efficacy of TCI using a hydrogel patch was evaluated. TCI using a hydrogel patch elicited toxoid-specific immune responses and the serum titer of antibody in the TCI groups were equivalent to or greater than those of the subcutaneous immunization (SCI) group ( Fig. 3E and F) . In rats vaccinated with combined TT and DT, both TT and DT-specific IgG antibodies were detected in serum as efficiently as that in rats vaccinated with each toxoid alone, suggesting that our TCI using a hydrogel patch is applicable to a combination vaccine. As mixed inoculationis now recommended in vaccination, our TCI formulation is suitable for practical use. We also demonstrated that TCI using a hydrogel patch containing TT and DT induced little adverse reactions in local and systemic toxicity assessments [61] , indicating that hydrogel patch-based TCI formulation is a non-invasive vaccination method. In addition, on the basis of IgG subclass analysis, it was suggested that our TCI using the hydrogel patch formulation predominantly elicited a Th2-type immune response rather than a Th1-type immune response [58, 59] . Further analyses are necessary to elucidate the Th2-dominant mechanism in our patch vaccination.

In our hydrogel patch-based TCI system, we can simply prepare a manageable TCI formulation like general fomentations with a concentrated Ag layer on the surface of the hydrogel patch. Our TCI system using a hydrogel patch enhanced Ag penetration into the skin and induced Ag-specific immune responses by single application onto skin surface without disrupting SC. This is superior to other patch-based TCI formulation in terms of avoiding secondary infections by breaking skin barriers.

Patch formulations, such as the hydrogel patch, are less effective at promoting penetration of particulates and insoluble Ags through the SC. Most practical vaccine Ags are in a particulate state, for example, the less virulent strains of bacteria. The development of a different TCI system that is effective for use with all Ag forms is needed. A microneedle array contains many micrometer-sized needles that can create a transport pathway large enough for proteins and nanoparticles, but small enough to avoid pain [68] [69] [70] [71] [72] [73] [74] . Microneedle arrays can penetrate the SC barrier and deliver Ag to immunocompetent cells in the skin more efficiently than other TCI systems. In addition, the use of a disposable array is suitable for selfadministration. Thus, microneedles are the most attractive devices for the development of effective TCI systems. Microneedles were first conceptualized for drug delivery in a 1976 patent [75] . Since then, several type of microneedles have been developed and they are classified into four types with respect to mechanism of action: (1) solid microneedles for pretreatment of the skin to increase permeability, (2) microneedles coated with drug that dissolves in the skin, (3) polymer microneedles encapsulating the drug that fully dissolves in the skin, and (4) hollow microneedles for infusing the drug into the skin.

Traditional microneedle arrays made from silicon, metal, stainless steel, or titanium were reported in the early stages of development, but the clinical use of microneedle arrays has faced serious obstacles because needles on microneedle arrays can fracture and remain in the skin, creating a safety issue. These conventional microneedle arrays suffer from the risk of fracture of microneedle fragments in the skin, therefore, in 2004, microneedle systems made with biocompatible or biodegradable polymers began to be developed [69] , and their superior safety has led to early clinical use. This system, however, remains the risk of breaking cutaneous barrier by insertion of microneedles into skin. In manufacture of dissolving microneedles, the technical innovation is required to allow Ag to be incorporated into the matrix of microneedle material using mild procedures that do not cause the decrease of antigenicity or compromise material strength.

Our research group has developed a dissolving microneedle array (MicroHyala ® ; MH) as a TCI device, which was fabricated using micromolding technologies with biocompatible sodium hyaluronate as the base material and this approach demonstrated effective vaccination effects comparable to those of conventional injection systems [76] [77] [78] .

We have developed a dissolving microneedle array, MH as mentioned above, made of sodium hyaluronate as the base material (Fig. 4A) . We successfully fabricated several types of MH in various forms and lengths: konide-shaped MH (needle length 200 or 300 m) and cone-shaped MH (needle length 300, 500, or 800 m) 4 g) , or intranasal application of HA (0.4 g) combined with CT (10 g) as an adjuvant twice at 4-week intervals. Two weeks after last vaccination, these mice were each infected intranasally with 6 × 10 5 PFU of the A/PR/8/34(H1N1) virus. (A) At the indicated points, sera collected from the mice were assayed for the titer of HA-specific IgG by ELISA. (B) Body weight was measured each day after infection and is presented as a percentage of the original weight before infection (day 0). (C) Six days after infection, the lungs were collected from the mice and the number of viruses in the lung homogenate was determined with a plaque assay system. Data are expressed as mean ± SE of results from (A) 13 or (B and C) 10 mice. Arrowheads indicate vaccination points. (Fig. 4A) . The microneedles on the MH were dissolved by water in the skin and thus had no danger of remaining in the skin, making our MH safer than traditional microneedle arrays made of metal or stainless steel. In fact, the microneedle tips were fully dissolved at 1 h (Fig. 4B) . Application of each MH caused only temporary skin irritation and the skin barrier function after insertion recovered immediately [76] , suggesting that the holes caused by insertion of each MH closed up quickly. These results suggest low probability of causing secondary infection by application of MH. In observation of skin sections after application of each MH containing fluorescein isothiocyanate (FITC)-silica particles, they were clearly detected (Fig. 4C) , suggesting that the MH delivered particulate Ag into the epidermis or dermis without regard for the Ag form. In addition, the MH size can be used to control the depth of Ag delivery, meaning that each MH might deliver Ag to specific skin-resident APCs, LCs in the epidermis or several dDCs in the dermis.

We examined the efficacy of vaccination with influenza hemagglutinin (HA) Ag, which is particulate Ag. In an influenza virus challenge, TCI with HA alone elicited production of HA-specific functional IgG antibody equivalent to that after intramuscular immunization (IMI) with HA alone or INI with combined HA and CT as an adjuvant (Fig. 5A) . On the other hand, little anti-HA IgA antibody was detected in the TCI and IMI groups [77] . After challenge with A/PR/8/34 influenza virus, mice in the TCI group showed no remarkable weight loss, similar to those in the IMI group and INI with CT group (Fig. 5B ). In addition, the virus titer in the lungs of the TCI group was below the detection limit (Fig. 5C) , demonstrating that our TCI system provided protection equal to that of IMI or INI with adjuvant. In INI system, mucosal vaccine adjuvants with high efficacy and safety for the purpose of a clinical application are necessary. As compared to INI system, our TCI could efficiently elicit Ag-specific vaccine effect without an adjuvant, which is an advantage of our TCI system.

In addition, the vaccination efficacy of TCI using MH was also demonstrated in tetanus, diphtheria, and malaria infection models. On the basis of these results, TCI system using MH suggested to induce Ag-specific immune responses against any vaccine Ags, such as soluble Ags, insolubleAgs, or particulate Ags, which conventional TCI system fail to do so. Thus, we can conclude that our TCI system using MH which is dissolved in the skin effectively confers protective immunity without causing serious adverse reactions in an animal model.

Conventional microneedle array made of metal or stainless steel has difficulties in clinical application because needles on microneedle arrays can fracture and remain in the skin, which is serious problem. However, the microneedles on the MH were dissolved by water in the skin and thus had no danger of remaining in the skin, indicating that TCI using MH would be attractive vaccination method in terms of both safety and efficacy.

Recent studies suggested that nanoparticles are attractive means for transcutaneous Ag delivery. By disrupting the SC as a result of the nano-bio interaction with skin lipids, antigenic proteins encapsulated in the nanoparticles can be delivered through the SC into the skin. Some researchers reported that nanoparticle vaccine compounds can penetrate via the hair follicles where there is a high density of APCs and enhanced immune responses. There are numerous nanoparticle systems available, including polymeric poly (d-l-lactic-co-glycolic acid) and poly (lactic acid) nanoparticles, biodegradable chitosan nanoparticles, and metal nanoparticles [65, [79] [80] [81] [82] [83] .

In addition, lipid-based vesicles such as liposomes, transfersomes, or niosomes have structures similar to those of biological membranes and facilitate skin penetration [84] [85] [86] [87] [88] . When mixed with SC lipids, flexible liposomes (FLs) can carry a remarkable amount of lipid mass into the skin and can, therefore, be advantageous in promoting cutaneous drug disposition after disrupting the skin barrier with their flexible bilayers [88] . It also has been reported that FLs stimulated a transcutaneous immune response by acting as an adjuvant [89] .

The design of novel formulations especially nanoscale systems, such as nanoparticles and lipid-based vesicles, can be helpful for protecting the Ag from external environment and keeping the long term activity. These properties are conductive to the application of transcutaneous vaccine. However, the development of novel nanoscale systems for TCI is limited by the low efficiency in eliciting robust immune responses.

For the diffusion of the vaccine worldwide including in developing countries, patch formulations and microneedles are more suitable because of their ease of use and efficacy. Several research groups have conducted clinical studies of TCI using patch formulations or microneedle systems in recent years ( Table 2 ). Glenn et al. first reported the results of TCI using a patch in humans [55] . Application of a patch containing LT as Ag resulted in robust LT-specific antibody responses. In addition, their group used LT to investigate patch vaccination against traveler's diarrhea in a phase II clinical trial and found that the 59 LT-patch recipients were protected against moderate-to-severe diarrhea (protective efficacy [PE] 75%) and severe diarrhea (PE 84%) [53] . LT-patch recipients who became ill had shorter episodes of diarrhea (0.5 vs 2.1 days) with fewer loose stools (3.7 vs 10.5) than recipients of placebo [55] . Since then, numerous studies of devices that serve as simple, easy-to-use, and low-invasive TCI systems have been undertaken. Etchart et al. showed that TCI of human adult volunteers with live-attenuated measles induced Ag-specific immune responses in their phase I/II clinical study [54] . Combadiere et al. demonstrated that TCI with an inactivated influenza vaccine induced a significant increase in influenza vaccine-specific CD8 responses compared with those obtained from the intramuscular route [90] . However, these TCI systems require cyanoacrylate skin surface stripping for Ag delivery into skin, which might cause skin irritation as one of the side effects.

Microneedle-based TCI systems have also been applied in clinical trials. Van Dammeet al. reported the results of a clinical study of influenza vaccination in which a hollow microneedle device (MicronJet) was used [91] . Local adverse reactions were significantly more frequent than those with intramuscular vaccination, but were mild and transient in nature. After TCI, immunogenic responses increased in humans. In addition, the safety and efficacy of several microneedle devices have been assessed in applications other than vaccination [92, 93] . In the future, more clinical studies will be conducted for needle-free, easy-to-use, low-invasive, and low-cost vaccination methods.

We performed a clinical study of our original hydrogel patch formulation containing combined TT and DT in humans ( Fig. 6A and B ) [62] . In the safety assessment to evaluate local adverse responses at 0 h and 24 h after patch removal, a TCI formulation containing TT and DT was shown not to induce local severe adverse events (Fig. 6C ). As shown in Fig. 6D , anti-TT IgG and anti-DT IgG increased (paired-t test; p < 0.01) following the first vaccination using the TCI formulation, indicating that a single application of our TCI formulation could induce an immune response in humans. We also administered a second vaccination to five subjects in whom neither antibody titer was significantly increased by the first vaccination. The IgG titers increased in a part of subjects following the second vaccination, suggesting that an additional application increases the efficacy of the TCI formulation. Antibody titers on day 365 after application of the TCI formulation were maintained at a higher level than those on day 0 in all subjects examined, although antibody titers tended to be lower on day 365 than on day 60 [62] . Conventional patch-based TCI systems require the pre-treatment of disrupting or removing SC, but our hydrogel patch achieved Ag penetration into skin without removing the SC and Ag-specific antibodies were produced in some subjects by a single application in humans, which represents a safety and efficacy advantage.

We also conducted a clinical evaluation of TCI using MH (Fig. 7) . Ag-free konide-shaped MH300, cone-shaped MH500, and coneshaped MH800 as TCI devices were applied on left brachial lateral skin (Fig. 7A ) and they caused no serious local or systemic adverse reactions (in preparation). To evaluate the efficacy of vaccination (Fig. 7B) , we used trivalent influenza HA Ags. HA-containing coneshaped MH800 induced HA-specific IgG responses against three HA Ags without severe adverse events (in preparation), indicating that our MH-based TCI system was safe and efficacious in humans.

These simple, easy-to-use, low-invasive, and effective TCI formulations might be applicable for mass treatment in the event of an outbreak and for increasing vaccination rates in developing countries. We expect that our TCI system as an innovative vaccination method will be put to practical use at an early date and greatly will contribute to decrease the mortality and morbidity by infectious diseases.

The development of vaccines, which represent the only basic prophylaxis against infectious diseases, is drawing attention worldwide. The main objective of vaccine development is the establishment of manufacturing technologies that supply safe and effective vaccine Ag rapidly and stably, but the problem of how to carry out enough vaccinations to prevent infectious diseases remains to be solved. In order to distribute the vaccine across the world to people who need it, especially those in developing countries, easy-to-use, low-cost, and low-invasive vaccination methods instead of conventional injection systems are required. TCI offers an attractive avenue for the development of needlefree prophylaxis. The main challenge to be addressed during the development of TCI systems is to ensure accurate delivery of Ag to the epidermis and dermis through the SC. As we introduced in this review, various approaches to overcome the SC barrier have been developed and basic, preclinical, or clinical studies of these approaches have been conducted.

Recent studies have demonstrated that intradermal vaccine delivery to skin-resident APCs can increase the magnitude of the immune response rather than IMI. For example, some studies evaluating intradermal delivery of influenza vaccine have suggested that dose sparing relative to IMI can be achieved [94, 95] . Nowadays, INTANZA ® /IDFlu ® is marketed as a new trivalent inactivated influenza vaccine administered by the intradermal route. Thus, TCI systems targeting the skin immune system are attractive vaccination methods that can supplant conventional IMI or SCI in terms of not only ease and safety but also efficacy.

Practical use of these easy-to-use, low-cost, low-invasive, and effective transcutaneous vaccination methods in the near future would contribute to a global countermeasure against infectious disease and would greatly benefit countries with poor vaccination rates.

Exploratory Research (23659079) from the Ministry of Education, Culture, Sports, Science, and Technology of Japan, a Grant-in-Aid from The Mochida Memorial Foundation for Medical and Pharmaceutical Research, and a Grant-in-Aid from the Tokyo Biochemical Research Foundation.

Conflict of interest: There is no conflict of interest.

",0.7120131649507675
Assessing the efficacy of tabs on filtering facepiece respirator straps to increase proper doffing techniques while reducing contact transmission of pathogens HHS Public Access,"NIOSH-certified N95 filtering facepiece respirators (FFRs) are used in healthcare settings as a control measure to mitigate exposures to airborne infectious particles. When the outer surface of an FFR becomes contaminated, it presents a contact transmission risk to the wearer. The Centers for Disease Control and Prevention (CDC) guidance recommends that healthcare workers (HCWs) doff FFRs by grasping the straps at the back of the head to avoid contact with the potentially contaminated surface. Adherence to proper doffing technique is reportedly low due to numerous factors including difficulty in locating and grasping the straps. This study compares the impact of tabs placed on FFR straps to controls (without tabs) on proper doffing, ease of use and comfort, and reduction of transfer of contamination to the wearer. Utilizing a fluorescent agent as a tracer to track contamination from FFRs to hand and head areas of 20 human subjects demonstrated that there was no difference in tabbed FFR straps and controls with respect to promoting proper doffing (p = 0.48), but did make doffing easier (p = 0.04) as indicated by 7 of 8 subjects that used the tabs. Seven of the 20 subjects felt that FFRs with tabs were easier to remove, while only 2 of 20 indicated that FFRs without tabs were easier to remove. Discomfort was not a factor for either FFR strap type. When removing an FFR with contaminated hands, the use of the tabs significantly reduced the amount of tracer transfer compared to straps without tabs (p = 0.012). FFRs with tabs on the straps are associated with ease of doffing and significantly less transfer of the fluorescent tracer.","The response to the Ebola outbreak has played a significant role in emphasizing the importance of personal protective equipment (PPE) in the hierarchy of safety measures to protect health care workers (HCWs) from pathogens encountered while administering patient care. [1] The outbreak of Ebola and subsequent infection of HCWs has heightened awareness regarding procedural gaps with the proper use of PPE. The types of PPE used in healthcare including, gowns and aprons, protective facemasks and respirators, goggles and face shields, and gloves provide a barrier between the HCW and potentially infectious materials. The benefits and shortcomings of PPE use in healthcare are not a new topic and have received substantial consideration for other pathogens encountered in healthcare, such as influenza, severe acute respiratory syndrome (SARS), human immunodeficiency virus (HIV), and tuberculosis (TB). [2] [3] [4] [5] PPE is the last category in the hierarchy of safety controls which includes training and administrative controls, engineering controls, and work practice controls, and often represents the last line of physical protection for HCW. Despite its importance, proper PPE use and respiratory protection compliance in healthcare is lacking. [6, 7] PPE can be difficult to select and use, uncomfortable to wear, and requires adherence to proper donning and doffing procedures. [8] These issues can lead to improper donning and doffing of PPE, which could increase the potential for PPE fomite transmission of pathogens to the wearer.

One of the reasons PPE is difficult to use is the lack of familiarity that HCWs may have with specific protective garments and ensembles. The recommendations for the specific types of PPE required to protect HCWs are based on a multitude of factors, such as the type of patient contact anticipated, the mode of transmission of the pathogen, the virulence of the pathogen, and PPE durability. [9] PPE recommendations can vary depending on the level of precautions being used. According to the Centers for Disease Control and Prevention (CDC) 2007 Guidelines for isolation precautions, transmission-based precautions are used in addition to standard precautions when standard precautions do not completely interrupt the route(s) of transmission. [9] Transmission based precautions are employed for specific pathogens which may be encountered on an intermittent basis, and may leave little opportunity for HCWs to gain experience with the specific protective devices recommended for the specific pathogen based on route(s) of transmission. PPE that is more intuitive to use could help HCWs traverse the PPE learning curve when emergency situations call for heightened precautions.

One type of PPE that is used on an intermittent basis by HCWs is a National Institute for Occupational Safety and Health (NIOSH)-certified N95 filtering facepiece respirator (FFR). The CDC has recommended the use of N95 FFRs as part of isolation precautions for pathogens transmitted via the airborne route, such as TB, and during certain medical procedures for some epidemiologically important organisms such as Ebola. [10, 11] FFRs reduce the wearer's inhalation exposure to infectious particles and restrict the user from touching his/her mouth and nose, which limits opportunities to transfer pathogens from the hands to the mucosa of the wearer. Studies in various workplaces have demonstrated that fittested FFRs, when used in a complete respiratory protection program, are effective at reducing inhalation exposures. [12] [13] [14] Like many other interventions (e.g., hand washing, vaccination, etc.), the effectiveness of FFRs is ultimately governed by compliance and proper use, including adherence to proper donning and doffing procedures.

Proper doffing technique is essential to minimize the transfer of infectious materials from PPE to the wearer; however, contact transmission could occur despite following proper use. [15, 16] The outer surface of the FFR can become contaminated and serve as a source of pathogens in the contact transmission chain. As detailed in the CDC recommended PPE doffing sequence poster (Figure 1 ), protective facemasks are the final piece of PPE to be removed and should be removed by grasping the tethering straps at the back of the head. Doffing the FFR by grasping the straps posteriorly allows the wearer to avoid making contact with the potentially contaminated filtering surface of the FFR. Unfortunately, adherence to proper FFR doffing technique is lacking. [17] [18] [19] Additionally, a HCWs hands can become contaminated while properly removing other types of PPE such as goggles, facemasks, and gowns. As FFRs and facemasks are the final devices to be removed as outlined in the recommended sequence of PPE doffing, it is possible that contamination can be spread to the head and neck area of the wearer even if the protective facemask is removed using proper technique.

Many potential barriers to proper use of PPE have been identified including deficiency of knowledge, lack of accountability for noncompliance and time constraints. [20] The current design of FFRs is often cited as one of the primary causes of discomfort and unwillingness to properly use and doff the respirator. [21] The FFR straps at the back of the head can become embedded within the wearer's hair which makes them difficult to find and grasp. Modifications to current FFR strap design might promote proper doffing by making the straps more accessible and easier to grasp.

In this study we aimed to assess the utility of the tabs that are attached to the straps of FFRs in decreasing potential contamination transfer and discomfort during doffing. The purpose of the tabs is to provide an easily accessible ""handle"" to allow the HCW to remove the FFR without touching its contaminated surfaces, while also minimizing uncomfortable and potentially hazardous contact of the fingers with the hair. Additionally, the tabs could serve as a visual and tactile reminder to use proper FFR doffing technique (i.e., remove the FFR using only the straps).

The study was approved by the National Institute for Occupational Safety and Health (NIOSH)human subjects review board, and all subjects provided oral and written informed consent. A total of 20 subjects between the ages of 18-60 were recruited for this study. Participants currently employed as a HCW, enrolled in a respiratory protection program, and experienced in wearing an FFR were preferred. However, a potential subject was not excluded if all of these qualities were not met. Participants with a history of skin cancer, sensitivity to Ultra Violet (UV) light, or burns from a black light were excluded from the study.

The Model 1860 N95 respirator (3M, St. Paul, MN) used for this study is a NIOSHapproved N95 FFR commonly used by HCWs and is FDA cleared for use as a surgical respirator. Some of the 3 M 1860 FFRs used in this research study were modified by placing 4 red foam tabs on the straps ( Figure 2 ). It is important to note that modifying FFRs in such a manner in the workplace may result in the device being in an unapproved configuration. The use of modified devices should be limited to research and development efforts and not used in devices intended for protection in actual workplaces. The tabs were cut into a ""bow tie"" shape and folded around the strap to form a trapezoidal shape with a one sided surface area of approximately 11 cm 2 . The design of the tabs was influenced by a brief search of the literature concerning the effectiveness of warning labels. Based on these studies, we determined that both the color red and triangular shape (truncated to a trapezoidal shape for durability) were two characteristics of warning labels that were readily recognized and recalled. [22] [23] [24] [25] The tabs measured 3.81 cm (1.5′) in length; preliminary trials assessing the comfort of grasping the tabs found that area of the tabs was sufficient to accommodate the volar surface of the index and middle finger on one side of the tab and the volar surface of the thumb on the opposite side. [26, 27] 

Simulation of contamination transfer was visualized through the use of a non-toxic, UV-light reactive fluorescent tracer. The fluorescent tracer was prepared by suspending 1 g of GloGerm (Glo Germ Company; Moab, UT) powder suspended in 25 mL of mineral oil. To contaminate the FFRs, 7 mL of fluorescent tracer was brushed onto the entire outer surface of the test FFRs. For each subject, six FFRs were contaminated with the fluorescent tracer; three with tabs and three without tabs. As only the outer surface of the FFR was contaminated with the fluorescent tracer, transfer from the FFR to the hands would only occur if the FFR was doffed improperly by grasping the contaminated surface. For the final test conducted by each subject, 1 mL of fluorescent tracer was also applied and rubbed into the hands of the test subject before removal of a clean FFR with or without tabs.

Doffing contaminated FFRs (transfer from FFRs to hands)-To test the utility of the tabs to serve as a reminder to properly doff the FFR and thus limit contamination transfer, a total of six FFR doffings were performed by each subject. Three FFRs with tabs and three FFRs without tabs were tested in random order. Each subject was monitored for the duration of each donning and doffing procedure and all observations were recorded in a laboratory notebook. Each doffing was recorded as either proper or improper. A proper rating was given if the subject utilized either the straps at the back of the head or the tabs connected to the straps of the FFR. An improper rating was recorded if the subject grasped the front surface of the FFR or grasped the straps near the location where the straps attach to the FFR (near the cheek).

The subject received a brief training and education session on proper donning and doffing techniques prior to the start of the test as per the CDC's donning and doffing recommendation posters (Figure 1 ). The subjects were not given specific instructions regarding the use of the tabs. The subjects then washed their hands following the World Health Organization (WHO) hand washing protocol [28] and put on a clean pair of nitrile gloves. The subject was instructed to don the first FFR following CDC recommended donning procedures; assistance was provided only if improper technique was used. The subject discarded the gloves using proper technique to minimize contamination transfer to their hands. The subject's hands were then checked for fluorescent contamination under UVA light. The subject was instructed to wash hands again if any contamination was present. After donning the FFR, the subject completed a computer based simulation of an interaction with an influenza patient. The purpose of the simulation was to remind the subject that he or she was a HCW wearing an FFR in the presence of an infected patient and to provide a distraction so that the subject was not focusing on proper donning and doffing technique. The subject was then instructed to doff the FFR and discard it in a labeled bin. Both the hands and hair were then photographed under UVA light. This procedure was repeated for each of the remaining FFRs.

Proper doffing with contaminated hands (transfer from hands to head)-To assess the ability of the tabs to limit contamination transfer from hands to the head and hair of the wearer while using proper doffing technique, each subject doffed one randomly assigned FFR with or without tabs. Only one FFR type was used for each subject, as it was not practical to have the subject wash their hair and face between trials. Following the WHO protocol, subjects washed hands and then donned the final FFR. 1 mL of fluorescent tracer was aliquoted onto the subject's palms and the subject rubbed hands together for 30 s to disperse the tracer evenly. The subject was then instructed to properly doff the FFR and to place it in a labeled bin. Photographs were taken under UVA light and the length of the subject's hair was measured from the back of the head to determine the effect of hair length on FFR comfort and ease of use.

Post-test subject survey (ease of use and comfort)-Each subject was asked to answer a brief, three-question survey regarding comfort and ease of donning and doffing of FFRs with tabs compared to FFRs without tabs.

Fluorescent contamination transfer to the hands or head area of test subjects was captured under UVA lighting (Utilitech Fluorescent Light Fixture TL 8W 05UV Hughesville, PA) with a Nikon D3000 digital still camera (Nikon Corp., Japan). The camera was maintained at a fixed distance of approximately 33 cm from the target surface (hands or head area). The camera shutter speed was fixed at 1/8 s. Photographs were saved to a Secure Digital (SD) memory card on the camera and imported into a desktop computer.

The photographs were analyzed using Adobe Photoshop CS4 version 11 (Adobe Systems Incorporated, San Jose, CA) by quantitatively measuring the intensity/brightness (lumens: brightness or intensity of a light source in a picture) and the surface area of each region of fluorescent contamination. Each image was analyzed in triplicate by using the Lasso tool (in Photoshop) to measure and generate histogram values corresponding to each zone of visual contamination.

Characteristics of FFR compliance were analyzed using McNemar's test to assess the differences in correlation between properly doffing and improperly doffing FFRs with both strap types. Average luminosity values of fluorescent contamination were compared using a two-tailed t-test to test the prediction that there is less contamination transfer present when using tabs on FFR straps. Questionnaire data concerning comfort and ease of use were analyzed using a Fisher's exact test. A statistical significance was accepted when p < 0.05. The tests were conducted using SPSS software (IBM Corporation, Armonk, New York).

A total of 20 subjects participated in this study and completed the tests: 5 male and 15 female. Seventeen of the 20 subjects had been formally fit tested for N95 FFR use within a year of testing. Only 6 of the subjects responded that they had used an N95 FFR as part of their duties as a HCW.

For the 60 trials involving contaminated FFRs with tabs (examining the transfer from FFRs to hands), 83% of doffings were conducted properly, while 17% were completed using improper technique. Of these 50 occurrences of proper doffing, 25 were performed using the straps even though tabs were present, 21 were conducted using the tabs, and 4 were observed to use a combination of tabs and straps. For the 10 occurrences of improper doffing, 9 were performed by grasping the filtering surface of the FFR, while 1 was conducted by grasping the straps near the location where the straps attach to the FFR. For the 60 trials involving contaminated FFRs without tabs, 87% of doffings could be characterized as using proper technique, while 13% of the trials were completed using improper techniques. For the eight occurrences of improper doffing, seven were performed by grasping the filtering surface of the FFR, while one was conducted by grasping the straps near the location where the straps attach to the FFR. There was no significant difference in occurrence of proper doffing of FFRs with tabs compared to FFRs without tabs (p = 0.4795).

In total, 35% of subjects (n = 20) felt that the respirator with tabs was easier to remove, 10% felt that the respirator without tabs was easier to remove, and 55% of subjects felt that there was no difference in removing each of the respirators. In terms of overall discomfort experienced by the wearer, 80% of the subjects did not experience any discomfort during respirator use; two subjects felt they experienced discomfort using a respirator with tabs, one subject felt there was discomfort using a respirator without tabs, and only one subject reported discomfort in using both types of respirators. Seven of eight subjects, including 5 of the 6 HCWs, that used tabs to properly doff the FFRs, indicated that the FFRs with tabs were easier to remove (p = 0.0387). Of the subjects that felt doffing an FFR with tabs was easier, 86% were females with long hair. The survey questionnaire and results are outlined in Table 1 .

For the 10 trials involving the proper doffing of FFRs with contaminated hands (examining the transfer from hands to the head), 100% of subjects transferred contamination to the head, face, and/or hair areas when FFRs without tabs were used. In contrast, for the 10 trials involving the proper doffing of FFRs with contaminated hands, only 30% of subjects transferred contamination to the head or hair when FFRs with tabs were used. As shown in Figure 3 , the average intensity of the amount of fluorescent contamination measured was significantly reduced (p = 0.0002) when tabs were used (55.19 lumens) compared to when not used (97.12 lumens).

In this study we assessed the utility of tabs attached to the straps of FFRs to provide an easily accessible ""handle"" to allow HCWs to remove the FFR without touching the contaminated filtering surface while minimizing contact with their hair.

We originally proposed to solely test HCWs as they should be accustomed to the protocols and special techniques required to doff FFRs due to the potential contact with infectious pathogens on the filtering surface. However, we were not able to recruit the proposed number of HCWs, thus the testing protocol was amended and approved to allow non-HCWs to participate. The subject pool did consist of 5 males and 15 females, a ratio that accurately reflects the reported healthcare gender distribution. [29] A broader pool of human subject recruits subsequently required a brief training and education session on proper donning and doffing techniques prior to the start of the tests. This factor, along with the absence of typical workplace distractions, may have influenced the rate in which the FFRs were doffed properly (85%), and may not be indicative of what is seen in a healthcare setting, where adherence has been reported at only 43% (respirators were doffed using the straps correctly). [6] The observed high adherence rate to proper doffing technique experienced in this study cannot properly discern the value of the tabs in increasing compliance to proper doffing; however, it demonstrates the value of timely education and training prior to the use of an N95 FFR.

The tabs were created as an extension of the tethering straps to allow the user to more easily locate and grasp the FFR at the back of the head without coincidentally grabbing their hair, thus causing discomfort. Specific mentions of discomfort associated with the straps getting entangled in the hair or inadvertent pulling of the hair when doffing was not an issue identified by the subjects; therefore, the effect on comfort could not be determined. As for ease of doffing, a cursory view of the results suggests that the tabs on the FFR straps did not make doffing easier as most subjects indicated that there was no noticeable difference between the FFRs with tabs and the FFRs without tabs (Table 1) . However, all but one of the subjects that used the tabs to doff the FFRs found the tabs to be easier to use (Table 1) . Furthermore, the results indicate that the use of tabs may be more helpful in cases of longer hair. As only 8 of the 20 subjects used the tabs, it can be concluded that the use of the tabs to doff FFRs was not intuitive, but as with all PPE and new technologies, training and education are imperative to improve compliance and proper use.

There is a high potential for the hands to become contaminated before removing the FFR. Hands can become contaminated while administering patient care in the event that a HCW is not using gloves. [30] [31] [32] [33] Even if HCWs are protecting their hands with the use of gloves, the sequence of proper PPE doffing (Figure 1 ) dictates that the FFR or mask is the last piece of PPE to be removed. If the hands do become contaminated during the process of PPE doffing, it is easy to remove potential infectious organisms by performing hand hygiene. In fact, the updated CDC recommended procedure and sequence for PPE removal states to ""perform hand hygiene between steps if hands become contaminated and immediately after removing all PPE."" [16] Proper hand hygiene compliance in healthcare settings is deficient. [34] Moreover, if pathogens are unknowingly transferred to the head or neck region of the HCW, removal of the pathogens would not occur until the HCW presumably showers after his or her shift. During the time between contamination and contamination removal, the HCW's head and hair serve as a source of pathogens for further transmission. Using the tabs to doff FFRs reduces the contact between the hands and the hair and head of the wearer, thus minimizing the potential for contact transmission. The tabs did not prohibit all contact between the hands and the hair and head of the subject, especially in cases where the subject's hair was long or curly; however, proper training and perhaps improved tab design can increase the protective efficacy of the tabs.

Subsequent to the onset of this investigation, a Grand Challenge Partnership (Fighting Ebola: A Grand Challenge for Development) was launched to help HCW provide safe and efficient care to affected individuals and to prevent further spread of the Ebola virus in West Africa. Some of the innovations resulting from the Grand Challenge employed tabs on various forms of PPE as a way to promote easier doffing. [35] 

The results of this investigation provide an initial assessment of tabs placed on PPE, particularly FFRs as a means to increase proper doffing technique thereby limiting selfcontamination, make PPE more comfortable to use, and reduce contamination transfer from PPE to the wearer even when proper doffing techniques are used. The use of the tabs was not intuitive and it could be concluded that the tabs had little influence in promoting proper doffing technique during this study. However, the tabs did make doffing easier and limited contamination transfer from hands to the head and neck areas when proper techniques were used. 

",0.7117683465036582
Health care workers' perceptions of respiratory and gastrointestinal algorithms for patient management in emergency care settings,"Background: Patients with respiratory or gastrointestinal illness in emergency care settings are often not yet diagnosed but are at risk of transmitting disease. Infection control algorithms delineating a standard approach to patient management decrease risk of secondary exposure, but few articles document health care workers' (HCWs) perceptions as to their effectiveness and ease of implementation. Methods: A cross-sectional survey approach was used to explore HCWs perceptions in 2 emergency departments of the current algorithms for management of potentially infectious respiratory and gastrointestinal illnesses. Results: Surveys from 96 HCWs revealed that algorithms were perceived as invaluable in protecting staff, patients, and colleagues. Differences in self-reported compliance, clarity, and ease of implementation of the respiratory algorithm were noted between facilities, likely reflecting variation in the physical plant. Physicians scored significantly lower for compliance with the respiratory algorithm. Conclusion: Algorithms were perceived to offer a clear and consistent approach to patient management and protect HCWs in spite of environmental and resource limitations.","Health care workers' perceptions of respiratory and gastrointestinal algorithms for patient management in emergency care settings Patients presenting with respiratory or gastrointestinal illness in emergency care settings are often not yet diagnosed but are potentially capable of transmitting disease. The potential for transmission increases when infection control measures for the early recognition and management of potentially infectious illnesses are not consistently used at the first point of contact. Infection control algorithms delineating a standard approach to managing patients with suspected communicable infections have been developed to decrease this risk of secondary exposure. [1] [2] [3] Written policies were revised and implemented by a multidisciplinary team (infection control, occupational health, emergency, and intensive care unit staff) for the immediate management of patients with respiratory

illness not yet diagnosed in 2003 at Vancouver General Hospital (VGH) and 2006 at Lions Gate Hospital (LGH). A separate algorithm for gastrointestinal (GI) illness was introduced in 2005 at VGH and 2006 at LGH. These administrative controls outline symptoms of potentially communicable respiratory or GI illness, the procedure to request engineering controls (eg, negative pressure room, dedicated commode), elements for communication with infection control, isolation precautions for patients, restrictions for staff and visitors, and requirements for environmental cleaning.

Previous efforts had assessed compliance to specific personal protective equipment elements included in the respiratory and GI algorithms. 4, 5 This study evaluated health care workers' (HCWs) perceptions and self-reported compliance to the algorithms. HCWs were asked their opinions as to the extent to which the algorithms were being used. Compliance, clarity, ease of implementation, and value of the algorithms were also assessed.

A cross-sectional survey approach was used to explore perceptions of HCWs in emergency departments of 2 acute care facilities in the province of British Columbia, Canada. VGH is a 955-bed, adult, tertiary care teaching hospital, offering 24-hour emergency services to residents from across British Columbia. As of July 2007, renovations to the VGH emergency department increased the number of patient beds from 22 to 28 and improved isolation capabilities with sliding doors between most beds. LGH, a 335-bed community hospital, also providing 24-hour emergency services, was renovating the emergency department during the survey and temporarily was without negative pressure ventilation (NPV) or isolation rooms.

Surveys were distributed by hand to a total of 150 HCWs based on the relative size of the 2 departments (100 at VGH, 50 at LGH) during the month of July 2008. The algorithms (available by e-mailing request to Elizabeth.Bryce@vch.ca) were deliberately not attached to assess unprompted knowledge. Respondents were asked to report the extent of agreement with statements about use, compliance, clarity, ease of implementation, and value of the respiratory and GI algorithms on 5point Likert scales. The survey instrument was anonymous to ensure confidentiality and took approximately 5 to 10 minutes to complete. Prospective respondents were provided with a coffee card as an incentive.

Standard descriptive statistics (eg, frequency, percentage) were employed to characterize the study population (data not shown). Occupations of respondents were grouped to facilitate analyses: ''Other Clinical'' includes resident care aide (RCA), registered respiratory therapist (RRT), licensed practical nurse (LPN), emergency response professional (ERP), and ward aide; ''Other Non-Clinical'' includes clerk, nursing unit assistant, patient care coordinator (PCC), and student. Statements marked ''not applicable'' by respondents were considered as missing values.

Frequencies and percentage distribution of algorithm use per shift were tabulated for each algorithm (Table 1) . Global mean scores were calculated for compliance, clarity, ease of implementation, and ability to protect ( Table 2 ). These were compared between facilities using independent samples t test, occupation groups using nonparametric Kruskal Wallis test, and groups of experience using ANOVA. For significant dependent variables, post hoc multiple comparisons were computed with the Mann-Whitney U test for occupation groups and Bonferroni test for groups of experience. Descriptive statistics for individual items relating to compliance, clarity, ease of implementation, and ability to protect were computed for each algorithm (Tables  3 and 4 ). Selected post hoc comparisons were computed for independent variables deemed significant in the global mean score analysis (results not shown). Qualitative comments provided were categorized into themes. All tests were carried out using Statistical Package for the Social Sciences SPSS 14.0 (SPSS, Inc, Chicago, IL) with 2-sided significance levels of P # .05.

A total of 96 of 150 surveys (64%) was returned, of which 53 (53%) were from VGH and 43 (86%) from LGH. Occupation groups were representative of the population studied: registered nurses (RNs) (70.5%), medical physicians/residents (MDs) (9.5%), other clinical staff (11.6%), and other non-clinical staff (8.4%). In terms of experience, respondents reported means of 11.3 years in health care, 7.4 years at their facility, and 5.1 years in the emergency department. Most (80%) respondents worked both day and night shifts; the remaining 20% worked day shifts only. The minimum number of shifts per week was 2, with 75% working more than 3.5 shifts per week (full-time equivalency). Table 1 shows distributions between expected and actual use of the respiratory and GI algorithms. During a MDs scored significantly lower for respiratory algorithm compliance (P 5 .033 compared with RNs, P 5 .023 compared with other clinical staff), respiratory algorithm ability to protect (P 5 .005 compared with RNs, P 5 .012 compared with non-clinical staff), and GI algorithm ability to protect (P 5 .007 compared with RNs, P 5 .020 compared with non-clinical staff). For respiratory algorithm compliance, those with 101 years in health care scored higher than those with ,5 (P 5 .002) or 5-9 years (P 5 .003). For respiratory algorithm clarity, those with 101 years in health care scored higher than those with 5-9 years (P 5 .041). Ten1 years at facility scored higher than ,2 years for respiratory algorithm compliance (P 5 .020) and clarity (P 5 .026). Less than 2 years in the emergency department scored lower than those with 2-9 years for GI compliance (P 5 .022) and respiratory algorithm ability to protect (P 5 .019). Those with 101 years in the emergency department scored lower than those with 2-9 years for GI ability to protect (P 5 0.17).

typical shift, 73% of respondents reported that between 1 and 5 patients fit criteria for use of the respiratory algorithm; 75.6% reported 1 to 5 actual applications of the respiratory algorithm. For the GI algorithm, 68.2% reported 1 to 5 eligible patients; 72.7% reported that the GI algorithm was applied 1 to 5 times.

Comparison of global mean scores Table 2 displays comparison of global mean scores for compliance, clarity, ease of implementation, and ability to protect for both respiratory and GI algorithms across independent variables (facilities, occupation groups, and groups of experience). For both respiratory and GI algorithms, global mean scores for compliance (3.3 and 3.5, respectively), clarity (3.5 and 3.7, respectively), and ease of implementation (3.5 and 3.8, respectively) were achieved. Respondents' global mean scores for ''ability to protect'' were 4.6 and 4.7, respectively, for the respiratory and GI algorithms. Differences for compliance (P 5 .001), clarity (P 5 .03), and ease of implementation (P 5 .001) of the respiratory algorithm were observed between facilities, with VGH showing significantly higher scores. Generally, those with more than 10 years experience in health care and at their facility scored significantly higher for respiratory algorithm compliance and clarity compared with those with less experience. Physicians scored significantly lower for respiratory algorithm compliance (P 5 .03 compared with RNs, P 5 .02 compared with other clinical staff), respiratory algorithm ability to protect (P 5 .005 compared with RNs), and GI algorithm ability to protect (P 5 .007 compared with RNs, P 5 .020 for non-clinical staff). Table 3 displays means of individual items evaluating the respiratory algorithm. Less than neutral scores for individual items of compliance were as follows: ''patient admitted to NPV room,'' ''HCW wears surgical mask,'' and ''HCW wears protective eyewear.'' All other items received neutral or above neutral scores, with the exception of ''HCW cleans hands after caring for patient'' (4.8/5), which was strongly positive. It should be noted that the item ''HCW wears surgical mask'' was included as a negative control; low scores were expected because HCWs are taught to use a N95 respirator at first patient contact, indicating that respondents were reading each statement and responding appropriately. Compared with LGH, VGH scored significantly higher for ''patient admitted to NPV room'' (P , .001) and ''HCW wears N95 respirator'' (P , .001) (data not shown); the former was expected, given the status of renovations at LGH. Means for all individual items evaluating ''ability to protect'' and ''facility commitment to GI algorithm Table 4 displays means of individual items evaluating the GI algorithm. In terms of compliance, mean scores of 2 items scored below neutral: ''patient admitted to a single room'' (2.81) and ''dedicated commode/ bathroom provided'' (2.92). The lowest mean score for ease of implementation was 3.22-''use of single room/ dedicated commode.'' Respondents rated the GI algorithm's ''ability to protect'' and ''facility commitment to safety'' positively, with scores ranging between 4.48 and 4.75. Both algorithms rated strongly positive for ability to assess and treat patients consistently.

Of the 96 respondents, 53 (55.2%) provided unprompted comments. Themes were extracted from the responses and coded into the following categories: lack of engineering controls/equipment (n 5 14); increasing awareness/visibility of the algorithms (n 5 12); safety culture/compliance (n 5 11); working with physicians (n 5 7); and about the survey itself (n 5 3).

Literature suggests that HCWs are more likely to adhere to infection control protocols when the diagnosis is known, yet a definitive answer on admission to emergency is uncommon. 6 Recent experiences with severe acute respiratory syndrome emphasized the need to consistently apply preventive measures based on clinical presentation at the time of admission. Factors influencing utilization of recommended practices include (1) organizational norms and safety climate and (2) individual practices, perceptions, and beliefs, which often vary among occupational groups. 7, 8 This study assessed HCWs perceptions of the utility and ability to comply with respiratory and GI infection control management algorithms at the time of initial patient presentation to emergency.

An overall response rate of 64% in our survey suggests that results were likely representative of HCWs in the emergency departments surveyed. RNs were most represented (70.5%) as expected, but, importantly, physicians were almost 10% of respondents, which reflected the occupational distribution in the departments. Most respondents had considerable experience, worked both day and night shifts, and worked full-time equivalents. HCWs reported an agreement between expected and actual use of the respiratory and GI algorithms. That is, the algorithms were applied to 1 to 5 patients per shift, which was also the number of eligible patients. Considering that 75% of respondents worked a minimum of 3.5 shifts per week, it seems plausible that each algorithm might be used up to 70 times per week (2 shifts per day, 7 days per week). The observations are also supported by a previous study at VGH, in which 86.5% of emergency department HCWs reported wearing a respirator from 1 to 10 times/shift. 4 Strongly positive global mean scores indicate that HCWs perceive the algorithms as clear and invaluable tools for consistently managing patients with potentially transmissible illnesses. This is supported by the qualitative data: ''The algorithms are [an] excellent resource/guide for triage-treatment of patients presenting symptoms of GI and respiratory infections.'' Several respondents provided comments helpful for improving visibility of the algorithms. These suggestions include laminated fact sheets for triage clipboards, posting laminated hard copies of the algorithms, and increasing visibility on the regional infection control intranet site.

Most items evaluating compliance and ease of implementation scored positively. This differs with results from an international review of 37 studies, which describes compliance to infection control precautions as suboptimal. 9 Previous experience with severe acute respiratory syndrome and local background rates of tuberculosis are likely 2 driving factors for the increased awareness and compliance by HCWs in our 2 facilities.

Low and neutral scores reflected constraints in the physical plant design, perceived restricted access to personal protective equipment, and limited availability of commodes similar to that found in a United Kingdom study of emergency department resources. 10 This was supported by HCW comments, eg,''not enough resources to treat patients consistently, ie, rooms, commodes, isolation.'' Low scores for compliance and ease of implementation of using NPV rooms and N95 respirators were particularly evident at LGH. The former reflected the state of renovations at the time of the survey. Reported differences between VGH and LGH regarding N95 respirator use likely reflect a difference in organizational culture rather than resource availability; the algorithms had been in place for approximately 1 year at LGH compared with 5 years at VGH, and a previous audit documented that respirators were accessible at all sites. 5 The challenge of adhering to guidelines regarding commode use as it pertains to the GI algorithm was illustrated in the following statement and reflected inadequate resources. ''Sometimes it is difficult to have a designated commode at the bedside due to not having enough commodes at the bedside. Often times we have to wipe down commodes aggressively so the next patient can have a disinfected commode.'' Compared with other HCWs, physicians reported lower compliance with the respiratory algorithm and scored lower on their perception that the algorithms protected either staff or patients. This contrasts with results from a survey conducted by Virginia Commonwealth University, in which physicians reported significantly better compliance with hand hygiene, contact precautions, and airborne precautions compared with other occupations. 6 Results were explained by different motives for compliance: RNs were motivated by patient safety more than personal safety, whereas physicians reported personal safety as more of a motivating factor. 6 Our findings showed that personal and patient safety were both strong motivating factors for all occupations.

Working effectively with physicians was conveyed qualitatively: ''[Algorithms are] too often ignored by physicians, which seems to often set the stage for all others caring for patients.

[Algorithms] need consistent implementation by everyone.'' Physicians act as role models to other professionals in the delivery of patient care, and their compliance with institutional policy is critical in ensuring success of implementation. 11 Importantly, all agreed that the algorithms provided staff with the tools to consistently manage patients while protecting others.

There were limitations to the study. First, the difference in response rates between facilities and occupation groups might have led to disproportionate representation in the results presented. Second, the cross-sectional survey method only evaluates perceptions at 1 point in time, and results are entirely self-reported. Despite these limitations, quantitative and qualitative data presented from the perspective of the algorithms' end-users help identify specific recommendations for improvements to patient safety and occupational health. Further studies may consider incorporating objective outcome measures to accurately estimate use and compliance.

The current study advances knowledge surrounding HCWs perceptions of organizational-specific guidelines for managing patients with suspected communicable respiratory and GI illnesses in emergency departments. Our findings suggest that workers believe that algorithms offer a clear and consistent approach to patient management. Importantly, HCWs feel that algorithms are invaluable in protecting patients and colleagues in spite of environmental and resource limitations.

",0.7115569571512254
